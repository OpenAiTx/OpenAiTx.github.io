<!DOCTYPE html>
<html lang="pt">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mapperatorinator - Uma estrutura de IA para gerar e modificar mapas de ritmo do osu! para todos os modos de jogo a partir de entradas de espectrograma.</title>
    <meta name="description" content="Uma estrutura de IA para gerar e modificar mapas de ritmo do osu! para todos os modos de jogo a partir de entradas de espectrograma.">
    <meta name="keywords" content="Mapperatorinator, Portuguese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "Mapperatorinator",
  "description": "Uma estrutura de IA para gerar e modificar mapas de ritmo do osu! para todos os modos de jogo a partir de entradas de espectrograma.",
  "author": {
    "@type": "Person",
    "name": "OliBomby"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 398
  },
  "url": "https://OpenAiTx.github.io/projects/OliBomby/Mapperatorinator/README-pt.html",
  "sameAs": "https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/README.md",
  "datePublished": "2026-01-24",
  "dateModified": "2026-01-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/OliBomby/Mapperatorinator" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    Mapperatorinator
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 398 stars</span>
                <span class="language">Portuguese</span>
                <span>by OliBomby</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Idioma</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=id">Bahasa Indonesia</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=as">অসমীয়া</
      </div>
    </div>
  </details>
</div></p><h1>Mapperatorinator</h1></p><p>Experimente o modelo generativo <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mapperatorinator_inference.ipynb" target="_blank" rel="noopener noreferrer">aqui</a>, ou o MaiMod <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mai_mod_inference.ipynb" target="_blank" rel="noopener noreferrer">aqui</a>. Veja uma demonstração em vídeo <a href="https://youtu.be/FEr7t1L2EoA" target="_blank" rel="noopener noreferrer">aqui</a>.</p><p>Mapperatorinator é uma estrutura multi-modelo que utiliza entradas de espectrograma para gerar mapas de osu! completos para todos os modos de jogo e <a href="#maimod-the-ai-driven-modding-tool" target="_blank" rel="noopener noreferrer">auxiliar na moderação de mapas</a>.
O objetivo deste projeto é gerar automaticamente mapas de osu! com qualidade rankeável a partir de qualquer música, com alto grau de personalização.</p><p>Este projeto é baseado em <a href="https://github.com/gyataro/osuT5" target="_blank" rel="noopener noreferrer">osuT5</a> e <a href="https://github.com/OliBomby/osu-diffusion" target="_blank" rel="noopener noreferrer">osu-diffusion</a>. No desenvolvimento, gastei cerca de 2500 horas de processamento de GPU em 142 execuções na minha 4060 Ti e aluguei instâncias 4090 na vast.ai.</p><p>#### Use esta ferramenta de forma responsável. Sempre divulgue o uso de IA em seus beatmaps.</p><h2>Instalação</h2></p><p>A instrução abaixo permite que você gere beatmaps em sua máquina local, alternativamente você pode executá-la na nuvem com o <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mapperatorinator_inference.ipynb" target="_blank" rel="noopener noreferrer">notebook do colab</a>.</p><h3>1. Clone o repositório</h3></p><pre><code class="language-sh">git clone https://github.com/OliBomby/Mapperatorinator.git
cd Mapperatorinator</code></pre></p><h3>2. (Opcional) Crie um ambiente virtual</h3></p><p>Use Python 3.10, versões posteriores podem não ser compatíveis com as dependências.</p><pre><code class="language-sh">python -m venv .venv</p><h1>In cmd.exe</h1>
.venv\Scripts\activate.bat
<h1>In PowerShell</h1>
.venv\Scripts\Activate.ps1
<h1>In Linux or MacOS</h1>
source .venv/bin/activate</code></pre></p><h3>3. Instale as dependências</h3></p><ul><li>Python 3.10</li>
<li><a href="https://git-scm.com/downloads" target="_blank" rel="noopener noreferrer">Git</a></li>
<li><a href="http://www.ffmpeg.org/" target="_blank" rel="noopener noreferrer">ffmpeg</a></li>
<li><a href="https://developer.nvidia.com/cuda-zone" target="_blank" rel="noopener noreferrer">CUDA</a> (Para GPUs NVIDIA) ou <a href="https://rocmdocs.amd.com/en/latest/Installation_Guide/Installation-Guide.html" target="_blank" rel="noopener noreferrer">ROCm</a> (Para GPUs AMD no Linux)</li>
<li><a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">PyTorch</a>: Certifique-se de seguir o guia Get Started para instalar <code>torch</code> e <code>torchaudio</code> com suporte a GPU. Selecione a versão correta da Plataforma de Computação que você instalou na etapa anterior.</li></p><p><li>e as demais dependências Python:</li></p><p></ul><pre><code class="language-sh">pip install -r requirements.txt</code></pre></p><h2>Interface Web (Recomendado)</h2></p><p>Para uma experiência mais amigável, considere usar a interface Web. Ela fornece uma interface gráfica para configurar os parâmetros de geração, iniciar o processo e monitorar a saída.</p><h3>Iniciar a GUI</h3></p><p>Navegue até o diretório clonado <code>Mapperatorinator</code> no seu terminal e execute:</p><pre><code class="language-sh">python web-ui.py</code></pre>
Isso iniciará um servidor web local e abrirá automaticamente a interface em uma nova janela.</p><h3>Usando a GUI</h3></p><ul><li><strong>Configurar:</strong> Defina os caminhos de entrada/saída usando os campos do formulário e os botões "Procurar". Ajuste os parâmetros de geração como modo de jogo, dificuldade, estilo (ano, ID do mapeador, descritores), tempo, recursos específicos (hitsounds, super timing) e mais, espelhando as opções da linha de comando. (Nota: Se você fornecer um <code>beatmap_path</code>, a interface determinará automaticamente o <code>audio_path</code> e o <code>output_path</code> a partir dele, então você pode deixar esses campos em branco)</li>
<li><strong>Iniciar:</strong> Clique no botão "Iniciar Inferência" para começar a geração do beatmap.</li>
<li><strong>Cancelar:</strong> Você pode interromper o processo em andamento usando o botão "Cancelar Inferência".</li>
<li><strong>Abrir Saída:</strong> Quando finalizar, use o botão "Abrir Pasta de Saída" para acessar rapidamente os arquivos gerados.</li></p><p></ul>A interface web atua como um wrapper conveniente em torno do script <code>inference.py</code>. Para opções avançadas ou resolução de problemas, consulte as instruções da linha de comando.</p><p><img src="https://github.com/user-attachments/assets/5312a45f-d51c-4b37-9389-da3258ddd0a1" alt="python_u3zyW0S3Vs"></p><h2>Inferência pela Linha de Comando</h2></p><p>Para usuários que preferem a linha de comando ou precisam acessar configurações avançadas, siga os passos abaixo. <strong>Nota:</strong> Para uma interface gráfica mais simples, consulte a seção <a href="#web-ui-recommended" target="_blank" rel="noopener noreferrer">Web UI (Recomendado)</a> acima.</p><p>Execute <code>inference.py</code> e passe alguns argumentos para gerar beatmaps. Para isso, use a <a href="https://hydra.cc/docs/advanced/override_grammar/basic/" target="_blank" rel="noopener noreferrer">sintaxe de override do Hydra</a>. Veja <code>configs/inference_v29.yaml</code> para todos os parâmetros disponíveis.</p><pre><code class="language-">python inference.py \
  audio_path           [Path to input audio] \
  output_path          [Path to output directory] \
  beatmap_path         [Path to .osu file to autofill metadata, and output_path, or use as reference] \
  
  gamemode             [Game mode to generate 0=std, 1=taiko, 2=ctb, 3=mania] \
  difficulty           [Difficulty star rating to generate] \
  mapper_id            [Mapper user ID for style] \
  year                 [Upload year to simulate] \
  hitsounded           [Whether to add hitsounds] \
  slider_multiplier    [Slider velocity multiplier] \
  circle_size          [Circle size] \
  keycount             [Key count for mania] \
  hold_note_ratio      [Hold note ratio for mania 0-1] \
  scroll_speed_ratio   [Scroll speed ratio for mania and ctb 0-1] \
  descriptors          [List of beatmap user tags for style] \
  negative_descriptors [List of beatmap user tags for classifier-free guidance] \
  
  add_to_beatmap       [Whether to add generated content to the reference beatmap instead of making a new beatmap] \
  start_time           [Generation start time in milliseconds] \
  end_time             [Generation end time in milliseconds] \
  in_context           [List of additional context to provide to the model [NONE,TIMING,KIAI,MAP,GD,NO_HS]] \
  output_type          [List of content types to generate] \
  cfg_scale            [Scale of the classifier-free guidance] \
  super_timing         [Whether to use slow accurate variable BPM timing generator] \
  seed                 [Random seed for generation] \</code></pre></p><p>Exemplo:
<pre><code class="language-">python inference.py beatmap_path="'C:\Users\USER\AppData\Local\osu!\Songs\1 Kenji Ninuma - DISCO PRINCE\Kenji Ninuma - DISCOPRINCE (peppy) [Normal].osu'" gamemode=0 difficulty=5.5 year=2023 descriptors="['jump aim','clean']" in_context=[TIMING,KIAI]</code></pre></p><h2>CLI Interativo</h2>
Para quem prefere um fluxo de trabalho baseado em terminal, mas deseja uma configuração guiada, o script CLI interativo é uma excelente alternativa à interface web.</p><h3>Iniciar o CLI</h3>
Navegue até o diretório clonado. Você pode precisar tornar o script executável primeiro.</p><pre><code class="language-sh"># Make the script executable (only needs to be done once)
chmod +x cli_inference.sh</code></pre></p><pre><code class="language-sh"># Run the script
./cli_inference.sh</code></pre></p><h3>Usando o CLI</h3>
O script irá guiá-lo por uma série de prompts para configurar todos os parâmetros de geração, assim como a interface Web.</p><p>Ele utiliza uma interface com código de cores para maior clareza.
Oferece um menu avançado de múltipla seleção para escolher os descritores de estilo usando as teclas de seta e barra de espaço.
Após responder todas as perguntas, exibirá o comando final para sua revisão.
Você pode então confirmar para executá-lo diretamente ou cancelar e copiar o comando para uso manual.</p><h2>Dicas de Geração</h2></p><ul><li>Você pode editar o arquivo <code>configs/inference_v29.yaml</code> e adicionar seus argumentos lá ao invés de digitá-los no terminal toda vez.</li>
<li>Todos os descritores disponíveis podem ser encontrados <a href="https://osu.ppy.sh/wiki/en/Beatmap/Beatmap_tags" target="_blank" rel="noopener noreferrer">aqui</a>.</li>
<li>Sempre forneça um argumento de ano entre 2007 e 2023. Se deixar desconhecido, o modelo pode gerar com um estilo inconsistente.</li>
<li>Sempre forneça um argumento de dificuldade. Se deixar desconhecido, o modelo pode gerar com uma dificuldade inconsistente.</li>
<li>Aumente o parâmetro <code>cfg_scale</code> para aumentar a efetividade dos argumentos <code>mapper_id</code> e <code>descriptors</code>.</li>
<li>Você pode usar o argumento <code>negative_descriptors</code> para direcionar o modelo a evitar certos estilos. Isso só funciona quando <code>cfg_scale > 1</code>. Certifique-se de que o número de descritores negativos seja igual ao número de descritores.</li>
<li>Se o estilo da sua música e o estilo de beatmap desejado não combinarem bem, o modelo pode não seguir suas direções. Por exemplo, é difícil gerar um beatmap de SR alto e SV alto para uma música calma.</li>
<li>Se você já tem timing e kiai times prontos para uma música, pode fornecê-los ao modelo para aumentar muito a velocidade e precisão da inferência: Use os argumentos <code>beatmap_path</code> e <code>in_context=[TIMING,KIAI]</code>.</li>
<li>Para remapear apenas uma parte do seu beatmap, use os argumentos <code>beatmap_path</code>, <code>start_time</code>, <code>end_time</code>, e <code>add_to_beatmap=true</code>.</li>
<li>Para gerar uma dificuldade guest para um beatmap, use os argumentos <code>beatmap_path</code> e <code>in_context=[GD,TIMING,KIAI]</code>.</li>
<li>Para gerar hitsounds para um beatmap, use os argumentos <code>beatmap_path</code> e <code>in_context=[NO_HS,TIMING,KIAI]</code>.</li>
<li>Para gerar apenas o timing para uma música, use os argumentos <code>super_timing=true</code> e <code>output_type=[TIMING]</code>.</li></p><p></ul><h2>MaiMod: A Ferramenta de Modding com IA</h2></p><p>MaiMod é uma ferramenta de modding para beatmaps do osu! que utiliza previsões do Mapperatorinator para encontrar possíveis falhas e inconsistências que não podem ser detectadas por outras ferramentas automáticas de modding como a <a href="https://github.com/Naxesss/MapsetVerifier" target="_blank" rel="noopener noreferrer">Mapset Verifier</a>.
Ela pode detectar problemas como:
<ul><li>Snapping incorreto ou padrões rítmicos inconsistentes</li>
<li>Pontos de timing imprecisos</li>
<li>Posições inconsistentes de hit objects ou placements de new combo</li>
<li>Formatos estranhos de sliders</li>
<li>Hitsounds ou volumes inconsistentes</li></p><p></ul>Você pode experimentar o MaiMod <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mai_mod_inference.ipynb" target="_blank" rel="noopener noreferrer">aqui</a>, ou executá-lo localmente:
Para executar o MaiMod localmente, será necessário instalar o Mapperatorinator. Depois, execute o script <code>mai_mod.py</code>, especificando o caminho do seu beatmap com o argumento <code>beatmap_path</code>.
<pre><code class="language-sh">python mai_mod.py beatmap_path="'C:\Users\USER\AppData\Local\osu!\Songs\1 Kenji Ninuma - DISCO PRINCE\Kenji Ninuma - DISCOPRINCE (peppy) [Normal].osu'"</code></pre>
Isso imprimirá as sugestões de modding no console, que você poderá então aplicar manualmente ao seu beatmap.
As sugestões são ordenadas cronologicamente e agrupadas em categorias.
O primeiro valor no círculo indica o 'surprisal', que é uma medida de quão inesperado o modelo considerou o problema, para que você possa priorizar as questões mais importantes.</p><p>O modelo pode cometer erros, especialmente em questões de baixo surprisal, então sempre confira as sugestões antes de aplicá-las ao seu beatmap.
O objetivo principal é ajudá-lo a reduzir o espaço de busca por possíveis problemas, para que você não precise verificar manualmente cada objeto de hit no seu beatmap.</p><h3>MaiMod GUI</h3>
Para executar a interface web do MaiMod, você precisará instalar o Mapperatorinator.
Em seguida, execute o script <code>mai_mod_ui.py</code>. Isso iniciará um servidor web local e abrirá automaticamente a interface em uma nova janela:</p><pre><code class="language-sh">python mai_mod_ui.py</code></pre></p><p><img width="850" height="1019" alt="afbeelding" src="https://github.com/user-attachments/assets/67c03a43-a7bd-4265-a5b1-5e4d62aca1fa" /></p><h2>Visão Geral</h2></p><h3>Tokenização</h3></p><p>Mapperatorinator converte mapas de ritmo do osu! em uma representação intermediária de eventos que pode ser convertida diretamente para e de tokens.
Inclui objetos de acerto, sons de acerto, velocidades de slider, novos combos, pontos de tempo, tempos de kiai e velocidades de rolagem de taiko/mania.</p><p>Aqui está um pequeno exemplo do processo de tokenização:</p><p><img src="https://github.com/user-attachments/assets/84efde76-4c27-48a1-b8ce-beceddd9e695" alt="mapperatorinator_parser"></p><p>Para economizar no tamanho do vocabulário, os eventos de tempo são quantizados em intervalos de 10ms e as coordenadas de posição são quantizadas em pontos de grade de 32 pixels.</p><h3>Arquitetura do modelo</h3>
O modelo é basicamente um wrapper em torno do <a href="https://huggingface.co/docs/transformers/en/model_doc/whisper#transformers.WhisperForConditionalGeneration" target="_blank" rel="noopener noreferrer">HF Transformers Whisper</a>, com embeddings de entrada e função de perda personalizados.
O tamanho do modelo é de 219M parâmetros.
Este modelo foi considerado mais rápido e preciso do que o T5 para esta tarefa.</p><p>A visão geral de alto nível da entrada e saída do modelo é a seguinte:</p><p><img src="https://user-images.githubusercontent.com/28675590/201044116-1384ad72-c540-44db-a285-7319dd01caad.svg" alt="Picture2"></p><p>O modelo utiliza frames de espectrograma Mel como entrada do encoder, com um frame por posição de entrada. A saída do decoder do modelo em cada passo é uma distribuição softmax sobre um vocabulário discreto e predefinido de eventos. As saídas são esparsas, os eventos só são necessários quando um objeto de acerto ocorre, em vez de anotar cada frame de áudio.</p><h3>Formato de treinamento multitarefa</h3></p><p><img src="https://github.com/user-attachments/assets/62f490bc-a567-4671-a7ce-dbcc5f9cd6d9" alt="Multitask training format"></p><p>Antes do token SOS existem tokens adicionais que facilitam a geração condicional. Estes tokens incluem o modo de jogo, dificuldade, ID do mapeador, ano e outros metadados.
Durante o treinamento, esses tokens não possuem rótulos correspondentes, então nunca são emitidos pelo modelo.
Também durante o treinamento existe uma chance aleatória de um token de metadado ser substituído por um token 'desconhecido', assim durante a inferência podemos usar esses tokens 'desconhecidos' para reduzir a quantidade de metadados que precisamos fornecer ao modelo.</p><h3>Geração longa contínua</h3></p><p>O comprimento de contexto do modelo é de 8.192 segundos. Isso obviamente não é suficiente para gerar um mapa completo, então precisamos dividir a música em várias janelas e gerar o mapa em pequenas partes.
Para garantir que o mapa gerado não tenha costuras perceptíveis entre as janelas, usamos uma sobreposição de 90% e geramos as janelas sequencialmente.
Cada janela de geração, exceto a primeira, começa com o decoder pré-preenchido até 50% da janela de geração com tokens das janelas anteriores.
Usamos um processador de logit para garantir que o modelo não possa gerar tokens de tempo que estejam nos primeiros 50% da janela de geração.
Além disso, os últimos 40% da janela de geração são reservados para a próxima janela. Quaisquer tokens de tempo gerados nesse intervalo são tratados como tokens EOS.
Isso garante que cada token gerado seja condicionado a pelo menos 4 segundos de tokens anteriores e 3,3 segundos de áudio futuro a antecipar.</p><p>Para evitar o desvio de offset durante gerações longas, offsets aleatórios foram adicionados aos eventos de tempo no decodificador durante o treinamento.
Isso o obriga a corrigir erros de temporização ouvindo os onsets no áudio, resultando em um offset consistentemente preciso.</p><h3>Coordenadas refinadas com difusão</h3></p><p>As coordenadas de posição geradas pelo decodificador são quantizadas para pontos de grade de 32 pixels, então depois usamos difusão para remover o ruído das coordenadas até as posições finais.
Para isso, treinamos uma versão modificada do <a href="https://github.com/OliBomby/osu-diffusion" target="_blank" rel="noopener noreferrer">osu-diffusion</a> especializada apenas nos últimos 10% do cronograma de ruído, e aceita tokens de metadados mais avançados que o Mapperatorinator usa para geração condicional.</p><p>Como o modelo Mapperatorinator gera o SV dos sliders, o comprimento necessário do slider é fixo independentemente do formato do caminho dos pontos de controle.
Portanto, tentamos guiar o processo de difusão para criar coordenadas que se ajustem aos comprimentos necessários dos sliders.
Fazemos isso recalculando as posições finais do slider após cada etapa do processo de difusão com base no comprimento requerido e no caminho atual dos pontos de controle.
Isso significa que o processo de difusão não tem controle direto sobre as posições finais dos sliders, mas ainda pode influenciá-las alterando o caminho dos pontos de controle.</p><h3>Pós-processamento</h3></p><p>O Mapperatorinator faz um pós-processamento extra para melhorar a qualidade do beatmap gerado:</p><ul><li>Refinar coordenadas de posição com difusão.</li>
<li>Resnap de eventos de tempo para o tick mais próximo usando os divisores de snap gerados pelo modelo.</li>
<li>Ajustar sobreposições posicionais quase perfeitas.</li>
<li>Converter eventos de coluna mania em coordenadas X.</li>
<li>Gerar caminhos de slider para drumrolls de taiko.</li>
<li>Corrigir grandes discrepâncias entre comprimento necessário do slider e comprimento do caminho dos pontos de controle.</li></p><p></ul><h3>Super timing generator</h3></p><p>Super timing generator é um algoritmo que melhora a precisão e acurácia do tempo gerado inferindo o tempo de toda a música 20 vezes e fazendo a média dos resultados.
Isso é útil para músicas com BPM variável ou com mudanças de BPM. O resultado é quase perfeito, restando apenas por vezes uma seção que precisa de ajuste manual.</p><h2>Treinamento</h2></p><p>A instrução abaixo cria um ambiente de treinamento em sua máquina local.</p><h3>1. Clone o repositório</h3></p><pre><code class="language-sh">git clone https://github.com/OliBomby/Mapperatorinator.git
cd Mapperatorinator</code></pre></p><h3>2. Criar conjunto de dados</h3></p><p>Crie seu próprio conjunto de dados usando o <a href="https://github.com/mappingtools/Mapperator/blob/master/README.md#create-a-high-quality-dataset" target="_blank" rel="noopener noreferrer">aplicativo de console Mapperator</a>. Ele exige um <a href="https://osu.ppy.sh/home/account/edit" target="_blank" rel="noopener noreferrer">token de cliente OAuth do osu!</a> para verificar beatmaps e obter metadados adicionais. Coloque o conjunto de dados em um diretório <code>datasets</code> ao lado do diretório <code>Mapperatorinator</code>.</p><pre><code class="language-sh">Mapperator.ConsoleApp.exe dataset2 -t "/Mapperatorinator/datasets/beatmap_descriptors.csv" -i "path/to/osz/files" -o "/datasets/cool_dataset"</code></pre></p><h3>3. (Opcional) Configure o Weight & Biases para registro</h3>
Crie uma conta no <a href="https://wandb.ai/site" target="_blank" rel="noopener noreferrer">Weight & Biases</a> e obtenha sua chave de API nas configurações da sua conta.
Em seguida, defina a variável de ambiente <code>WANDB_API_KEY</code>, para que o processo de treinamento saiba registrar usando essa chave.</p><pre><code class="language-sh">export WANDB_API_KEY=<your_api_key></code></pre></p><h3>4. Criar contêiner Docker</h3>
Também é possível treinar no seu venv, mas recomendamos o uso do Docker no WSL para melhor desempenho.
<pre><code class="language-sh">docker compose up -d --force-recreate
docker attach mapperatorinator_space
cd Mapperatorinator</code></pre></p><h3>5. Configure parâmetros e inicie o treinamento</h3></p><p>Todas as configurações estão localizadas em <code>./configs/train/default.yaml</code>.
Certifique-se de definir corretamente os parâmetros <code>train_dataset_path</code> e <code>test_dataset_path</code> para o seu conjunto de dados, assim como os índices inicial e final do mapset para divisão de treino/teste.
O caminho é local para o container docker, então se você colocou seu conjunto de dados chamado <code>cool_dataset</code> no diretório <code>datasets</code>, ele deve ser <code>/workspace/datasets/cool_dataset</code>.</p><p>Recomendo criar um arquivo de configuração personalizado que substitua a configuração padrão, para que você tenha um registro da sua configuração de treinamento para reprodutibilidade.</p><pre><code class="language-yaml">data:
  train_dataset_path: "/workspace/datasets/cool_dataset"
  test_dataset_path: "/workspace/datasets/cool_dataset"
  train_dataset_start: 0
  train_dataset_end: 90
  test_dataset_start: 90
  test_dataset_end: 100</code></pre></p><p>Begin training by calling <code>python osuT5/train.py</code> or <code>torchrun --nproc_per_node=NUM_GPUS osuT5/train.py</code> for multi-GPU training.</p><pre><code class="language-sh">python osuT5/train.py -cn train_v29 train_dataset_path="/workspace/datasets/cool_dataset" test_dataset_path="/workspace/datasets/cool_dataset" train_dataset_end=90 test_dataset_start=90 test_dataset_end=100</code></pre></p><h3>6. Ajuste fino com LoRA</h3></p><p>Você também pode ajustar um modelo pré-treinado com <a href="https://arxiv.org/abs/2106.09685" target="_blank" rel="noopener noreferrer">LoRA</a> para adaptá-lo a um estilo ou modo de jogo específico.
Para isso, adapte <code>configs/train/lora.yaml</code> conforme suas necessidades e execute a configuração de treinamento <code>lora</code>:</p><pre><code class="language-sh">python osuT5/train.py -cn lora train_dataset_path="/workspace/datasets/cool_dataset" test_dataset_path="/workspace/datasets/cool_dataset" train_dataset_end=90 test_dataset_start=90 test_dataset_end=100</code></pre>
Parâmetros importantes do LoRA a considerar:
<ul><li><code>pretrained_path</code>: Caminho ou repositório HF do modelo base para ajuste fino.</li>
<li><code>r</code>: Rank das matrizes LoRA. Valores maiores aumentam a capacidade do modelo, mas também o uso de memória.</li>
<li><code>lora_alpha</code>: Fator de escala para as atualizações do LoRA.</li>
<li><code>total_steps</code>: Número total de passos de treinamento. Equilibre isso de acordo com o tamanho do seu conjunto de dados.</li>
<li><code>enable_lora</code>: Se deve usar LoRA ou ajuste fino do modelo completo.</li></p><p></ul>Durante a inferência, você pode especificar os pesos do LoRA a serem usados com o argumento <code>lora_path</code>.
Isto pode ser um caminho local ou um repositório do Hugging Face.</p><h2>Veja também</h2>
<ul><li><a href="https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/./classifier/README.md" target="_blank" rel="noopener noreferrer">Mapper Classifier</a></li>
<li><a href="https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/./rcomplexion/README.md" target="_blank" rel="noopener noreferrer">RComplexion</a></li></p><p></ul><h2>Créditos</h2></p><p>Agradecimentos especiais a:
<ul><li>Os autores do <a href="https://github.com/gyataro/osuT5" target="_blank" rel="noopener noreferrer">osuT5</a> pelo código de treinamento.</li>
<li>Equipe do Hugging Face por suas <a href="https://huggingface.co/docs/transformers/index" target="_blank" rel="noopener noreferrer">ferramentas</a>.</li>
<li><a href="https://github.com/jaswon" target="_blank" rel="noopener noreferrer">Jason Won</a> e <a href="https://github.com/sedthh" target="_blank" rel="noopener noreferrer">Richard Nagyfi</a> pelas trocas de ideias.</li>
<li><a href="https://github.com/minetoblend" target="_blank" rel="noopener noreferrer">Marvin</a> por doar créditos de treinamento.</li>
<li>A comunidade osu! pelos beatmaps.</li></p><p></ul><h2>Trabalhos relacionados</h2></p><ul><li><a href="https://github.com/Syps/osu_beatmap_generator" target="_blank" rel="noopener noreferrer">osu! Beatmap Generator</a> por Syps (Nick Sypteras)</li>
<li><a href="https://github.com/kotritrona/osumapper" target="_blank" rel="noopener noreferrer">osumapper</a> por kotritrona, jyvden, Yoyolick (Ryan Zmuda)</li>
<li><a href="https://github.com/OliBomby/osu-diffusion" target="_blank" rel="noopener noreferrer">osu-diffusion</a> por OliBomby (Olivier Schipper), NiceAesth (Andrei Baciu)</li>
<li><a href="https://github.com/gyataro/osuT5" target="_blank" rel="noopener noreferrer">osuT5</a> por gyataro (Xiwen Teoh)</li>
<li><a href="https://github.com/sedthh/BeatLearning" target="_blank" rel="noopener noreferrer">Beat Learning</a> por sedthh (Richard Nagyfi)</li>
<li><a href="https://github.com/jaswon/osu-dreamer" target="_blank" rel="noopener noreferrer">osu!dreamer</a> por jaswon (Jason Won)</li></p><p>

</ul>---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-01-24

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-01-24 
    </div>
    
</body>
</html>