<!DOCTYPE html>
<html lang="pl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mapperatorinator - Framework AI do generowania i modyfikowania map beat&#243;w osu! dla wszystkich tryb&#243;w gry na podstawie danych ze spektrogramu.</title>
    <meta name="description" content="Framework AI do generowania i modyfikowania map beat&#243;w osu! dla wszystkich tryb&#243;w gry na podstawie danych ze spektrogramu.">
    <meta name="keywords" content="Mapperatorinator, Polish, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "Mapperatorinator",
  "description": "Framework AI do generowania i modyfikowania map beatów osu! dla wszystkich trybów gry na podstawie danych ze spektrogramu.",
  "author": {
    "@type": "Person",
    "name": "OliBomby"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 398
  },
  "url": "https://OpenAiTx.github.io/projects/OliBomby/Mapperatorinator/README-pl.html",
  "sameAs": "https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/README.md",
  "datePublished": "2026-01-24",
  "dateModified": "2026-01-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/OliBomby/Mapperatorinator" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    Mapperatorinator
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 398 stars</span>
                <span class="language">Polish</span>
                <span>by OliBomby</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Język</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=id">Bahasa Indonesia</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=as">অসমীয়া</
      </div>
    </div>
  </details>
</div></p><h1>Mapperatorinator</h1></p><p>Wypróbuj model generatywny <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mapperatorinator_inference.ipynb" target="_blank" rel="noopener noreferrer">tutaj</a>, lub MaiMod <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mai_mod_inference.ipynb" target="_blank" rel="noopener noreferrer">tutaj</a>. Zobacz prezentację wideo <a href="https://youtu.be/FEr7t1L2EoA" target="_blank" rel="noopener noreferrer">tutaj</a>.</p><p>Mapperatorinator to wielomodelowa platforma wykorzystująca wejścia spektrogramowe do generowania w pełni funkcjonalnych beatmap osu! dla wszystkich trybów gry oraz <a href="#maimod-the-ai-driven-modding-tool" target="_blank" rel="noopener noreferrer">wspomagania moderacji beatmap</a>.
Celem tego projektu jest automatyczne generowanie beatmap osu! o rankowalnej jakości z dowolnej piosenki, z wysokim stopniem możliwości personalizacji.</p><p>Projekt bazuje na <a href="https://github.com/gyataro/osuT5" target="_blank" rel="noopener noreferrer">osuT5</a> oraz <a href="https://github.com/OliBomby/osu-diffusion" target="_blank" rel="noopener noreferrer">osu-diffusion</a>. Podczas tworzenia poświęciłem około 2500 godzin obliczeń GPU podczas 142 sesji na moim 4060 Ti oraz wynajmowanych instancjach 4090 na vast.ai.</p><p>#### Używaj tego narzędzia odpowiedzialnie. Zawsze ujawniaj wykorzystanie AI w swoich beatmapach.</p><h2>Instalacja</h2></p><p>Instrukcja poniżej pozwala na generowanie beatmap na Twoim lokalnym komputerze, alternatywnie możesz uruchomić ją w chmurze za pomocą <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mapperatorinator_inference.ipynb" target="_blank" rel="noopener noreferrer">notatnika colab</a>.</p><h3>1. Sklonuj repozytorium</h3></p><pre><code class="language-sh">git clone https://github.com/OliBomby/Mapperatorinator.git
cd Mapperatorinator</code></pre></p><h3>2. (Opcjonalnie) Utwórz środowisko wirtualne</h3></p><p>Użyj Pythona 3.10, nowsze wersje mogą być niekompatybilne z zależnościami.</p><pre><code class="language-sh">python -m venv .venv</p><h1>In cmd.exe</h1>
.venv\Scripts\activate.bat
<h1>In PowerShell</h1>
.venv\Scripts\Activate.ps1
<h1>In Linux or MacOS</h1>
source .venv/bin/activate</code></pre></p><h3>3. Zainstaluj zależności</h3></p><ul><li>Python 3.10</li>
<li><a href="https://git-scm.com/downloads" target="_blank" rel="noopener noreferrer">Git</a></li>
<li><a href="http://www.ffmpeg.org/" target="_blank" rel="noopener noreferrer">ffmpeg</a></li>
<li><a href="https://developer.nvidia.com/cuda-zone" target="_blank" rel="noopener noreferrer">CUDA</a> (dla GPU NVIDIA) lub <a href="https://rocmdocs.amd.com/en/latest/Installation_Guide/Installation-Guide.html" target="_blank" rel="noopener noreferrer">ROCm</a> (dla GPU AMD na Linuksie)</li>
<li><a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">PyTorch</a>: Upewnij się, że postępujesz zgodnie z przewodnikiem Get Started, aby zainstalować <code>torch</code> i <code>torchaudio</code> z obsługą GPU. Wybierz odpowiednią wersję Compute Platform, którą zainstalowałeś w poprzednim kroku.</li></p><p><li>oraz pozostałe zależności Pythona:</li></p><p></ul><pre><code class="language-sh">pip install -r requirements.txt</code></pre></p><h2>Graficzny interfejs WWW (zalecane)</h2></p><p>Dla bardziej przyjaznej obsługi zalecamy użycie interfejsu WWW. Zapewnia on graficzny interfejs do konfiguracji parametrów generowania, uruchamiania procesu oraz monitorowania wyników.</p><h3>Uruchomienie GUI</h3></p><p>Przejdź do sklonowanego katalogu <code>Mapperatorinator</code> w terminalu i uruchom:</p><pre><code class="language-sh">python web-ui.py</code></pre></p><p>To uruchomi lokalny serwer WWW i automatycznie otworzy interfejs użytkownika w nowym oknie.</p><h3>Korzystanie z GUI</h3></p><ul><li><strong>Konfiguracja:</strong> Ustaw ścieżki wejścia/wyjścia za pomocą pól formularza i przycisków "Przeglądaj". Dostosuj parametry generowania takie jak tryb gry, poziom trudności, styl (rok, ID mappera, deskryptory), timing, konkretne funkcje (hitsounds, super timing) i więcej, odzwierciedlając opcje z wiersza poleceń. (Uwaga: Jeśli podasz <code>beatmap_path</code>, interfejs automatycznie określi <code>audio_path</code> oraz <code>output_path</code>, więc możesz zostawić te pola puste)</li>
<li><strong>Start:</strong> Kliknij przycisk "Start Inference", aby rozpocząć generowanie beatmapy.</li>
<li><strong>Anuluj:</strong> Możesz zatrzymać trwający proces, korzystając z przycisku "Cancel Inference".</li>
<li><strong>Otwórz wyjście:</strong> Po zakończeniu użyj przycisku "Otwórz folder wyjściowy", aby szybko uzyskać dostęp do wygenerowanych plików.</li></p><p></ul>Web UI działa jako wygodna nakładka na skrypt <code>inference.py</code>. W celu uzyskania zaawansowanych opcji lub rozwiązywania problemów, zapoznaj się z instrukcjami wiersza poleceń.</p><p><img src="https://github.com/user-attachments/assets/5312a45f-d51c-4b37-9389-da3258ddd0a1" alt="python_u3zyW0S3Vs"></p><h2>Wnioskowanie z wiersza poleceń</h2></p><p>Dla użytkowników preferujących wiersz poleceń lub wymagających dostępu do zaawansowanych ustawień, postępuj zgodnie z poniższymi krokami. <strong>Uwaga:</strong> Dla prostszego interfejsu graficznego zobacz sekcję <a href="#web-ui-recommended" target="_blank" rel="noopener noreferrer">Web UI (Zalecane)</a> powyżej.</p><p>Uruchom <code>inference.py</code> i przekaż odpowiednie argumenty, aby wygenerować beatmapy. Użyj w tym celu <a href="https://hydra.cc/docs/advanced/override_grammar/basic/" target="_blank" rel="noopener noreferrer">składni nadpisywania Hydra</a>. Wszystkie dostępne parametry znajdziesz w <code>configs/inference_v29.yaml</code>.
<pre><code class="language-">python inference.py \
  audio_path           [Path to input audio] \
  output_path          [Path to output directory] \
  beatmap_path         [Path to .osu file to autofill metadata, and output_path, or use as reference] \
  
  gamemode             [Game mode to generate 0=std, 1=taiko, 2=ctb, 3=mania] \
  difficulty           [Difficulty star rating to generate] \
  mapper_id            [Mapper user ID for style] \
  year                 [Upload year to simulate] \
  hitsounded           [Whether to add hitsounds] \
  slider_multiplier    [Slider velocity multiplier] \
  circle_size          [Circle size] \
  keycount             [Key count for mania] \
  hold_note_ratio      [Hold note ratio for mania 0-1] \
  scroll_speed_ratio   [Scroll speed ratio for mania and ctb 0-1] \
  descriptors          [List of beatmap user tags for style] \
  negative_descriptors [List of beatmap user tags for classifier-free guidance] \
  
  add_to_beatmap       [Whether to add generated content to the reference beatmap instead of making a new beatmap] \
  start_time           [Generation start time in milliseconds] \
  end_time             [Generation end time in milliseconds] \
  in_context           [List of additional context to provide to the model [NONE,TIMING,KIAI,MAP,GD,NO_HS]] \
  output_type          [List of content types to generate] \
  cfg_scale            [Scale of the classifier-free guidance] \
  super_timing         [Whether to use slow accurate variable BPM timing generator] \
  seed                 [Random seed for generation] \</code></pre></p><p>Przykład:
<pre><code class="language-">python inference.py beatmap_path="'C:\Users\USER\AppData\Local\osu!\Songs\1 Kenji Ninuma - DISCO PRINCE\Kenji Ninuma - DISCOPRINCE (peppy) [Normal].osu'" gamemode=0 difficulty=5.5 year=2023 descriptors="['jump aim','clean']" in_context=[TIMING,KIAI]</code></pre></p><h2>Interaktywny CLI</h2>
Dla osób preferujących pracę w terminalu, które chcą przejść przez konfigurację krok po kroku, interaktywny skrypt CLI jest doskonałą alternatywą dla interfejsu Web UI.</p><h3>Uruchomienie CLI</h3>
Przejdź do sklonowanego katalogu. Może być konieczne nadanie skryptowi uprawnień do wykonywania.</p><pre><code class="language-sh"># Make the script executable (only needs to be done once)
chmod +x cli_inference.sh</code></pre></p><pre><code class="language-sh"># Run the script
./cli_inference.sh</code></pre></p><h3>Używanie CLI</h3>
Skrypt przeprowadzi cię przez serię pytań konfiguracyjnych dotyczących wszystkich parametrów generowania, podobnie jak interfejs Web UI.</p><p>Wykorzystuje interfejs z kolorowym kodowaniem dla przejrzystości.
Oferuje zaawansowane menu wielokrotnego wyboru do wybierania deskryptorów stylu za pomocą klawiszy strzałek i spacji.
Po udzieleniu odpowiedzi na wszystkie pytania, wyświetli końcową komendę do przejrzenia.
Możesz wtedy potwierdzić jej wykonanie bezpośrednio lub anulować i skopiować komendę do ręcznego użycia.</p><h2>Wskazówki dotyczące generowania</h2></p><ul><li>Możesz edytować plik <code>configs/inference_v29.yaml</code> i dodać tam swoje argumenty zamiast wpisywać je za każdym razem w terminalu.</li>
<li>Wszystkie dostępne deskryptory znajdziesz <a href="https://osu.ppy.sh/wiki/en/Beatmap/Beatmap_tags" target="_blank" rel="noopener noreferrer">tutaj</a>.</li>
<li>Zawsze podawaj argument roku pomiędzy 2007 a 2023. Jeśli pozostawisz go nieznanym, model może wygenerować beatmapę o niespójnym stylu.</li>
<li>Zawsze podawaj argument trudności. Jeśli pozostawisz go nieznanym, model może wygenerować beatmapę o niespójnej trudności.</li>
<li>Zwiększ parametr <code>cfg_scale</code>, aby zwiększyć skuteczność argumentów <code>mapper_id</code> oraz <code>descriptors</code>.</li>
<li>Możesz użyć argumentu <code>negative_descriptors</code>, by odciągnąć model od niektórych stylów. Działa to tylko, gdy <code>cfg_scale > 1</code>. Upewnij się, że liczba negatywnych deskryptorów jest równa liczbie deskryptorów.</li>
<li>Jeśli styl twojej piosenki i pożądany styl beatmapy nie pasują do siebie, model może nie wykonać twoich poleceń. Na przykład trudno wygenerować beatmapę o wysokim SR, wysokim SV dla spokojnej piosenki.</li>
<li>Jeśli masz już gotowe czasy timingów i kiai dla utworu, możesz je przekazać modelowi, znacznie zwiększając szybkość i dokładność wnioskowania: użyj argumentów <code>beatmap_path</code> oraz <code>in_context=[TIMING,KIAI]</code>.</li>
<li>Aby zremapować tylko fragment beatmapy, użyj argumentów <code>beatmap_path</code>, <code>start_time</code>, <code>end_time</code> oraz <code>add_to_beatmap=true</code>.</li>
<li>Aby wygenerować gościnną trudność dla beatmapy, użyj argumentów <code>beatmap_path</code> oraz <code>in_context=[GD,TIMING,KIAI]</code>.</li>
<li>Aby wygenerować hitsoundy dla beatmapy, użyj argumentów <code>beatmap_path</code> oraz <code>in_context=[NO_HS,TIMING,KIAI]</code>.</li>
<li>Aby wygenerować tylko timing dla utworu, użyj argumentów <code>super_timing=true</code> oraz <code>output_type=[TIMING]</code>.</li></p><p></ul><h2>MaiMod: Narzędzie do modowania wspierane przez AI</h2></p><p>MaiMod to narzędzie do modowania beatmap osu!, które wykorzystuje predykcje Mapperatorinator do wykrywania potencjalnych błędów i niespójności, których nie wykrywają inne automatyczne narzędzia do modowania, takie jak <a href="https://github.com/Naxesss/MapsetVerifier" target="_blank" rel="noopener noreferrer">Mapset Verifier</a>.
Może wykryć takie problemy jak:
<ul><li>Nieprawidłowe snapowanie lub wzorce rytmiczne</li>
<li>Niedokładne punkty timingowe</li>
<li>Niespójne pozycje obiektów lub oznaczenia nowych combo</li>
<li>Dziwne kształty sliderów</li>
<li>Niespójne hitsoundy lub głośności</li></p><p></ul>Możesz wypróbować MaiMod <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mai_mod_inference.ipynb" target="_blank" rel="noopener noreferrer">tutaj</a> lub uruchomić go lokalnie:
Aby uruchomić MaiMod lokalnie, musisz zainstalować Mapperatorinator. Następnie uruchom skrypt <code>mai_mod.py</code>, podając ścieżkę do swojej beatmapy argumentem <code>beatmap_path</code>.
<pre><code class="language-sh">python mai_mod.py beatmap_path="'C:\Users\USER\AppData\Local\osu!\Songs\1 Kenji Ninuma - DISCO PRINCE\Kenji Ninuma - DISCOPRINCE (peppy) [Normal].osu'"</code></pre>
To wydrukuje sugestie dotyczące modyfikacji na konsoli, które następnie możesz ręcznie zastosować do swojej beatmapy.
Sugestie są uporządkowane chronologicznie i pogrupowane w kategorie.
Pierwsza wartość w okręgu wskazuje „zaskoczenie”, czyli miarę tego, jak bardzo model uznał dany problem za nieoczekiwany, dzięki czemu możesz nadać priorytet najważniejszym kwestiom.</p><p>Model może popełniać błędy, szczególnie w przypadku problemów o niskim zaskoczeniu, więc zawsze dokładnie sprawdzaj sugestie przed ich zastosowaniem do swojej beatmapy.
Głównym celem jest pomoc w zawężeniu obszaru poszukiwań potencjalnych problemów, abyś nie musiał ręcznie sprawdzać każdego pojedynczego obiektu w beatmapie.</p><h3>MaiMod GUI</h3>
Aby uruchomić MaiMod Web UI, musisz zainstalować Mapperatorinator.
Następnie uruchom skrypt <code>mai_mod_ui.py</code>. Spowoduje to uruchomienie lokalnego serwera WWW i automatyczne otwarcie interfejsu użytkownika w nowym oknie:</p><pre><code class="language-sh">python mai_mod_ui.py</code></pre></p><p><img width="850" height="1019" alt="afbeelding" src="https://github.com/user-attachments/assets/67c03a43-a7bd-4265-a5b1-5e4d62aca1fa" /></p><h2>Przegląd</h2></p><h3>Tokenizacja</h3></p><p>Mapperatorinator konwertuje beatmapy osu! na pośrednią reprezentację zdarzeń, którą można bezpośrednio konwertować na tokeny i z powrotem.
Uwzględnia obiekty trafień, dźwięki trafień, prędkości sliderów, nowe kombosy, punkty tempa, czasy kiai oraz prędkości przewijania taiko/mania.</p><p>Oto krótki przykład procesu tokenizacji:</p><p><img src="https://github.com/user-attachments/assets/84efde76-4c27-48a1-b8ce-beceddd9e695" alt="mapperatorinator_parser"></p><p>Aby zaoszczędzić na wielkości słownika, zdarzenia czasowe są kwantyzowane do 10 ms, a współrzędne pozycji do siatki co 32 piksele.</p><h3>Architektura modelu</h3>
Model jest w zasadzie nakładką na <a href="https://huggingface.co/docs/transformers/en/model_doc/whisper#transformers.WhisperForConditionalGeneration" target="_blank" rel="noopener noreferrer">HF Transformers Whisper</a>, z niestandardowymi osadzeniami wejściowymi i funkcją straty.
Wielkość modelu to 219M parametrów.
Ten model okazał się szybszy i dokładniejszy od T5 dla tego zadania.</p><p>Ogólny schemat wejścia-wyjścia modelu wygląda następująco:</p><p><img src="https://user-images.githubusercontent.com/28675590/201044116-1384ad72-c540-44db-a285-7319dd01caad.svg" alt="Picture2"></p><p>Model używa klatek spektrogramu Mel jako wejścia enkodera, jedna klatka na pozycję wejściową. Wyjście dekodera na każdym kroku to rozkład softmax nad dyskretnym, zdefiniowanym z góry słownikiem zdarzeń. Wyjścia są rzadkie, zdarzenia są potrzebne tylko gdy występuje obiekt trafienia, zamiast adnotacji dla każdej pojedynczej klatki audio.</p><h3>Format treningu multitaskowego</h3></p><p><img src="https://github.com/user-attachments/assets/62f490bc-a567-4671-a7ce-dbcc5f9cd6d9" alt="Multitask training format"></p><p>Przed tokenem SOS znajdują się dodatkowe tokeny ułatwiające generowanie warunkowe. Tokeny te obejmują tryb gry, trudność, ID mapera, rok i inne metadane.
Podczas treningu tokeny te nie mają przypisanych etykiet, więc nigdy nie są generowane przez model.
Podczas treningu istnieje także losowa szansa, że token metadanych zostanie zastąpiony tokenem 'nieznanym', dzięki czemu podczas inferencji możemy użyć tych tokenów 'nieznanych', by ograniczyć ilość metadanych przekazywanych do modelu.</p><h3>Płynne długie generowanie</h3></p><p>Długość kontekstu modelu to 8,192 sekundy. To oczywiście za mało, by wygenerować całą beatmapę, więc musimy podzielić utwór na kilka okien i generować beatmapę małymi fragmentami.
Aby wygenerowana beatmapa nie miała widocznych szwów między oknami, używamy 90% nakładania i generujemy okna sekwencyjnie.
Każde okno generacji z wyjątkiem pierwszego zaczyna się z dekoderem wstępnie wypełnionym do 50% długości okna tokenami z poprzednich okien.
Używamy procesora logitów, aby upewnić się, że model nie może generować tokenów czasu, które znajdują się w pierwszych 50% okna generacji.
Dodatkowo, ostatnie 40% okna generacji jest zarezerwowane dla następnego okna. Wszelkie wygenerowane tokeny czasu w tym zakresie są traktowane jako tokeny EOS.
Zapewnia to, że każdy wygenerowany token jest uzależniony od co najmniej 4 sekund poprzednich tokenów i 3,3 sekundy przyszłego dźwięku do przewidzenia.</p><p>Aby zapobiec dryfowi offsetu podczas długiej generacji, do zdarzeń czasowych w dekoderze podczas treningu dodano losowe offsety.
Wymusza to korygowanie błędów czasowych poprzez nasłuchiwanie ataków w audio, co skutkuje konsekwentnie dokładnym offsetem.</p><h3>Udoskonalone współrzędne z dyfuzją</h3></p><p>Współrzędne pozycji generowane przez dekoder są kwantowane do siatki o oczkach 32 pikseli, dlatego później używamy dyfuzji do odszumiania współrzędnych do ostatecznych pozycji.
W tym celu wytrenowaliśmy zmodyfikowaną wersję <a href="https://github.com/OliBomby/osu-diffusion" target="_blank" rel="noopener noreferrer">osu-diffusion</a>, która jest wyspecjalizowana tylko do ostatnich 10% harmonogramu szumu i akceptuje bardziej zaawansowane tokeny metadanych, których Mapperatorinator używa do warunkowej generacji.</p><p>Ponieważ model Mapperatorinator generuje SV sliderów, wymagana długość slidera jest stała niezależnie od kształtu ścieżki punktów kontrolnych.
Dlatego staramy się ukierunkować proces dyfuzji na tworzenie współrzędnych pasujących do wymaganych długości sliderów.
Robimy to, przeliczając pozycje końcowe slidera po każdym kroku procesu dyfuzji na podstawie wymaganej długości i aktualnej ścieżki punktów kontrolnych.
Oznacza to, że proces dyfuzji nie ma bezpośredniej kontroli nad pozycjami końcowymi slidera, ale nadal może je wpływać, zmieniając ścieżkę punktów kontrolnych.</p><h3>Post-processing</h3></p><p>Mapperatorinator wykonuje dodatkową post-obróbkę w celu poprawy jakości wygenerowanej beatmapy:</p><ul><li>Udoskonal współrzędne pozycji za pomocą dyfuzji.</li>
<li>Przyciągnij zdarzenia czasowe do najbliższego taktu, używając podziałek snap wygenerowanych przez model.</li>
<li>Przyciągnij niemal idealne nakładki pozycyjne.</li>
<li>Konwertuj zdarzenia kolumn mania na współrzędne X.</li>
<li>Generuj ścieżki sliderów dla taiko drumrolls.</li>
<li>Napraw duże rozbieżności między wymaganą długością slidera a długością ścieżki punktów kontrolnych.</li></p><p></ul><h3>Generator super-timingu</h3></p><p>Generator super-timingu to algorytm, który poprawia precyzję i dokładność generowanego timingu poprzez wywnioskowanie timingu dla całej piosenki 20 razy i uśrednienie wyników.
Jest to przydatne dla utworów o zmiennym BPM lub utworów ze zmianami BPM. Wynik jest niemal idealny, czasami tylko jedna sekcja wymaga ręcznej korekty.</p><h2>Trening</h2></p><p>Instrukcja poniżej tworzy środowisko treningowe na Twoim lokalnym komputerze.</p><h3>1. Sklonuj repozytorium</h3></p><pre><code class="language-sh">git clone https://github.com/OliBomby/Mapperatorinator.git
cd Mapperatorinator</code></pre></p><h3>2. Utwórz zestaw danych</h3></p><p>Utwórz własny zestaw danych za pomocą <a href="https://github.com/mappingtools/Mapperator/blob/master/README.md#create-a-high-quality-dataset" target="_blank" rel="noopener noreferrer">aplikacji konsolowej Mapperator</a>. Wymaga ona <a href="https://osu.ppy.sh/home/account/edit" target="_blank" rel="noopener noreferrer">osu! OAuth client token</a>, aby weryfikować beatmapy i pobierać dodatkowe metadane. Umieść zestaw danych w katalogu <code>datasets</code> obok katalogu <code>Mapperatorinator</code>.</p><pre><code class="language-sh">Mapperator.ConsoleApp.exe dataset2 -t "/Mapperatorinator/datasets/beatmap_descriptors.csv" -i "path/to/osz/files" -o "/datasets/cool_dataset"</code></pre></p><h3>3. (Opcjonalnie) Skonfiguruj Weight & Biases do rejestrowania</h3>
Załóż konto na <a href="https://wandb.ai/site" target="_blank" rel="noopener noreferrer">Weight & Biases</a> i pobierz swój klucz API z ustawień konta.
Następnie ustaw zmienną środowiskową <code>WANDB_API_KEY</code>, aby proces treningu wiedział, na który klucz logować.</p><pre><code class="language-sh">export WANDB_API_KEY=<your_api_key></code></pre></p><h3>4. Utwórz kontener Docker</h3>
Szkolenie w twoim venv jest również możliwe, ale zalecamy użycie Dockera na WSL dla lepszej wydajności.
<pre><code class="language-sh">docker compose up -d --force-recreate
docker attach mapperatorinator_space
cd Mapperatorinator</code></pre></p><h3>5. Skonfiguruj parametry i rozpocznij trening</h3></p><p>Wszystkie konfiguracje znajdują się w pliku <code>./configs/train/default.yaml</code>. 
Upewnij się, że ustawiłeś poprawne <code>train_dataset_path</code> oraz <code>test_dataset_path</code> do swojego zbioru danych, a także indeksy mapsetu początkowego i końcowego dla podziału train/test.
Ścieżka jest lokalna względem kontenera Docker, więc jeśli umieściłeś swój zbiór danych o nazwie <code>cool_dataset</code> w katalogu <code>datasets</code>, to powinna ona być <code>/workspace/datasets/cool_dataset</code>.</p><p>Zalecam utworzenie własnego pliku konfiguracyjnego, który nadpisuje domyślną konfigurację, aby mieć zapis konfiguracji treningu dla powtarzalności.</p><pre><code class="language-yaml">data:
  train_dataset_path: "/workspace/datasets/cool_dataset"
  test_dataset_path: "/workspace/datasets/cool_dataset"
  train_dataset_start: 0
  train_dataset_end: 90
  test_dataset_start: 90
  test_dataset_end: 100</code></pre></p><p>Begin training by calling <code>python osuT5/train.py</code> or <code>torchrun --nproc_per_node=NUM_GPUS osuT5/train.py</code> for multi-GPU training.</p><pre><code class="language-sh">python osuT5/train.py -cn train_v29 train_dataset_path="/workspace/datasets/cool_dataset" test_dataset_path="/workspace/datasets/cool_dataset" train_dataset_end=90 test_dataset_start=90 test_dataset_end=100</code></pre></p><h3>6. Dostrajanie LoRA</h3></p><p>Możesz również dostroić wstępnie wytrenowany model za pomocą <a href="https://arxiv.org/abs/2106.09685" target="_blank" rel="noopener noreferrer">LoRA</a>, aby dostosować go do konkretnego stylu lub trybu gry.
Aby to zrobić, dostosuj <code>configs/train/lora.yaml</code> do swoich potrzeb i uruchom konfigurację treningową <code>lora</code>:</p><pre><code class="language-sh">python osuT5/train.py -cn lora train_dataset_path="/workspace/datasets/cool_dataset" test_dataset_path="/workspace/datasets/cool_dataset" train_dataset_end=90 test_dataset_start=90 test_dataset_end=100</code></pre></p><p>Ważne parametry LoRA do rozważenia:
<ul><li><code>pretrained_path</code>: Ścieżka lub repozytorium HF bazowego modelu do dalszego trenowania.</li>
<li><code>r</code>: Ranga macierzy LoRA. Wyższe wartości zwiększają pojemność modelu, ale także zużycie pamięci.</li>
<li><code>lora_alpha</code>: Współczynnik skalowania dla aktualizacji LoRA.</li>
<li><code>total_steps</code>: Całkowita liczba kroków treningowych. Wyważ ją w zależności od wielkości zbioru danych.</li>
<li><code>enable_lora</code>: Czy używać LoRA czy pełnego tuningu modelu.</li></p><p></ul>Podczas wnioskowania możesz określić wagę LoRA za pomocą argumentu <code>lora_path</code>.
Może to być lokalna ścieżka lub repozytorium Hugging Face.</p><h2>Zobacz także</h2>
<ul><li><a href="https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/./classifier/README.md" target="_blank" rel="noopener noreferrer">Mapper Classifier</a></li>
<li><a href="https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/./rcomplexion/README.md" target="_blank" rel="noopener noreferrer">RComplexion</a></li></p><p></ul><h2>Podziękowania</h2></p><p>Szczególne podziękowania dla:
<ul><li>Autorów <a href="https://github.com/gyataro/osuT5" target="_blank" rel="noopener noreferrer">osuT5</a> za kod treningowy.</li>
<li>Zespołu Hugging Face za ich <a href="https://huggingface.co/docs/transformers/index" target="_blank" rel="noopener noreferrer">narzędzia</a>.</li>
<li><a href="https://github.com/jaswon" target="_blank" rel="noopener noreferrer">Jason Won</a> i <a href="https://github.com/sedthh" target="_blank" rel="noopener noreferrer">Richard Nagyfi</a> za wymianę pomysłów.</li>
<li><a href="https://github.com/minetoblend" target="_blank" rel="noopener noreferrer">Marvin</a> za przekazanie kredytów treningowych.</li>
<li>Społeczności osu! za beatmapy.</li></p><p></ul><h2>Powiązane projekty</h2></p><ul><li><a href="https://github.com/Syps/osu_beatmap_generator" target="_blank" rel="noopener noreferrer">osu! Beatmap Generator</a> autorstwa Syps (Nick Sypteras)</li>
<li><a href="https://github.com/kotritrona/osumapper" target="_blank" rel="noopener noreferrer">osumapper</a> autorstwa kotritrona, jyvden, Yoyolick (Ryan Zmuda)</li>
<li><a href="https://github.com/OliBomby/osu-diffusion" target="_blank" rel="noopener noreferrer">osu-diffusion</a> autorstwa OliBomby (Olivier Schipper), NiceAesth (Andrei Baciu)</li>
<li><a href="https://github.com/gyataro/osuT5" target="_blank" rel="noopener noreferrer">osuT5</a> autorstwa gyataro (Xiwen Teoh)</li>
<li><a href="https://github.com/sedthh/BeatLearning" target="_blank" rel="noopener noreferrer">Beat Learning</a> autorstwa sedthh (Richard Nagyfi)</li>
<li><a href="https://github.com/jaswon/osu-dreamer" target="_blank" rel="noopener noreferrer">osu!dreamer</a> autorstwa jaswon (Jason Won)</li></p><p>
</ul>---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-01-24

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-01-24 
    </div>
    
</body>
</html>