<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mapperatorinator - Un framework AI per generare e modificare beatmap di osu! per tutte le modalit&#224; di gioco a partire da input di spettrogramma.</title>
    <meta name="description" content="Un framework AI per generare e modificare beatmap di osu! per tutte le modalit&#224; di gioco a partire da input di spettrogramma.">
    <meta name="keywords" content="Mapperatorinator, Italian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "Mapperatorinator",
  "description": "Un framework AI per generare e modificare beatmap di osu! per tutte le modalità di gioco a partire da input di spettrogramma.",
  "author": {
    "@type": "Person",
    "name": "OliBomby"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 398
  },
  "url": "https://OpenAiTx.github.io/projects/OliBomby/Mapperatorinator/README-it.html",
  "sameAs": "https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/README.md",
  "datePublished": "2026-01-24",
  "dateModified": "2026-01-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/OliBomby/Mapperatorinator" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    Mapperatorinator
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 398 stars</span>
                <span class="language">Italian</span>
                <span>by OliBomby</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Lingua</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=id">Bahasa Indonesia</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=as">অসমীয়া</
      </div>
    </div>
  </details>
</div></p><h1>Mapperatorinator</h1></p><p>Prova il modello generativo <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mapperatorinator_inference.ipynb" target="_blank" rel="noopener noreferrer">qui</a>, o MaiMod <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mai_mod_inference.ipynb" target="_blank" rel="noopener noreferrer">qui</a>. Guarda una dimostrazione video <a href="https://youtu.be/FEr7t1L2EoA" target="_blank" rel="noopener noreferrer">qui</a>.</p><p>Mapperatorinator è un framework multi-modello che utilizza input spettrogrammi per generare beatmap osu! completamente funzionali per tutte le modalità di gioco e per <a href="#maimod-the-ai-driven-modding-tool" target="_blank" rel="noopener noreferrer">supportare la moderazione delle beatmap</a>.
L’obiettivo di questo progetto è generare automaticamente beatmap osu! di qualità “rankable” da qualsiasi canzone, con un elevato grado di personalizzazione.</p><p>Questo progetto si basa su <a href="https://github.com/gyataro/osuT5" target="_blank" rel="noopener noreferrer">osuT5</a> e <a href="https://github.com/OliBomby/osu-diffusion" target="_blank" rel="noopener noreferrer">osu-diffusion</a>. Per svilupparlo, ho impiegato circa 2500 ore di calcolo GPU in 142 sessioni sulla mia 4060 Ti e istanze 4090 a noleggio su vast.ai.</p><p>#### Usa questo strumento responsabilmente. Segnala sempre l’uso dell’IA nelle tue beatmap.</p><h2>Installazione</h2></p><p>Le istruzioni seguenti ti permettono di generare beatmap sulla tua macchina locale, in alternativa puoi eseguirlo nel cloud tramite il <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mapperatorinator_inference.ipynb" target="_blank" rel="noopener noreferrer">colab notebook</a>.</p><h3>1. Clona il repository</h3></p><pre><code class="language-sh">git clone https://github.com/OliBomby/Mapperatorinator.git
cd Mapperatorinator</code></pre></p><h3>2. (Opzionale) Crea un ambiente virtuale</h3></p><p>Utilizza Python 3.10, le versioni successive potrebbero non essere compatibili con le dipendenze.</p><pre><code class="language-sh">python -m venv .venv</p><h1>In cmd.exe</h1>
.venv\Scripts\activate.bat
<h1>In PowerShell</h1>
.venv\Scripts\Activate.ps1
<h1>In Linux or MacOS</h1>
source .venv/bin/activate</code></pre></p><h3>3. Installa le dipendenze</h3></p><ul><li>Python 3.10</li>
<li><a href="https://git-scm.com/downloads" target="_blank" rel="noopener noreferrer">Git</a></li>
<li><a href="http://www.ffmpeg.org/" target="_blank" rel="noopener noreferrer">ffmpeg</a></li>
<li><a href="https://developer.nvidia.com/cuda-zone" target="_blank" rel="noopener noreferrer">CUDA</a> (Per GPU NVIDIA) o <a href="https://rocmdocs.amd.com/en/latest/Installation_Guide/Installation-Guide.html" target="_blank" rel="noopener noreferrer">ROCm</a> (Per GPU AMD su Linux)</li>
<li><a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">PyTorch</a>: Assicurati di seguire la guida Get Started per installare <code>torch</code> e <code>torchaudio</code> con supporto GPU. Seleziona la versione della Compute Platform corretta che hai installato nel passaggio precedente.</li></p><p><li>e le restanti dipendenze Python:</li></p><p></ul><pre><code class="language-sh">pip install -r requirements.txt</code></pre></p><h2>Interfaccia Web GUI (Consigliata)</h2></p><p>Per un'esperienza più intuitiva, considera l'utilizzo della Web UI. Essa offre un'interfaccia grafica per configurare i parametri di generazione, avviare il processo e monitorare l'output.</p><h3>Avviare la GUI</h3></p><p>Naviga nella directory <code>Mapperatorinator</code> clonata tramite il tuo terminale ed esegui:</p><pre><code class="language-sh">python web-ui.py</code></pre></p><p>Questo avvierà un server web locale e aprirà automaticamente l'interfaccia utente in una nuova finestra.</p><h3>Utilizzo della GUI</h3></p><ul><li><strong>Configura:</strong> Imposta i percorsi di input/output utilizzando i campi del modulo e i pulsanti "Sfoglia". Regola i parametri di generazione come modalità di gioco, difficoltà, stile (anno, ID mapper, descrittori), timing, funzionalità specifiche (hitsounds, super timing) e altro, rispecchiando le opzioni della riga di comando. (Nota: Se fornisci un <code>beatmap_path</code>, l'interfaccia utente determinerà automaticamente <code>audio_path</code> e <code>output_path</code>, quindi puoi lasciare questi campi vuoti)</li>
<li><strong>Avvia:</strong> Fai clic sul pulsante "Avvia Inferenza" per iniziare la generazione della beatmap.</li>
<li><strong>Annulla:</strong> Puoi interrompere il processo in corso utilizzando il pulsante "Annulla Inferenza".</li>
<li><strong>Apri Output:</strong> Una volta terminato, usa il pulsante "Apri Cartella Output" per accedere rapidamente ai file generati.</li></p><p></ul>La Web UI funge da pratico wrapper attorno allo script <code>inference.py</code>. Per opzioni avanzate o risoluzione dei problemi, consulta le istruzioni della riga di comando.</p><p><img src="https://github.com/user-attachments/assets/5312a45f-d51c-4b37-9389-da3258ddd0a1" alt="python_u3zyW0S3Vs"></p><h2>Inferenza da Riga di Comando</h2></p><p>Per gli utenti che preferiscono la riga di comando o necessitano di configurazioni avanzate, seguire i passaggi sotto. <strong>Nota:</strong> Per un'interfaccia grafica più semplice, vedere la sezione <a href="#web-ui-recommended" target="_blank" rel="noopener noreferrer">Web UI (Consigliata)</a> sopra.</p><p>Esegui <code>inference.py</code> e passa alcuni argomenti per generare le beatmap. Per questo utilizza la <a href="https://hydra.cc/docs/advanced/override_grammar/basic/" target="_blank" rel="noopener noreferrer">sintassi di override Hydra</a>. Consulta <code>configs/inference_v29.yaml</code> per tutti i parametri disponibili.
<pre><code class="language-">python inference.py \
  audio_path           [Path to input audio] \
  output_path          [Path to output directory] \
  beatmap_path         [Path to .osu file to autofill metadata, and output_path, or use as reference] \
  
  gamemode             [Game mode to generate 0=std, 1=taiko, 2=ctb, 3=mania] \
  difficulty           [Difficulty star rating to generate] \
  mapper_id            [Mapper user ID for style] \
  year                 [Upload year to simulate] \
  hitsounded           [Whether to add hitsounds] \
  slider_multiplier    [Slider velocity multiplier] \
  circle_size          [Circle size] \
  keycount             [Key count for mania] \
  hold_note_ratio      [Hold note ratio for mania 0-1] \
  scroll_speed_ratio   [Scroll speed ratio for mania and ctb 0-1] \
  descriptors          [List of beatmap user tags for style] \
  negative_descriptors [List of beatmap user tags for classifier-free guidance] \
  
  add_to_beatmap       [Whether to add generated content to the reference beatmap instead of making a new beatmap] \
  start_time           [Generation start time in milliseconds] \
  end_time             [Generation end time in milliseconds] \
  in_context           [List of additional context to provide to the model [NONE,TIMING,KIAI,MAP,GD,NO_HS]] \
  output_type          [List of content types to generate] \
  cfg_scale            [Scale of the classifier-free guidance] \
  super_timing         [Whether to use slow accurate variable BPM timing generator] \
  seed                 [Random seed for generation] \</code></pre></p><p>Esempio:
<pre><code class="language-">python inference.py beatmap_path="'C:\Users\USER\AppData\Local\osu!\Songs\1 Kenji Ninuma - DISCO PRINCE\Kenji Ninuma - DISCOPRINCE (peppy) [Normal].osu'" gamemode=0 difficulty=5.5 year=2023 descriptors="['jump aim','clean']" in_context=[TIMING,KIAI]</code></pre></p><h2>CLI Interattiva</h2>
Per chi preferisce un flusso di lavoro basato sul terminale ma desidera una configurazione guidata, lo script CLI interattivo è un'ottima alternativa all'interfaccia Web.</p><h3>Avvia la CLI</h3>
Naviga nella directory clonata. Potresti dover rendere eseguibile lo script prima.</p><pre><code class="language-sh"># Make the script executable (only needs to be done once)
chmod +x cli_inference.sh</code></pre></p><pre><code class="language-sh"># Run the script
./cli_inference.sh</code></pre></p><h3>Utilizzo della CLI</h3>
Lo script ti guiderà attraverso una serie di prompt per configurare tutti i parametri di generazione, proprio come l'interfaccia Web.</p><p>Utilizza un'interfaccia con codifica a colori per maggiore chiarezza.
Fornisce un menu avanzato multi-selezione per scegliere i descrittori di stile usando i tasti freccia e la barra spaziatrice.
Dopo aver risposto a tutte le domande, verrà mostrato il comando finale per la tua revisione.
Potrai quindi confermare per eseguirlo direttamente oppure annullare e copiare il comando per un utilizzo manuale.</p><h2>Suggerimenti per la Generazione</h2></p><ul><li>Puoi modificare <code>configs/inference_v29.yaml</code> e aggiungere lì i tuoi argomenti invece di digitarli ogni volta nel terminale.</li>
<li>Tutti i descrittori disponibili si trovano <a href="https://osu.ppy.sh/wiki/en/Beatmap/Beatmap_tags" target="_blank" rel="noopener noreferrer">qui</a>.</li>
<li>Fornisci sempre un argomento anno compreso tra il 2007 e il 2023. Se lo lasci sconosciuto, il modello potrebbe generare con uno stile incoerente.</li>
<li>Fornisci sempre un argomento difficoltà. Se lo lasci sconosciuto, il modello potrebbe generare con una difficoltà incoerente.</li>
<li>Aumenta il parametro <code>cfg_scale</code> per aumentare l'efficacia degli argomenti <code>mapper_id</code> e <code>descriptors</code>.</li>
<li>Puoi utilizzare l'argomento <code>negative_descriptors</code> per indirizzare il modello lontano da certi stili. Funziona solo quando <code>cfg_scale > 1</code>. Assicurati che il numero di descrittori negativi sia uguale al numero di descrittori.</li>
<li>Se lo stile della tua canzone e quello desiderato della beatmap non combaciano bene, il modello potrebbe non seguire le tue indicazioni. Ad esempio, è difficile generare una beatmap ad alto SR, alto SV per una canzone calma.</li>
<li>Se hai già fatto timing e tempi kiai per una canzone, puoi fornirli al modello per aumentare notevolmente la velocità e l'accuratezza dell'inferenza: usa gli argomenti <code>beatmap_path</code> e <code>in_context=[TIMING,KIAI]</code>.</li>
<li>Per rimappare solo una parte della tua beatmap, usa gli argomenti <code>beatmap_path</code>, <code>start_time</code>, <code>end_time</code> e <code>add_to_beatmap=true</code>.</li>
<li>Per generare una guest difficulty per una beatmap, usa gli argomenti <code>beatmap_path</code> e <code>in_context=[GD,TIMING,KIAI]</code>.</li>
<li>Per generare i hitsound per una beatmap, usa gli argomenti <code>beatmap_path</code> e <code>in_context=[NO_HS,TIMING,KIAI]</code>.</li>
<li>Per generare solo il timing per una canzone, usa gli argomenti <code>super_timing=true</code> e <code>output_type=[TIMING]</code>.</li></p><p></ul><h2>MaiMod: Lo Strumento di Modding Guidato da AI</h2></p><p>MaiMod è uno strumento di modding per le beatmap di osu! che utilizza le previsioni di Mapperatorinator per trovare potenziali errori e incoerenze che non possono essere rilevati da altri strumenti di modding automatico come <a href="https://github.com/Naxesss/MapsetVerifier" target="_blank" rel="noopener noreferrer">Mapset Verifier</a>.
Può rilevare problemi come:
<ul><li>Snapping o pattern ritmici errati</li>
<li>Punti di timing inaccurati</li>
<li>Posizioni degli oggetti hit o nuove combo incoerenti</li>
<li>Forme di slider strane</li>
<li>Hitsound o volumi incoerenti</li></p><p></ul>Puoi provare MaiMod <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mai_mod_inference.ipynb" target="_blank" rel="noopener noreferrer">qui</a>, oppure eseguirlo in locale:
Per eseguire MaiMod in locale, dovrai installare Mapperatorinator. Poi, esegui lo script <code>mai_mod.py</code>, specificando il percorso della tua beatmap con l'argomento <code>beatmap_path</code>.
<pre><code class="language-sh">python mai_mod.py beatmap_path="'C:\Users\USER\AppData\Local\osu!\Songs\1 Kenji Ninuma - DISCO PRINCE\Kenji Ninuma - DISCOPRINCE (peppy) [Normal].osu'"</code></pre>
Questo stamperà i suggerimenti di modding sulla console, che potrai poi applicare manualmente alla tua beatmap.
I suggerimenti sono ordinati cronologicamente e raggruppati in categorie.
Il primo valore nel cerchio indica la 'sorpresa', che è una misura di quanto il modello abbia trovato inaspettato il problema, così puoi dare priorità alle questioni più importanti.</p><p>Il modello può commettere errori, specialmente su problemi a bassa sorpresa, quindi controlla sempre due volte i suggerimenti prima di applicarli alla tua beatmap.
L'obiettivo principale è aiutarti a restringere lo spazio di ricerca dei potenziali problemi, così non dovrai controllare manualmente ogni singolo oggetto nella tua beatmap.</p><h3>MaiMod GUI</h3>
Per eseguire la MaiMod Web UI, dovrai installare Mapperatorinator.
Poi, esegui lo script <code>mai_mod_ui.py</code>. Questo avvierà un server web locale e aprirà automaticamente l'interfaccia in una nuova finestra:</p><pre><code class="language-sh">python mai_mod_ui.py</code></pre>
<img width="850" height="1019" alt="afbeelding" src="https://github.com/user-attachments/assets/67c03a43-a7bd-4265-a5b1-5e4d62aca1fa" /></p><h2>Panoramica</h2></p><h3>Tokenizzazione</h3></p><p>Mapperatorinator converte le beatmap di osu! in una rappresentazione intermedia di eventi che può essere direttamente convertita da e verso i token.
Include oggetti di colpo, hitsound, velocità degli slider, nuovi combo, punti di timing, tempi di kiai e velocità di scorrimento taiko/mania.</p><p>Ecco un piccolo esempio del processo di tokenizzazione:</p><p><img src="https://github.com/user-attachments/assets/84efde76-4c27-48a1-b8ce-beceddd9e695" alt="mapperatorinator_parser"></p><p>Per ridurre la dimensione del vocabolario, gli eventi temporali sono quantizzati a intervalli di 10 ms e le coordinate delle posizioni sono quantizzate su una griglia di 32 pixel.</p><h3>Architettura del modello</h3>
Il modello è fondamentalmente un wrapper attorno al modello <a href="https://huggingface.co/docs/transformers/en/model_doc/whisper#transformers.WhisperForConditionalGeneration" target="_blank" rel="noopener noreferrer">HF Transformers Whisper</a>, con embedding di input e funzione di perdita personalizzati.
La dimensione del modello ammonta a 219 milioni di parametri.
Questo modello è risultato essere più veloce e preciso rispetto a T5 per questo compito.</p><p>La panoramica ad alto livello dell’input-output del modello è la seguente:</p><p><img src="https://user-images.githubusercontent.com/28675590/201044116-1384ad72-c540-44db-a285-7319dd01caad.svg" alt="Picture2"></p><p>Il modello utilizza frame di spettrogramma Mel come input dell’encoder, con un frame per posizione di input. L’output del decoder del modello a ogni step è una distribuzione softmax su un vocabolario discreto e predefinito di eventi. Gli output sono sparsi, gli eventi sono necessari solo quando si verifica un oggetto di colpo, invece di annotare ogni singolo frame audio.</p><h3>Formato di training multitask</h3></p><p><img src="https://github.com/user-attachments/assets/62f490bc-a567-4671-a7ce-dbcc5f9cd6d9" alt="Multitask training format"></p><p>Prima del token SOS ci sono token aggiuntivi che facilitano la generazione condizionale. Questi token includono la modalità di gioco, la difficoltà, l’ID del mapper, l’anno e altri metadati.
Durante l’addestramento, questi token non hanno etichette associate, quindi non vengono mai prodotti dal modello.
Inoltre, durante l’addestramento c’è una possibilità casuale che un token di metadati venga sostituito da un token ‘sconosciuto’, così durante l’inferenza possiamo usare questi token ‘sconosciuti’ per ridurre la quantità di metadati da fornire al modello.</p><h3>Generazione continua senza soluzione di continuità</h3></p><p>La lunghezza del contesto del modello è di 8,192 secondi. Ovviamente non è sufficiente per generare una beatmap completa, quindi dobbiamo suddividere la canzone in più finestre e generare la beatmap in piccole parti.
Per assicurarci che la beatmap generata non abbia giunture evidenti tra le finestre, utilizziamo una sovrapposizione del 90% e generiamo le finestre in modo sequenziale.
Ogni finestra di generazione tranne la prima inizia con il decoder precompilato fino al 50% della finestra di generazione con token dalle finestre precedenti.</p><p>Utilizziamo un processore logit per assicurarci che il modello non possa generare token temporali che si trovano nel primo 50% della finestra di generazione.
Inoltre, l’ultimo 40% della finestra di generazione è riservato per la finestra successiva. Qualsiasi token temporale generato in quell’intervallo viene trattato come token EOS.
Ciò garantisce che ogni token generato sia condizionato su almeno 4 secondi di token precedenti e 3,3 secondi di audio futuro da anticipare.</p><p>Per prevenire la deriva dell’offset durante generazioni lunghe, sono stati aggiunti offset casuali agli eventi temporali nel decoder durante l’addestramento.
Questo lo costringe a correggere gli errori di temporizzazione ascoltando invece gli attacchi nell’audio, e produce un offset costantemente accurato.</p><h3>Coordinate raffinate con diffusione</h3></p><p>Le coordinate di posizione generate dal decoder sono quantizzate su una griglia di 32 pixel, quindi successivamente utilizziamo la diffusione per denoizzare le coordinate fino alle posizioni finali.
Per questo abbiamo addestrato una versione modificata di <a href="https://github.com/OliBomby/osu-diffusion" target="_blank" rel="noopener noreferrer">osu-diffusion</a> specializzata solo sull’ultimo 10% dello schedule di rumore, e che accetta i token di metadati più avanzati che Mapperatorinator usa per la generazione condizionata.</p><p>Poiché il modello Mapperatorinator produce l’SV degli slider, la lunghezza richiesta dello slider è fissa indipendentemente dalla forma del percorso dei punti di controllo.
Pertanto, cerchiamo di guidare il processo di diffusione per creare coordinate che si adattino alle lunghezze richieste degli slider.
Facciamo questo ricalcolando le posizioni finali degli slider dopo ogni passo del processo di diffusione in base alla lunghezza richiesta e al percorso corrente dei punti di controllo.
Ciò significa che il processo di diffusione non ha controllo diretto sulle posizioni finali degli slider, ma può comunque influenzarle modificando il percorso dei punti di controllo.</p><h3>Post-processing</h3></p><p>Mapperatorinator esegue alcune elaborazioni aggiuntive per migliorare la qualità della beatmap generata:</p><ul><li>Raffina le coordinate di posizione con la diffusione.</li>
<li>Riallinea gli eventi temporali al tick più vicino usando i divisori di snap generati dal modello.</li>
<li>Allinea sovrapposizioni posizionali quasi perfette.</li>
<li>Converte gli eventi delle colonne mania in coordinate X.</li>
<li>Genera percorsi slider per i taiko drumroll.</li>
<li>Corregge grandi discrepanze tra la lunghezza richiesta dello slider e la lunghezza del percorso dei punti di controllo.</li></p><p></ul><h3>Generatore di super timing</h3></p><p>Il generatore di super timing è un algoritmo che migliora la precisione e accuratezza del timing generato inferendo il timing per l’intera canzone 20 volte e facendo la media dei risultati.
Questo è utile per canzoni con BPM variabile, o canzoni con cambi di BPM. Il risultato è quasi perfetto con solo occasionalmente una sezione che necessita di aggiustamento manuale.</p><h2>Addestramento</h2></p><p>L’istruzione seguente crea un ambiente di addestramento sulla tua macchina locale.</p><h3>1. Clona il repository</h3></p><pre><code class="language-sh">git clone https://github.com/OliBomby/Mapperatorinator.git
cd Mapperatorinator</code></pre></p><h3>2. Creare un dataset</h3></p><p>Crea il tuo dataset utilizzando l'<a href="https://github.com/mappingtools/Mapperator/blob/master/README.md#create-a-high-quality-dataset" target="_blank" rel="noopener noreferrer">applicazione console Mapperator</a>. È necessario un <a href="https://osu.ppy.sh/home/account/edit" target="_blank" rel="noopener noreferrer">token client OAuth di osu!</a> per verificare le beatmap e ottenere metadati aggiuntivi. Posiziona il dataset in una directory <code>datasets</code> accanto alla directory <code>Mapperatorinator</code>.</p><pre><code class="language-sh">Mapperator.ConsoleApp.exe dataset2 -t "/Mapperatorinator/datasets/beatmap_descriptors.csv" -i "path/to/osz/files" -o "/datasets/cool_dataset"</code></pre></p><h3>3. (Opzionale) Configura Weight & Biases per la registrazione</h3>
Crea un account su <a href="https://wandb.ai/site" target="_blank" rel="noopener noreferrer">Weight & Biases</a> e ottieni la tua chiave API dalle impostazioni del tuo account.
Quindi imposta la variabile d'ambiente <code>WANDB_API_KEY</code>, così il processo di training saprà a quale chiave registrare.</p><pre><code class="language-sh">export WANDB_API_KEY=<your_api_key></code></pre></p><h3>4. Crea un container Docker</h3>
L'addestramento nel tuo venv è possibile, ma consigliamo di utilizzare Docker su WSL per prestazioni migliori.
<pre><code class="language-sh">docker compose up -d --force-recreate
docker attach mapperatorinator_space
cd Mapperatorinator</code></pre></p><h3>5. Configurare i parametri e iniziare l'addestramento</h3></p><p>Tutte le configurazioni si trovano in <code>./configs/train/default.yaml</code>.
Assicurati di impostare correttamente <code>train_dataset_path</code> e <code>test_dataset_path</code> sul tuo dataset, così come gli indici iniziali e finali del mapset per la divisione train/test.
Il percorso è locale al container docker, quindi se hai inserito il tuo dataset chiamato <code>cool_dataset</code> nella directory <code>datasets</code>, allora dovrebbe essere <code>/workspace/datasets/cool_dataset</code>.</p><p>Consiglio di creare un file di configurazione personalizzato che sovrascriva la configurazione di default, così avrai una traccia della tua configurazione di addestramento per la riproducibilità.</p><pre><code class="language-yaml">data:
  train_dataset_path: "/workspace/datasets/cool_dataset"
  test_dataset_path: "/workspace/datasets/cool_dataset"
  train_dataset_start: 0
  train_dataset_end: 90
  test_dataset_start: 90
  test_dataset_end: 100</code></pre></p><p>Begin training by calling <code>python osuT5/train.py</code> or <code>torchrun --nproc_per_node=NUM_GPUS osuT5/train.py</code> for multi-GPU training.</p><pre><code class="language-sh">python osuT5/train.py -cn train_v29 train_dataset_path="/workspace/datasets/cool_dataset" test_dataset_path="/workspace/datasets/cool_dataset" train_dataset_end=90 test_dataset_start=90 test_dataset_end=100</code></pre></p><h3>6. Fine-tuning LoRA</h3></p><p>Puoi anche perfezionare un modello pre-addestrato con <a href="https://arxiv.org/abs/2106.09685" target="_blank" rel="noopener noreferrer">LoRA</a> per adattarlo a uno stile o modalità di gioco specifica.
Per farlo, adatta <code>configs/train/lora.yaml</code> alle tue esigenze ed esegui la configurazione di training <code>lora</code>:</p><pre><code class="language-sh">python osuT5/train.py -cn lora train_dataset_path="/workspace/datasets/cool_dataset" test_dataset_path="/workspace/datasets/cool_dataset" train_dataset_end=90 test_dataset_start=90 test_dataset_end=100</code></pre></p><p>Parametri LoRA importanti da considerare:
<ul><li><code>pretrained_path</code>: Percorso o repository HF del modello base da ottimizzare.</li>
<li><code>r</code>: Rango delle matrici LoRA. Valori più alti aumentano la capacità del modello ma anche l’uso della memoria.</li>
<li><code>lora_alpha</code>: Fattore di scala per gli aggiornamenti LoRA.</li>
<li><code>total_steps</code>: Numero totale di step di addestramento. Bilancia in base alla dimensione del tuo dataset.</li>
<li><code>enable_lora</code>: Indica se usare LoRA o la regolazione completa del modello.</li></p><p></ul>Durante l’inferenza, puoi specificare i pesi LoRA da usare con l’argomento <code>lora_path</code>.
Questo può essere un percorso locale o un repository Hugging Face.</p><h2>Vedi anche</h2>
<ul><li><a href="https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/./classifier/README.md" target="_blank" rel="noopener noreferrer">Mapper Classifier</a></li>
<li><a href="https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/./rcomplexion/README.md" target="_blank" rel="noopener noreferrer">RComplexion</a></li></p><p></ul><h2>Crediti</h2></p><p>Ringraziamenti speciali a:
<ul><li>Gli autori di <a href="https://github.com/gyataro/osuT5" target="_blank" rel="noopener noreferrer">osuT5</a> per il loro codice di training.</li>
<li>Il team di Hugging Face per i loro <a href="https://huggingface.co/docs/transformers/index" target="_blank" rel="noopener noreferrer">strumenti</a>.</li>
<li><a href="https://github.com/jaswon" target="_blank" rel="noopener noreferrer">Jason Won</a> e <a href="https://github.com/sedthh" target="_blank" rel="noopener noreferrer">Richard Nagyfi</a> per lo scambio di idee.</li>
<li><a href="https://github.com/minetoblend" target="_blank" rel="noopener noreferrer">Marvin</a> per la donazione di crediti di training.</li>
<li>La community di osu! per le beatmap.</li></p><p></ul><h2>Lavori correlati</h2></p><ul><li><a href="https://github.com/Syps/osu_beatmap_generator" target="_blank" rel="noopener noreferrer">osu! Beatmap Generator</a> di Syps (Nick Sypteras)</li>
<li><a href="https://github.com/kotritrona/osumapper" target="_blank" rel="noopener noreferrer">osumapper</a> di kotritrona, jyvden, Yoyolick (Ryan Zmuda)</li>
<li><a href="https://github.com/OliBomby/osu-diffusion" target="_blank" rel="noopener noreferrer">osu-diffusion</a> di OliBomby (Olivier Schipper), NiceAesth (Andrei Baciu)</li>
<li><a href="https://github.com/gyataro/osuT5" target="_blank" rel="noopener noreferrer">osuT5</a> di gyataro (Xiwen Teoh)</li>
<li><a href="https://github.com/sedthh/BeatLearning" target="_blank" rel="noopener noreferrer">Beat Learning</a> di sedthh (Richard Nagyfi)</li>
<li><a href="https://github.com/jaswon/osu-dreamer" target="_blank" rel="noopener noreferrer">osu!dreamer</a> di jaswon (Jason Won)</li></p><p>
</ul>---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-01-24

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-01-24 
    </div>
    
</body>
</html>