<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mapperatorinator - Ein KI-Framework zur Erstellung und Modifikation von osu!-Beatmaps f&#252;r alle Spielmodi anhand von Spektrogramm-Eingaben.</title>
    <meta name="description" content="Ein KI-Framework zur Erstellung und Modifikation von osu!-Beatmaps f&#252;r alle Spielmodi anhand von Spektrogramm-Eingaben.">
    <meta name="keywords" content="Mapperatorinator, German, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "Mapperatorinator",
  "description": "Ein KI-Framework zur Erstellung und Modifikation von osu!-Beatmaps für alle Spielmodi anhand von Spektrogramm-Eingaben.",
  "author": {
    "@type": "Person",
    "name": "OliBomby"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 398
  },
  "url": "https://OpenAiTx.github.io/projects/OliBomby/Mapperatorinator/README-de.html",
  "sameAs": "https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/README.md",
  "datePublished": "2026-01-24",
  "dateModified": "2026-01-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/OliBomby/Mapperatorinator" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    Mapperatorinator
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 398 stars</span>
                <span class="language">German</span>
                <span>by OliBomby</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Sprache</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=id">Bahasa Indonesia</a>
        | <a href="https://openaitx.github.io/view.html?user=OliBomby&project=Mapperatorinator&lang=as">অসমীয়া</
      </div>
    </div>
  </details>
</div></p><h1>Mapperatorinator</h1></p><p>Teste das generative Modell <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mapperatorinator_inference.ipynb" target="_blank" rel="noopener noreferrer">hier</a>, oder MaiMod <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mai_mod_inference.ipynb" target="_blank" rel="noopener noreferrer">hier</a>. Sieh dir eine Video-Demo <a href="https://youtu.be/FEr7t1L2EoA" target="_blank" rel="noopener noreferrer">hier</a> an.</p><p>Mapperatorinator ist ein Multi-Model-Framework, das Spektrogramme als Eingabe nutzt, um voll ausgestattete osu!-Beatmaps für alle Spielmodi zu generieren und <a href="#maimod-the-ai-driven-modding-tool" target="_blank" rel="noopener noreferrer">beim Modden von Beatmaps zu unterstützen</a>.
Das Ziel dieses Projekts ist es, automatisch osu!-Beatmaps in rankbarer Qualität aus jedem beliebigen Song mit einem hohen Maß an Anpassbarkeit zu erstellen.</p><p>Dieses Projekt basiert auf <a href="https://github.com/gyataro/osuT5" target="_blank" rel="noopener noreferrer">osuT5</a> und <a href="https://github.com/OliBomby/osu-diffusion" target="_blank" rel="noopener noreferrer">osu-diffusion</a>. Für die Entwicklung habe ich etwa 2500 Stunden GPU-Rechenzeit in 142 Durchläufen auf meiner 4060 Ti und gemieteten 4090-Instanzen auf vast.ai investiert.</p><p>#### Verwenden Sie dieses Tool verantwortungsbewusst. Geben Sie immer die Nutzung von KI in Ihren Beatmaps an.</p><h2>Installation</h2></p><p>Die folgende Anleitung ermöglicht es Ihnen, Beatmaps auf Ihrem lokalen Rechner zu erstellen. Alternativ können Sie das Tool in der Cloud mit dem <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mapperatorinator_inference.ipynb" target="_blank" rel="noopener noreferrer">Colab-Notebook</a> ausführen.</p><h3>1. Klonen Sie das Repository</h3></p><pre><code class="language-sh">git clone https://github.com/OliBomby/Mapperatorinator.git
cd Mapperatorinator</code></pre></p><h3>2. (Optional) Virtuelle Umgebung erstellen</h3></p><p>Verwenden Sie Python 3.10, spätere Versionen sind möglicherweise nicht mit den Abhängigkeiten kompatibel.</p><pre><code class="language-sh">python -m venv .venv</p><h1>In cmd.exe</h1>
.venv\Scripts\activate.bat
<h1>In PowerShell</h1>
.venv\Scripts\Activate.ps1
<h1>In Linux or MacOS</h1>
source .venv/bin/activate</code></pre></p><h3>3. Abhängigkeiten installieren</h3></p><ul><li>Python 3.10</li>
<li><a href="https://git-scm.com/downloads" target="_blank" rel="noopener noreferrer">Git</a></li>
<li><a href="http://www.ffmpeg.org/" target="_blank" rel="noopener noreferrer">ffmpeg</a></li>
<li><a href="https://developer.nvidia.com/cuda-zone" target="_blank" rel="noopener noreferrer">CUDA</a> (Für NVIDIA-GPUs) oder <a href="https://rocmdocs.amd.com/en/latest/Installation_Guide/Installation-Guide.html" target="_blank" rel="noopener noreferrer">ROCm</a> (Für AMD-GPUs unter Linux)</li>
<li><a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">PyTorch</a>: Achten Sie darauf, dem Get Started-Guide zu folgen, damit Sie <code>torch</code> und <code>torchaudio</code> mit GPU-Unterstützung installieren. Wählen Sie die richtige Compute Platform-Version, die Sie im vorherigen Schritt installiert haben.</li></p><p><li>und die restlichen Python-Abhängigkeiten:</li></p><p></ul><pre><code class="language-sh">pip install -r requirements.txt</code></pre></p><h2>Web-GUI (Empfohlen)</h2></p><p>Für eine benutzerfreundlichere Erfahrung empfiehlt sich die Nutzung der Web-Oberfläche. Sie bietet eine grafische Oberfläche zum Konfigurieren der Generierungsparameter, Starten des Prozesses und Überwachen der Ausgabe.</p><h3>Starten der GUI</h3></p><p>Navigieren Sie im Terminal zum geklonten Verzeichnis <code>Mapperatorinator</code> und führen Sie aus:</p><pre><code class="language-sh">python web-ui.py</code></pre>
Dadurch wird ein lokaler Webserver gestartet und die Benutzeroberfläche automatisch in einem neuen Fenster geöffnet.</p><h3>Verwendung der GUI</h3></p><ul><li><strong>Konfigurieren:</strong> Legen Sie Eingabe-/Ausgabepfade über die Formularfelder und „Durchsuchen“-Schaltflächen fest. Passen Sie Generierungsparameter wie Spielmodus, Schwierigkeitsgrad, Stil (Jahr, Mapper-ID, Deskriptoren), Timing, spezifische Features (Hitsounds, Super Timing) und mehr an, analog zu den Kommandozeilenoptionen. (Hinweis: Wenn Sie einen <code>beatmap_path</code> angeben, ermittelt die UI automatisch den <code>audio_path</code> und <code>output_path</code>, sodass Sie diese Felder leer lassen können)</li>
<li><strong>Starten:</strong> Klicken Sie auf die Schaltfläche „Inference starten“, um die Beatmap-Generierung zu beginnen.</li>
<li><strong>Abbrechen:</strong> Sie können den laufenden Prozess mit der Schaltfläche „Inference abbrechen“ stoppen.</li>
<li><strong>Ausgabe öffnen:</strong> Nach Abschluss können Sie mit der Schaltfläche „Ausgabeordner öffnen“ schnell auf die generierten Dateien zugreifen.</li></p><p></ul>Die Web-UI dient als komfortable Hülle für das Skript <code>inference.py</code>. Für erweiterte Optionen oder zur Fehlerbehebung beachten Sie bitte die Kommandozeilenanweisungen.</p><p><img src="https://github.com/user-attachments/assets/5312a45f-d51c-4b37-9389-da3258ddd0a1" alt="python_u3zyW0S3Vs"></p><h2>Kommandozeilen-Inferenz</h2></p><p>Für Nutzer, die die Kommandozeile bevorzugen oder Zugriff auf erweiterte Konfigurationen benötigen, folgen Sie den untenstehenden Schritten. <strong>Hinweis:</strong> Für eine einfachere grafische Oberfläche siehe bitte den Abschnitt <a href="#web-ui-recommended" target="_blank" rel="noopener noreferrer">Web-UI (Empfohlen)</a> oben.</p><p>Führen Sie <code>inference.py</code> aus und übergeben Sie einige Argumente, um Beatmaps zu generieren. Verwenden Sie dazu die <a href="https://hydra.cc/docs/advanced/override_grammar/basic/" target="_blank" rel="noopener noreferrer">Hydra-Override-Syntax</a>. Alle verfügbaren Parameter finden Sie in <code>configs/inference_v29.yaml</code>.</p><pre><code class="language-">python inference.py \
  audio_path           [Path to input audio] \
  output_path          [Path to output directory] \
  beatmap_path         [Path to .osu file to autofill metadata, and output_path, or use as reference] \
  
  gamemode             [Game mode to generate 0=std, 1=taiko, 2=ctb, 3=mania] \
  difficulty           [Difficulty star rating to generate] \
  mapper_id            [Mapper user ID for style] \
  year                 [Upload year to simulate] \
  hitsounded           [Whether to add hitsounds] \
  slider_multiplier    [Slider velocity multiplier] \
  circle_size          [Circle size] \
  keycount             [Key count for mania] \
  hold_note_ratio      [Hold note ratio for mania 0-1] \
  scroll_speed_ratio   [Scroll speed ratio for mania and ctb 0-1] \
  descriptors          [List of beatmap user tags for style] \
  negative_descriptors [List of beatmap user tags for classifier-free guidance] \
  
  add_to_beatmap       [Whether to add generated content to the reference beatmap instead of making a new beatmap] \
  start_time           [Generation start time in milliseconds] \
  end_time             [Generation end time in milliseconds] \
  in_context           [List of additional context to provide to the model [NONE,TIMING,KIAI,MAP,GD,NO_HS]] \
  output_type          [List of content types to generate] \
  cfg_scale            [Scale of the classifier-free guidance] \
  super_timing         [Whether to use slow accurate variable BPM timing generator] \
  seed                 [Random seed for generation] \</code></pre></p><p>Beispiel:
<pre><code class="language-">python inference.py beatmap_path="'C:\Users\USER\AppData\Local\osu!\Songs\1 Kenji Ninuma - DISCO PRINCE\Kenji Ninuma - DISCOPRINCE (peppy) [Normal].osu'" gamemode=0 difficulty=5.5 year=2023 descriptors="['jump aim','clean']" in_context=[TIMING,KIAI]</code></pre></p><h2>Interaktive CLI</h2>
Für diejenigen, die einen terminalbasierten Workflow bevorzugen, aber eine geführte Einrichtung wünschen, ist das interaktive CLI-Skript eine ausgezeichnete Alternative zur Web-Oberfläche.</p><h3>Starten der CLI</h3>
Navigieren Sie zum geklonten Verzeichnis. Möglicherweise müssen Sie das Skript zuerst ausführbar machen.</p><pre><code class="language-sh"># Make the script executable (only needs to be done once)
chmod +x cli_inference.sh</code></pre></p><pre><code class="language-sh"># Run the script
./cli_inference.sh</code></pre></p><h3>Verwendung der CLI</h3>
Das Skript führt Sie durch eine Reihe von Eingabeaufforderungen, um alle Generierungsparameter zu konfigurieren, genau wie die Web-Oberfläche.</p><p>Es verwendet eine farbcodierte Oberfläche für bessere Übersichtlichkeit.
Es stellt ein erweitertes Multi-Select-Menü bereit, um Stil-Deskriptoren mit den Pfeiltasten und der Leertaste auszuwählen.
Nachdem Sie alle Fragen beantwortet haben, zeigt es den endgültigen Befehl zur Überprüfung an.
Sie können dann bestätigen, um ihn direkt auszuführen, oder abbrechen und den Befehl für die manuelle Verwendung kopieren.</p><h2>Tipps zur Generierung</h2></p><ul><li>Sie können <code>configs/inference_v29.yaml</code> bearbeiten und Ihre Argumente dort eintragen, anstatt sie jedes Mal im Terminal einzugeben.</li>
<li>Alle verfügbaren Deskriptoren finden Sie <a href="https://osu.ppy.sh/wiki/en/Beatmap/Beatmap_tags" target="_blank" rel="noopener noreferrer">hier</a>.</li>
<li>Geben Sie immer ein Jahr zwischen 2007 und 2023 an. Wenn Sie dies offen lassen, kann das Modell mit uneinheitlichem Stil generieren.</li>
<li>Geben Sie immer einen Schwierigkeitsgrad an. Wenn Sie dies offen lassen, kann das Modell mit uneinheitlicher Schwierigkeit generieren.</li>
<li>Erhöhen Sie den Parameter <code>cfg_scale</code>, um die Wirksamkeit der Argumente <code>mapper_id</code> und <code>descriptors</code> zu steigern.</li>
<li>Sie können das Argument <code>negative_descriptors</code> verwenden, um das Modell von bestimmten Stilen abzulenken. Dies funktioniert nur, wenn <code>cfg_scale > 1</code>. Achten Sie darauf, dass die Anzahl der negativen Deskriptoren der der Deskriptoren entspricht.</li>
<li>Wenn sich der Songstil und der gewünschte Beatmap-Stil nicht gut ergänzen, hält sich das Modell möglicherweise nicht an Ihre Vorgaben. Zum Beispiel ist es schwer, für ein ruhiges Lied eine Beatmap mit hohem SR und hohem SV zu generieren.</li>
<li>Wenn Sie bereits Timing- und Kiai-Zeiten für ein Lied haben, können Sie diese dem Modell geben, um die Inferenzgeschwindigkeit und Genauigkeit stark zu erhöhen: Verwenden Sie die Argumente <code>beatmap_path</code> und <code>in_context=[TIMING,KIAI]</code>.</li>
<li>Um nur einen Teil Ihrer Beatmap neu zu gestalten, verwenden Sie die Argumente <code>beatmap_path</code>, <code>start_time</code>, <code>end_time</code> und <code>add_to_beatmap=true</code>.</li>
<li>Um eine Gast-Schwierigkeit für eine Beatmap zu generieren, verwenden Sie die Argumente <code>beatmap_path</code> und <code>in_context=[GD,TIMING,KIAI]</code>.</li>
<li>Um Hitsounds für eine Beatmap zu generieren, verwenden Sie die Argumente <code>beatmap_path</code> und <code>in_context=[NO_HS,TIMING,KIAI]</code>.</li>
<li>Um nur das Timing für ein Lied zu generieren, verwenden Sie die Argumente <code>super_timing=true</code> und <code>output_type=[TIMING]</code>.</li></p><p></ul><h2>MaiMod: Das KI-gestützte Modding-Tool</h2></p><p>MaiMod ist ein Modding-Tool für osu!-Beatmaps, das Mapperatorinator-Vorhersagen verwendet, um potenzielle Fehler und Inkonsistenzen zu finden, die von anderen automatischen Modding-Tools wie <a href="https://github.com/Naxesss/MapsetVerifier" target="_blank" rel="noopener noreferrer">Mapset Verifier</a> nicht erkannt werden können.
Es kann Probleme wie folgende erkennen:
<ul><li>Falsches Snapping oder rhythmische Muster</li>
<li>Ungenaue Timing-Punkte</li>
<li>Inkonsistente Hit-Objekt-Positionen oder neue Combo-Platzierungen</li>
<li>Seltsame Slider-Formen</li>
<li>Inkonsistente Hitsounds oder Lautstärken</li></p><p></ul>Sie können MaiMod <a href="https://colab.research.google.com/github/OliBomby/Mapperatorinator/blob/main/colab/mai_mod_inference.ipynb" target="_blank" rel="noopener noreferrer">hier</a> ausprobieren oder lokal ausführen:
Um MaiMod lokal auszuführen, müssen Sie Mapperatorinator installieren. Führen Sie dann das Skript <code>mai_mod.py</code> aus und geben Sie den Pfad zu Ihrer Beatmap mit dem Argument <code>beatmap_path</code> an.
<pre><code class="language-sh">python mai_mod.py beatmap_path="'C:\Users\USER\AppData\Local\osu!\Songs\1 Kenji Ninuma - DISCO PRINCE\Kenji Ninuma - DISCOPRINCE (peppy) [Normal].osu'"</code></pre>
Dadurch werden die Modding-Vorschläge in der Konsole ausgegeben, die du dann manuell auf deine Beatmap anwenden kannst.
Die Vorschläge sind chronologisch geordnet und in Kategorien gruppiert.
Der erste Wert im Kreis zeigt die „Überraschung“ an, ein Maß dafür, wie unerwartet das Modell das Problem fand, sodass du die wichtigsten Probleme priorisieren kannst.</p><p>Das Modell kann Fehler machen, besonders bei Problemen mit niedriger Überraschung, daher solltest du die Vorschläge immer überprüfen, bevor du sie auf deine Beatmap anwendest.
Das Hauptziel ist, dir zu helfen, den Suchraum für potenzielle Probleme einzugrenzen, sodass du nicht jedes einzelne Hit-Objekt deiner Beatmap manuell prüfen musst.</p><h3>MaiMod GUI</h3>
Um die MaiMod Web-Oberfläche auszuführen, musst du Mapperatorinator installieren.
Danach starte das Skript <code>mai_mod_ui.py</code>. Dadurch wird ein lokaler Webserver gestartet und die Oberfläche automatisch in einem neuen Fenster geöffnet:</p><pre><code class="language-sh">python mai_mod_ui.py</code></pre></p><p><img width="850" height="1019" alt="afbeelding" src="https://github.com/user-attachments/assets/67c03a43-a7bd-4265-a5b1-5e4d62aca1fa" /></p><h2>Übersicht</h2></p><h3>Tokenisierung</h3></p><p>Mapperatorinator konvertiert osu!-Beatmaps in eine Zwischenrepräsentation von Ereignissen, die direkt in Tokens umgewandelt werden kann und umgekehrt.
Sie umfasst Hit-Objekte, Hitsounds, Slider-Geschwindigkeiten, neue Combos, Timing-Punkte, Kiai-Zeiten sowie Taiko/Mania-Scroll-Geschwindigkeiten.</p><p>Hier ist ein kleines Beispiel des Tokenisierungsprozesses:</p><p><img src="https://github.com/user-attachments/assets/84efde76-4c27-48a1-b8ce-beceddd9e695" alt="mapperatorinator_parser"></p><p>Um den Vokabularumfang zu reduzieren, werden Zeitereignisse auf 10ms-Intervalle quantisiert und Positionskoordinaten auf ein 32-Pixel-Raster.</p><h3>Modellarchitektur</h3>
Das Modell ist im Wesentlichen ein Wrapper um das <a href="https://huggingface.co/docs/transformers/en/model_doc/whisper#transformers.WhisperForConditionalGeneration" target="_blank" rel="noopener noreferrer">HF Transformers Whisper</a>-Modell mit eigenen Eingabe-Embeddings und Loss-Funktion.
Die Modellgröße beträgt 219 Mio. Parameter.
Für diese Aufgabe erwies sich dieses Modell als schneller und genauer als T5.</p><p>Die Übersicht des Modells auf hoher Ebene sieht wie folgt aus:</p><p><img src="https://user-images.githubusercontent.com/28675590/201044116-1384ad72-c540-44db-a285-7319dd01caad.svg" alt="Picture2"></p><p>Das Modell verwendet Mel-Spektrogramm-Frames als Encoder-Eingabe, mit einem Frame pro Eingabeposition. Die Decoder-Ausgabe des Modells ist bei jedem Schritt eine Softmax-Verteilung über einen diskreten, vordefinierten Ereignis-Wortschatz. Die Ausgaben sind spärlich, Ereignisse werden nur dann benötigt, wenn ein Hit-Objekt auftritt, anstatt jeden einzelnen Audioframe zu annotieren.</p><h3>Multitasking-Trainingsformat</h3></p><p><img src="https://github.com/user-attachments/assets/62f490bc-a567-4671-a7ce-dbcc5f9cd6d9" alt="Multitask training format"></p><p>Vor dem SOS-Token befinden sich zusätzliche Tokens, die die bedingte Generierung erleichtern. Diese Tokens umfassen den Spielmodus, Schwierigkeitsgrad, Mapper-ID, Jahr und weitere Metadaten.
Während des Trainings haben diese Tokens keine zugehörigen Labels und werden daher nie vom Modell ausgegeben.
Außerdem besteht während des Trainings eine zufällige Chance, dass ein Metadaten-Token durch ein „Unbekannt“-Token ersetzt wird, sodass wir diese „Unbekannt“-Tokens zur Inferenz nutzen können, um den Umfang der an das Modell zu übergebenden Metadaten zu reduzieren.</p><h3>Nahtlose lange Generierung</h3></p><p>Die Kontextlänge des Modells beträgt 8,192 Sekunden. Das reicht offensichtlich nicht aus, um eine vollständige Beatmap zu erzeugen, daher müssen wir das Lied in mehrere Fenster aufteilen und die Beatmap in kleinen Teilen generieren.
Um sicherzustellen, dass die generierte Beatmap keine auffälligen Nähte zwischen den Fenstern aufweist, verwenden wir eine 90%ige Überlappung und generieren die Fenster nacheinander.
Jedes Generierungsfenster außer dem ersten beginnt mit einem Decoder, der bis zu 50% des Fensters mit Tokens aus den vorherigen Fenstern vorbefüllt ist.
Wir verwenden einen Logit-Prozessor, um sicherzustellen, dass das Modell keine Zeit-Token generieren kann, die im ersten 50 % des Generierungsfensters liegen.
Zusätzlich sind die letzten 40 % des Generierungsfensters für das nächste Fenster reserviert. Alle generierten Zeit-Token in diesem Bereich werden als EOS-Token behandelt.
Dies stellt sicher, dass jedes generierte Token auf mindestens 4 Sekunden vorheriger Token und 3,3 Sekunden zukünftiger Audiodaten zum Antizipieren basiert.</p><p>Um ein Offset-Driften während langer Generierung zu verhindern, wurden während des Trainings zufällige Offsets zu den Zeitereignissen im Decoder hinzugefügt.
Dadurch wird das Modell gezwungen, Timing-Fehler zu korrigieren, indem es stattdessen auf die Onsets im Audio hört, was zu einem durchgehend genauen Offset führt.</p><h3>Verfeinerte Koordinaten mit Diffusion</h3></p><p>Vom Decoder generierte Positionskoordinaten werden auf 32-Pixel-Gitterpunkte quantisiert, daher verwenden wir anschließend Diffusion, um die Koordinaten auf die endgültigen Positionen zu entrauschen.
Dafür haben wir eine modifizierte Version von <a href="https://github.com/OliBomby/osu-diffusion" target="_blank" rel="noopener noreferrer">osu-diffusion</a> trainiert, die speziell auf die letzten 10 % des Rauschplans spezialisiert ist und die fortschrittlicheren Metadaten-Token akzeptiert, die Mapperatorinator für die bedingte Generierung verwendet.</p><p>Da das Mapperatorinator-Modell die SV von Slidern ausgibt, ist die erforderliche Länge des Sliders unabhängig von der Form des Kontrollpunktpfads festgelegt.
Daher versuchen wir, den Diffusionsprozess so zu lenken, dass Koordinaten entstehen, die zu den erforderlichen Slider-Längen passen.
Dies erreichen wir, indem wir nach jedem Schritt des Diffusionsprozesses die Slider-Endpositionen basierend auf der erforderlichen Länge und dem aktuellen Kontrollpunktpfad neu berechnen.
Das bedeutet, dass der Diffusionsprozess keinen direkten Einfluss auf die Slider-Endpositionen hat, diese aber durch Änderung des Kontrollpunktpfads beeinflussen kann.</p><h3>Nachbearbeitung</h3></p><p>Mapperatorinator führt zusätzliche Nachbearbeitung durch, um die Qualität der generierten Beatmap zu verbessern:</p><ul><li>Verfeinerung der Positionskoordinaten mit Diffusion.</li>
<li>Zeitereignisse an das nächste Tick mithilfe der vom Modell generierten Snap-Divisoren snappen.</li>
<li>Fast perfekte Positionsüberlagerungen snappen.</li>
<li>Mania-Spaltenereignisse in X-Koordinaten umwandeln.</li>
<li>Sliderpfade für Taiko-Drumrolls generieren.</li>
<li>Große Diskrepanzen zwischen erforderlicher Sliderlänge und Länge des Kontrollpunktpfads beheben.</li></p><p></ul><h3>Super Timing Generator</h3></p><p>Der Super Timing Generator ist ein Algorithmus, der die Präzision und Genauigkeit der generierten Zeitwerte verbessert, indem er die Zeitwerte für das gesamte Lied 20-mal ermittelt und die Ergebnisse mittelt.
Dies ist nützlich für Lieder mit variablem BPM oder BPM-Wechseln. Das Ergebnis ist fast perfekt, nur gelegentlich muss ein Abschnitt manuell angepasst werden.</p><h2>Training</h2></p><p>Die folgende Anleitung erstellt eine Trainingsumgebung auf Ihrem lokalen Rechner.</p><h3>1. Klonen Sie das Repository</h3></p><pre><code class="language-sh">git clone https://github.com/OliBomby/Mapperatorinator.git
cd Mapperatorinator</code></pre></p><h3>2. Datensatz erstellen</h3></p><p>Erstellen Sie Ihren eigenen Datensatz mit der <a href="https://github.com/mappingtools/Mapperator/blob/master/README.md#create-a-high-quality-dataset" target="_blank" rel="noopener noreferrer">Mapperator-Konsolenanwendung</a>. Dafür wird ein <a href="https://osu.ppy.sh/home/account/edit" target="_blank" rel="noopener noreferrer">osu! OAuth-Client-Token</a> benötigt, um Beatmaps zu verifizieren und zusätzliche Metadaten abzurufen. Legen Sie den Datensatz in einem <code>datasets</code>-Verzeichnis neben dem <code>Mapperatorinator</code>-Verzeichnis ab.</p><pre><code class="language-sh">Mapperator.ConsoleApp.exe dataset2 -t "/Mapperatorinator/datasets/beatmap_descriptors.csv" -i "path/to/osz/files" -o "/datasets/cool_dataset"</code></pre></p><h3>3. (Optional) Einrichtung von Weight & Biases zum Logging</h3>
Erstellen Sie ein Konto bei <a href="https://wandb.ai/site" target="_blank" rel="noopener noreferrer">Weight & Biases</a> und holen Sie sich Ihren API-Schlüssel aus den Kontoeinstellungen.
Setzen Sie dann die Umgebungsvariable <code>WANDB_API_KEY</code>, damit der Trainingsprozess weiß, dass zu diesem Schlüssel geloggt werden soll.</p><pre><code class="language-sh">export WANDB_API_KEY=<your_api_key></code></pre></p><h3>4. Docker-Container erstellen</h3>
Das Training in Ihrer venv ist ebenfalls möglich, aber wir empfehlen die Verwendung von Docker unter WSL für eine bessere Leistung.
<pre><code class="language-sh">docker compose up -d --force-recreate
docker attach mapperatorinator_space
cd Mapperatorinator</code></pre></p><h3>5. Parameter konfigurieren und Training starten</h3></p><p>Alle Konfigurationen befinden sich in <code>./configs/train/default.yaml</code>.
Stellen Sie sicher, dass Sie den korrekten <code>train_dataset_path</code> und <code>test_dataset_path</code> zu Ihrem Datensatz sowie die Start- und End-Mapset-Indizes für die Train/Test-Aufteilung festlegen.
Der Pfad ist lokal zum Docker-Container, also wenn Sie Ihren Datensatz namens <code>cool_dataset</code> in das Verzeichnis <code>datasets</code> gelegt haben, sollte er <code>/workspace/datasets/cool_dataset</code> lauten.</p><p>Ich empfehle, eine eigene Konfigurationsdatei zu erstellen, die die Standardkonfiguration überschreibt, damit Sie eine Aufzeichnung Ihrer Trainingskonfiguration für die Reproduzierbarkeit haben.</p><pre><code class="language-yaml">data:
  train_dataset_path: "/workspace/datasets/cool_dataset"
  test_dataset_path: "/workspace/datasets/cool_dataset"
  train_dataset_start: 0
  train_dataset_end: 90
  test_dataset_start: 90
  test_dataset_end: 100</code></pre></p><p>Begin training by calling <code>python osuT5/train.py</code> or <code>torchrun --nproc_per_node=NUM_GPUS osuT5/train.py</code> for multi-GPU training.</p><pre><code class="language-sh">python osuT5/train.py -cn train_v29 train_dataset_path="/workspace/datasets/cool_dataset" test_dataset_path="/workspace/datasets/cool_dataset" train_dataset_end=90 test_dataset_start=90 test_dataset_end=100</code></pre></p><h3>6. LoRA-Feinabstimmung</h3></p><p>Sie können auch ein vortrainiertes Modell mit <a href="https://arxiv.org/abs/2106.09685" target="_blank" rel="noopener noreferrer">LoRA</a> feinabstimmen, um es an einen bestimmten Stil oder Spielmodus anzupassen.
Passen Sie dazu <code>configs/train/lora.yaml</code> an Ihre Anforderungen an und führen Sie die <code>lora</code>-Trainingskonfiguration aus:</p><pre><code class="language-sh">python osuT5/train.py -cn lora train_dataset_path="/workspace/datasets/cool_dataset" test_dataset_path="/workspace/datasets/cool_dataset" train_dataset_end=90 test_dataset_start=90 test_dataset_end=100</code></pre></p><p>Wichtige LoRA-Parameter, die zu berücksichtigen sind:
<ul><li><code>pretrained_path</code>: Pfad oder HF-Repository des Basismodells zum Fine-Tuning.</li>
<li><code>r</code>: Rang der LoRA-Matrizen. Höhere Werte erhöhen die Modellkapazität, aber auch den Speicherverbrauch.</li>
<li><code>lora_alpha</code>: Skalierungsfaktor für die LoRA-Updates.</li>
<li><code>total_steps</code>: Gesamtanzahl der Trainingsschritte. Stimmen Sie dies auf die Größe Ihres Datensatzes ab.</li>
<li><code>enable_lora</code>: Ob LoRA oder vollständiges Modell-Fine-Tuning verwendet wird.</li></p><p></ul>Während der Inferenz können Sie die zu verwendenden LoRA-Gewichte mit dem Argument <code>lora_path</code> angeben.
Dies kann ein lokaler Pfad oder ein Hugging Face-Repository sein.</p><h2>Siehe auch</h2>
<ul><li><a href="https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/./classifier/README.md" target="_blank" rel="noopener noreferrer">Mapper Classifier</a></li>
<li><a href="https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/./rcomplexion/README.md" target="_blank" rel="noopener noreferrer">RComplexion</a></li></p><p></ul><h2>Danksagungen</h2></p><p>Besonderer Dank an:
<ul><li>Die Autoren von <a href="https://github.com/gyataro/osuT5" target="_blank" rel="noopener noreferrer">osuT5</a> für ihren Trainingscode.</li>
<li>Das Hugging Face-Team für ihre <a href="https://huggingface.co/docs/transformers/index" target="_blank" rel="noopener noreferrer">Tools</a>.</li>
<li><a href="https://github.com/jaswon" target="_blank" rel="noopener noreferrer">Jason Won</a> und <a href="https://github.com/sedthh" target="_blank" rel="noopener noreferrer">Richard Nagyfi</a> für das Austauschen von Ideen.</li>
<li><a href="https://github.com/minetoblend" target="_blank" rel="noopener noreferrer">Marvin</a> für das Spenden von Trainings-Credits.</li>
<li>Die osu!-Community für die Beatmaps.</li></p><p></ul><h2>Verwandte Arbeiten</h2></p><ul><li><a href="https://github.com/Syps/osu_beatmap_generator" target="_blank" rel="noopener noreferrer">osu! Beatmap Generator</a> von Syps (Nick Sypteras)</li>
<li><a href="https://github.com/kotritrona/osumapper" target="_blank" rel="noopener noreferrer">osumapper</a> von kotritrona, jyvden, Yoyolick (Ryan Zmuda)</li>
<li><a href="https://github.com/OliBomby/osu-diffusion" target="_blank" rel="noopener noreferrer">osu-diffusion</a> von OliBomby (Olivier Schipper), NiceAesth (Andrei Baciu)</li>
<li><a href="https://github.com/gyataro/osuT5" target="_blank" rel="noopener noreferrer">osuT5</a> von gyataro (Xiwen Teoh)</li>
<li><a href="https://github.com/sedthh/BeatLearning" target="_blank" rel="noopener noreferrer">Beat Learning</a> von sedthh (Richard Nagyfi)</li>
<li><a href="https://github.com/jaswon/osu-dreamer" target="_blank" rel="noopener noreferrer">osu!dreamer</a> von jaswon (Jason Won)</li></p><p>
</ul>---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-01-24

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/OliBomby/Mapperatorinator/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-01-24 
    </div>
    
</body>
</html>