<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>no-time-to-train - M&#227; ch&#237;nh thức cho &quot;Kh&#244;ng cần thời gian huấn luyện! Ph&#226;n đoạn đối tượng dựa tr&#234;n tham chiếu m&#224; kh&#244;ng cần huấn luyện&quot;</title>
    <meta name="description" content="M&#227; ch&#237;nh thức cho &quot;Kh&#244;ng cần thời gian huấn luyện! Ph&#226;n đoạn đối tượng dựa tr&#234;n tham chiếu m&#224; kh&#244;ng cần huấn luyện&quot;">
    <meta name="keywords" content="no-time-to-train, Vietnamese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "no-time-to-train",
  "description": "Mã chính thức cho \"Không cần thời gian huấn luyện! Phân đoạn đối tượng dựa trên tham chiếu mà không cần huấn luyện\"",
  "author": {
    "@type": "Person",
    "name": "miquel-espinosa"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 228
  },
  "url": "https://OpenAiTx.github.io/projects/miquel-espinosa/no-time-to-train/README-vi.html",
  "sameAs": "https://raw.githubusercontent.com/miquel-espinosa/no-time-to-train/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/miquel-espinosa/no-time-to-train" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    no-time-to-train
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 228 stars</span>
                <span class="language">Vietnamese</span>
                <span>by miquel-espinosa</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Ngôn ngữ</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=miquel-espinosa&project=no-time-to-train&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div></p><p><div align="center"></p><h1>🚀 Không Thời Gian Để Huấn Luyện!  </h1>
<h3>Phân Đoạn Tham Chiếu Theo Đối Tượng Không Cần Huấn Luyện  </h3>
<a href="https://github.com/miquel-espinosa/no-time-to-train" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/%E2%80%8B-Không%20Thời%20Gian%20Để%20Huấn%20Luyện-black?logo=github" alt="GitHub"></a>
<a href="https://miquel-espinosa.github.io/no-time-to-train/" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/🌐-Trang%20Dự%20Án-grey" alt="Website"></a>
<a href="https://arxiv.org/abs/2507.02798" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-2507.02798-b31b1b" alt="arXiv"></a></p><p><strong>Trạng thái tiên tiến nhất (Papers with Code)</strong>
<a href="https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference" target="_blank" rel="noopener noreferrer"><strong>_SOTA 1-shot_</strong></a> | <a href="https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(1--shot" alt="PWC">-21CBCE?style=flat&logo=paperswithcode)</a></p><p><a href="https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference" target="_blank" rel="noopener noreferrer"><strong>_SOTA 10-shot_</strong></a> | <a href="https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(10--shot" alt="PWC">-21CBCE?style=flat&logo=paperswithcode)</a></p><p><a href="https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference" target="_blank" rel="noopener noreferrer"><strong>_SOTA 30-shot_</strong></a> | <a href="https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/State%20of%20the%20Art-Few--Shot%20Object%20Detection%20on%20MS--COCO%20(30--shot" alt="PWC">-21CBCE?style=flat&logo=paperswithcode)</a></p><p><!-- <a href="https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference" target="_blank" rel="noopener noreferrer"><strong>_SOTA 1-shot_</strong></a> | <a href="https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-1-shot?p=no-time-to-train-training-free-reference" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-1-shot" alt="PWC"></a></p><p><a href="https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference" target="_blank" rel="noopener noreferrer"><strong>_SOTA 10-shot_</strong></a> | <a href="https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-10-shot?p=no-time-to-train-training-free-reference" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-10-shot" alt="PWC"></a></p><p><a href="https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference" target="_blank" rel="noopener noreferrer"><strong>_SOTA 30-shot_</strong></a> | <a href="https://paperswithcode.com/sota/few-shot-object-detection-on-ms-coco-30-shot?p=no-time-to-train-training-free-reference" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/no-time-to-train-training-free-reference/few-shot-object-detection-on-ms-coco-30-shot" alt="PWC"></a> --></p><p></div></p><hr></p><blockquote>🚨 <strong>Cập nhật (22 tháng 7 năm 2025):</strong> Đã thêm hướng dẫn cho bộ dữ liệu tùy chỉnh!</blockquote>
<blockquote></blockquote>
<blockquote>🔔 <strong>Cập nhật (16 tháng 7 năm 2025):</strong> Mã nguồn đã được cập nhật kèm hướng dẫn!</blockquote></p><hr></p><h2>📋 Mục lục</h2></p><ul><li><a href="#-highlights" target="_blank" rel="noopener noreferrer">🎯 Điểm nổi bật</a></li>
<li><a href="#-abstract" target="_blank" rel="noopener noreferrer">📜 Tóm tắt</a></li>
<li><a href="#-architecture" target="_blank" rel="noopener noreferrer">🧠 Kiến trúc</a></li>
<li><a href="#️-installation-instructions" target="_blank" rel="noopener noreferrer">🛠️ Hướng dẫn cài đặt</a></li>
  <li><a href="#1-clone-the-repository" target="_blank" rel="noopener noreferrer">1. Sao chép kho lưu trữ</a></li>
  <li><a href="#2-create-conda-environment" target="_blank" rel="noopener noreferrer">2. Tạo môi trường conda</a></li>
  <li><a href="#3-install-sam2-and-dinov2" target="_blank" rel="noopener noreferrer">3. Cài đặt SAM2 và DinoV2</a></li>
  <li><a href="#4-download-datasets" target="_blank" rel="noopener noreferrer">4. Tải bộ dữ liệu</a></li>
  <li><a href="#5-download-sam2-and-dinov2-checkpoints" target="_blank" rel="noopener noreferrer">5. Tải các checkpoint SAM2 và DinoV2</a></li>
<li><a href="#-inference-code" target="_blank" rel="noopener noreferrer">📊 Mã suy luận: Tái tạo kết quả SOTA 30-shot trên Few-shot COCO</a></li>
  <li><a href="#0-create-reference-set" target="_blank" rel="noopener noreferrer">0. Tạo bộ tham chiếu</a></li>
  <li><a href="#1-fill-memory-with-references" target="_blank" rel="noopener noreferrer">1. Nạp bộ nhớ với các tham chiếu</a></li>
  <li><a href="#2-post-process-memory-bank" target="_blank" rel="noopener noreferrer">2. Xử lý hậu kỳ bộ nhớ</a></li>
  <li><a href="#3-inference-on-target-images" target="_blank" rel="noopener noreferrer">3. Suy luận trên ảnh mục tiêu</a></li>
  <li><a href="#results" target="_blank" rel="noopener noreferrer">Kết quả</a></li></p><p><li><a href="#-custom-dataset" target="_blank" rel="noopener noreferrer">🔍 Bộ dữ liệu tùy chỉnh</a></li>
  <li><a href="#0-prepare-a-custom-dataset" target="_blank" rel="noopener noreferrer">0. Chuẩn bị bộ dữ liệu tùy chỉnh ⛵🐦</a></li>
  <li><a href="#01-if-only-bbox-annotations-are-available" target="_blank" rel="noopener noreferrer">0.1 Nếu chỉ có chú thích bbox</a></li>
  <li><a href="#02-convert-coco-annotations-to-pickle-file" target="_blank" rel="noopener noreferrer">0.2 Chuyển đổi chú thích coco sang file pickle</a></li>
  <li><a href="#1-fill-memory-with-references" target="_blank" rel="noopener noreferrer">1. Nạp bộ nhớ với các tham chiếu</a></li>
  <li><a href="#2-post-process-memory-bank" target="_blank" rel="noopener noreferrer">2. Xử lý hậu kỳ ngân hàng bộ nhớ</a></li>
<li><a href="#-citation" target="_blank" rel="noopener noreferrer">📚 Trích dẫn</a></li></p><p>
</ul><h2>🎯 Điểm nổi bật</h2>
<ul><li>💡 <strong>Không cần huấn luyện</strong>: Không tinh chỉnh, không thiết kế prompt—chỉ cần một ảnh tham chiếu.  </li>
<li>🖼️ <strong>Dựa trên tham chiếu</strong>: Phân đoạn đối tượng mới chỉ với một vài ví dụ.  </li>
<li>🔥 <strong>Hiệu năng SOTA</strong>: Vượt trội các phương pháp không huấn luyện trước đó trên COCO, PASCAL VOC, và Cross-Domain FSOD.</li></p><p></ul><strong>Liên kết:</strong>
<ul><li>🧾 <a href="https://arxiv.org/abs/2507.02798" target="_blank" rel="noopener noreferrer"><strong>Bài báo arXiv</strong></a>  </li>
<li>🌐 <a href="https://miquel-espinosa.github.io/no-time-to-train/" target="_blank" rel="noopener noreferrer"><strong>Website dự án</strong></a>  </li>
<li>📈 <a href="https://paperswithcode.com/paper/no-time-to-train-training-free-reference" target="_blank" rel="noopener noreferrer"><strong>Papers with Code</strong></a></li></p><p></ul><h2>📜 Tóm tắt</h2></p><blockquote>The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).</blockquote></p><p><img src="https://github.com/user-attachments/assets/ab302c02-c080-4042-99fc-0e181ba8abb9" alt="cdfsod-results-final-comic-sans-min"></p><h2>🧠 Architecture</h2></p><p><img src="https://github.com/user-attachments/assets/d84dd83a-505e-45a0-8ce3-98e1838017f9" alt="training-free-architecture-comic-sans-min"></p><h2>🛠️ Installation instructions</h2></p><h3>1. Clone the repository</h3></p><pre><code class="language-bash">git clone https://github.com/miquel-espinosa/no-time-to-train.git
cd no-time-to-train</code></pre>
<h3>2. Tạo môi trường conda</h3></p><p>Chúng ta sẽ tạo một môi trường conda với các gói cần thiết.</p><pre><code class="language-bash">conda env create -f environment.yml
conda activate no-time-to-train</code></pre>
<h3>3. Cài đặt SAM2 và DinoV2</h3></p><p>Chúng ta sẽ cài đặt SAM2 và DinoV2 từ mã nguồn.</p><pre><code class="language-bash">pip install -e .
cd dinov2
pip install -e .
cd ..</code></pre>
<h3>4. Tải xuống các bộ dữ liệu</h3></p><p>Vui lòng tải xuống bộ dữ liệu COCO và đặt nó vào <code>data/coco</code></p><h3>5. Tải xuống các checkpoint SAM2 và DinoV2</h3></p><p>Chúng ta sẽ tải xuống các checkpoint SAM2 chính xác đã được sử dụng trong bài báo.
(Tuy nhiên, lưu ý rằng các checkpoint SAM2.1 đã có sẵn và có thể hoạt động tốt hơn.)</p><pre><code class="language-bash">mkdir -p checkpoints/dinov2
cd checkpoints
wget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt
cd dinov2
wget https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth
cd ../..</code></pre>
<h2>📊 Mã suy luận</h2></p><p>⚠️ Lưu ý: Đây là mã nghiên cứu — có thể sẽ hơi lộn xộn!</p><h3>Tái tạo kết quả SOTA 30-shot trong Few-shot COCO</h3></p><p>Định nghĩa các biến hữu ích và tạo một thư mục cho kết quả:</p><pre><code class="language-bash">CONFIG=./no_time_to_train/new_exps/coco_fewshot_10shot_Sam2L.yaml
CLASS_SPLIT="few_shot_classes"
RESULTS_DIR=work_dirs/few_shot_results
SHOTS=30
SEED=33
GPUS=4</p><p>mkdir -p $RESULTS_DIR
FILENAME=few_shot_${SHOTS}shot_seed${SEED}.pkl</code></pre>
#### 0. Tạo bộ tham chiếu</p><pre><code class="language-bash">python no_time_to_train/dataset/few_shot_sampling.py \
        --n-shot $SHOTS \
        --out-path ${RESULTS_DIR}/${FILENAME} \
        --seed $SEED \
        --dataset $CLASS_SPLIT</code></pre>
#### 1. Lấp đầy bộ nhớ bằng các tham chiếu</p><pre><code class="language-bash">python run_lightening.py test --config $CONFIG \
                              --model.test_mode fill_memory \
                              --out_path ${RESULTS_DIR}/memory.ckpt \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --model.init_args.dataset_cfgs.fill_memory.memory_pkl ${RESULTS_DIR}/${FILENAME} \
                              --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOTS \
                              --model.init_args.dataset_cfgs.fill_memory.class_split $CLASS_SPLIT \
                              --trainer.logger.save_dir ${RESULTS_DIR}/ \
                              --trainer.devices $GPUS</code></pre>
#### 2. Xử lý hậu kỳ bộ nhớ ngân hàng</p><pre><code class="language-bash">python run_lightening.py test --config $CONFIG \
                              --model.test_mode postprocess_memory \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --ckpt_path ${RESULTS_DIR}/memory.ckpt \
                              --out_path ${RESULTS_DIR}/memory_postprocessed.ckpt \
                              --trainer.devices 1</code></pre>
#### 3. Suy luận trên các hình ảnh mục tiêu</p><pre><code class="language-bash">python run_lightening.py test --config $CONFIG  \
                              --ckpt_path ${RESULTS_DIR}/memory_postprocessed.ckpt \
                              --model.init_args.test_mode test \
                              --model.init_args.model_cfg.memory_bank_cfg.length $SHOTS \
                              --model.init_args.model_cfg.dataset_name $CLASS_SPLIT \
                              --model.init_args.dataset_cfgs.test.class_split $CLASS_SPLIT \
                              --trainer.logger.save_dir ${RESULTS_DIR}/ \
                              --trainer.devices $GPUS</code></pre>
Nếu bạn muốn xem kết quả suy luận trực tuyến (ngay khi chúng được tính toán), hãy thêm đối số:</p><pre><code class="language-bash">    --model.init_args.model_cfg.test.online_vis True</code></pre>
Để điều chỉnh tham số ngưỡng điểm số <code>score_thr</code>, hãy thêm đối số (ví dụ, trực quan hóa tất cả các trường hợp có điểm số cao hơn <code>0.4</code>):
<pre><code class="language-bash">    --model.init_args.model_cfg.test.vis_thr 0.4</code></pre>
Các hình ảnh bây giờ sẽ được lưu trong <code>results_analysis/few_shot_classes/</code>. Hình ảnh bên trái hiển thị dữ liệu thực tế, hình ảnh bên phải hiển thị các vùng phân đoạn do phương pháp không cần huấn luyện của chúng tôi tìm được.</p><p>Lưu ý rằng trong ví dụ này chúng tôi đang sử dụng bộ chia <code>few_shot_classes</code>, do đó, chúng ta chỉ nên mong đợi thấy các vùng phân đoạn của các lớp trong bộ chia này (không phải tất cả các lớp trong COCO).</p><p>#### Kết quả</p><p>Sau khi chạy tất cả các hình ảnh trong tập kiểm định, bạn sẽ thu được:</p><pre><code class="language-">BBOX RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.368</p><p>SEGM RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342</code></pre>
<hr></p><h2>🔍 Bộ dữ liệu tùy chỉnh</h2></p><p>Chúng tôi cung cấp hướng dẫn để chạy pipeline của mình trên một bộ dữ liệu tùy chỉnh. Định dạng chú thích luôn ở định dạng COCO.</p><blockquote><strong>TLDR;</strong> Để xem trực tiếp cách chạy toàn bộ pipeline trên <em>bộ dữ liệu tùy chỉnh</em>, hãy xem <code>scripts/matching_cdfsod_pipeline.sh</code> cùng với các script ví dụ của bộ dữ liệu CD-FSOD (ví dụ: <code>scripts/dior_fish.sh</code>)</blockquote></p><h3>0. Chuẩn bị bộ dữ liệu tùy chỉnh ⛵🐦</h3></p><p>Hãy tưởng tượng chúng ta muốn phát hiện <strong>thuyền</strong>⛵ và <strong>chim</strong>🐦 trong một bộ dữ liệu tùy chỉnh. Để sử dụng phương pháp của chúng tôi, bạn sẽ cần:
<ul><li>Ít nhất 1 ảnh tham chiếu <em>được chú thích</em> cho mỗi lớp (ví dụ: 1 ảnh tham chiếu cho thuyền và 1 ảnh tham chiếu cho chim)</li>
<li>Nhiều ảnh mục tiêu để tìm các đối tượng của lớp mong muốn.</li></p><p></ul>Chúng tôi đã chuẩn bị một script ví dụ để tạo bộ dữ liệu tùy chỉnh với ảnh coco, cho trường hợp <strong>1-shot</strong>.
<pre><code class="language-bash">mkdir -p data/my_custom_dataset
python scripts/make_custom_dataset.py</code></pre>
Điều này sẽ tạo ra một bộ dữ liệu tùy chỉnh với cấu trúc thư mục như sau:
<pre><code class="language-">data/my_custom_dataset/
    ├── annotations/
    │   ├── custom_references.json
    │   ├── custom_targets.json
    │   └── references_visualisations/
    │       ├── bird_1.jpg
    │       └── boat_1.jpg
    └── images/
        ├── 429819.jpg
        ├── 101435.jpg
        └── (all target and reference images)</code></pre>
<strong>Trực quan hóa hình ảnh tham chiếu (1-shot):</strong></p><p>| Hình ảnh tham chiếu 1-shot cho CHIM 🐦 | Hình ảnh tham chiếu 1-shot cho THUYỀN ⛵ |
|:--------------------------------------:|:---------------------------------------:|
| <img src="https://github.com/user-attachments/assets/e59e580d-a7db-42ac-b386-892af211fc85" alt="bird_1" width="500"/> | <img src="https://github.com/user-attachments/assets/f94ee025-ae37-4a45-9c3e-0cfe8f8cd2bc" alt="boat_1" width="500"/> |</p><h3>0.1 Nếu chỉ có chú thích bbox</h3></p><p>Chúng tôi cũng cung cấp một script để tạo mặt nạ phân đoạn cấp đối tượng bằng cách sử dụng SAM2. Điều này hữu ích nếu bạn chỉ có các chú thích bounding box cho hình ảnh tham chiếu.</p><pre><code class="language-bash"># Download sam_h checkpoint. Feel free to use more recent checkpoints (note: code might need to be adapted)
wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O checkpoints/sam_vit_h_4b8939.pth
<h1>Run automatic instance segmentation from ground truth bounding boxes.</h1>
python no_time_to_train/dataset/sam_bbox_to_segm_batch.py \
    --input_json data/my_custom_dataset/annotations/custom_references.json \
    --image_dir data/my_custom_dataset/images \
    --sam_checkpoint checkpoints/sam_vit_h_4b8939.pth \
    --model_type vit_h \
    --device cuda \
    --batch_size 8 \
    --visualize</code></pre>
<strong>Hình ảnh tham chiếu với mặt nạ phân đoạn cấp độ đối tượng (được tạo bởi SAM2 từ các hộp chứa gt, 1-shot):</strong></p><p>Hình ảnh trực quan hóa của các mặt nạ phân đoạn đã được lưu tại <code>data/my_custom_dataset/annotations/custom_references_with_SAM_segm/references_visualisations/</code>.</p><p>
| Hình ảnh tham chiếu 1-shot cho CHIM 🐦 (tự động phân đoạn bằng SAM) | Hình ảnh tham chiếu 1-shot cho THUYỀN ⛵ (tự động phân đoạn bằng SAM) |
|:---------------------------------:|:----------------------------------:|
| <img src="https://github.com/user-attachments/assets/65d38dc4-1454-43cd-9600-e8efc67b3a82" alt="bird_1_with_SAM_segm" width="500"/> | <img src="https://github.com/user-attachments/assets/43a558ad-50ca-4715-8285-9aa3268843c6" alt="boat_1_with_SAM_segm" width="500"/> |</p><h3>0.2 Chuyển đổi chú thích coco sang tập tin pickle</h3></p><pre><code class="language-bash">python no_time_to_train/dataset/coco_to_pkl.py \
    data/my_custom_dataset/annotations/custom_references_with_segm.json \
    data/my_custom_dataset/annotations/custom_references_with_segm.pkl \
    1</code></pre>
<h3>1. Đổ đầy bộ nhớ với các tham chiếu</h3></p><p>Đầu tiên, định nghĩa các biến hữu ích và tạo một thư mục để lưu kết quả. Để hiển thị nhãn đúng cách, tên các lớp phải được sắp xếp theo id danh mục như trong tệp json. Ví dụ, <code>bird</code> có id danh mục là <code>16</code>, <code>boat</code> có id danh mục là <code>9</code>. Do đó, <code>CAT_NAMES=boat,bird</code>.</p><pre><code class="language-bash">DATASET_NAME=my_custom_dataset
DATASET_PATH=data/my_custom_dataset
CAT_NAMES=boat,bird
CATEGORY_NUM=2
SHOT=1
YAML_PATH=no_time_to_train/pl_configs/matching_cdfsod_template.yaml
PATH_TO_SAVE_CKPTS=./tmp_ckpts/my_custom_dataset
mkdir -p $PATH_TO_SAVE_CKPTS</code></pre>
Chạy bước 1:</p><pre><code class="language-bash">python run_lightening.py test --config $YAML_PATH \
    --model.test_mode fill_memory \
    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory.pth \
    --model.init_args.dataset_cfgs.fill_memory.root $DATASET_PATH/images \
    --model.init_args.dataset_cfgs.fill_memory.json_file $DATASET_PATH/annotations/custom_references_with_segm.json \
    --model.init_args.dataset_cfgs.fill_memory.memory_pkl $DATASET_PATH/annotations/custom_references_with_segm.pkl \
    --model.init_args.dataset_cfgs.fill_memory.memory_length $SHOT \
    --model.init_args.dataset_cfgs.fill_memory.cat_names $CAT_NAMES \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --trainer.devices 1</code></pre>
<h3>2. Xử lý hậu kỳ bộ nhớ ngân hàng</h3></p><pre><code class="language-bash">python run_lightening.py test --config $YAML_PATH \
    --model.test_mode postprocess_memory \
    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory.pth \
    --out_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory_postprocessed.pth \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --trainer.devices 1</code></pre>
<h3>3. Suy luận trên các ảnh mục tiêu</h3></p><p>Nếu <code>ONLINE_VIS</code> được đặt thành True, kết quả dự đoán sẽ được lưu trong <code>results_analysis/my_custom_dataset/</code> và hiển thị ngay khi được tính toán. LƯU Ý rằng chạy với chế độ trực quan hóa trực tuyến sẽ chậm hơn nhiều.</p><p>Bạn có thể thay đổi ngưỡng điểm số <code>VIS_THR</code> để xem nhiều hoặc ít đối tượng được phân đoạn hơn.</p><pre><code class="language-bash">ONLINE_VIS=True
VIS_THR=0.4
python run_lightening.py test --config $YAML_PATH \
    --model.test_mode test \
    --ckpt_path $PATH_TO_SAVE_CKPTS/$DATASET_NAME\_$SHOT\_refs_memory_postprocessed.pth \
    --model.init_args.model_cfg.dataset_name $DATASET_NAME \
    --model.init_args.model_cfg.memory_bank_cfg.length $SHOT \
    --model.init_args.model_cfg.memory_bank_cfg.category_num $CATEGORY_NUM \
    --model.init_args.model_cfg.test.imgs_path $DATASET_PATH/images \
    --model.init_args.model_cfg.test.online_vis $ONLINE_VIS \
    --model.init_args.model_cfg.test.vis_thr $VIS_THR \
    --model.init_args.dataset_cfgs.test.root $DATASET_PATH/images \
    --model.init_args.dataset_cfgs.test.json_file $DATASET_PATH/annotations/custom_targets.json \
    --model.init_args.dataset_cfgs.test.cat_names $CAT_NAMES \
    --trainer.devices 1</code></pre>
<h3>Kết quả</h3></p><p>Các chỉ số hiệu suất (với đúng các tham số như các lệnh trên) nên là:</p><pre><code class="language-">BBOX RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.478</p><p>SEGM RESULTS:
  Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.458</code></pre>
Kết quả trực quan được lưu trong <code>results_analysis/my_custom_dataset/</code>. Lưu ý rằng phương pháp của chúng tôi hoạt động với các trường hợp âm tính giả, tức là các hình ảnh không chứa bất kỳ đối tượng nào thuộc các lớp mong muốn.</p><p><em>Bấm vào hình để phóng to ⬇️</em></p><p>| Ảnh mục tiêu với thuyền ⛵ (trái GT, phải dự đoán) | Ảnh mục tiêu với chim 🐦 (trái GT, phải dự đoán) |
|:----------------------:|:----------------------:|
| <img src="https://github.com/user-attachments/assets/678dc15a-dd3b-49d5-9287-6290da16aa6b" alt="000000459673"> | <img src="https://github.com/user-attachments/assets/fe306e48-af49-4d83-ac82-76fac6c456d1" alt="000000407180"> |</p><p>| Ảnh mục tiêu với thuyền và chim ⛵🐦 (trái GT, phải dự đoán) | Ảnh mục tiêu không có thuyền hoặc chim 🚫 (trái GT, phải dự đoán) |
|:---------------------------------:|:----------------------------------:|
| <img src="https://github.com/user-attachments/assets/9849b227-7f43-43d7-81ea-58010a623ad5" alt="000000517410"> | <img src="https://github.com/user-attachments/assets/7587700c-e09d-4cf6-8590-3df129c2568e" alt="000000460598"> |</p><h2>📚 Trích dẫn</h2></p><p>Nếu bạn sử dụng công trình này, vui lòng trích dẫn chúng tôi:</p><pre><code class="language-bibtex">@article{espinosa2025notimetotrain,
  title={No time to train! Training-Free Reference-Based Instance Segmentation},
  author={Miguel Espinosa and Chenhongyi Yang and Linus Ericsson and Steven McDonagh and Elliot J. Crowley},
  journal={arXiv preprint arXiv:2507.02798},
  year={2025},
  primaryclass={cs.CV}
}</code></pre></p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-09-06

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/miquel-espinosa/no-time-to-train/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>