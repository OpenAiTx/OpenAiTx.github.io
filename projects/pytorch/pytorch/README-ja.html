<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch - Read pytorch documentation in Japanese. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read pytorch documentation in Japanese. This project has 0 stars on GitHub.">
    <meta name="keywords" content="pytorch, Japanese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "pytorch",
  "description": "Read pytorch documentation in Japanese. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "pytorch"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/pytorch/pytorch/README-ja.html",
  "sameAs": "https://raw.githubusercontent.com/pytorch/pytorch/master/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    pytorch
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Japanese</span>
                <span>by pytorch</span>
            </div>
        </div>
        
        <div class="content">
            <p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="PyTorch ロゴ"></p><p>--------------------------------------------------------------------------------</p><p>PyTorch は、次の2つの高レベル機能を提供する Python パッケージです。
<ul><li>強力な GPU アクセラレーションを備えた Tensor 計算（NumPy のようなもの）</li>
<li>テープベースの自動微分システム上に構築されたディープニューラルネットワーク</li></p><p></ul>必要に応じて、NumPy、SciPy、Cython などお好きな Python パッケージを再利用して、PyTorch を拡張できます。</p><p>私たちの trunk health（継続的インテグレーションのシグナル）は <a href="https://hud.pytorch.org/ci/pytorch/pytorch/main" target="_blank" rel="noopener noreferrer">hud.pytorch.org</a> で確認できます。</p><p><!-- toc --></p><ul><li><a href="#more-about-pytorch" target="_blank" rel="noopener noreferrer">PyTorch についてさらに詳しく</a></li>
  <li><a href="#a-gpu-ready-tensor-library" target="_blank" rel="noopener noreferrer">GPU 対応のテンソルライブラリ</a></li>
  <li><a href="#dynamic-neural-networks-tape-based-autograd" target="_blank" rel="noopener noreferrer">動的ニューラルネットワーク: テープベース自動微分</a></li>
  <li><a href="#python-first" target="_blank" rel="noopener noreferrer">Python ファースト</a></li>
  <li><a href="#imperative-experiences" target="_blank" rel="noopener noreferrer">命令型の体験</a></li>
  <li><a href="#fast-and-lean" target="_blank" rel="noopener noreferrer">高速かつ軽量</a></li>
  <li><a href="#extensions-without-pain" target="_blank" rel="noopener noreferrer">簡単な拡張性</a></li>
<li><a href="#installation" target="_blank" rel="noopener noreferrer">インストール</a></li>
  <li><a href="#binaries" target="_blank" rel="noopener noreferrer">バイナリ</a></li>
    <li><a href="#nvidia-jetson-platforms" target="_blank" rel="noopener noreferrer">NVIDIA Jetson プラットフォーム</a></li>
  <li><a href="#from-source" target="_blank" rel="noopener noreferrer">ソースからのビルド</a></li>
    <li><a href="#prerequisites" target="_blank" rel="noopener noreferrer">前提条件</a></li>
      <li><a href="#nvidia-cuda-support" target="_blank" rel="noopener noreferrer">NVIDIA CUDA サポート</a></li>
      <li><a href="#amd-rocm-support" target="_blank" rel="noopener noreferrer">AMD ROCm サポート</a></li>
      <li><a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">Intel GPU サポート</a></li>
    <li><a href="#get-the-pytorch-source" target="_blank" rel="noopener noreferrer">PyTorch ソースの取得</a></li>
    <li><a href="#install-dependencies" target="_blank" rel="noopener noreferrer">依存関係のインストール</a></li>
    <li><a href="#install-pytorch" target="_blank" rel="noopener noreferrer">PyTorch のインストール</a></li>
      <li><a href="#adjust-build-options-optional" target="_blank" rel="noopener noreferrer">ビルドオプションの調整（オプション）</a></li>
  <li><a href="#docker-image" target="_blank" rel="noopener noreferrer">Docker イメージ</a></li>
    <li><a href="#using-pre-built-images" target="_blank" rel="noopener noreferrer">事前ビルドイメージの利用</a></li>
    <li><a href="#building-the-image-yourself" target="_blank" rel="noopener noreferrer">イメージの自作</a></li>
  <li><a href="#building-the-documentation" target="_blank" rel="noopener noreferrer">ドキュメントのビルド</a></li>
    <li><a href="#building-a-pdf" target="_blank" rel="noopener noreferrer">PDF のビルド</a></li>
  <li><a href="#previous-versions" target="_blank" rel="noopener noreferrer">過去バージョン</a></li>
<li><a href="#getting-started" target="_blank" rel="noopener noreferrer">はじめに</a></li>
<li><a href="#resources" target="_blank" rel="noopener noreferrer">リソース</a></li>
<li><a href="#communication" target="_blank" rel="noopener noreferrer">コミュニケーション</a></li>
<li><a href="#releases-and-contributing" target="_blank" rel="noopener noreferrer">リリースとコントリビュート</a></li>
<li><a href="#the-team" target="_blank" rel="noopener noreferrer">チーム</a></li>
<li><a href="#license" target="_blank" rel="noopener noreferrer">ライセンス</a></li></p><p></ul><!-- tocstop --></p><h2>PyTorch についてさらに詳しく</h2></p><p><a href="https://pytorch.org/tutorials/beginner/basics/intro.html" target="_blank" rel="noopener noreferrer">PyTorch の基本を学ぶ</a></p><p>詳細レベルでは、PyTorch は以下のコンポーネントから成るライブラリです。</p><p>| コンポーネント | 説明 |
| ---- | --- |
| <a href="https://pytorch.org/docs/stable/torch.html" target="_blank" rel="noopener noreferrer"><strong>torch</strong></a> | NumPy のようなテンソルライブラリで、強力な GPU サポートを持つ |
| <a href="https://pytorch.org/docs/stable/autograd.html" target="_blank" rel="noopener noreferrer"><strong>torch.autograd</strong></a> | torch の全ての微分可能なテンソル操作をサポートするテープベース自動微分ライブラリ |
| <a href="https://pytorch.org/docs/stable/jit.html" target="_blank" rel="noopener noreferrer"><strong>torch.jit</strong></a> | PyTorch コードからシリアライズ可能かつ最適化可能なモデルを作成するためのコンパイルスタック（TorchScript） |
| <a href="https://pytorch.org/docs/stable/nn.html" target="_blank" rel="noopener noreferrer"><strong>torch.nn</strong></a> | autograd と深く統合されたニューラルネットワークライブラリ。最大の柔軟性を持つよう設計 |
| <a href="https://pytorch.org/docs/stable/multiprocessing.html" target="_blank" rel="noopener noreferrer"><strong>torch.multiprocessing</strong></a> | Python のマルチプロセッシング。ただし、torch テンソルの魔法のようなメモリ共有機能付き。データローディングや Hogwild トレーニングに便利 |
| <a href="https://pytorch.org/docs/stable/data.html" target="_blank" rel="noopener noreferrer"><strong>torch.utils</strong></a> | DataLoader やその他のユーティリティ関数 |</p><p>通常、PyTorch は以下の用途で使われます：</p><ul><li>NumPy の代替として、GPU の力を活用したい場合</li>
<li>最大限の柔軟性と速度を提供するディープラーニング研究プラットフォームとして</li></p><p></ul>詳細解説：</p><h3>GPU 対応のテンソルライブラリ</h3></p><p>NumPy を使ったことがあれば、テンソル（別名 ndarray）を使ったことがあるはずです。</p><p><img src="./docs/source/_static/img/tensor_illustration.png" alt="Tensor illustration"></p><p>PyTorch は、CPU または GPU 上で動作するテンソルを提供し、計算を大幅に高速化します。</p><p>スライス、インデックス操作、数学演算、線形代数、リダクションなど、幅広いテンソル操作ルーチンを提供し、
科学計算のニーズに合うよう設計されています。
そして、とても高速です！</p><h3>動的ニューラルネットワーク: テープベース自動微分</h3></p><p>PyTorch には、ニューラルネットワークを構築するユニークな方法があります：テープレコーダーを使って記録・再生します。</p><p>TensorFlow、Theano、Caffe、CNTK などほとんどのフレームワークは静的なネットワーク構造を持っています。
一度ネットワークを構築すると、同じ構造を何度も再利用しなければなりません。
ネットワークの挙動を変えるには、一からやり直す必要があります。</p><p>PyTorch では、逆モード自動微分（reverse-mode auto-differentiation）という技術を使い、
ネットワークの挙動を遅延やオーバーヘッドなしに自由に変更できます。
この発想は、いくつかの研究論文や
<a href="https://github.com/twitter/torch-autograd" target="_blank" rel="noopener noreferrer">torch-autograd</a>、
<a href="https://github.com/HIPS/autograd" target="_blank" rel="noopener noreferrer">autograd</a>、
<a href="https://chainer.org" target="_blank" rel="noopener noreferrer">Chainer</a> など現在・過去の実装からインスパイアされています。</p><p>この技術は PyTorch 固有ではありませんが、PyTorch の実装は現時点で最速クラスです。
スピードと柔軟性の両方を手に入れることができます。</p><p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="Dynamic graph"></p><h3>Python ファースト</h3></p><p>PyTorch は、巨大な C++ フレームワークへの Python バインディングではありません。
Python との深い統合を前提に設計されています。
<a href="https://www.numpy.org/" target="_blank" rel="noopener noreferrer">NumPy</a> / <a href="https://www.scipy.org/" target="_blank" rel="noopener noreferrer">SciPy</a> / <a href="https://scikit-learn.org" target="_blank" rel="noopener noreferrer">scikit-learn</a> のように自然に使えます。
お気に入りのライブラリを使って Python でニューラルネットワーク層を記述したり、
<a href="https://cython.org/" target="_blank" rel="noopener noreferrer">Cython</a> や <a href="http://numba.pydata.org/" target="_blank" rel="noopener noreferrer">Numba</a> などのパッケージも利用できます。
再発明する必要のないところは、再発明しないことを目指しています。</p><h3>命令型の体験</h3></p><p>PyTorch は直感的で、思考の流れに沿った、使いやすい設計です。
コードを1行書くと、その行が即実行されます。非同期的な世界観はありません。
デバッガに入ったりエラーメッセージやスタックトレースを受け取る場合も、理解が容易です。
スタックトレースは、まさに自分が書いたコードの箇所を指します。
悪いスタックトレースや非同期・ブラックボックスな実行エンジンのせいで
何時間もデバッグに費やすことがないよう願っています。</p><h3>高速かつ軽量</h3></p><p>PyTorch はフレームワークとしてのオーバーヘッドが最小限です。
<a href="https://software.intel.com/mkl" target="_blank" rel="noopener noreferrer">Intel MKL</a> や NVIDIA の
(<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">cuDNN</a>, <a href="https://developer.nvidia.com/nccl" target="_blank" rel="noopener noreferrer">NCCL</a>) などの
アクセラレーションライブラリと統合し、最大限の速度を実現しています。
コアとなる CPU・GPU のテンソルやニューラルネットワークのバックエンドは
成熟しており、長年にわたってテストされています。</p><p>そのため、PyTorch は小さなニューラルネットワークでも大きなニューラルネットワークでも
非常に高速です。</p><p>PyTorch のメモリ使用量は Torch や一部の代替案に比べて非常に効率的です。
GPU 用のカスタムメモリアロケータを作成し、
ディープラーニングモデルが最大限メモリ効率良くなるよう設計しています。
これにより、より大きなディープラーニングモデルの学習が可能になります。</p><h3>簡単な拡張性</h3></p><p>新しいニューラルネットワークモジュールの作成や、PyTorch の Tensor API とのインターフェースは
シンプルで最小限の抽象化で実現できるよう設計されています。</p><p>torch API を用いて Python で新しいニューラルネットワーク層を記述したり、
<a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html" target="_blank" rel="noopener noreferrer">NumPy ベースのライブラリ（SciPy など）</a> を使うこともできます。</p><p>C/C++ で層を書きたい場合は、効率的でボイラープレートの少ない便利な拡張 API を提供しています。
ラッパーコードを書く必要はありません。
<a href="https://pytorch.org/tutorials/advanced/cpp_extension.html" target="_blank" rel="noopener noreferrer">チュートリアルはこちら</a>、
<a href="https://github.com/pytorch/extension-cpp" target="_blank" rel="noopener noreferrer">サンプルはこちら</a> をご参照ください。</p><h2>インストール</h2></p><h3>バイナリ</h3>
Conda または pip wheels でバイナリをインストールするためのコマンドは公式サイトにあります: <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">https://pytorch.org/get-started/locally/</a></p><p>#### NVIDIA Jetson プラットフォーム</p><p>NVIDIA の Jetson Nano, Jetson TX1/TX2, Jetson Xavier NX/AGX, Jetson AGX Orin 向けの Python wheels は <a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048" target="_blank" rel="noopener noreferrer">こちら</a> で提供されており、L4T コンテナは <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch" target="_blank" rel="noopener noreferrer">こちら</a> で公開されています。</p><p>JetPack 4.2 以上が必要です。<a href="https://github.com/dusty-nv" target="_blank" rel="noopener noreferrer"><code>@dusty-nv</code></a> および <a href="https://github.com/ptrblck" target="_blank" rel="noopener noreferrer"><code>@ptrblck</code></a> がメンテナンスしています。</p><h3>ソースからのビルド</h3></p><p>#### 前提条件
ソースからインストールする場合、以下が必要です：
<ul><li>Python 3.9 以上</li>
<li>C++17 を完全サポートするコンパイラ（clang または gcc、Linux では gcc 9.4.0 以上が必要）</li>
<li>Visual Studio または Visual Studio Build Tool（Windows のみ）</li></p><p></ul>\* PyTorch CI では Visual C++ BuildTools を使用しています。これは Visual Studio Enterprise, Professional, Community Edition に付属しています。ビルドツールは https://visualstudio.microsoft.com/visual-cpp-build-tools/ からもインストール可能です。ビルドツールは Visual Studio Code にはデフォルトでは付属しません。</p><p>環境構築例を以下に示します。</p><ul><li>Linux:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>/bin/activate
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME></code></pre></p><ul><li>Windows:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>\Scripts\activate.bat
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME>
$ call "C:\Program Files\Microsoft Visual Studio\<VERSION>\Community\VC\Auxiliary\Build\vcvarsall.bat" x64</code></pre></p><p>##### NVIDIA CUDA サポート
CUDA サポート付きでコンパイルする場合は、<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">サポートマトリクスから対応 CUDA バージョンを選択</a>し、下記をインストールしてください：
<ul><li><a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener noreferrer">NVIDIA CUDA</a></li>
<li><a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">NVIDIA cuDNN</a> v8.5 以上</li>
<li>CUDA に対応した <a href="https://gist.github.com/ax3l/9489132" target="_blank" rel="noopener noreferrer">コンパイラ</a></li></p><p></ul>注：cuDNN のバージョンと各種対応 CUDA・CUDA ドライバ・NVIDIA ハードウェアについては <a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html" target="_blank" rel="noopener noreferrer">cuDNN Support Matrix</a> を参照してください。</p><p>CUDA サポートを無効化する場合は、環境変数 <code>USE_CUDA=0</code> をエクスポートしてください。
他にも有用な環境変数は <code>setup.py</code> に記載されています。</p><p>NVIDIA の Jetson プラットフォーム（Jetson Nano, TX1, TX2, AGX Xavier）向けのビルドの場合、Jetson Nano 用 PyTorch インストール手順は <a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/" target="_blank" rel="noopener noreferrer">こちら</a> を参照してください。</p><p>##### AMD ROCm サポート
ROCm サポート付きでコンパイルする場合は、下記をインストールしてください。
<ul><li><a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html" target="_blank" rel="noopener noreferrer">AMD ROCm</a> 4.0 以上</li>
<li>ROCm は現在 Linux システムのみサポートしています。</li></p><p></ul>デフォルトではビルドシステムは ROCm を <code>/opt/rocm</code> にインストールされているものと期待します。別ディレクトリの場合、環境変数 <code>ROCM_PATH</code> で ROCm のインストールディレクトリを指定してください。ビルドシステムは自動で AMD GPU アーキテクチャを検出します。必要なら <code>PYTORCH_ROCM_ARCH</code> で明示的指定も可能です。<a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus" target="_blank" rel="noopener noreferrer">AMD GPU アーキテクチャ</a> を参照。</p><p>ROCm サポートを無効化する場合は、環境変数 <code>USE_ROCM=0</code> をエクスポートしてください。
他にも有用な環境変数は <code>setup.py</code> に記載されています。</p><p>##### Intel GPU サポート
Intel GPU サポート付きでコンパイルする場合は、下記を参照してください。
<ul><li><a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html" target="_blank" rel="noopener noreferrer">PyTorch Prerequisites for Intel GPUs</a> の手順</li>
<li>Intel GPU は Linux および Windows をサポート</li></p><p></ul>Intel GPU サポートを無効化する場合は、環境変数 <code>USE_XPU=0</code> をエクスポートしてください。
他にも有用な環境変数は <code>setup.py</code> に記載されています。</p><p>#### PyTorch ソースの取得
<pre><code class="language-bash">git clone https://github.com/pytorch/pytorch
cd pytorch
<h1>既存のチェックアウトを更新する場合</h1>
git submodule sync
git submodule update --init --recursive</code></pre></p><p>#### 依存関係のインストール</p><p><strong>共通</strong></p><pre><code class="language-bash">conda install cmake ninja
<h1>ソースコード取得後、PyTorch ディレクトリで実行</h1>
pip install -r requirements.txt</code></pre></p><p><strong>Linux の場合</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>CUDA のみ: GPU 向け LAPACK サポートが必要な場合</h1>
<h1>magma インストール: 有効な conda 環境で実行し、CUDA バージョンを指定</h1>
.ci/docker/common/install_magma_conda.sh 12.4</p><h1>（オプション）torch.compile with inductor/triton 利用時、対応バージョンの triton をインストール</h1>
<h1>クローン後、pytorch ディレクトリで実行</h1>
<h1>Intel GPU サポート時は、コマンド実行前に明示的に <code>export USE_XPU=1</code> してください。</h1>
make triton</code></pre></p><p><strong>MacOS の場合</strong></p><pre><code class="language-bash"># Intel x86 プロセッサ搭載機のみ追加
pip install mkl-static mkl-include
<h1>torch.distributed が必要な場合のみ追加</h1>
conda install pkg-config libuv</code></pre></p><p><strong>Windows の場合</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>torch.distributed が必要な場合のみ追加</h1>
<h1>Windows での distributed パッケージサポートはプロトタイプ機能です。変更されることがあります。</h1>
conda install -c conda-forge libuv=1.39</code></pre></p><p>#### PyTorch のインストール
<strong>Linux の場合</strong></p><p>AMD ROCm 向けにコンパイルする場合、最初に以下を実行してください：
<pre><code class="language-bash"># ROCm 用コンパイル時のみ実行
python tools/amd_build/build_amd.py</code></pre></p><p>PyTorch のインストール
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py develop</code></pre></p><p><strong>macOS の場合</strong></p><pre><code class="language-bash">python3 setup.py develop</code></pre></p><p><strong>Windows の場合</strong></p><p>レガシー Python コードのビルド方法は <a href="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda" target="_blank" rel="noopener noreferrer">Building on legacy code and CUDA</a> を参照してください。</p><p><strong>CPU のみのビルド</strong></p><p>このモードでは、PyTorch の計算は GPU ではなく CPU で実行されます。</p><pre><code class="language-cmd">python setup.py develop</code></pre></p><p>OpenMP に関する注意：推奨される OpenMP 実装は Intel OpenMP（iomp）です。iomp にリンクするには、ライブラリを手動でダウンロードし、<code>CMAKE_INCLUDE_PATH</code> および <code>LIB</code> を調整してください。<a href="https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source" target="_blank" rel="noopener noreferrer">こちらの手順</a> を参照。設定しない場合、Microsoft Visual C OpenMP ランタイム（vcomp）が使われます。</p><p><strong>CUDA ベースのビルド</strong></p><p>このモードでは、CUDA を介して PyTorch の計算が GPU で高速化されます。</p><p><a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm" target="_blank" rel="noopener noreferrer">NVTX</a> が CUDA ビルドに必要です。
NVTX は CUDA 配布物の一部で "Nsight Compute" と呼ばれています。すでに CUDA をインストール済みなら、再度 CUDA インストールを実行し、該当チェックボックスをオンにしてください。
CUDA + Nsight Compute は Visual Studio の後にインストールしてください。</p><p>現在、VS 2017 / 2019、および Ninja が CMake のジェネレータとしてサポートされています。<code>ninja.exe</code> が <code>PATH</code> に見つかった場合は Ninja がデフォルト、なければ VS 2017/2019 が使われます。
<br/> Ninja 使用時は最新の MSVC がツールチェーンとして選択されます。</p><p>追加ライブラリとして
<a href="https://developer.nvidia.com/magma" target="_blank" rel="noopener noreferrer">Magma</a>, <a href="https://github.com/oneapi-src/oneDNN" target="_blank" rel="noopener noreferrer">oneDNN（MKLDNN/DNNL）</a>, <a href="https://github.com/mozilla/sccache" target="_blank" rel="noopener noreferrer">Sccache</a> などが必要なことがあります。<a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers" target="_blank" rel="noopener noreferrer">インストールヘルパー</a> を参照してください。</p><p>他環境変数の設定例は <a href="https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat" target="_blank" rel="noopener noreferrer">build_pytorch.bat</a> を参照してください。</p><pre><code class="language-cmd">cmd</p><p>:: mkl パッケージをダウンロード・解凍後に環境変数を設定してください。
:: そうでないと CMake が <code>Could NOT find OpenMP</code> エラーを出します。
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%</p><p>:: 前セクション内容をよく読んでから実行してください。
:: [オプション] Ninja および Visual Studio で使うツールセットを上書きしたい場合は下記スクリプトを実行。
:: "Visual Studio 2019 Developer Command Prompt" が自動で起動します。
:: Visual Studio ジェネレータ利用時は CMake >= 3.12 が必要です。
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f "usebackq tokens=<em>" %i in (<code>"%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe" -version [15^,17^) -products </em> -latest -property installationPath</code>) do call "%i\VC\Auxiliary\Build\vcvarsall.bat" x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%</p><p>:: [オプション] CUDA のホストコンパイラを上書きしたい場合
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe</p><p>python setup.py develop
</code></pre></p><p><strong>Intel GPU ビルド</strong></p><p>このモードでは Intel GPU サポート付きで PyTorch をビルドします。</p><p><a href="#prerequisites" target="_blank" rel="noopener noreferrer">共通の前提条件</a> および <a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">Intel GPU 用の前提条件</a> を事前にインストールし、
環境変数を構成してください。ビルドツールは <code>Visual Studio 2022</code> が必要です。</p><p>その後、以下のコマンドでビルドできます。</p><pre><code class="language-cmd">:: CMD コマンド:
:: CMAKE_PREFIX_PATH をセットして対応パッケージを見つけやすくします
:: %CONDA_PREFIX% は <code>conda activate custom_env</code> 後のみ機能します</p><p>if defined CMAKE_PREFIX_PATH (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%"
) else (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library"
)</p><p>python setup.py develop</code></pre></p><p>##### ビルドオプションの調整（オプション）</p><p>cmake 変数の設定を（ビルド前に）調整できます。たとえば CuDNN や BLAS のディレクトリを手動設定したい場合など。</p><p>Linux の場合
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py build --cmake-only
ccmake build  # または cmake-gui build</code></pre></p><p>macOS の場合
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only
ccmake build  # または cmake-gui build</code></pre></p><h3>Docker イメージ</h3></p><p>#### 事前ビルドイメージの利用</p><p>Docker Hub から事前ビルドの docker イメージを pull し、docker v19.03+ で実行できます。</p><pre><code class="language-bash">docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest</code></pre></p><p>PyTorch はプロセス間でデータ共有のため共有メモリを使うため、torch のマルチプロセッシング機能
（例：マルチスレッドデータローダ）が使われる場合、コンテナのデフォルト共有メモリサイズでは足りません。
<code>--ipc=host</code> または <code>--shm-size</code> オプションで共有メモリサイズを増やしてください。</p><p>#### イメージの自作</p><p><strong>注意:</strong> docker バージョン > 18.06 でビルドしてください。</p><p><code>Dockerfile</code> は CUDA 11.1 サポート・cuDNN v8 対応イメージをビルドするためのものです。
<code>PYTHON_VERSION=x.y</code> を make 変数で指定すれば、Miniconda で使う Python バージョンを指定できます。
未指定ならデフォルト値が使われます。</p><pre><code class="language-bash">make -f docker.Makefile
<h1>イメージは docker.io/${your_docker_username}/pytorch でタグ付けされます</code></pre></h1></p><p>ビルド時に追加の CMake 変数を指定したい場合は、<code>CMAKE_VARS="..."</code> 環境変数を使ってください。
利用可能な変数一覧は <a href="./setup.py" target="_blank" rel="noopener noreferrer">setup.py</a> を参照。</p><pre><code class="language-bash">make -f docker.Makefile</code></pre></p><h3>ドキュメントのビルド</h3></p><p>さまざまな形式でドキュメントをビルドするには、<a href="http://www.sphinx-doc.org" target="_blank" rel="noopener noreferrer">Sphinx</a> と pytorch_sphinx_theme2 が必要です。</p><p>ローカルでドキュメントをビルドする前に、<code>torch</code> を環境にインストールしてください。
小さな修正であれば <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">Getting Started</a> の説明に従い
nightly バージョンをインストールできます。</p><p>新しいモジュール追加や docstring 追加のような大きな修正の場合、<a href="#from-source" target="_blank" rel="noopener noreferrer">ソースからインストール</a>が必要です。
docstring 規約については <a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines" target="_blank" rel="noopener noreferrer">Docstring Guidelines</a> を参照。</p><pre><code class="language-bash">cd docs/
pip install -r requirements.txt
make html
make serve</code></pre></p><p><code>make</code> を実行すると全出力形式の一覧が得られます。</p><p>katex エラーが出た場合は <code>npm install katex</code> を実行してください。解決しない場合は
<code>npm install -g katex</code> を試してください。</p><blockquote>[!NOTE]</blockquote>
<blockquote><code>nodejs</code> を別のパッケージマネージャ（例：<code>conda</code>）でインストールした場合、<code>npm</code> でインストールされる <code>katex</code> バージョンが</blockquote>
<blockquote><code>nodejs</code> のバージョンと互換性がなくなり、ドキュメントビルドが失敗することがあります。</blockquote>
<blockquote>動作確認済みの組み合わせは <code>node@6.13.1</code> と <code>katex@0.13.18</code> です。後者は</blockquote>
<blockquote>``<code>npm install -g katex@0.13.18</code>`<code> でインストールできます。</blockquote></p><blockquote>[!NOTE]</blockquote>
<blockquote>numpy の互換性エラーが出る場合は、次を実行してください:</blockquote>
<blockquote><pre><code class="language-">> pip install 'numpy<2'</blockquote>
<blockquote></code>`<code></blockquote></p><p>CI で実行される依存関係に変更を加えた場合は、
</code>.ci/docker/requirements-docs.txt<code> ファイルを編集してください。</p><p>#### PDF のビルド</p><p>PyTorch ドキュメント全体の PDF をビルドするには、
</code>texlive<code> および LaTeX をインストールしてください。macOS では下記でインストールできます：
</code></pre>
brew install --cask mactex
</code>`<code></p><p>PDF 作成手順：</p><ul><li>実行：</li></p><p>   </ul></code>`<code>
   make latexpdf
   </code>`<code></p><p>   </code>build/latex<code> ディレクトリに必要ファイルが生成されます。</p><ul><li>このディレクトリに移動して下記を実行：</li></p><p>   </ul></code>`<code>
   make LATEXOPTS="-interaction=nonstopmode"
   </code>`<code></p><p>   これで </code>pytorch.pdf` が生成されます。目次やインデックスを正しく生成するために、もう一度このコマンドを実行してください。</p><blockquote>[!NOTE]</blockquote>
<blockquote>PDF ビューアの <strong>Table of Contents</strong> 表示を使うと目次が見られます。</blockquote></p><h3>過去バージョン</h3></p><p>過去の PyTorch バージョンのインストール手順やバイナリは
<a href="https://pytorch.org/get-started/previous-versions" target="_blank" rel="noopener noreferrer">公式サイト</a> で確認できます。</p><h2>はじめに</h2></p><p>入門に役立つ3つのポイント：
<ul><li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">チュートリアル: PyTorch の理解と利用を始める</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">サンプル: 各ドメイン向けの分かりやすい PyTorch コード</a></li>
<li><a href="https://pytorch.org/docs/" target="_blank" rel="noopener noreferrer">API リファレンス</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md" target="_blank" rel="noopener noreferrer">用語集</a></li></p><p></ul><h2>リソース</h2></p><ul><li><a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">PyTorch.org</a></li>
<li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">PyTorch チュートリアル</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">PyTorch サンプル</a></li>
<li><a href="https://pytorch.org/hub/" target="_blank" rel="noopener noreferrer">PyTorch モデル</a></li>
<li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188" target="_blank" rel="noopener noreferrer">Udacity による PyTorch 入門</a></li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229" target="_blank" rel="noopener noreferrer">Udacity による PyTorch で始める機械学習</a></li>
<li><a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch" target="_blank" rel="noopener noreferrer">Coursera による PyTorch で学ぶディープニューラルネットワーク</a></li>
<li><a href="https://twitter.com/PyTorch" target="_blank" rel="noopener noreferrer">PyTorch Twitter</a></li>
<li><a href="https://pytorch.org/blog/" target="_blank" rel="noopener noreferrer">PyTorch ブログ</a></li>
<li><a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw" target="_blank" rel="noopener noreferrer">PyTorch YouTube</a></li></p><p></ul><h2>コミュニケーション</h2>
<ul><li>フォーラム: 実装・研究などの議論 https://discuss.pytorch.org</li>
<li>GitHub Issues: バグ報告、機能要望、インストール問題、RFC、意見交換など</li>
<li>Slack: <a href="https://pytorch.slack.com/" target="_blank" rel="noopener noreferrer">PyTorch Slack</a> には中級～上級 PyTorch ユーザー・開発者向けのチャットや議論の場があります。初心者の方は主に <a href="https://discuss.pytorch.org" target="_blank" rel="noopener noreferrer">PyTorch Forums</a> をご利用ください。Slack 招待が必要な場合は次のフォームを記入してください: https://goo.gl/forms/PP1AGvNHpSaJP8to1</li>
<li>ニュースレター: ノイズなしで重要なお知らせのみの一方向メールニュース。登録はこちら: https://eepurl.com/cbG0rv</li>
<li>Facebook ページ: PyTorch の重要なお知らせ https://www.facebook.com/pytorch</li>
<li>ブランドガイドラインは <a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">pytorch.org</a> をご参照ください。</li></p><p></ul><h2>リリースとコントリビュート</h2></p><p>通常、PyTorch は年3回のマイナーリリースを行っています。バグを見つけたら <a href="https://github.com/pytorch/pytorch/issues" target="_blank" rel="noopener noreferrer">Issue を登録</a> してください。</p><p>全てのコントリビュートを歓迎します。バグ修正のコントリビュートは事前相談なしで構いません。</p><p>新機能・ユーティリティ・コア拡張などを提案したい場合は、まず issue を立ててご相談ください。
事前相談なしで PR を送ると、プロジェクトの方向性次第でリジェクトされる場合があります。</p><p>PyTorch へのコントリビュート方法は <a href="CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">Contribution ページ</a> を、
リリース情報は <a href="RELEASE.md" target="_blank" rel="noopener noreferrer">Release ページ</a> を参照してください。</p><h2>チーム</h2></p><p>PyTorch は、多くの優れたエンジニア・研究者によるコミュニティ主導のプロジェクトです。</p><p>現在の PyTorch メンテナーは <a href="http://soumith.ch" target="_blank" rel="noopener noreferrer">Soumith Chintala</a>, <a href="https://github.com/gchanan" target="_blank" rel="noopener noreferrer">Gregory Chanan</a>, <a href="https://github.com/dzhulgakov" target="_blank" rel="noopener noreferrer">Dmytro Dzhulgakov</a>, <a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a>, <a href="https://github.com/malfet" target="_blank" rel="noopener noreferrer">Nikita Shulga</a> です。その他、多数の才能ある個人が多様な形で貢献しています。
（抜粋・随時拡大中）：<a href="https://github.com/killeent" target="_blank" rel="noopener noreferrer">Trevor Killeen</a>, <a href="https://github.com/chsasank" target="_blank" rel="noopener noreferrer">Sasank Chilamkurthy</a>, <a href="https://github.com/szagoruyko" target="_blank" rel="noopener noreferrer">Sergey Zagoruyko</a>, <a href="https://github.com/adamlerer" target="_blank" rel="noopener noreferrer">Adam Lerer</a>, <a href="https://github.com/fmassa" target="_blank" rel="noopener noreferrer">Francisco Massa</a>, <a href="https://github.com/alykhantejani" target="_blank" rel="noopener noreferrer">Alykhan Tejani</a>, <a href="https://github.com/lantiga" target="_blank" rel="noopener noreferrer">Luca Antiga</a>, <a href="https://github.com/albanD" target="_blank" rel="noopener noreferrer">Alban Desmaison</a>, <a href="https://github.com/andreaskoepf" target="_blank" rel="noopener noreferrer">Andreas Koepf</a>, <a href="https://github.com/jekbradbury" target="_blank" rel="noopener noreferrer">James Bradbury</a>, <a href="https://github.com/ebetica" target="_blank" rel="noopener noreferrer">Zeming Lin</a>, <a href="https://github.com/yuandong-tian" target="_blank" rel="noopener noreferrer">Yuandong Tian</a>, <a href="https://github.com/glample" target="_blank" rel="noopener noreferrer">Guillaume Lample</a>, <a href="https://github.com/Maratyszcza" target="_blank" rel="noopener noreferrer">Marat Dukhan</a>, <a href="https://github.com/ngimel" target="_blank" rel="noopener noreferrer">Natalia Gimelshein</a>, <a href="https://github.com/csarofeen" target="_blank" rel="noopener noreferrer">Christian Sarofeen</a>, <a href="https://github.com/martinraison" target="_blank" rel="noopener noreferrer">Martin Raison</a>, <a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a>, <a href="https://github.com/zdevito" target="_blank" rel="noopener noreferrer">Zachary Devito</a> など。</p><p>注意：このプロジェクトは、同名の <a href="https://github.com/hughperkins/pytorch" target="_blank" rel="noopener noreferrer">hughperkins/pytorch</a> とは無関係です。Hugh 氏は Torch コミュニティの貴重な貢献者であり、Torch および PyTorch の多くの事柄に協力しています。</p><h2>ライセンス</h2></p><p>PyTorch は BSD スタイルのライセンスです。詳細は <a href="LICENSE" target="_blank" rel="noopener noreferrer">LICENSE</a> ファイルをご覧ください。

---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/pytorch/pytorch/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>