<!DOCTYPE html>
<html lang="th">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch - Read pytorch documentation in Thai. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read pytorch documentation in Thai. This project has 0 stars on GitHub.">
    <meta name="keywords" content="pytorch, Thai, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "pytorch",
  "description": "Read pytorch documentation in Thai. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "pytorch"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/pytorch/pytorch/README-th.html",
  "sameAs": "https://raw.githubusercontent.com/pytorch/pytorch/master/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    pytorch
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Thai</span>
                <span>by pytorch</span>
            </div>
        </div>
        
        <div class="content">
            <p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="PyTorch Logo"></p><p>--------------------------------------------------------------------------------</p><p>PyTorch คือแพ็คเกจ Python ที่ให้ฟีเจอร์ระดับสูงสองอย่าง:
<ul><li>การคำนวณเทนเซอร์ (เหมือน NumPy) พร้อมการเร่งความเร็วโดย GPU อย่างมีประสิทธิภาพ</li>
<li>เครือข่ายประสาทเทียมเชิงลึกที่สร้างบนระบบ autograd แบบเทป</li></p><p></ul>คุณสามารถนำแพ็คเกจ Python ที่คุณชื่นชอบ เช่น NumPy, SciPy และ Cython มาใช้ขยาย PyTorch ได้เมื่อต้องการ</p><p>สุขภาพของ trunk (สัญญาณ Continuous Integration) สามารถดูได้ที่ <a href="https://hud.pytorch.org/ci/pytorch/pytorch/main" target="_blank" rel="noopener noreferrer">hud.pytorch.org</a>.</p><p><!-- toc --></p><ul><li><a href="#more-about-pytorch" target="_blank" rel="noopener noreferrer">ข้อมูลเพิ่มเติมเกี่ยวกับ PyTorch</a></li>
  <li><a href="#a-gpu-ready-tensor-library" target="_blank" rel="noopener noreferrer">ไลบรารีเทนเซอร์ที่พร้อมใช้งานกับ GPU</a></li>
  <li><a href="#dynamic-neural-networks-tape-based-autograd" target="_blank" rel="noopener noreferrer">เครือข่ายประสาทเทียมแบบไดนามิก: Tape-Based Autograd</a></li>
  <li><a href="#python-first" target="_blank" rel="noopener noreferrer">Python มาก่อน</a></li>
  <li><a href="#imperative-experiences" target="_blank" rel="noopener noreferrer">ประสบการณ์แบบ Imperative</a></li>
  <li><a href="#fast-and-lean" target="_blank" rel="noopener noreferrer">รวดเร็วและประหยัด</a></li>
  <li><a href="#extensions-without-pain" target="_blank" rel="noopener noreferrer">ขยายต่อได้ง่ายดาย</a></li>
<li><a href="#installation" target="_blank" rel="noopener noreferrer">การติดตั้ง</a></li>
  <li><a href="#binaries" target="_blank" rel="noopener noreferrer">ไบนารี</a></li>
    <li><a href="#nvidia-jetson-platforms" target="_blank" rel="noopener noreferrer">แพลตฟอร์ม NVIDIA Jetson</a></li>
  <li><a href="#from-source" target="_blank" rel="noopener noreferrer">จากซอร์สโค้ด</a></li>
    <li><a href="#prerequisites" target="_blank" rel="noopener noreferrer">ข้อกำหนดเบื้องต้น</a></li>
      <li><a href="#nvidia-cuda-support" target="_blank" rel="noopener noreferrer">รองรับ NVIDIA CUDA</a></li>
      <li><a href="#amd-rocm-support" target="_blank" rel="noopener noreferrer">รองรับ AMD ROCm</a></li>
      <li><a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">รองรับ Intel GPU</a></li>
    <li><a href="#get-the-pytorch-source" target="_blank" rel="noopener noreferrer">รับซอร์สของ PyTorch</a></li>
    <li><a href="#install-dependencies" target="_blank" rel="noopener noreferrer">ติดตั้ง dependencies</a></li>
    <li><a href="#install-pytorch" target="_blank" rel="noopener noreferrer">ติดตั้ง PyTorch</a></li>
      <li><a href="#adjust-build-options-optional" target="_blank" rel="noopener noreferrer">ปรับตัวเลือกการ build (ไม่บังคับ)</a></li>
  <li><a href="#docker-image" target="_blank" rel="noopener noreferrer">Docker Image</a></li>
    <li><a href="#using-pre-built-images" target="_blank" rel="noopener noreferrer">ใช้งานอิมเมจที่ build ไว้แล้ว</a></li>
    <li><a href="#building-the-image-yourself" target="_blank" rel="noopener noreferrer">สร้างอิมเมจด้วยตนเอง</a></li>
  <li><a href="#building-the-documentation" target="_blank" rel="noopener noreferrer">สร้างเอกสารประกอบ</a></li>
    <li><a href="#building-a-pdf" target="_blank" rel="noopener noreferrer">สร้าง PDF</a></li>
  <li><a href="#previous-versions" target="_blank" rel="noopener noreferrer">เวอร์ชันก่อนหน้า</a></li>
<li><a href="#getting-started" target="_blank" rel="noopener noreferrer">เริ่มต้นใช้งาน</a></li>
<li><a href="#resources" target="_blank" rel="noopener noreferrer">แหล่งข้อมูล</a></li>
<li><a href="#communication" target="_blank" rel="noopener noreferrer">การสื่อสาร</a></li>
<li><a href="#releases-and-contributing" target="_blank" rel="noopener noreferrer">การออกเวอร์ชันและการมีส่วนร่วม</a></li>
<li><a href="#the-team" target="_blank" rel="noopener noreferrer">ทีมงาน</a></li>
<li><a href="#license" target="_blank" rel="noopener noreferrer">สัญญาอนุญาต</a></li></p><p></ul><!-- tocstop --></p><h2>ข้อมูลเพิ่มเติมเกี่ยวกับ PyTorch</h2></p><p><a href="https://pytorch.org/tutorials/beginner/basics/intro.html" target="_blank" rel="noopener noreferrer">เรียนรู้พื้นฐานของ PyTorch</a></p><p>ในรายละเอียด PyTorch คือไลบรารีที่ประกอบด้วยส่วนประกอบต่อไปนี้:</p><p>| ส่วนประกอบ | คำอธิบาย |
| ---- | --- |
| <a href="https://pytorch.org/docs/stable/torch.html" target="_blank" rel="noopener noreferrer"><strong>torch</strong></a> | ไลบรารีเทนเซอร์เหมือน NumPy พร้อมรองรับ GPU อย่างมีประสิทธิภาพ |
| <a href="https://pytorch.org/docs/stable/autograd.html" target="_blank" rel="noopener noreferrer"><strong>torch.autograd</strong></a> | ไลบรารี differentiation อัตโนมัติแบบเทปที่รองรับทุก operation ของ Tensor ที่สามารถ differentiable ใน torch |
| <a href="https://pytorch.org/docs/stable/jit.html" target="_blank" rel="noopener noreferrer"><strong>torch.jit</strong></a> | สแตกการ compile (TorchScript) เพื่อสร้างโมเดลที่ serialize และ optimize ได้จากโค้ด PyTorch  |
| <a href="https://pytorch.org/docs/stable/nn.html" target="_blank" rel="noopener noreferrer"><strong>torch.nn</strong></a> | ไลบรารี neural network ที่ผสานกับ autograd อย่างลึกซึ้ง ออกแบบมาเพื่อความยืดหยุ่นสูงสุด |
| <a href="https://pytorch.org/docs/stable/multiprocessing.html" target="_blank" rel="noopener noreferrer"><strong>torch.multiprocessing</strong></a> | multiprocessing ของ Python แต่สามารถแชร์หน่วยความจำของ torch Tensor ระหว่าง process ได้ เหมาะสำหรับ data loading และการฝึก Hogwild |
| <a href="https://pytorch.org/docs/stable/data.html" target="_blank" rel="noopener noreferrer"><strong>torch.utils</strong></a> | DataLoader และฟังก์ชันอำนวยความสะดวกอื่น ๆ |</p><p>โดยปกติแล้ว PyTorch จะถูกใช้งานเป็น:</p><ul><li>ตัวแทน NumPy เพื่อใช้ประโยชน์จากพลังของ GPU</li>
<li>แพลตฟอร์มวิจัย deep learning ที่ให้ความยืดหยุ่นและความเร็วสูงสุด</li></p><p></ul>รายละเอียดเพิ่มเติม:</p><h3>ไลบรารีเทนเซอร์ที่พร้อมใช้งานกับ GPU</h3></p><p>ถ้าคุณเคยใช้ NumPy แสดงว่าคุณเคยใช้ Tensor (หรือ ndarray) มาแล้ว</p><p><img src="./docs/source/_static/img/tensor_illustration.png" alt="Tensor illustration"></p><p>PyTorch มี Tensor ที่สามารถอยู่ทั้งใน CPU หรือ GPU และช่วยเร่งการคำนวณได้อย่างมาก</p><p>เรามีฟังก์ชัน tensor หลากหลายสำหรับการคำนวณทางวิทยาศาสตร์ของคุณ เช่น slicing, indexing, การคำนวณทางคณิตศาสตร์, พีชคณิตเชิงเส้น, การลดค่า ฯลฯ และรวดเร็วมาก!</p><h3>เครือข่ายประสาทเทียมแบบไดนามิก: Tape-Based Autograd</h3></p><p>PyTorch มีวิธีสร้าง neural network ที่ไม่เหมือนใคร: โดยใช้และเล่นซ้ำเหมือนเทปบันทึกเสียง</p><p>เฟรมเวิร์กส่วนใหญ่ เช่น TensorFlow, Theano, Caffe และ CNTK จะมีมุมมองแบบ static คุณต้องสร้างโครงสร้าง neural network และใช้ซ้ำแบบเดิมไปเรื่อย ๆ การเปลี่ยนแปลงพฤติกรรมของ network หมายถึงการเริ่มใหม่ตั้งแต่ต้น</p><p>ใน PyTorch เราใช้เทคนิคที่เรียกว่า reverse-mode auto-differentiation ซึ่งช่วยให้คุณเปลี่ยนพฤติกรรมของ network ได้อย่างอิสระโดยไม่มีความล่าช้าหรือ overhead แรงบันดาลใจมาจากงานวิจัยหลายฉบับ รวมถึงงานในอดีตและปัจจุบัน เช่น
<a href="https://github.com/twitter/torch-autograd" target="_blank" rel="noopener noreferrer">torch-autograd</a>,
<a href="https://github.com/HIPS/autograd" target="_blank" rel="noopener noreferrer">autograd</a>,
<a href="https://chainer.org" target="_blank" rel="noopener noreferrer">Chainer</a> ฯลฯ</p><p>แม้เทคนิคนี้จะไม่ใช่เอกลักษณ์ของ PyTorch แต่ก็เป็นหนึ่งใน implementation ที่เร็วที่สุดในปัจจุบัน คุณจะได้ทั้งความเร็วและความยืดหยุ่นสำหรับงานวิจัยที่ซับซ้อนของคุณ</p><p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="Dynamic graph"></p><h3>Python มาก่อน</h3></p><p>PyTorch ไม่ใช่ Python binding สำหรับ C++ framework ขนาดใหญ่
แต่มันถูกสร้างขึ้นมาเพื่อผสานกับ Python อย่างลึกซึ้ง
คุณสามารถใช้งานได้เหมือน <a href="https://www.numpy.org/" target="_blank" rel="noopener noreferrer">NumPy</a> / <a href="https://www.scipy.org/" target="_blank" rel="noopener noreferrer">SciPy</a> / <a href="https://scikit-learn.org" target="_blank" rel="noopener noreferrer">scikit-learn</a> ฯลฯ
คุณสามารถเขียนเลเยอร์ใหม่ของ neural network ใน Python ได้เอง ใช้ไลบรารีโปรดของคุณ
และใช้แพ็คเกจอย่าง <a href="https://cython.org/" target="_blank" rel="noopener noreferrer">Cython</a> และ <a href="http://numba.pydata.org/" target="_blank" rel="noopener noreferrer">Numba</a>
เป้าหมายของเราคือไม่ reinvent the wheel เมื่อไม่จำเป็น</p><h3>ประสบการณ์แบบ Imperative</h3></p><p>PyTorch ถูกออกแบบมาให้ใช้งานง่าย เข้าใจตรงไปตรงมา และใช้งานสะดวก
เมื่อคุณรันโค้ด 1 บรรทัด มันจะถูกรันทันที ไม่มีการ asynchronous
เมื่อคุณ debug หรือเจอ error/stack trace คุณจะเข้าใจได้ง่าย
Stack trace จะชี้ไปยังที่มาของโค้ดโดยตรง
เราหวังว่าคุณจะไม่ต้องเสียเวลานานในการ debug เพราะ stack trace ที่เข้าใจยากหรือ execution engine ที่ซับซ้อน</p><h3>รวดเร็วและประหยัด</h3></p><p>PyTorch มี overhead ของ framework น้อยมาก เราได้ผสาน acceleration libraries
เช่น <a href="https://software.intel.com/mkl" target="_blank" rel="noopener noreferrer">Intel MKL</a> และ NVIDIA (<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">cuDNN</a>, <a href="https://developer.nvidia.com/nccl" target="_blank" rel="noopener noreferrer">NCCL</a>) เพื่อความเร็วสูงสุด
แกนหลักของมัน ทั้ง Tensor และ neural network backend ของ CPU/GPU
มีความสมบูรณ์และผ่านการทดสอบมาหลายปี</p><p>ดังนั้น PyTorch จึงเร็วมาก ไม่ว่าคุณจะรัน neural network ขนาดเล็กหรือใหญ่</p><p>การใช้หน่วยความจำของ PyTorch มีประสิทธิภาพสูงมาก เมื่อเทียบกับ Torch หรือทางเลือกอื่น ๆ
เราได้เขียน memory allocator สำหรับ GPU ขึ้นมาเองเพื่อให้แน่ใจว่า
โมเดล deep learning ของคุณใช้หน่วยความจำอย่างคุ้มค่าสูงสุด
สิ่งนี้ทำให้คุณสามารถฝึกโมเดล deep learning ขนาดใหญ่กว่าเดิมได้</p><h3>ขยายต่อได้ง่ายดาย</h3></p><p>การเขียนโมดูล neural network ใหม่ หรือเชื่อมต่อกับ Tensor API ของ PyTorch ถูกออกแบบมาให้ตรงไปตรงมา
และมี abstraction น้อยที่สุด</p><p>คุณสามารถเขียนเลเยอร์ neural network ใหม่ใน Python โดยใช้ torch API
<a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html" target="_blank" rel="noopener noreferrer">หรือไลบรารีที่ใช้ NumPy อย่าง SciPy</a> ได้</p><p>หากคุณอยากเขียนเลเยอร์ใน C/C++ เราก็มี extension API ที่สะดวกและมี boilerplate น้อยมาก
ไม่จำเป็นต้องเขียนโค้ด wrapper ดู <a href="https://pytorch.org/tutorials/advanced/cpp_extension.html" target="_blank" rel="noopener noreferrer">ตัวอย่างการใช้งาน</a> และ <a href="https://github.com/pytorch/extension-cpp" target="_blank" rel="noopener noreferrer">โค้ดตัวอย่าง</a></p><h2>การติดตั้ง</h2></p><h3>ไบนารี</h3>
คำสั่งสำหรับติดตั้งไบนารีผ่าน Conda หรือ pip wheels อยู่ในเว็บไซต์ของเรา: <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">https://pytorch.org/get-started/locally/</a></p><p>#### แพลตฟอร์ม NVIDIA Jetson</p><p>Python wheels สำหรับ Jetson Nano, Jetson TX1/TX2, Jetson Xavier NX/AGX และ Jetson AGX Orin มีให้ที่ <a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048" target="_blank" rel="noopener noreferrer">ที่นี่</a> และ L4T container เผยแพร่ที่ <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch" target="_blank" rel="noopener noreferrer">ที่นี่</a></p><p>ต้องการ JetPack 4.2 ขึ้นไป และ <a href="https://github.com/dusty-nv" target="_blank" rel="noopener noreferrer">@dusty-nv</a> กับ <a href="https://github.com/ptrblck" target="_blank" rel="noopener noreferrer">@ptrblck</a> เป็นผู้ดูแล</p><h3>จากซอร์สโค้ด</h3></p><p>#### ข้อกำหนดเบื้องต้น
ถ้าคุณจะติดตั้งจากซอร์สโค้ด คุณจะต้องมี:
<ul><li>Python 3.9 หรือใหม่กว่า</li>
<li>คอมไพเลอร์ที่รองรับ C++17 อย่างสมบูรณ์ เช่น clang หรือ gcc (ต้องการ gcc 9.4.0 หรือใหม่กว่า บน Linux)</li>
<li>Visual Studio หรือ Visual Studio Build Tool (Windows เท่านั้น)</li></p><p></ul>\* PyTorch CI ใช้ Visual C++ BuildTools ซึ่งมาพร้อมกับ Visual Studio Enterprise,
Professional, หรือ Community Editions หรือดาวน์โหลดได้จาก
https://visualstudio.microsoft.com/visual-cpp-build-tools/ Build tools <em>ไม่มี</em> ใน Visual Studio Code โดยปริยาย</p><p>ตัวอย่างการตั้งค่าสภาพแวดล้อมด้านล่าง:</p><ul><li>Linux:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>/bin/activate
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME></code></pre></p><ul><li>Windows:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>\Scripts\activate.bat
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME>
$ call "C:\Program Files\Microsoft Visual Studio\<VERSION>\Community\VC\Auxiliary\Build\vcvarsall.bat" x64</code></pre></p><p>##### รองรับ NVIDIA CUDA
หากต้องการ compile ให้รองรับ CUDA <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">เลือกเวอร์ชัน CUDA ที่รองรับจาก matrix ของเรา</a> แล้วติดตั้ง:
<ul><li><a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener noreferrer">NVIDIA CUDA</a></li>
<li><a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">NVIDIA cuDNN</a> v8.5 ขึ้นไป</li>
<li><a href="https://gist.github.com/ax3l/9489132" target="_blank" rel="noopener noreferrer">Compiler</a> ที่รองรับ CUDA</li></p><p></ul>หมายเหตุ: สามารถดู <a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html" target="_blank" rel="noopener noreferrer">cuDNN Support Matrix</a> สำหรับเวอร์ชัน cuDNN ที่รองรับ CUDA, CUDA driver และฮาร์ดแวร์ NVIDIA ได้</p><p>หากต้องการปิดการรองรับ CUDA ให้ export ตัวแปรแวดล้อม <code>USE_CUDA=0</code>
ตัวแปรแวดล้อมอื่น ๆ ดูได้ใน <code>setup.py</code></p><p>หาก build สำหรับ NVIDIA Jetson (Jetson Nano, TX1, TX2, AGX Xavier) อ่านวิธีติดตั้ง PyTorch สำหรับ Jetson Nano ได้ที่ <a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/" target="_blank" rel="noopener noreferrer">ที่นี่</a></p><p>##### รองรับ AMD ROCm
หากต้องการ compile ให้รองรับ ROCm ให้ติดตั้ง
<ul><li><a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html" target="_blank" rel="noopener noreferrer">AMD ROCm</a> 4.0 ขึ้นไป</li>
<li>ROCm รองรับเฉพาะระบบ Linux</li></p><p></ul>โดยปกติระบบ build จะมองว่า ROCm อยู่ที่ <code>/opt/rocm</code> หากอยู่ที่อื่นให้ตั้งค่า <code>ROCM_PATH</code> ชี้ไปยังที่ติดตั้ง ROCm ระบบจะตรวจสอบสถาปัตยกรรม GPU อัตโนมัติ หรือจะตั้งค่า <code>PYTORCH_ROCM_ARCH</code> เพื่อเลือกสถาปัตยกรรม GPU เองได้ <a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus" target="_blank" rel="noopener noreferrer">ดูข้อมูล</a></p><p>หากต้องการปิดการรองรับ ROCm ให้ export ตัวแปรแวดล้อม <code>USE_ROCM=0</code>
ตัวแปรแวดล้อมอื่น ๆ ดูได้ใน <code>setup.py</code></p><p>##### รองรับ Intel GPU
หากต้องการ compile ให้รองรับ Intel GPU ให้ทำตาม
<ul><li><a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html" target="_blank" rel="noopener noreferrer">PyTorch Prerequisites for Intel GPUs</a></li>
<li>Intel GPU รองรับทั้ง Linux และ Windows</li></p><p></ul>หากต้องการปิดการรองรับ Intel GPU ให้ export ตัวแปรแวดล้อม <code>USE_XPU=0</code>
ตัวแปรแวดล้อมอื่น ๆ ดูได้ใน <code>setup.py</code></p><p>#### รับซอร์สของ PyTorch
<pre><code class="language-bash">git clone https://github.com/pytorch/pytorch
cd pytorch
<h1>หากอัปเดต checkout ที่มีอยู่แล้ว</h1>
git submodule sync
git submodule update --init --recursive</code></pre></p><p>#### ติดตั้ง dependencies</p><p><strong>ทั่วไป</strong></p><pre><code class="language-bash">conda install cmake ninja
<h1>รันคำสั่งนี้จากไดเรกทอรี PyTorch หลังจาก clone ซอร์สโค้ดตามหัวข้อ “Get the PyTorch Source” ข้างบน</h1>
pip install -r requirements.txt</code></pre></p><p><strong>บน Linux</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>CUDA เท่านั้น: เพิ่ม LAPACK สำหรับ GPU หากจำเป็น</h1>
<h1>การติดตั้ง magma: รันใน conda environment ที่ activate แล้ว ระบุเวอร์ชัน CUDA ที่จะติดตั้ง</h1>
.ci/docker/common/install_magma_conda.sh 12.4</p><h1>(เลือกได้) ถ้าใช้ torch.compile กับ inductor/triton ติดตั้ง triton เวอร์ชันที่ตรงกัน</h1>
<h1>รันจากไดเรกทอรี pytorch หลังจาก clone แล้ว</h1>
<h1>หากรองรับ Intel GPU กรุณา <code>export USE_XPU=1</code> ก่อนรันคำสั่งนี้</h1>
make triton</code></pre></p><p><strong>บน MacOS</strong></p><pre><code class="language-bash"># ติดตั้งแพ็คเกจนี้บนเครื่องที่ใช้ intel x86 processor เท่านั้น
pip install mkl-static mkl-include
<h1>ติดตั้งแพ็คเกจเหล่านี้หากต้องการใช้ torch.distributed</h1>
conda install pkg-config libuv</code></pre></p><p><strong>บน Windows</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>ติดตั้งแพ็คเกจเหล่านี้หากต้องการใช้ torch.distributed</h1>
<h1>Distributed package บน Windows เป็นฟีเจอร์ทดลองและอาจเปลี่ยนแปลงได้</h1>
conda install -c conda-forge libuv=1.39</code></pre></p><p>#### ติดตั้ง PyTorch
<strong>บน Linux</strong></p><p>หาก compile สำหรับ AMD ROCm ให้รันคำสั่งนี้ก่อน:
<pre><code class="language-bash"># รันเฉพาะกรณี compile สำหรับ ROCm เท่านั้น
python tools/amd_build/build_amd.py</code></pre></p><p>ติดตั้ง PyTorch
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py develop</code></pre></p><p><strong>บน macOS</strong></p><pre><code class="language-bash">python3 setup.py develop</code></pre></p><p><strong>บน Windows</strong></p><p>ถ้าต้องการ build legacy python code โปรดดู <a href="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda" target="_blank" rel="noopener noreferrer">Building on legacy code and CUDA</a></p><p><strong>Build แบบ CPU เท่านั้น</strong></p><p>โหมดนี้ PyTorch จะคำนวณโดยใช้ CPU ไม่ใช่ GPU</p><pre><code class="language-cmd">python setup.py develop</code></pre></p><p>หมายเหตุเกี่ยวกับ OpenMP: Implementation ที่ต้องการคือ Intel OpenMP (iomp) หากต้องการ link กับ iomp คุณต้องดาวน์โหลด library เองและตั้งค่าสภาพแวดล้อมโดยปรับ <code>CMAKE_INCLUDE_PATH</code> และ <code>LIB</code> ดูตัวอย่างการตั้งค่าทั้ง MKL และ Intel OpenMP <a href="https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source" target="_blank" rel="noopener noreferrer">ได้ที่นี่</a> หากไม่ตั้งค่า CMake จะใช้ Microsoft Visual C OpenMP runtime (vcomp)</p><p><strong>Build แบบใช้ CUDA</strong></p><p>โหมดนี้ PyTorch จะคำนวณบน GPU ผ่าน CUDA เพื่อความเร็ว</p><p><a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm" target="_blank" rel="noopener noreferrer">NVTX</a> จำเป็นสำหรับ build PyTorch กับ CUDA
NVTX เป็นส่วนหนึ่งของ CUDA ที่เรียกว่า "Nsight Compute" ติดตั้งโดยรันตัวติดตั้ง CUDA อีกครั้งแล้วเลือก checkbox ที่เกี่ยวข้อง
ตรวจสอบให้แน่ใจว่า CUDA กับ Nsight Compute ถูกติดตั้งหลัง Visual Studio</p><p>ขณะนี้ VS 2017 / 2019 และ Ninja รองรับเป็น generator ของ CMake หากพบ <code>ninja.exe</code> ใน <code>PATH</code> จะใช้ Ninja เป็น generator โดยอัตโนมัติ มิฉะนั้นจะใช้ VS 2017 / 2019
<br/> หากเลือก Ninja เป็น generator จะใช้ MSVC ล่าสุดเป็น toolchain ด้านล่าง</p><p>ต้องติดตั้งไลบรารีเพิ่มเติมเช่น
<a href="https://developer.nvidia.com/magma" target="_blank" rel="noopener noreferrer">Magma</a>, <a href="https://github.com/oneapi-src/oneDNN" target="_blank" rel="noopener noreferrer">oneDNN หรือ MKLDNN/DNNL</a>, และ <a href="https://github.com/mozilla/sccache" target="_blank" rel="noopener noreferrer">Sccache</a> ดู <a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers" target="_blank" rel="noopener noreferrer">installation-helper</a> เพื่อดูวิธีติดตั้ง</p><p>ดูตัวอย่างการตั้งค่าตัวแปรแวดล้อมใน <a href="https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat" target="_blank" rel="noopener noreferrer">build_pytorch.bat</a></p><pre><code class="language-cmd">cmd</p><p>:: ตั้งค่าตัวแปรหลังจากดาวน์โหลดและแตกไฟล์ mkl แล้ว
:: ไม่เช่นนั้น CMake จะ error ว่า <code>Could NOT find OpenMP</code>
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%</p><p>:: อ่านรายละเอียดข้างบนให้ดีก่อนดำเนินการ
:: [ไม่บังคับ] หากต้องการ override toolset ของ Ninja และ Visual Studio กับ CUDA ให้รันบล็อกนี้
:: จะรัน "Visual Studio 2019 Developer Command Prompt" ให้อัตโนมัติ
:: ตรวจสอบให้แน่ใจว่า CMake >= 3.12 เมื่อใช้ Visual Studio generator
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f "usebackq tokens=<em>" %i in (<code>"%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe" -version [15^,17^) -products </em> -latest -property installationPath</code>) do call "%i\VC\Auxiliary\Build\vcvarsall.bat" x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%</p><p>:: [ไม่บังคับ] หากต้องการ override CUDA host compiler
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe</p><p>python setup.py develop
</code></pre></p><p><strong>Build Intel GPU</strong></p><p>โหมดนี้จะ build PyTorch พร้อมรองรับ Intel GPU</p><p>โปรดตรวจสอบให้แน่ใจว่า <a href="#prerequisites" target="_blank" rel="noopener noreferrer">ข้อกำหนดทั่วไป</a> และ <a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">ข้อกำหนดสำหรับ Intel GPU</a> ได้รับการติดตั้งและตั้งค่าสภาพแวดล้อมแล้วก่อนเริ่ม build สำหรับ build tool ต้องใช้ <code>Visual Studio 2022</code></p><p>จากนั้นสามารถ build PyTorch ด้วยคำสั่ง:</p><pre><code class="language-cmd">:: คำสั่ง CMD:
:: ตั้งค่า CMAKE_PREFIX_PATH เพื่อค้นหาแพ็คเกจที่เกี่ยวข้อง
:: %CONDA_PREFIX% ใช้งานได้หลัง <code>conda activate custom_env</code></p><p>if defined CMAKE_PREFIX_PATH (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%"
) else (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library"
)</p><p>python setup.py develop</code></pre></p><p>##### ปรับตัวเลือกการ build (ไม่บังคับ)</p><p>คุณสามารถปรับค่า cmake variables ได้ (โดยไม่ต้อง build ก่อน) เช่น ปรับ directory ของ CuDNN หรือ BLAS</p><p>บน Linux
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py build --cmake-only
ccmake build  # หรือ cmake-gui build</code></pre></p><p>บน macOS
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only
ccmake build  # หรือ cmake-gui build</code></pre></p><h3>Docker Image</h3></p><p>#### ใช้งานอิมเมจที่ build ไว้แล้ว</p><p>คุณสามารถดึง docker image ที่ build ไว้แล้วจาก Docker Hub และรันกับ docker v19.03+</p><pre><code class="language-bash">docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest</code></pre></p><p>โปรดทราบว่า PyTorch ใช้ shared memory เพื่อแชร์ข้อมูลระหว่าง process ดังนั้นถ้าใช้ torch multiprocessing (เช่น data loader แบบ multithreaded) ขนาด shared memory ปริยายใน container จะไม่พอ ควรเพิ่มขนาด shared memory ด้วย <code>--ipc=host</code> หรือ <code>--shm-size</code> ในคำสั่ง <code>nvidia-docker run</code></p><p>#### สร้างอิมเมจด้วยตนเอง</p><p><strong>หมายเหตุ:</strong> ต้องใช้ docker เวอร์ชัน > 18.06</p><p><code>Dockerfile</code> ที่ให้มาสำหรับ build image ที่รองรับ CUDA 11.1 และ cuDNN v8
คุณสามารถส่งตัวแปร <code>PYTHON_VERSION=x.y</code> ให้ make เพื่อกำหนดเวอร์ชัน Python หรือไม่ระบุก็จะใช้ค่าเริ่มต้น</p><pre><code class="language-bash">make -f docker.Makefile
<h1>images จะถูก tag เป็น docker.io/${your_docker_username}/pytorch</code></pre></h1></p><p>สามารถระบุตัวแปร CMake เพิ่มเติมโดยใช้ <code>CMAKE_VARS="..."</code> เพื่อส่งค่าไปยัง CMake ระหว่าง build
ดู <a href="./setup.py" target="_blank" rel="noopener noreferrer">setup.py</a> สำหรับตัวแปรที่มี</p><pre><code class="language-bash">make -f docker.Makefile</code></pre></p><h3>สร้างเอกสารประกอบ</h3></p><p>เพื่อ build เอกสารในหลายรูปแบบ คุณจะต้องมี <a href="http://www.sphinx-doc.org" target="_blank" rel="noopener noreferrer">Sphinx</a>
และ pytorch_sphinx_theme2</p><p>ก่อน build เอกสารในเครื่อง ให้แน่ใจว่า <code>torch</code> ถูกติดตั้งใน environment แล้ว สำหรับการแก้ไขเล็ก ๆ สามารถติดตั้ง nightly version ตาม <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">Getting Started</a></p><p>สำหรับการแก้ไขที่ซับซ้อน เช่น การเพิ่มโมดูลใหม่และ docstring อาจต้องติดตั้ง torch <a href="#from-source" target="_blank" rel="noopener noreferrer">จากซอร์ส</a>
ดู <a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines" target="_blank" rel="noopener noreferrer">Docstring Guidelines</a> สำหรับแนวทาง docstring</p><pre><code class="language-bash">cd docs/
pip install -r requirements.txt
make html
make serve</code></pre></p><p>รัน <code>make</code> เพื่อดูรายการรูปแบบ output ทั้งหมด</p><p>ถ้าเจอ katex error ให้รัน <code>npm install katex</code> ถ้ายังไม่หาย ให้ลอง
<code>npm install -g katex</code></p><blockquote>[!หมายเหตุ]</blockquote>
<blockquote>หากติดตั้ง <code>nodejs</code> ด้วย package manager อื่น (เช่น</blockquote>
<blockquote><code>conda</code>) <code>npm</code> อาจติดตั้งเวอร์ชัน <code>katex</code> ที่ไม่ compatible กับ <code>nodejs</code> และ build เอกสารจะล้มเหลว</blockquote>
<blockquote>เวอร์ชันที่ยืนยันว่าใช้ได้คือ <code>node@6.13.1</code> และ</blockquote>
<blockquote><code>katex@0.13.18</code> ติดตั้ง katex ด้วย <code>npm</code> โดยรัน</blockquote>
<blockquote>``<code>npm install -g katex@0.13.18<pre><code class="language-"></blockquote>
<blockquote>[!หมายเหตุ]</blockquote>
<blockquote>หากเจอ numpy incompatibility error ให้รัน:</blockquote>
<blockquote></code>`<code></blockquote>
<blockquote>pip install 'numpy<2'</blockquote>
<blockquote></code>`<code></blockquote></p><p>เมื่อแก้ไข dependencies ที่ CI ใช้งาน ให้แก้ไขไฟล์
</code>.ci/docker/requirements-docs.txt<code></p><p>#### สร้าง PDF</p><p>เพื่อ compile PDF ของเอกสาร PyTorch ทั้งหมด ต้องติดตั้ง
</code>texlive<code> และ LaTeX บน macOS ติดตั้งได้ด้วย:
</code></pre>
brew install --cask mactex
</code>`<code></p><p>เพื่อสร้าง PDF:</p><ul><li>รัน:</li></p><p>   </ul></code>`<code>
   make latexpdf
   </code>`<code></p><p>   ไฟล์จะถูกสร้างในไดเรกทอรี </code>build/latex<code></p><ul><li>เข้าไปที่ไดเรกทอรีนี้แล้วรัน:</li></p><p>   </ul></code>`<code>
   make LATEXOPTS="-interaction=nonstopmode"
   </code>`<code></p><p>   จะได้ไฟล์ </code>pytorch.pdf` พร้อมเนื้อหาที่ต้องการ รันคำสั่งนี้ซ้ำอีกครั้งเพื่อให้สร้างสารบัญและดัชนีที่ถูกต้อง</p><blockquote>[!หมายเหตุ]</blockquote>
<blockquote>หากต้องการดูสารบัญ ให้เปลี่ยนไปใช้ <strong>Table of Contents</strong></blockquote>
<blockquote>ในโปรแกรมอ่าน PDF ของคุณ</blockquote></p><h3>เวอร์ชันก่อนหน้า</h3></p><p>คำแนะนำการติดตั้งและไบนารีของ PyTorch เวอร์ชันก่อนหน้าสามารถดูได้ที่
<a href="https://pytorch.org/get-started/previous-versions" target="_blank" rel="noopener noreferrer">เว็บไซต์ของเรา</a></p><h2>เริ่มต้นใช้งาน</h2></p><p>สามแหล่งข้อมูลสำหรับการเริ่มต้น:
<ul><li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">บทเรียน: เริ่มต้นเรียนรู้และใช้งาน PyTorch</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">ตัวอย่าง: โค้ด PyTorch เข้าใจง่ายสำหรับทุกโดเมน</a></li>
<li><a href="https://pytorch.org/docs/" target="_blank" rel="noopener noreferrer">เอกสาร API</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md" target="_blank" rel="noopener noreferrer">Glossary</a></li></p><p></ul><h2>แหล่งข้อมูล</h2></p><ul><li><a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">PyTorch.org</a></li>
<li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">PyTorch Tutorials</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">PyTorch Examples</a></li>
<li><a href="https://pytorch.org/hub/" target="_blank" rel="noopener noreferrer">PyTorch Models</a></li>
<li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188" target="_blank" rel="noopener noreferrer">Intro to Deep Learning with PyTorch จาก Udacity</a></li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229" target="_blank" rel="noopener noreferrer">Intro to Machine Learning with PyTorch จาก Udacity</a></li>
<li><a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch" target="_blank" rel="noopener noreferrer">Deep Neural Networks with PyTorch จาก Coursera</a></li>
<li><a href="https://twitter.com/PyTorch" target="_blank" rel="noopener noreferrer">PyTorch Twitter</a></li>
<li><a href="https://pytorch.org/blog/" target="_blank" rel="noopener noreferrer">PyTorch Blog</a></li>
<li><a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw" target="_blank" rel="noopener noreferrer">PyTorch YouTube</a></li></p><p></ul><h2>การสื่อสาร</h2>
<ul><li>ฟอรัม: พูดคุยเกี่ยวกับการ implement, งานวิจัย ฯลฯ https://discuss.pytorch.org</li>
<li>GitHub Issues: รายงานบั๊ก, ขอฟีเจอร์, ปัญหาการติดตั้ง, RFC, ความคิดเห็น ฯลฯ</li>
<li>Slack: <a href="https://pytorch.slack.com/" target="_blank" rel="noopener noreferrer">PyTorch Slack</a> มีผู้ใช้และนักพัฒนา PyTorch ระดับกลางถึงสูง สำหรับแชท, ถกปัญหา, ทำงานร่วมกัน ฯลฯ หากคุณเป็นมือใหม่ให้ใช้ <a href="https://discuss.pytorch.org" target="_blank" rel="noopener noreferrer">PyTorch Forums</a> หากต้องการ invite Slack กรุณากรอกแบบฟอร์มนี้: https://goo.gl/forms/PP1AGvNHpSaJP8to1</li>
<li>จดหมายข่าว: อีเมลประกาศสำคัญเกี่ยวกับ PyTorch สมัครได้ที่: https://eepurl.com/cbG0rv</li>
<li>Facebook Page: ข่าวสารสำคัญเกี่ยวกับ PyTorch https://www.facebook.com/pytorch</li>
<li>สำหรับแนวทางการใช้แบรนด์ กรุณาดูที่ <a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">pytorch.org</a></li></p><p></ul><h2>การออกเวอร์ชันและการมีส่วนร่วม</h2></p><p>โดยปกติ PyTorch จะมี minor release ปีละ 3 ครั้ง หากคุณพบข้อผิดพลาดโปรด <a href="https://github.com/pytorch/pytorch/issues" target="_blank" rel="noopener noreferrer">แจ้ง issue</a></p><p>เราขอขอบคุณทุกการมีส่วนร่วม หากคุณจะช่วยแก้บั๊กสามารถส่ง pull request ได้เลยโดยไม่ต้องพูดคุยเพิ่มเติม</p><p>หากคุณจะเพิ่มฟีเจอร์ใหม่, utility function, หรือ extension ให้กับ core กรุณาเปิด issue และพูดคุยกับทีมเราก่อน ส่ง PR มาโดยไม่พูดคุยอาจถูกปฏิเสธ เพราะเราอาจมีทิศทางของ core ที่ต่างจากที่คุณคิด</p><p>ศึกษาวิธีมีส่วนร่วมกับ Pytorch เพิ่มเติมได้ที่ <a href="CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">หน้า Contribution</a> ข้อมูลเกี่ยวกับ release ดูที่ <a href="RELEASE.md" target="_blank" rel="noopener noreferrer">Release page</a></p><h2>ทีมงาน</h2></p><p>PyTorch เป็นโครงการที่ขับเคลื่อนโดยชุมชน มีวิศวกรและนักวิจัยที่มีความสามารถจำนวนมากร่วมพัฒนา</p><p>ปัจจุบัน PyTorch ดูแลโดย <a href="http://soumith.ch" target="_blank" rel="noopener noreferrer">Soumith Chintala</a>, <a href="https://github.com/gchanan" target="_blank" rel="noopener noreferrer">Gregory Chanan</a>, <a href="https://github.com/dzhulgakov" target="_blank" rel="noopener noreferrer">Dmytro Dzhulgakov</a>, <a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a>, และ <a href="https://github.com/malfet" target="_blank" rel="noopener noreferrer">Nikita Shulga</a> โดยมีผู้ร่วมสมทบหลักจากบุคคลมากมายในหลากหลายรูปแบบ
รายชื่อที่ไม่ครบถ้วนแต่เพิ่มขึ้นเรื่อย ๆ ได้แก่: <a href="https://github.com/killeent" target="_blank" rel="noopener noreferrer">Trevor Killeen</a>, <a href="https://github.com/chsasank" target="_blank" rel="noopener noreferrer">Sasank Chilamkurthy</a>, <a href="https://github.com/szagoruyko" target="_blank" rel="noopener noreferrer">Sergey Zagoruyko</a>, <a href="https://github.com/adamlerer" target="_blank" rel="noopener noreferrer">Adam Lerer</a>, <a href="https://github.com/fmassa" target="_blank" rel="noopener noreferrer">Francisco Massa</a>, <a href="https://github.com/alykhantejani" target="_blank" rel="noopener noreferrer">Alykhan Tejani</a>, <a href="https://github.com/lantiga" target="_blank" rel="noopener noreferrer">Luca Antiga</a>, <a href="https://github.com/albanD" target="_blank" rel="noopener noreferrer">Alban Desmaison</a>, <a href="https://github.com/andreaskoepf" target="_blank" rel="noopener noreferrer">Andreas Koepf</a>, <a href="https://github.com/jekbradbury" target="_blank" rel="noopener noreferrer">James Bradbury</a>, <a href="https://github.com/ebetica" target="_blank" rel="noopener noreferrer">Zeming Lin</a>, <a href="https://github.com/yuandong-tian" target="_blank" rel="noopener noreferrer">Yuandong Tian</a>, <a href="https://github.com/glample" target="_blank" rel="noopener noreferrer">Guillaume Lample</a>, <a href="https://github.com/Maratyszcza" target="_blank" rel="noopener noreferrer">Marat Dukhan</a>, <a href="https://github.com/ngimel" target="_blank" rel="noopener noreferrer">Natalia Gimelshein</a>, <a href="https://github.com/csarofeen" target="_blank" rel="noopener noreferrer">Christian Sarofeen</a>, <a href="https://github.com/martinraison" target="_blank" rel="noopener noreferrer">Martin Raison</a>, <a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a>, <a href="https://github.com/zdevito" target="_blank" rel="noopener noreferrer">Zachary Devito</a>.</p><p>หมายเหตุ: โปรเจกต์นี้ไม่เกี่ยวข้องกับ <a href="https://github.com/hughperkins/pytorch" target="_blank" rel="noopener noreferrer">hughperkins/pytorch</a> ที่ชื่อเหมือนกัน Hugh เป็นผู้ร่วมสมทบที่มีคุณค่าของชุมชน Torch และช่วยเหลือ Torch และ PyTorch ในหลายส่วน</p><h2>สัญญาอนุญาต</h2></p><p>PyTorch ใช้สัญญาอนุญาตแบบ BSD ตามที่พบในไฟล์ <a href="LICENSE" target="_blank" rel="noopener noreferrer">LICENSE</a>

---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/pytorch/pytorch/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>