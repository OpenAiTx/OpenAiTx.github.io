<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch - Read pytorch documentation in Vietnamese. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read pytorch documentation in Vietnamese. This project has 0 stars on GitHub.">
    <meta name="keywords" content="pytorch, Vietnamese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "pytorch",
  "description": "Read pytorch documentation in Vietnamese. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "pytorch"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/pytorch/pytorch/README-vi.html",
  "sameAs": "https://raw.githubusercontent.com/pytorch/pytorch/master/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    pytorch
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Vietnamese</span>
                <span>by pytorch</span>
            </div>
        </div>
        
        <div class="content">
            <p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="Logo PyTorch"></p><p>--------------------------------------------------------------------------------</p><p>PyTorch là một gói Python cung cấp hai tính năng cấp cao:
<ul><li>Tính toán Tensor (giống như NumPy) với khả năng tăng tốc GPU mạnh mẽ</li>
<li>Mạng nơ-ron sâu được xây dựng trên hệ thống autograd dựa trên băng ghi (tape-based)</li></p><p></ul>Bạn có thể tái sử dụng các gói Python yêu thích như NumPy, SciPy và Cython để mở rộng PyTorch khi cần.</p><p>Tình trạng nhánh chính (tín hiệu Kiểm tra Liên tục - Continuous Integration) có thể được tìm thấy tại <a href="https://hud.pytorch.org/ci/pytorch/pytorch/main" target="_blank" rel="noopener noreferrer">hud.pytorch.org</a>.</p><p><!-- toc --></p><ul><li><a href="#more-about-pytorch" target="_blank" rel="noopener noreferrer">Tìm hiểu thêm về PyTorch</a></li>
  <li><a href="#a-gpu-ready-tensor-library" target="_blank" rel="noopener noreferrer">Thư viện Tensor sẵn sàng cho GPU</a></li>
  <li><a href="#dynamic-neural-networks-tape-based-autograd" target="_blank" rel="noopener noreferrer">Mạng nơ-ron động: Autograd dựa trên băng ghi</a></li>
  <li><a href="#python-first" target="_blank" rel="noopener noreferrer">Ưu tiên Python</a></li>
  <li><a href="#imperative-experiences" target="_blank" rel="noopener noreferrer">Trải nghiệm trực tiếp</a></li>
  <li><a href="#fast-and-lean" target="_blank" rel="noopener noreferrer">Nhanh và tiết kiệm tài nguyên</a></li>
  <li><a href="#extensions-without-pain" target="_blank" rel="noopener noreferrer">Mở rộng dễ dàng</a></li>
<li><a href="#installation" target="_blank" rel="noopener noreferrer">Cài đặt</a></li>
  <li><a href="#binaries" target="_blank" rel="noopener noreferrer">Các gói nhị phân</a></li>
    <li><a href="#nvidia-jetson-platforms" target="_blank" rel="noopener noreferrer">Nền tảng NVIDIA Jetson</a></li>
  <li><a href="#from-source" target="_blank" rel="noopener noreferrer">Cài đặt từ mã nguồn</a></li>
    <li><a href="#prerequisites" target="_blank" rel="noopener noreferrer">Yêu cầu</a></li>
      <li><a href="#nvidia-cuda-support" target="_blank" rel="noopener noreferrer">Hỗ trợ NVIDIA CUDA</a></li>
      <li><a href="#amd-rocm-support" target="_blank" rel="noopener noreferrer">Hỗ trợ AMD ROCm</a></li>
      <li><a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">Hỗ trợ GPU Intel</a></li>
    <li><a href="#get-the-pytorch-source" target="_blank" rel="noopener noreferrer">Lấy mã nguồn PyTorch</a></li>
    <li><a href="#install-dependencies" target="_blank" rel="noopener noreferrer">Cài đặt các phụ thuộc</a></li>
    <li><a href="#install-pytorch" target="_blank" rel="noopener noreferrer">Cài đặt PyTorch</a></li>
      <li><a href="#adjust-build-options-optional" target="_blank" rel="noopener noreferrer">Điều chỉnh tuỳ chọn biên dịch (Tùy chọn)</a></li>
  <li><a href="#docker-image" target="_blank" rel="noopener noreferrer">Docker Image</a></li>
    <li><a href="#using-pre-built-images" target="_blank" rel="noopener noreferrer">Sử dụng image dựng sẵn</a></li>
    <li><a href="#building-the-image-yourself" target="_blank" rel="noopener noreferrer">Tự dựng image</a></li>
  <li><a href="#building-the-documentation" target="_blank" rel="noopener noreferrer">Biên dịch tài liệu</a></li>
    <li><a href="#building-a-pdf" target="_blank" rel="noopener noreferrer">Biên dịch PDF</a></li>
  <li><a href="#previous-versions" target="_blank" rel="noopener noreferrer">Các phiên bản trước đây</a></li>
<li><a href="#getting-started" target="_blank" rel="noopener noreferrer">Bắt đầu sử dụng</a></li>
<li><a href="#resources" target="_blank" rel="noopener noreferrer">Tài nguyên</a></li>
<li><a href="#communication" target="_blank" rel="noopener noreferrer">Trao đổi</a></li>
<li><a href="#releases-and-contributing" target="_blank" rel="noopener noreferrer">Phát hành và đóng góp</a></li>
<li><a href="#the-team" target="_blank" rel="noopener noreferrer">Nhóm phát triển</a></li>
<li><a href="#license" target="_blank" rel="noopener noreferrer">Giấy phép</a></li></p><p></ul><!-- tocstop --></p><h2>Tìm hiểu thêm về PyTorch</h2></p><p><a href="https://pytorch.org/tutorials/beginner/basics/intro.html" target="_blank" rel="noopener noreferrer">Học những kiến thức cơ bản về PyTorch</a></p><p>Ở mức chi tiết, PyTorch là một thư viện bao gồm các thành phần sau:</p><p>| Thành phần | Mô tả |
| ---- | --- |
| <a href="https://pytorch.org/docs/stable/torch.html" target="_blank" rel="noopener noreferrer"><strong>torch</strong></a> | Thư viện Tensor giống như NumPy, với hỗ trợ GPU mạnh mẽ |
| <a href="https://pytorch.org/docs/stable/autograd.html" target="_blank" rel="noopener noreferrer"><strong>torch.autograd</strong></a> | Thư viện phân biệt tự động dựa trên băng ghi, hỗ trợ tất cả các phép toán Tensor khả vi trong torch |
| <a href="https://pytorch.org/docs/stable/jit.html" target="_blank" rel="noopener noreferrer"><strong>torch.jit</strong></a> | Chuỗi biên dịch (TorchScript) để tạo mô hình có thể tuần tự hóa và tối ưu hóa từ mã PyTorch |
| <a href="https://pytorch.org/docs/stable/nn.html" target="_blank" rel="noopener noreferrer"><strong>torch.nn</strong></a> | Thư viện mạng nơ-ron tích hợp sâu với autograd, thiết kế để tối đa hóa tính linh hoạt |
| <a href="https://pytorch.org/docs/stable/multiprocessing.html" target="_blank" rel="noopener noreferrer"><strong>torch.multiprocessing</strong></a> | Đa tiến trình Python, nhưng với khả năng chia sẻ bộ nhớ kỳ diệu của Tensor torch giữa các tiến trình. Hữu ích cho việc nạp dữ liệu và huấn luyện Hogwild |
| <a href="https://pytorch.org/docs/stable/data.html" target="_blank" rel="noopener noreferrer"><strong>torch.utils</strong></a> | DataLoader và các hàm tiện ích khác |</p><p>Thông thường, PyTorch được sử dụng như:
<ul><li>Một sự thay thế cho NumPy để tận dụng sức mạnh GPU.</li>
<li>Nền tảng nghiên cứu học sâu cung cấp tính linh hoạt và tốc độ tối đa.</li></p><p></ul>Chi tiết hơn:</p><h3>Thư viện Tensor sẵn sàng cho GPU</h3></p><p>Nếu bạn sử dụng NumPy, bạn đã từng dùng Tensor (hay còn gọi là ndarray).</p><p><img src="./docs/source/_static/img/tensor_illustration.png" alt="Minh họa Tensor"></p><p>PyTorch cung cấp các Tensor có thể tồn tại trên CPU hoặc GPU và tăng tốc tính toán lên rất nhiều.</p><p>Chúng tôi cung cấp nhiều hàm xử lý tensor để đáp ứng nhu cầu tính toán khoa học của bạn như cắt, đánh chỉ số, phép toán toán học, đại số tuyến tính, phép giảm, v.v.
Và chúng rất nhanh!</p><h3>Mạng nơ-ron động: Autograd dựa trên băng ghi</h3></p><p>PyTorch có một cách xây dựng mạng nơ-ron độc đáo: sử dụng và phát lại một máy ghi băng (tape recorder).</p><p>Phần lớn các framework như TensorFlow, Theano, Caffe, CNTK có cách nhìn tĩnh về thế giới.
Bạn phải xây dựng mạng nơ-ron và sử dụng lại cùng một cấu trúc nhiều lần.
Thay đổi cách hoạt động của mạng nghĩa là phải bắt đầu lại từ đầu.</p><p>Với PyTorch, chúng tôi sử dụng kỹ thuật gọi là phân biệt tự động chế độ ngược (reverse-mode auto-differentiation), cho phép bạn thay đổi cách mạng hoạt động một cách tuỳ ý mà không có độ trễ hay chi phí nào. Chúng tôi lấy cảm hứng từ nhiều bài báo nghiên cứu về chủ đề này, cũng như các dự án hiện tại và trước đây như
<a href="https://github.com/twitter/torch-autograd" target="_blank" rel="noopener noreferrer">torch-autograd</a>,
<a href="https://github.com/HIPS/autograd" target="_blank" rel="noopener noreferrer">autograd</a>,
<a href="https://chainer.org" target="_blank" rel="noopener noreferrer">Chainer</a>, v.v.</p><p>Dù kỹ thuật này không phải riêng của PyTorch, nhưng đây là một trong những hiện thực hóa nhanh nhất hiện nay.
Bạn sẽ có được tốc độ và tính linh hoạt tối ưu cho các nghiên cứu táo bạo của mình.</p><p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="Biểu đồ động"></p><h3>Ưu tiên Python</h3></p><p>PyTorch không phải là một liên kết Python vào một framework C++ nguyên khối.
Nó được xây dựng để tích hợp sâu vào Python.
Bạn có thể sử dụng nó tự nhiên như với <a href="https://www.numpy.org/" target="_blank" rel="noopener noreferrer">NumPy</a> / <a href="https://www.scipy.org/" target="_blank" rel="noopener noreferrer">SciPy</a> / <a href="https://scikit-learn.org" target="_blank" rel="noopener noreferrer">scikit-learn</a> v.v.
Bạn có thể viết các lớp mạng nơ-ron mới bằng chính Python, sử dụng các thư viện yêu thích và các gói như <a href="https://cython.org/" target="_blank" rel="noopener noreferrer">Cython</a> và <a href="http://numba.pydata.org/" target="_blank" rel="noopener noreferrer">Numba</a>.
Mục tiêu của chúng tôi là không phát minh lại bánh xe khi không cần thiết.</p><h3>Trải nghiệm trực tiếp</h3></p><p>PyTorch được thiết kế để trực quan, tuyến tính trong suy nghĩ và dễ sử dụng.
Khi bạn thực thi một dòng mã, nó sẽ được thực thi ngay lập tức. Không có cái nhìn bất đồng bộ về thế giới.
Khi bạn sử dụng trình gỡ lỗi hoặc nhận thông báo lỗi và các trace stack, việc hiểu chúng rất đơn giản.
Trace stack chỉ rõ vị trí mã của bạn được định nghĩa.
Chúng tôi hy vọng bạn không phải mất hàng giờ để gỡ lỗi do trace stack tệ hoặc các engine thực thi bất đồng bộ, khó hiểu.</p><h3>Nhanh và tiết kiệm tài nguyên</h3></p><p>PyTorch có chi phí framework tối thiểu. Chúng tôi tích hợp các thư viện tăng tốc như
<a href="https://software.intel.com/mkl" target="_blank" rel="noopener noreferrer">Intel MKL</a> và NVIDIA (<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">cuDNN</a>, <a href="https://developer.nvidia.com/nccl" target="_blank" rel="noopener noreferrer">NCCL</a>) để tối đa hóa tốc độ.
Ở lõi, backend Tensor và mạng nơ-ron cho CPU và GPU đã trưởng thành và được kiểm thử nhiều năm.</p><p>Do đó, PyTorch rất nhanh — dù bạn chạy mạng nơ-ron nhỏ hay lớn.</p><p>Việc sử dụng bộ nhớ trong PyTorch cực kỳ hiệu quả so với Torch hoặc một số lựa chọn thay thế.
Chúng tôi đã viết bộ cấp phát bộ nhớ tùy chỉnh cho GPU để đảm bảo mô hình học sâu của bạn sử dụng bộ nhớ tối ưu nhất.
Điều này cho phép bạn huấn luyện các mô hình học sâu lớn hơn trước.</p><h3>Mở rộng dễ dàng</h3></p><p>Viết module mạng nơ-ron mới, hoặc giao tiếp với API Tensor của PyTorch được thiết kế đơn giản và với mức trừu tượng tối thiểu.</p><p>Bạn có thể viết các lớp mạng nơ-ron mới bằng Python sử dụng API torch
<a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html" target="_blank" rel="noopener noreferrer">hoặc các thư viện dựa trên NumPy yêu thích như SciPy</a>.</p><p>Nếu bạn muốn viết lớp của mình bằng C/C++, chúng tôi cung cấp API mở rộng tiện lợi, hiệu quả và không cần mã bọc phức tạp.
Bạn có thể xem <a href="https://pytorch.org/tutorials/advanced/cpp_extension.html" target="_blank" rel="noopener noreferrer">hướng dẫn tại đây</a> và <a href="https://github.com/pytorch/extension-cpp" target="_blank" rel="noopener noreferrer">ví dụ tại đây</a>.</p><h2>Cài đặt</h2></p><h3>Các gói nhị phân</h3>
Lệnh cài đặt các gói nhị phân qua Conda hoặc pip wheels có trên website: <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">https://pytorch.org/get-started/locally/</a></p><p>
#### Nền tảng NVIDIA Jetson</p><p>Python wheels cho NVIDIA Jetson Nano, Jetson TX1/TX2, Jetson Xavier NX/AGX, và Jetson AGX Orin được cung cấp <a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048" target="_blank" rel="noopener noreferrer">tại đây</a> và L4T container được phát hành <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch" target="_blank" rel="noopener noreferrer">tại đây</a></p><p>Chúng yêu cầu JetPack 4.2 trở lên, và <a href="https://github.com/dusty-nv" target="_blank" rel="noopener noreferrer">@dusty-nv</a> cùng <a href="https://github.com/ptrblck" target="_blank" rel="noopener noreferrer">@ptrblck</a> đang duy trì chúng.</p><h3>Cài đặt từ mã nguồn</h3></p><p>#### Yêu cầu
Nếu bạn cài đặt từ mã nguồn, bạn sẽ cần:
<ul><li>Python 3.9 trở lên</li>
<li>Trình biên dịch hỗ trợ đầy đủ C++17, như clang hoặc gcc (gcc 9.4.0 hoặc mới hơn trên Linux)</li>
<li>Visual Studio hoặc Visual Studio Build Tool (chỉ dành cho Windows)</li></p><p></ul>\* PyTorch CI sử dụng Visual C++ BuildTools, đi kèm với Visual Studio Enterprise,
Professional hoặc Community Editions. Bạn cũng có thể cài build tools từ
https://visualstudio.microsoft.com/visual-cpp-build-tools/. Build tools <em>không</em> đi kèm với Visual Studio Code theo mặc định.</p><p>Ví dụ thiết lập môi trường như sau:</p><ul><li>Linux:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>/bin/activate
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME></code></pre></p><ul><li>Windows:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>\Scripts\activate.bat
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME>
$ call "C:\Program Files\Microsoft Visual Studio\<VERSION>\Community\VC\Auxiliary\Build\vcvarsall.bat" x64</code></pre></p><p>##### Hỗ trợ NVIDIA CUDA
Nếu bạn muốn biên dịch với hỗ trợ CUDA, <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">chọn phiên bản CUDA được hỗ trợ từ ma trận hỗ trợ của chúng tôi</a>, sau đó cài đặt:
<ul><li><a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener noreferrer">NVIDIA CUDA</a></li>
<li><a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">NVIDIA cuDNN</a> v8.5 trở lên</li>
<li><a href="https://gist.github.com/ax3l/9489132" target="_blank" rel="noopener noreferrer">Trình biên dịch</a> tương thích với CUDA</li></p><p></ul>Lưu ý: Bạn có thể tham khảo <a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html" target="_blank" rel="noopener noreferrer">cuDNN Support Matrix</a> để biết các phiên bản cuDNN tương thích với các phiên bản CUDA, driver CUDA và phần cứng NVIDIA khác nhau</p><p>Nếu muốn tắt hỗ trợ CUDA, xuất biến môi trường <code>USE_CUDA=0</code>.
Các biến môi trường hữu ích khác có thể được tìm thấy trong <code>setup.py</code>.</p><p>Nếu bạn đang biên dịch cho nền tảng Jetson của NVIDIA (Jetson Nano, TX1, TX2, AGX Xavier), hướng dẫn cài đặt PyTorch cho Jetson Nano có <a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/" target="_blank" rel="noopener noreferrer">tại đây</a></p><p>##### Hỗ trợ AMD ROCm
Nếu muốn biên dịch với hỗ trợ ROCm, hãy cài đặt
<ul><li><a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html" target="_blank" rel="noopener noreferrer">AMD ROCm</a> 4.0 trở lên</li>
<li>ROCm hiện chỉ hỗ trợ hệ thống Linux.</li></p><p></ul>Mặc định, hệ thống build mong đợi ROCm được cài tại <code>/opt/rocm</code>. Nếu ROCm được cài ở thư mục khác, biến môi trường <code>ROCM_PATH</code> phải được đặt về thư mục cài đặt ROCm. Hệ thống build tự động nhận diện kiến trúc GPU AMD. Tuỳ chọn, kiến trúc GPU AMD có thể được đặt rõ ràng bằng biến môi trường <code>PYTORCH_ROCM_ARCH</code> <a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus" target="_blank" rel="noopener noreferrer">Kiến trúc GPU AMD</a></p><p>Nếu muốn tắt hỗ trợ ROCm, xuất biến môi trường <code>USE_ROCM=0</code>.
Các biến môi trường hữu ích khác có thể được tìm thấy trong <code>setup.py</code>.</p><p>##### Hỗ trợ GPU Intel
Nếu muốn biên dịch với hỗ trợ GPU Intel, thực hiện các bước sau
<ul><li><a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html" target="_blank" rel="noopener noreferrer">Yêu cầu PyTorch cho GPU Intel</a>.</li>
<li>GPU Intel được hỗ trợ trên Linux và Windows.</li></p><p></ul>Nếu muốn tắt hỗ trợ GPU Intel, xuất biến môi trường <code>USE_XPU=0</code>.
Các biến môi trường hữu ích khác có thể được tìm thấy trong <code>setup.py</code>.</p><p>#### Lấy mã nguồn PyTorch
<pre><code class="language-bash">git clone https://github.com/pytorch/pytorch
cd pytorch
<h1>nếu bạn đang cập nhật một bản checkout đã có</h1>
git submodule sync
git submodule update --init --recursive</code></pre></p><p>#### Cài đặt các phụ thuộc</p><p><strong>Chung</strong></p><pre><code class="language-bash">conda install cmake ninja
<h1>Chạy lệnh này trong thư mục PyTorch sau khi clone mã nguồn theo mục “Lấy mã nguồn PyTorch” phía trên</h1>
pip install -r requirements.txt</code></pre></p><p><strong>Trên Linux</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>Chỉ CUDA: Thêm hỗ trợ LAPACK cho GPU nếu cần</h1>
<h1>cài đặt magma: chạy với môi trường conda đang hoạt động. chỉ định phiên bản CUDA để cài</h1>
.ci/docker/common/install_magma_conda.sh 12.4</p><h1>(tùy chọn) Nếu sử dụng torch.compile với inductor/triton, cài phiên bản triton tương ứng</h1>
<h1>Chạy từ thư mục pytorch sau khi clone</h1>
<h1>Đối với GPU Intel, hãy xuất rõ ràng <code>export USE_XPU=1</code> trước khi chạy lệnh.</h1>
make triton</code></pre></p><p><strong>Trên MacOS</strong></p><pre><code class="language-bash"># Chỉ thêm gói này trên máy x86 Intel
pip install mkl-static mkl-include
<h1>Thêm các gói này nếu cần torch.distributed</h1>
conda install pkg-config libuv</code></pre></p><p><strong>Trên Windows</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>Thêm các gói này nếu cần torch.distributed.</h1>
<h1>Hỗ trợ package distributed trên Windows là tính năng thử nghiệm và có thể thay đổi.</h1>
conda install -c conda-forge libuv=1.39</code></pre></p><p>#### Cài đặt PyTorch
<strong>Trên Linux</strong></p><p>Nếu bạn biên dịch cho AMD ROCm, hãy chạy lệnh này trước:
<pre><code class="language-bash"># Chỉ chạy nếu biên dịch cho ROCm
python tools/amd_build/build_amd.py</code></pre></p><p>Cài đặt PyTorch
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py develop</code></pre></p><p><strong>Trên macOS</strong></p><pre><code class="language-bash">python3 setup.py develop</code></pre></p><p><strong>Trên Windows</strong></p><p>Nếu bạn muốn build mã Python cũ, vui lòng xem <a href="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda" target="_blank" rel="noopener noreferrer">Xây dựng trên mã cũ và CUDA</a></p><p><strong>Chỉ build CPU</strong></p><p>Ở chế độ này, các phép tính PyTorch sẽ chạy trên CPU của bạn, không sử dụng GPU.</p><pre><code class="language-cmd">python setup.py develop</code></pre></p><p>Lưu ý về OpenMP: Phiên bản OpenMP mong muốn là Intel OpenMP (iomp). Để liên kết với iomp, bạn cần tự tải thư viện về và thiết lập môi trường build bằng cách chỉnh <code>CMAKE_INCLUDE_PATH</code> và <code>LIB</code>. Hướng dẫn <a href="https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source" target="_blank" rel="noopener noreferrer">tại đây</a> là ví dụ để thiết lập cả MKL và Intel OpenMP. Nếu không cấu hình cho CMake, runtime OpenMP của Microsoft Visual C (vcomp) sẽ được sử dụng.</p><p><strong>Build dựa trên CUDA</strong></p><p>Ở chế độ này, các phép tính PyTorch sẽ tận dụng GPU thông qua CUDA để tính toán nhanh hơn</p><p><a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm" target="_blank" rel="noopener noreferrer">NVTX</a> cần thiết để build PyTorch với CUDA.
NVTX là một phần của bộ CUDA, có tên "Nsight Compute". Để cài đặt nó vào CUDA đã cài, hãy chạy cài đặt CUDA một lần nữa và chọn checkbox tương ứng.
Đảm bảo CUDA với Nsight Compute được cài sau Visual Studio.</p><p>Hiện tại, VS 2017 / 2019, và Ninja được hỗ trợ làm generator của CMake. Nếu tìm thấy <code>ninja.exe</code> trong <code>PATH</code>, Ninja sẽ được dùng mặc định, nếu không sẽ dùng VS 2017 / 2019.
<br/> Nếu Ninja được chọn làm generator, MSVC mới nhất sẽ được chọn làm toolchain.</p><p>Các thư viện bổ sung như
<a href="https://developer.nvidia.com/magma" target="_blank" rel="noopener noreferrer">Magma</a>, <a href="https://github.com/oneapi-src/oneDNN" target="_blank" rel="noopener noreferrer">oneDNN, còn gọi là MKLDNN hoặc DNNL</a>, và <a href="https://github.com/mozilla/sccache" target="_blank" rel="noopener noreferrer">Sccache</a> thường cần thiết. Tham khảo <a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers" target="_blank" rel="noopener noreferrer">installation-helper</a> để cài đặt chúng.</p><p>Bạn có thể tham khảo script <a href="https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat" target="_blank" rel="noopener noreferrer">build_pytorch.bat</a> để biết các cấu hình biến môi trường khác</p><pre><code class="language-cmd">cmd</p><p>:: Đặt biến môi trường sau khi đã tải và giải nén gói mkl,
:: nếu không CMake sẽ báo lỗi <code>Could NOT find OpenMP</code>.
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%</p><p>:: Đọc kỹ nội dung phần trước khi tiếp tục.
:: [Tùy chọn] Nếu bạn muốn ghi đè toolset sử dụng bởi Ninja và Visual Studio với CUDA, hãy chạy khối lệnh sau.
:: "Visual Studio 2019 Developer Command Prompt" sẽ được chạy tự động.
:: Đảm bảo bạn có CMake >= 3.12 khi sử dụng Visual Studio generator.
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f "usebackq tokens=<em>" %i in (<code>"%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe" -version [15^,17^) -products </em> -latest -property installationPath</code>) do call "%i\VC\Auxiliary\Build\vcvarsall.bat" x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%</p><p>:: [Tùy chọn] Nếu muốn ghi đè CUDA host compiler
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe</p><p>python setup.py develop
</code></pre></p><p><strong>Build GPU Intel</strong></p><p>Ở chế độ này PyTorch sẽ được build với hỗ trợ GPU Intel.</p><p>Đảm bảo <a href="#prerequisites" target="_blank" rel="noopener noreferrer">các yêu cầu chung</a> cũng như <a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">yêu cầu cho GPU Intel</a> đã được cài đặt và cấu hình biến môi trường trước khi bắt đầu build. Đối với công cụ build, yêu cầu <code>Visual Studio 2022</code>.</p><p>Sau đó có thể build PyTorch với lệnh:</p><pre><code class="language-cmd">:: Lệnh CMD:
:: Đặt CMAKE_PREFIX_PATH để giúp tìm các package tương ứng
:: %CONDA_PREFIX% chỉ hoạt động sau khi <code>conda activate custom_env</code></p><p>if defined CMAKE_PREFIX_PATH (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%"
) else (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library"
)</p><p>python setup.py develop</code></pre></p><p>##### Điều chỉnh tuỳ chọn biên dịch (Tùy chọn)</p><p>Bạn có thể điều chỉnh cấu hình các biến cmake (mà không cần build trước), ví dụ, chỉnh lại đường dẫn phát hiện cho CuDNN hoặc BLAS.</p><p>Trên Linux
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py build --cmake-only
ccmake build  # hoặc cmake-gui build</code></pre></p><p>Trên macOS
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only
ccmake build  # hoặc cmake-gui build</code></pre></p><h3>Docker Image</h3></p><p>#### Sử dụng image dựng sẵn</p><p>Bạn cũng có thể tải image docker dựng sẵn từ Docker Hub và chạy với docker v19.03+</p><pre><code class="language-bash">docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest</code></pre></p><p>Lưu ý rằng PyTorch sử dụng shared memory để chia sẻ dữ liệu giữa các tiến trình, nên nếu sử dụng torch multiprocessing (ví dụ cho data loader đa luồng) thì shared memory mặc định container chạy không đủ, bạn nên tăng kích thước shared memory với tuỳ chọn dòng lệnh <code>--ipc=host</code> hoặc <code>--shm-size</code> cho <code>nvidia-docker run</code>.</p><p>#### Tự dựng image</p><p><strong>LƯU Ý:</strong> Phải được dựng với phiên bản docker > 18.06</p><p><code>Dockerfile</code> được cung cấp để build image với hỗ trợ CUDA 11.1 và cuDNN v8.
Bạn có thể truyền biến make <code>PYTHON_VERSION=x.y</code> để chỉ định phiên bản Python dùng cho Miniconda, hoặc để mặc định.</p><pre><code class="language-bash">make -f docker.Makefile
<h1>các image sẽ được tag là docker.io/${your_docker_username}/pytorch</code></pre></h1></p><p>Bạn cũng có thể truyền biến môi trường <code>CMAKE_VARS="..."</code> để chỉ định các biến CMake bổ sung khi build.
Xem <a href="./setup.py" target="_blank" rel="noopener noreferrer">setup.py</a> để biết danh sách các biến khả dụng.</p><pre><code class="language-bash">make -f docker.Makefile</code></pre></p><h3>Biên dịch tài liệu</h3></p><p>Để biên dịch tài liệu ở nhiều định dạng, bạn cần <a href="http://www.sphinx-doc.org" target="_blank" rel="noopener noreferrer">Sphinx</a>
và pytorch_sphinx_theme2.</p><p>Trước khi biên dịch tài liệu cục bộ, đảm bảo <code>torch</code> đã được
cài vào môi trường của bạn. Với các sửa lỗi nhỏ, bạn có thể cài
bản nightly như mô tả ở <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">Bắt đầu sử dụng</a>.</p><p>Với các sửa lớn, như thêm module mới và docstrings cho module đó, bạn có thể cần cài torch <a href="#from-source" target="_blank" rel="noopener noreferrer">từ mã nguồn</a>.
Xem <a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines" target="_blank" rel="noopener noreferrer">Hướng dẫn Docstring</a>
cho quy tắc docstring.</p><pre><code class="language-bash">cd docs/
pip install -r requirements.txt
make html
make serve</code></pre></p><p>Chạy <code>make</code> để xem tất cả các định dạng đầu ra khả dụng.</p><p>Nếu gặp lỗi katex, chạy <code>npm install katex</code>.  Nếu vẫn còn, thử
<code>npm install -g katex</code></p><blockquote>[!LƯU Ý]</blockquote>
<blockquote>Nếu bạn cài <code>nodejs</code> qua một trình quản lý gói khác (ví dụ,</blockquote>
<blockquote><code>conda</code>) thì <code>npm</code> có thể cài một phiên bản <code>katex</code> không tương thích với phiên bản <code>nodejs</code> của bạn khiến biên dịch tài liệu bị lỗi.</blockquote>
<blockquote>Một tổ hợp phiên bản hoạt động là <code>node@6.13.1</code> và</blockquote>
<blockquote><code>katex@0.13.18</code>. Để cài bản này với <code>npm</code> chạy</blockquote>
<blockquote>``<code>npm install -g katex@0.13.18<pre><code class="language-"></blockquote>
<blockquote>[!LƯU Ý]</blockquote>
<blockquote>Nếu gặp lỗi không tương thích numpy, chạy:</blockquote>
<blockquote></code>`<code></blockquote>
<blockquote>pip install 'numpy<2'</blockquote>
<blockquote></code>`<code></blockquote></p><p>Khi bạn thay đổi các phụ thuộc được CI chạy, hãy chỉnh file
</code>.ci/docker/requirements-docs.txt<code>.</p><p>#### Biên dịch PDF</p><p>Để biên dịch PDF của toàn bộ tài liệu PyTorch, đảm bảo bạn đã cài
</code>texlive<code> và LaTeX. Trên macOS, bạn có thể cài bằng:
</code></pre>
brew install --cask mactex
</code>`<code></p><p>Để tạo PDF:</p><ul><li>Chạy:</li></p><p>   </ul></code>`<code>
   make latexpdf
   </code>`<code></p><p>   Lệnh này sẽ sinh các file cần thiết trong thư mục </code>build/latex<code>.</p><ul><li>Chuyển đến thư mục này và thực thi:</li></p><p>   </ul></code>`<code>
   make LATEXOPTS="-interaction=nonstopmode"
   </code>`<code></p><p>   Lệnh này sẽ tạo </code>pytorch.pdf` với nội dung mong muốn. Chạy lại
   lệnh này một lần nữa để tạo bảng mục lục và chỉ mục chính xác.</p><blockquote>[!LƯU Ý]</blockquote>
<blockquote>Để xem bảng mục lục, chuyển sang chế độ <strong>Table of Contents</strong></blockquote>
<blockquote>trên trình xem PDF của bạn.</blockquote></p><h3>Các phiên bản trước đây</h3></p><p>Hướng dẫn cài đặt và các gói nhị phân cho các phiên bản PyTorch trước đây có thể tìm thấy
trên <a href="https://pytorch.org/get-started/previous-versions" target="_blank" rel="noopener noreferrer">website của chúng tôi</a>.</p><h2>Bắt đầu sử dụng</h2></p><p>Ba mục tiêu giúp bạn bắt đầu:
<ul><li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">Hướng dẫn: giúp bạn hiểu và sử dụng PyTorch</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">Ví dụ: mã PyTorch dễ hiểu ở mọi lĩnh vực</a></li>
<li><a href="https://pytorch.org/docs/" target="_blank" rel="noopener noreferrer">Tham khảo API</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md" target="_blank" rel="noopener noreferrer">Thuật ngữ</a></li></p><p></ul><h2>Tài nguyên</h2></p><ul><li><a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">PyTorch.org</a></li>
<li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">Hướng dẫn PyTorch</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">Ví dụ PyTorch</a></li>
<li><a href="https://pytorch.org/hub/" target="_blank" rel="noopener noreferrer">Các mô hình PyTorch</a></li>
<li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188" target="_blank" rel="noopener noreferrer">Giới thiệu về Deep Learning với PyTorch từ Udacity</a></li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229" target="_blank" rel="noopener noreferrer">Giới thiệu về Machine Learning với PyTorch từ Udacity</a></li>
<li><a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch" target="_blank" rel="noopener noreferrer">Deep Neural Networks with PyTorch từ Coursera</a></li>
<li><a href="https://twitter.com/PyTorch" target="_blank" rel="noopener noreferrer">PyTorch Twitter</a></li>
<li><a href="https://pytorch.org/blog/" target="_blank" rel="noopener noreferrer">PyTorch Blog</a></li>
<li><a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw" target="_blank" rel="noopener noreferrer">PyTorch YouTube</a></li></p><p></ul><h2>Trao đổi</h2>
<ul><li>Diễn đàn: Thảo luận về triển khai, nghiên cứu, v.v. https://discuss.pytorch.org</li>
<li>GitHub Issues: Báo lỗi, yêu cầu tính năng, vấn đề cài đặt, RFC, ý kiến, v.v.</li>
<li>Slack: <a href="https://pytorch.slack.com/" target="_blank" rel="noopener noreferrer">PyTorch Slack</a> dành cho người dùng và nhà phát triển PyTorch trung cấp đến cao cấp cho trò chuyện, thảo luận online, cộng tác, v.v. Nếu bạn là người mới cần trợ giúp, nên dùng <a href="https://discuss.pytorch.org" target="_blank" rel="noopener noreferrer">Diễn đàn PyTorch</a>. Nếu bạn cần thư mời Slack, vui lòng điền vào form: https://goo.gl/forms/PP1AGvNHpSaJP8to1</li>
<li>Bản tin: Email một chiều với thông báo quan trọng về PyTorch. Đăng ký tại đây: https://eepurl.com/cbG0rv</li>
<li>Facebook Page: Thông báo quan trọng về PyTorch. https://www.facebook.com/pytorch</li>
<li>Để biết hướng dẫn thương hiệu, vui lòng truy cập website tại <a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">pytorch.org</a></li></p><p></ul><h2>Phát hành và đóng góp</h2></p><p>Thông thường, PyTorch có ba bản phát hành nhỏ mỗi năm. Vui lòng thông báo cho chúng tôi nếu bạn gặp lỗi bằng cách <a href="https://github.com/pytorch/pytorch/issues" target="_blank" rel="noopener noreferrer">tạo issue</a>.</p><p>Chúng tôi trân trọng mọi đóng góp. Nếu bạn định đóng góp bản sửa lỗi, hãy thực hiện mà không cần thảo luận thêm.</p><p>Nếu bạn định đóng góp tính năng mới, hàm tiện ích hoặc mở rộng lõi, vui lòng mở issue trước và thảo luận với chúng tôi.
Gửi PR mà không thảo luận có thể bị từ chối nếu chúng tôi đang phát triển theo hướng khác mà bạn chưa biết.</p><p>Để tìm hiểu thêm về đóng góp cho PyTorch, vui lòng xem <a href="CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">Trang đóng góp</a>. Để biết thêm thông tin về các bản phát hành PyTorch, xem <a href="RELEASE.md" target="_blank" rel="noopener noreferrer">Trang phát hành</a>.</p><h2>Nhóm phát triển</h2></p><p>PyTorch là dự án cộng đồng với nhiều kỹ sư và nhà nghiên cứu tài năng đóng góp.</p><p>Hiện tại PyTorch được duy trì bởi <a href="http://soumith.ch" target="_blank" rel="noopener noreferrer">Soumith Chintala</a>, <a href="https://github.com/gchanan" target="_blank" rel="noopener noreferrer">Gregory Chanan</a>, <a href="https://github.com/dzhulgakov" target="_blank" rel="noopener noreferrer">Dmytro Dzhulgakov</a>, <a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a>, và <a href="https://github.com/malfet" target="_blank" rel="noopener noreferrer">Nikita Shulga</a> cùng sự đóng góp lớn từ hàng trăm cá nhân xuất sắc với nhiều hình thức khác nhau.
Danh sách dưới đây không đầy đủ nhưng đang mở rộng, gồm: <a href="https://github.com/killeent" target="_blank" rel="noopener noreferrer">Trevor Killeen</a>, <a href="https://github.com/chsasank" target="_blank" rel="noopener noreferrer">Sasank Chilamkurthy</a>, <a href="https://github.com/szagoruyko" target="_blank" rel="noopener noreferrer">Sergey Zagoruyko</a>, <a href="https://github.com/adamlerer" target="_blank" rel="noopener noreferrer">Adam Lerer</a>, <a href="https://github.com/fmassa" target="_blank" rel="noopener noreferrer">Francisco Massa</a>, <a href="https://github.com/alykhantejani" target="_blank" rel="noopener noreferrer">Alykhan Tejani</a>, <a href="https://github.com/lantiga" target="_blank" rel="noopener noreferrer">Luca Antiga</a>, <a href="https://github.com/albanD" target="_blank" rel="noopener noreferrer">Alban Desmaison</a>, <a href="https://github.com/andreaskoepf" target="_blank" rel="noopener noreferrer">Andreas Koepf</a>, <a href="https://github.com/jekbradbury" target="_blank" rel="noopener noreferrer">James Bradbury</a>, <a href="https://github.com/ebetica" target="_blank" rel="noopener noreferrer">Zeming Lin</a>, <a href="https://github.com/yuandong-tian" target="_blank" rel="noopener noreferrer">Yuandong Tian</a>, <a href="https://github.com/glample" target="_blank" rel="noopener noreferrer">Guillaume Lample</a>, <a href="https://github.com/Maratyszcza" target="_blank" rel="noopener noreferrer">Marat Dukhan</a>, <a href="https://github.com/ngimel" target="_blank" rel="noopener noreferrer">Natalia Gimelshein</a>, <a href="https://github.com/csarofeen" target="_blank" rel="noopener noreferrer">Christian Sarofeen</a>, <a href="https://github.com/martinraison" target="_blank" rel="noopener noreferrer">Martin Raison</a>, <a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a>, <a href="https://github.com/zdevito" target="_blank" rel="noopener noreferrer">Zachary Devito</a>.</p><p>Lưu ý: Dự án này không liên quan đến <a href="https://github.com/hughperkins/pytorch" target="_blank" rel="noopener noreferrer">hughperkins/pytorch</a> cùng tên. Hugh là cộng tác viên giá trị cho cộng đồng Torch và đã giúp đỡ nhiều việc liên quan Torch và PyTorch.</p><h2>Giấy phép</h2></p><p>PyTorch sử dụng giấy phép kiểu BSD, chi tiết trong file <a href="LICENSE" target="_blank" rel="noopener noreferrer">LICENSE</a>.

---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/pytorch/pytorch/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>