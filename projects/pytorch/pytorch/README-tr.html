<!DOCTYPE html>
<html lang="tr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch - Read pytorch documentation in Turkish. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read pytorch documentation in Turkish. This project has 0 stars on GitHub.">
    <meta name="keywords" content="pytorch, Turkish, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "pytorch",
  "description": "Read pytorch documentation in Turkish. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "pytorch"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/pytorch/pytorch/README-tr.html",
  "sameAs": "https://raw.githubusercontent.com/pytorch/pytorch/master/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    pytorch
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Turkish</span>
                <span>by pytorch</span>
            </div>
        </div>
        
        <div class="content">
            <p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="PyTorch Logosu"></p><p>--------------------------------------------------------------------------------</p><p>PyTorch, iki üst düzey özelliğe sahip bir Python paketidir:
<ul><li>Güçlü GPU hızlandırmalı tensör hesaplaması (NumPy gibi)</li>
<li>Bant tabanlı otomatik türev sistemiyle oluşturulmuş derin sinir ağları</li></p><p></ul>İhtiyaç duyduğunuzda PyTorch'u genişletmek için NumPy, SciPy ve Cython gibi favori Python paketlerinizi yeniden kullanabilirsiniz.</p><p>Ana daldaki sağlık durumu (Sürekli Entegrasyon sinyalleri) <a href="https://hud.pytorch.org/ci/pytorch/pytorch/main" target="_blank" rel="noopener noreferrer">hud.pytorch.org</a> adresinde bulunabilir.</p><p><!-- toc --></p><ul><li><a href="#more-about-pytorch" target="_blank" rel="noopener noreferrer">PyTorch Hakkında Daha Fazlası</a></li>
  <li><a href="#a-gpu-ready-tensor-library" target="_blank" rel="noopener noreferrer">GPU'ya Hazır Bir Tensör Kütüphanesi</a></li>
  <li><a href="#dynamic-neural-networks-tape-based-autograd" target="_blank" rel="noopener noreferrer">Dinamik Sinir Ağları: Bant Tabanlı Otomatik Türev</a></li>
  <li><a href="#python-first" target="_blank" rel="noopener noreferrer">Öncelik Python'da</a></li>
  <li><a href="#imperative-experiences" target="_blank" rel="noopener noreferrer">Emirsel Deneyimler</a></li>
  <li><a href="#fast-and-lean" target="_blank" rel="noopener noreferrer">Hızlı ve Hafif</a></li>
  <li><a href="#extensions-without-pain" target="_blank" rel="noopener noreferrer">Sorunsuz Genişletmeler</a></li>
<li><a href="#installation" target="_blank" rel="noopener noreferrer">Kurulum</a></li>
  <li><a href="#binaries" target="_blank" rel="noopener noreferrer">İkili Dosyalar</a></li>
    <li><a href="#nvidia-jetson-platforms" target="_blank" rel="noopener noreferrer">NVIDIA Jetson Platformları</a></li>
  <li><a href="#from-source" target="_blank" rel="noopener noreferrer">Kaynaktan Kurulum</a></li>
    <li><a href="#prerequisites" target="_blank" rel="noopener noreferrer">Önkoşullar</a></li>
      <li><a href="#nvidia-cuda-support" target="_blank" rel="noopener noreferrer">NVIDIA CUDA Desteği</a></li>
      <li><a href="#amd-rocm-support" target="_blank" rel="noopener noreferrer">AMD ROCm Desteği</a></li>
      <li><a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">Intel GPU Desteği</a></li>
    <li><a href="#get-the-pytorch-source" target="_blank" rel="noopener noreferrer">PyTorch Kaynağını Edinin</a></li>
    <li><a href="#install-dependencies" target="_blank" rel="noopener noreferrer">Bağımlılıkları Kurun</a></li>
    <li><a href="#install-pytorch" target="_blank" rel="noopener noreferrer">PyTorch'u Kurun</a></li>
      <li><a href="#adjust-build-options-optional" target="_blank" rel="noopener noreferrer">Derleme Seçeneklerini Ayarlama (İsteğe Bağlı)</a></li>
  <li><a href="#docker-image" target="_blank" rel="noopener noreferrer">Docker İmajı</a></li>
    <li><a href="#using-pre-built-images" target="_blank" rel="noopener noreferrer">Hazır İmajların Kullanılması</a></li>
    <li><a href="#building-the-image-yourself" target="_blank" rel="noopener noreferrer">Kendi İmajınızı Oluşturma</a></li>
  <li><a href="#building-the-documentation" target="_blank" rel="noopener noreferrer">Dokümantasyonu Derleme</a></li>
    <li><a href="#building-a-pdf" target="_blank" rel="noopener noreferrer">PDF Oluşturma</a></li>
  <li><a href="#previous-versions" target="_blank" rel="noopener noreferrer">Önceki Sürümler</a></li>
<li><a href="#getting-started" target="_blank" rel="noopener noreferrer">Başlangıç</a></li>
<li><a href="#resources" target="_blank" rel="noopener noreferrer">Kaynaklar</a></li>
<li><a href="#communication" target="_blank" rel="noopener noreferrer">İletişim</a></li>
<li><a href="#releases-and-contributing" target="_blank" rel="noopener noreferrer">Sürümler ve Katkı</a></li>
<li><a href="#the-team" target="_blank" rel="noopener noreferrer">Ekip</a></li>
<li><a href="#license" target="_blank" rel="noopener noreferrer">Lisans</a></li></p><p></ul><!-- tocstop --></p><h2>PyTorch Hakkında Daha Fazlası</h2></p><p><a href="https://pytorch.org/tutorials/beginner/basics/intro.html" target="_blank" rel="noopener noreferrer">PyTorch'un temellerini öğrenin</a></p><p>Detaylı olarak, PyTorch aşağıdaki bileşenlerden oluşan bir kütüphanedir:</p><p>| Bileşen | Açıklama |
| ---- | --- |
| <a href="https://pytorch.org/docs/stable/torch.html" target="_blank" rel="noopener noreferrer"><strong>torch</strong></a> | NumPy gibi bir Tensör kütüphanesi, güçlü GPU desteğiyle |
| <a href="https://pytorch.org/docs/stable/autograd.html" target="_blank" rel="noopener noreferrer"><strong>torch.autograd</strong></a> | torch içindeki tüm türevlenebilir Tensör işlemlerini destekleyen bant tabanlı otomatik türev kütüphanesi |
| <a href="https://pytorch.org/docs/stable/jit.html" target="_blank" rel="noopener noreferrer"><strong>torch.jit</strong></a> | PyTorch kodundan serileştirilebilir ve optimize edilebilir modeller oluşturan bir derleme yığını (TorchScript) |
| <a href="https://pytorch.org/docs/stable/nn.html" target="_blank" rel="noopener noreferrer"><strong>torch.nn</strong></a> | Maksimum esneklik için autograd ile derinlemesine entegre edilmiş bir sinir ağları kütüphanesi |
| <a href="https://pytorch.org/docs/stable/multiprocessing.html" target="_blank" rel="noopener noreferrer"><strong>torch.multiprocessing</strong></a> | torch Tensörlerinin işlemler arasında sihirli bellek paylaşımı ile Python çoklu işlem. Veri yükleme ve Hogwild eğitimi için faydalı |
| <a href="https://pytorch.org/docs/stable/data.html" target="_blank" rel="noopener noreferrer"><strong>torch.utils</strong></a> | Kolaylık için DataLoader ve diğer yardımcı işlevler |</p><p>Genellikle, PyTorch ya:</p><ul><li>GPU’ların gücünü kullanmak için NumPy yerine,</li>
<li>Maksimum esneklik ve hız sağlayan bir derin öğrenme araştırma platformu olarak kullanılır.</li></p><p></ul>Daha Fazlası:</p><h3>GPU'ya Hazır Bir Tensör Kütüphanesi</h3></p><p>NumPy kullanıyorsanız, zaten Tensörleri (veya ndarray) kullanıyorsunuz demektir.</p><p><img src="./docs/source/_static/img/tensor_illustration.png" alt="Tensör illüstrasyonu"></p><p>PyTorch, CPU veya GPU üzerinde yaşayabilen Tensörler sağlar ve
hesaplamayı büyük ölçüde hızlandırır.</p><p>Bilimsel hesaplama ihtiyaçlarınızı karşılamak ve hızlandırmak için çok çeşitli tensör rutinleri sağlıyoruz:
bölütleme, indeksleme, matematiksel işlemler, lineer cebir, indirgemeler gibi.
Ve bunlar oldukça hızlıdır!</p><h3>Dinamik Sinir Ağları: Bant Tabanlı Otomatik Türev</h3></p><p>PyTorch, sinir ağlarını kurmak için benzersiz bir yol sunar: bir bant kaydedici kullanmak ve tekrar oynatmak.</p><p>TensorFlow, Theano, Caffe ve CNTK gibi çoğu framework dünyayı statik olarak görür.
Bir sinir ağı inşa edilir ve aynı yapı tekrar tekrar kullanılır.
Ağın davranışını değiştirmek için sıfırdan başlamak gerekir.</p><p>PyTorch ile, ters mod otomatik türevleme (reverse-mode auto-differentiation) adı verilen bir teknik kullanıyoruz; bu, ağınızın davranışını gecikmesiz ve ek yük olmadan keyfi olarak değiştirmenize olanak tanır. İlham kaynağımız bu konudaki çeşitli araştırma makaleleri ile <a href="https://github.com/twitter/torch-autograd" target="_blank" rel="noopener noreferrer">torch-autograd</a>,
<a href="https://github.com/HIPS/autograd" target="_blank" rel="noopener noreferrer">autograd</a>,
<a href="https://chainer.org" target="_blank" rel="noopener noreferrer">Chainer</a> gibi önceki ve güncel çalışmalardır.</p><p>Bu teknik sadece PyTorch'a özgü olmasa da, bugüne kadarki en hızlı uygulamalardan biridir.
Çılgın araştırmalarınız için hız ve esnekliğin en iyisini elde edersiniz.</p><p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="Dinamik grafik"></p><h3>Öncelik Python'da</h3></p><p>PyTorch, tekdüze bir C++ framework'üne Python bağlaması değildir.
Python ile derinlemesine entegre olacak şekilde inşa edilmiştir.
<a href="https://www.numpy.org/" target="_blank" rel="noopener noreferrer">NumPy</a> / <a href="https://www.scipy.org/" target="_blank" rel="noopener noreferrer">SciPy</a> / <a href="https://scikit-learn.org" target="_blank" rel="noopener noreferrer">scikit-learn</a> gibi doğal olarak kullanabilirsiniz.
Yeni sinir ağı katmanlarınızı doğrudan Python'da, favori kütüphanelerinizi kullanarak yazabilirsiniz
ve <a href="https://cython.org/" target="_blank" rel="noopener noreferrer">Cython</a> ile <a href="http://numba.pydata.org/" target="_blank" rel="noopener noreferrer">Numba</a> gibi paketler kullanabilirsiniz.
Amacımız, uygun olan yerde tekerleği yeniden icat etmemektir.</p><h3>Emirsel Deneyimler</h3></p><p>PyTorch, sezgisel, doğrusal düşünceye uygun ve kullanımı kolay olacak şekilde tasarlanmıştır.
Bir kod satırı çalıştırdığınızda, hemen çalışır. Asenkron bir dünya yoktur.
Bir hata mesajı veya stack trace aldığınızda, anlaması kolaydır.
Stack trace doğrudan kodunuzun tanımlandığı yere işaret eder.
Kötü stack trace'ler veya asenkron ve opak yürütme motorları yüzünden saatlerce hata ayıklamak zorunda kalmamanızı umuyoruz.</p><h3>Hızlı ve Hafif</h3></p><p>PyTorch, minimum framework yüküne sahiptir. <a href="https://software.intel.com/mkl" target="_blank" rel="noopener noreferrer">Intel MKL</a> ve NVIDIA (<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">cuDNN</a>, <a href="https://developer.nvidia.com/nccl" target="_blank" rel="noopener noreferrer">NCCL</a>) gibi hızlandırıcı kütüphaneler entegre ediyoruz.
Çekirdekteki CPU ve GPU Tensör ile sinir ağı arka uçları
oldukça olgundur ve yıllardır test edilmektedir.</p><p>Bu nedenle, PyTorch oldukça hızlıdır — ister küçük ister büyük sinir ağları çalıştırıyor olun.</p><p>PyTorch'taki bellek kullanımı, Torch veya bazı alternatiflerle karşılaştırıldığında son derece verimlidir.
GPU için özel bellek ayırıcılar yazdık, böylece
derin öğrenme modelleriniz maksimum bellek verimliliğine sahip olur.
Bu, daha önceki modellere göre daha büyük derin öğrenme modelleri eğitmenizi sağlar.</p><h3>Sorunsuz Genişletmeler</h3></p><p>Yeni sinir ağı modülleri yazmak veya PyTorch'un Tensör API'siyle arayüz oluşturmak, basit ve minimum soyutlamalarla tasarlanmıştır.</p><p>torch API'sini kullanarak Python'da yeni sinir ağı katmanları
<a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html" target="_blank" rel="noopener noreferrer">veya SciPy gibi favori NumPy tabanlı kütüphanelerinizle</a> yazabilirsiniz.</p><p>Katmanlarınızı C/C++'ta yazmak isterseniz, verimli ve az kod gerektiren uygun bir genişletme API'si sağlıyoruz.
Ek bir sarmalayıcı kod yazmanız gerekmez. <a href="https://pytorch.org/tutorials/advanced/cpp_extension.html" target="_blank" rel="noopener noreferrer">Burada bir eğitim</a> ve <a href="https://github.com/pytorch/extension-cpp" target="_blank" rel="noopener noreferrer">örnek</a> bulabilirsiniz.</p><h2>Kurulum</h2></p><h3>İkili Dosyalar</h3>
Conda veya pip wheels ile ikili dosyaları yüklemek için komutlar web sitemizdedir: <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">https://pytorch.org/get-started/locally/</a></p><p>
#### NVIDIA Jetson Platformları</p><p>NVIDIA'nın Jetson Nano, Jetson TX1/TX2, Jetson Xavier NX/AGX ve Jetson AGX Orin için Python wheel dosyaları <a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048" target="_blank" rel="noopener noreferrer">burada</a> sağlanmıştır ve L4T container <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch" target="_blank" rel="noopener noreferrer">burada</a> yayınlanmıştır.</p><p>JetPack 4.2 ve üstü gereklidir, ve <a href="https://github.com/dusty-nv" target="_blank" rel="noopener noreferrer">@dusty-nv</a> ile <a href="https://github.com/ptrblck" target="_blank" rel="noopener noreferrer">@ptrblck</a> tarafından bakım yapılmaktadır.</p><h3>Kaynaktan Kurulum</h3></p><p>#### Önkoşullar
Kaynak koddan kurulum yapacaksanız, şunlara ihtiyacınız olacak:
<ul><li>Python 3.9 veya üstü</li>
<li>C++17'yi tamamen destekleyen bir derleyici, örn. clang veya gcc (Linux'ta gcc 9.4.0 veya üstü gereklidir)</li>
<li>Visual Studio veya Visual Studio Build Tool (sadece Windows için)</li></p><p></ul>\<em> PyTorch CI, Visual Studio Enterprise, Professional veya Community Sürümleriyle gelen Visual C++ BuildTools'u kullanır. Build tools'u ayrıca https://visualstudio.microsoft.com/visual-cpp-build-tools/ adresinden kurabilirsiniz. Build tools </em>varsayılan olarak* Visual Studio Code ile gelmez.</p><p>Aşağıda bir ortam kurulumu örneği gösterilmiştir:</p><ul><li>Linux:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>/bin/activate
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME></code></pre></p><ul><li>Windows:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>\Scripts\activate.bat
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME>
$ call "C:\Program Files\Microsoft Visual Studio\<VERSION>\Community\VC\Auxiliary\Build\vcvarsall.bat" x64</code></pre></p><p>##### NVIDIA CUDA Desteği
CUDA desteğiyle derleme yapmak istiyorsanız, <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">destek matrisimizden desteklenen bir CUDA sürümü seçin</a>, ardından şunları yükleyin:
<ul><li><a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener noreferrer">NVIDIA CUDA</a></li>
<li><a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">NVIDIA cuDNN</a> v8.5 veya üstü</li>
<li>CUDA ile uyumlu <a href="https://gist.github.com/ax3l/9489132" target="_blank" rel="noopener noreferrer">Derleyici</a></li></p><p></ul>Not: <a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html" target="_blank" rel="noopener noreferrer">cuDNN Destek Matrisi</a> üzerinden, farklı CUDA, CUDA sürücüsü ve NVIDIA donanımlarıyla uyumlu cuDNN sürümlerine bakabilirsiniz.</p><p>CUDA desteğini devre dışı bırakmak isterseniz, <code>USE_CUDA=0</code> ortam değişkenini dışa aktarın.
Diğer faydalı ortam değişkenleri <code>setup.py</code> içinde bulunabilir.</p><p>NVIDIA'nın Jetson platformları (Jetson Nano, TX1, TX2, AGX Xavier) için derleme yapıyorsanız, Jetson Nano için PyTorch kurulum talimatları <a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/" target="_blank" rel="noopener noreferrer">burada</a> mevcuttur.</p><p>##### AMD ROCm Desteği
ROCm desteğiyle derleme yapmak istiyorsanız, şunları yükleyin:
<ul><li><a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html" target="_blank" rel="noopener noreferrer">AMD ROCm</a> 4.0 ve üstü</li>
<li>ROCm şu anda sadece Linux sistemlerinde desteklenmektedir.</li></p><p></ul>Varsayılan olarak derleme sistemi, ROCm'un <code>/opt/rocm</code> dizinine kurulu olduğunu varsayar. ROCm farklı bir dizine kuruluysa, <code>ROCM_PATH</code> ortam değişkeni ROCm kurulum dizinine ayarlanmalıdır. Derleme sistemi AMD GPU mimarisini otomatik olarak algılar. İsteğe bağlı olarak, AMD GPU mimarisi <code>PYTORCH_ROCM_ARCH</code> ortam değişkeniyle açıkça ayarlanabilir <a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus" target="_blank" rel="noopener noreferrer">AMD GPU mimarisi</a></p><p>ROCm desteğini devre dışı bırakmak için <code>USE_ROCM=0</code> ortam değişkenini dışa aktarın.
Diğer faydalı ortam değişkenleri <code>setup.py</code> içinde bulunabilir.</p><p>##### Intel GPU Desteği
Intel GPU desteğiyle derleme yapmak istiyorsanız, şunları takip edin:
<ul><li><a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html" target="_blank" rel="noopener noreferrer">Intel GPU'lar için PyTorch Önkoşulları</a> talimatları.</li>
<li>Intel GPU desteği Linux ve Windows için mevcuttur.</li></p><p></ul>Intel GPU desteğini devre dışı bırakmak için <code>USE_XPU=0</code> ortam değişkenini dışa aktarın.
Diğer faydalı ortam değişkenleri <code>setup.py</code> içinde bulunabilir.</p><p>#### PyTorch Kaynağını Edinin
<pre><code class="language-bash">git clone https://github.com/pytorch/pytorch
cd pytorch
<h1>mevcut bir checkout'u güncelliyorsanız</h1>
git submodule sync
git submodule update --init --recursive</code></pre></p><p>#### Bağımlılıkları Kurun</p><p><strong>Ortak</strong></p><pre><code class="language-bash">conda install cmake ninja
<h1>Aşağıdaki “PyTorch Kaynağını Edinin” bölümünden kaynak kodunu klonladıktan sonra bu komutu PyTorch dizininde çalıştırın</h1>
pip install -r requirements.txt</code></pre></p><p><strong>Linux'ta</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>Sadece CUDA: Gerekirse GPU için LAPACK desteği ekleyin</h1>
<h1>magma kurulumu: aktif conda ortamında çalıştırın. kurulacak CUDA sürümünü belirtin</h1>
.ci/docker/common/install_magma_conda.sh 12.4</p><h1>(isteğe bağlı) torch.compile ile inductor/triton kullanıyorsanız, triton'un uyumlu sürümünü kurun</h1>
<h1>pytorch dizininde çalıştırın</h1>
<h1>Intel GPU desteği için, komutu çalıştırmadan önce <code>export USE_XPU=1</code> komutunu açıkça verin.</h1>
make triton</code></pre></p><p><strong>MacOS'ta</strong></p><pre><code class="language-bash"># Sadece intel x86 işlemcili makinelerde bu paketi ekleyin
pip install mkl-static mkl-include
<h1>torch.distributed gerekiyorsa bu paketleri ekleyin</h1>
conda install pkg-config libuv</code></pre></p><p><strong>Windows'ta</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>torch.distributed gerekiyorsa bu paketleri ekleyin.</h1>
<h1>Windows'ta distributed paket desteği prototip aşamasındadır ve değişebilir.</h1>
conda install -c conda-forge libuv=1.39</code></pre></p><p>#### PyTorch'u Kurun
<strong>Linux'ta</strong></p><p>AMD ROCm için derleme yapıyorsanız öncelikle bu komutu çalıştırın:
<pre><code class="language-bash"># Sadece ROCm için derliyorsanız çalıştırın
python tools/amd_build/build_amd.py</code></pre></p><p>PyTorch'u Kurun
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py develop</code></pre></p><p><strong>macOS'ta</strong></p><pre><code class="language-bash">python3 setup.py develop</code></pre></p><p><strong>Windows'ta</strong></p><p>Eski python kodu için derleme yapmak isterseniz, <a href="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda" target="_blank" rel="noopener noreferrer">Eski kod ve CUDA ile Derleme</a> başvurusuna bakın.</p><p><strong>Sadece CPU derlemesi</strong></p><p>Bu modda PyTorch hesaplamaları GPU yerine CPU'nuzda çalışacaktır.</p><pre><code class="language-cmd">python setup.py develop</code></pre></p><p>OpenMP notu: İstenen OpenMP uygulaması Intel OpenMP (iomp)'dur. iomp'a bağlanmak için kütüphaneyi manuel indirmeniz ve <code>CMAKE_INCLUDE_PATH</code> ile <code>LIB</code> ortamlarını ayarlamanız gerekir. <a href="https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source" target="_blank" rel="noopener noreferrer">Buradaki</a> talimatlar MKL ve Intel OpenMP'nin nasıl kurulacağına dair örnektir. Bu CMake yapılandırmaları olmadan, Microsoft Visual C OpenMP runtime (vcomp) kullanılacaktır.</p><p><strong>CUDA tabanlı derleme</strong></p><p>Bu modda PyTorch hesaplamaları, daha hızlı hesaplama için GPU'nuzu CUDA üzerinden kullanacaktır.</p><p>PyTorch'u CUDA ile derlemek için <a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm" target="_blank" rel="noopener noreferrer">NVTX</a> gereklidir.
NVTX, CUDA dağıtımının bir parçasıdır ve "Nsight Compute" olarak adlandırılır. Zaten kurulu bir CUDA'ya eklemek için CUDA kurulumunu tekrar çalıştırıp ilgili seçeneği işaretleyin.
CUDA ve Nsight Compute'un Visual Studio'dan sonra kurulu olduğundan emin olun.</p><p>Şu anda, CMake için VS 2017 / 2019 ve Ninja desteklenmektedir. <code>ninja.exe</code> <code>PATH</code> içinde tespit edilirse, Ninja varsayılan jeneratör olarak kullanılır, aksi takdirde VS 2017 / 2019 kullanılır.
<br/> Jeneratör olarak Ninja seçilirse, en son MSVC altta yatan araç seti olarak seçilecektir.</p><p>Ek kütüphaneler olarak
<a href="https://developer.nvidia.com/magma" target="_blank" rel="noopener noreferrer">Magma</a>, <a href="https://github.com/oneapi-src/oneDNN" target="_blank" rel="noopener noreferrer">oneDNN, diğer adıyla MKLDNN veya DNNL</a> ve <a href="https://github.com/mozilla/sccache" target="_blank" rel="noopener noreferrer">Sccache</a> çoğunlukla gereklidir. Kurulum için <a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers" target="_blank" rel="noopener noreferrer">installation-helper</a> başvurusuna bakabilirsiniz.</p><p>Bazı diğer ortam değişkenleri ayarları için <a href="https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat" target="_blank" rel="noopener noreferrer">build_pytorch.bat</a> scriptine bakabilirsiniz.</p><pre><code class="language-cmd">cmd</p><p>:: mkl paketini indirip açtıktan sonra ortam değişkenlerini ayarlayın,
:: aksi halde CMake <code>Could NOT find OpenMP</code> hatası verecektir.
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%</p><p>:: Önceki bölümü dikkatlice okuyun.
:: [İsteğe Bağlı] Ninja ve Visual Studio ile CUDA kullanırken alt araç setini değiştirmek isterseniz aşağıdaki komut bloğunu çalıştırın.
:: "Visual Studio 2019 Developer Command Prompt" otomatik olarak çalışacaktır.
:: Visual Studio jeneratörü kullanırken CMake >= 3.12 gereklidir.
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f "usebackq tokens=<em>" %i in (<code>"%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe" -version [15^,17^) -products </em> -latest -property installationPath</code>) do call "%i\VC\Auxiliary\Build\vcvarsall.bat" x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%</p><p>:: [İsteğe Bağlı] CUDA ana derleyicisini değiştirmek isterseniz
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe</p><p>python setup.py develop
</code></pre></p><p><strong>Intel GPU derlemesi</strong></p><p>Bu modda Intel GPU desteğiyle PyTorch derlenecektir.</p><p><a href="#prerequisites" target="_blank" rel="noopener noreferrer">Lütfen ortak önkoşullar</a> ve <a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">Intel GPU için önkoşullar</a> düzgün yüklendiğinden ve ortam değişkenleri ayarlandığından emin olun. Derleme aracı desteği için <code>Visual Studio 2022</code> gereklidir.</p><p>Daha sonra PyTorch şu komutla derlenebilir:</p><pre><code class="language-cmd">:: CMD Komutları:
:: Karşılık gelen paketleri bulmak için CMAKE_PREFIX_PATH ayarlayın
:: %CONDA_PREFIX% sadece <code>conda activate custom_env</code> sonrası çalışır</p><p>if defined CMAKE_PREFIX_PATH (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%"
) else (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library"
)</p><p>python setup.py develop</code></pre></p><p>##### Derleme Seçeneklerini Ayarlama (İsteğe Bağlı)</p><p>Cmake değişkenlerinin yapılandırmasını isteğe bağlı olarak (önceden derleme yapmadan) aşağıdaki gibi ayarlayabilirsiniz. Örneğin, CuDNN veya BLAS için önceden tespit edilen dizinleri ayarlamak bu adımla mümkündür.</p><p>Linux'ta
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py build --cmake-only
ccmake build  # veya cmake-gui build</code></pre></p><p>macOS'ta
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only
ccmake build  # veya cmake-gui build</code></pre></p><h3>Docker İmajı</h3></p><p>#### Hazır İmajların Kullanılması</p><p>Docker Hub'dan önceden hazırlanmış bir docker imajını çekebilir ve docker v19.03+ ile çalıştırabilirsiniz</p><pre><code class="language-bash">docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest</code></pre></p><p>PyTorch'un işlemler arasında veri paylaşımı için shared memory kullandığını unutmayın, bu nedenle torch multiprocessing kullanılırsa (ör. çoklu iş parçacıklı veri yükleyiciler için) konteynerin varsayılan shared memory segment boyutu yeterli olmayacaktır; bu nedenle, shared memory boyutunu <code>--ipc=host</code> veya <code>--shm-size</code> komut satırı seçenekleriyle artırmalısınız.</p><p>#### Kendi İmajınızı Oluşturma</p><p><strong>NOT:</strong> Docker'ın 18.06'dan büyük bir sürümüyle oluşturulmalıdır.</p><p><code>Dockerfile</code>, CUDA 11.1 desteği ve cuDNN v8 ile imaj oluşturmak için sağlanmıştır.
Hangi Python sürümünün Miniconda tarafından kullanılacağını belirtmek için <code>PYTHON_VERSION=x.y</code> make değişkenini iletebilir veya varsayılanı kullanmak için bırakabilirsiniz.</p><pre><code class="language-bash">make -f docker.Makefile
<h1>imajlar docker.io/${your_docker_username}/pytorch olarak etiketlenir</code></pre></h1></p><p>Ek CMake değişkenlerini derleme sırasında CMake'e iletmek için <code>CMAKE_VARS="..."</code> ortam değişkenini de verebilirsiniz.
Kullanılabilir değişkenlerin listesi için <a href="./setup.py" target="_blank" rel="noopener noreferrer">setup.py</a> dosyasına bakınız.</p><pre><code class="language-bash">make -f docker.Makefile</code></pre></p><h3>Dokümantasyonu Derleme</h3></p><p>Dokümantasyonu çeşitli formatlarda oluşturmak için <a href="http://www.sphinx-doc.org" target="_blank" rel="noopener noreferrer">Sphinx</a>
ve pytorch_sphinx_theme2 gereklidir.</p><p>Dokümantasyonu yerel olarak oluşturmadan önce, ortamınıza <code>torch</code> kurulu olduğundan emin olun. Küçük düzeltmeler için, <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">Başlangıç</a> bölümünde anlatıldığı gibi nightly sürümü kurabilirsiniz.</p><p>Yeni bir modül eklemek ve bunun için docstring eklemek gibi daha karmaşık düzeltmeler için, torch'u <a href="#from-source" target="_blank" rel="noopener noreferrer">kaynak koddan</a> yüklemeniz gerekebilir.
Docstring kuralları için <a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines" target="_blank" rel="noopener noreferrer">Docstring Guidelines</a> sayfasına bakınız.</p><pre><code class="language-bash">cd docs/
pip install -r requirements.txt
make html
make serve</code></pre></p><p>Tüm mevcut çıktı formatları listesini almak için <code>make</code> komutunu çalıştırın.</p><p>Eğer katex hatası alırsanız <code>npm install katex</code> çalıştırın. Sorun devam ederse
<code>npm install -g katex</code> deneyin.</p><blockquote>[!NOT]</blockquote>
<blockquote>Eğer <code>nodejs</code>'i farklı bir paket yöneticisiyle (örn. <code>conda</code>) yüklediyseniz, <code>npm</code> büyük olasılıkla <code>nodejs</code> sürümünüzle uyumlu olmayan bir <code>katex</code> sürümü yükleyecek ve dokümantasyon derlemesi başarısız olacaktır.</blockquote>
<blockquote>Bilinen çalışan bir sürüm kombinasyonu <code>node@6.13.1</code> ve</blockquote>
<blockquote><code>katex@0.13.18</code>'dir. Sonuncuyu yüklemek için:</blockquote>
<blockquote>``<code>npm install -g katex@0.13.18<pre><code class="language-"></blockquote>
<blockquote>[!NOT]</blockquote>
<blockquote>numpy uyumsuzluk hatası görürseniz:</blockquote>
<blockquote></code>`<code></blockquote>
<blockquote>pip install 'numpy<2'</blockquote>
<blockquote></code>`<code></blockquote></p><p>CI tarafından çalıştırılan bağımlılıkları değiştirdiğinizde
</code>.ci/docker/requirements-docs.txt<code> dosyasını düzenleyin.</p><p>#### PDF Oluşturma</p><p>Tüm PyTorch dokümantasyonunun PDF'ini derlemek için,
</code>texlive<code> ve LaTeX kurulu olmalıdır. macOS'ta, şunlarla kurabilirsiniz:
</code></pre>
brew install --cask mactex
</code>`<code></p><p>PDF oluşturmak için:</p><ul><li>Şunu çalıştırın:</li></p><p>   </ul></code>`<code>
   make latexpdf
   </code>`<code></p><p>   Gerekli dosyalar </code>build/latex<code> dizininde oluşturulacaktır.</p><ul><li>Bu dizine gidip şunu çalıştırın:</li></p><p>   </ul></code>`<code>
   make LATEXOPTS="-interaction=nonstopmode"
   </code>`<code></p><p>   Bu, istenen içeriğe sahip bir </code>pytorch.pdf` oluşturacaktır. Doğru içindekiler tablosu ve indeksin oluşturulması için komutu bir kez daha çalıştırın.</p><blockquote>[!NOT]</blockquote>
<blockquote>İçindekiler Tablosunu görmek için, PDF görüntüleyicinizde <strong>Table of Contents</strong> görünümüne geçin.</blockquote></p><h3>Önceki Sürümler</h3></p><p>Önceki PyTorch sürümlerinin kurulum talimatları ve ikili dosyalar
<a href="https://pytorch.org/get-started/previous-versions" target="_blank" rel="noopener noreferrer">web sitemizde</a> bulunabilir.</p><h2>Başlangıç</h2></p><p>Başlamak için üç öneri:
<ul><li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">Eğitimler: PyTorch'u anlamak ve kullanmak için</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">Örnekler: Tüm alanlarda kolay anlaşılır PyTorch kodları</a></li>
<li><a href="https://pytorch.org/docs/" target="_blank" rel="noopener noreferrer">API Referansı</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md" target="_blank" rel="noopener noreferrer">Sözlük</a></li></p><p></ul><h2>Kaynaklar</h2></p><ul><li><a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">PyTorch.org</a></li>
<li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">PyTorch Eğitimleri</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">PyTorch Örnekleri</a></li>
<li><a href="https://pytorch.org/hub/" target="_blank" rel="noopener noreferrer">PyTorch Modelleri</a></li>
<li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188" target="_blank" rel="noopener noreferrer">Udacity'den PyTorch ile Derin Öğrenmeye Giriş</a></li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229" target="_blank" rel="noopener noreferrer">Udacity'den PyTorch ile Makine Öğrenimine Giriş</a></li>
<li><a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch" target="_blank" rel="noopener noreferrer">Coursera'dan PyTorch ile Derin Sinir Ağları</a></li>
<li><a href="https://twitter.com/PyTorch" target="_blank" rel="noopener noreferrer">PyTorch Twitter</a></li>
<li><a href="https://pytorch.org/blog/" target="_blank" rel="noopener noreferrer">PyTorch Blog</a></li>
<li><a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw" target="_blank" rel="noopener noreferrer">PyTorch YouTube</a></li></p><p></ul><h2>İletişim</h2>
<ul><li>Forumlar: Uygulama, araştırma vb. tartışmaları için: https://discuss.pytorch.org</li>
<li>GitHub Issues: Hata raporları, özellik talepleri, kurulum sorunları, RFC'ler, düşünceler vb.</li>
<li>Slack: <a href="https://pytorch.slack.com/" target="_blank" rel="noopener noreferrer">PyTorch Slack</a> esas olarak orta ve ileri seviye PyTorch kullanıcıları ve geliştiricilerine hitap eder; genel sohbet, çevrimiçi tartışmalar, iş birliği vs. Başlangıç seviyesindeyseniz ana ortam <a href="https://discuss.pytorch.org" target="_blank" rel="noopener noreferrer">PyTorch Forumları</a>'dur. Slack davetiyesi için şu formu doldurun: https://goo.gl/forms/PP1AGvNHpSaJP8to1</li>
<li>Bülten: Gürültüsüz, tek yönlü e-posta bülteniyle PyTorch ile ilgili önemli duyurular. Buradan kayıt olabilirsiniz: https://eepurl.com/cbG0rv</li>
<li>Facebook Sayfası: PyTorch ile ilgili önemli duyurular. https://www.facebook.com/pytorch</li>
<li>Marka yönergeleri için lütfen <a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">web sitemizi</a> ziyaret edin.</li></p><p></ul><h2>Sürümler ve Katkı</h2></p><p>Genellikle, PyTorch yılda üç küçük sürüm yayınlar. Bir hata ile karşılaşırsanız lütfen <a href="https://github.com/pytorch/pytorch/issues" target="_blank" rel="noopener noreferrer">bir issue açarak</a> bize bildirin.</p><p>Tüm katkılarınız için minnettarız. Hata düzeltmeleri yapmak istiyorsanız, herhangi bir ek tartışma olmadan katkıda bulunabilirsiniz.</p><p>Yeni özellikler, yardımcı işlevler veya çekirdeğe eklenecek genişletmeler katkısı yapmayı planlıyorsanız, önce bir issue açıp bizimle tartışın.
Tartışma olmadan PR göndermek, çekirdek başka bir yöne gidiyorsa reddedilmiş bir PR ile sonuçlanabilir.</p><p>PyTorch'a katkı hakkında daha fazla bilgi için <a href="CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">Katkı sayfamıza</a> bakabilirsiniz. PyTorch sürümleriyle ilgili daha fazla bilgi için <a href="RELEASE.md" target="_blank" rel="noopener noreferrer">Sürüm sayfasına</a> bakabilirsiniz.</p><h2>Ekip</h2></p><p>PyTorch, çok sayıda yetenekli mühendis ve araştırmacının katkıda bulunduğu topluluk odaklı bir projedir.</p><p>PyTorch şu anda <a href="http://soumith.ch" target="_blank" rel="noopener noreferrer">Soumith Chintala</a>, <a href="https://github.com/gchanan" target="_blank" rel="noopener noreferrer">Gregory Chanan</a>, <a href="https://github.com/dzhulgakov" target="_blank" rel="noopener noreferrer">Dmytro Dzhulgakov</a>, <a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a> ve <a href="https://github.com/malfet" target="_blank" rel="noopener noreferrer">Nikita Shulga</a> tarafından sürdürülmektedir ve yüzlerce yetenekli bireyin çeşitli katkılarıyla gelişmektedir.
Eksik ama büyüyen bir liste olarak: <a href="https://github.com/killeent" target="_blank" rel="noopener noreferrer">Trevor Killeen</a>, <a href="https://github.com/chsasank" target="_blank" rel="noopener noreferrer">Sasank Chilamkurthy</a>, <a href="https://github.com/szagoruyko" target="_blank" rel="noopener noreferrer">Sergey Zagoruyko</a>, <a href="https://github.com/adamlerer" target="_blank" rel="noopener noreferrer">Adam Lerer</a>, <a href="https://github.com/fmassa" target="_blank" rel="noopener noreferrer">Francisco Massa</a>, <a href="https://github.com/alykhantejani" target="_blank" rel="noopener noreferrer">Alykhan Tejani</a>, <a href="https://github.com/lantiga" target="_blank" rel="noopener noreferrer">Luca Antiga</a>, <a href="https://github.com/albanD" target="_blank" rel="noopener noreferrer">Alban Desmaison</a>, <a href="https://github.com/andreaskoepf" target="_blank" rel="noopener noreferrer">Andreas Koepf</a>, <a href="https://github.com/jekbradbury" target="_blank" rel="noopener noreferrer">James Bradbury</a>, <a href="https://github.com/ebetica" target="_blank" rel="noopener noreferrer">Zeming Lin</a>, <a href="https://github.com/yuandong-tian" target="_blank" rel="noopener noreferrer">Yuandong Tian</a>, <a href="https://github.com/glample" target="_blank" rel="noopener noreferrer">Guillaume Lample</a>, <a href="https://github.com/Maratyszcza" target="_blank" rel="noopener noreferrer">Marat Dukhan</a>, <a href="https://github.com/ngimel" target="_blank" rel="noopener noreferrer">Natalia Gimelshein</a>, <a href="https://github.com/csarofeen" target="_blank" rel="noopener noreferrer">Christian Sarofeen</a>, <a href="https://github.com/martinraison" target="_blank" rel="noopener noreferrer">Martin Raison</a>, <a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a>, <a href="https://github.com/zdevito" target="_blank" rel="noopener noreferrer">Zachary Devito</a>.</p><p>Not: Bu proje, aynı ada sahip <a href="https://github.com/hughperkins/pytorch" target="_blank" rel="noopener noreferrer">hughperkins/pytorch</a> ile ilişkili değildir. Hugh, Torch topluluğuna değerli katkılarda bulunmuş ve Torch ile PyTorch'a birçok konuda yardımcı olmuştur.</p><h2>Lisans</h2></p><p>PyTorch, <a href="LICENSE" target="_blank" rel="noopener noreferrer">LICENSE</a> dosyasında bulunan BSD tarzı bir lisansa sahiptir.</p><p>
---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/pytorch/pytorch/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>