<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch - Read pytorch documentation in Arabic. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read pytorch documentation in Arabic. This project has 0 stars on GitHub.">
    <meta name="keywords" content="pytorch, Arabic, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "pytorch",
  "description": "Read pytorch documentation in Arabic. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "pytorch"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/pytorch/pytorch/README-ar.html",
  "sameAs": "https://raw.githubusercontent.com/pytorch/pytorch/master/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    pytorch
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Arabic</span>
                <span>by pytorch</span>
            </div>
        </div>
        
        <div class="content">
            <p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="شعار بايتورتش"></p><p>--------------------------------------------------------------------------------</p><p>بايتورتش هي حزمة بايثون توفر ميزتين عاليتي المستوى:
<ul><li>حساب الموترات (مثل NumPy) مع تسريع قوي باستخدام وحدة معالجة الرسومات (GPU)</li>
<li>الشبكات العصبية العميقة مبنية على نظام تفاضل تلقائي يعتمد على الشريط (Tape-based Autograd)</li></p><p></ul>يمكنك إعادة استخدام حزم بايثون المفضلة لديك مثل NumPy وSciPy وCython لتوسيع بايتورتش عند الحاجة.</p><p>حالة التطوير المستمر (إشارات التكامل المستمر) يمكن العثور عليها على <a href="https://hud.pytorch.org/ci/pytorch/pytorch/main" target="_blank" rel="noopener noreferrer">hud.pytorch.org</a>.</p><p><!-- toc --></p><ul><li><a href="#more-about-pytorch" target="_blank" rel="noopener noreferrer">المزيد عن بايتورتش</a></li>
  <li><a href="#a-gpu-ready-tensor-library" target="_blank" rel="noopener noreferrer">مكتبة موترات جاهزة لـ GPU</a></li>
  <li><a href="#dynamic-neural-networks-tape-based-autograd" target="_blank" rel="noopener noreferrer">الشبكات العصبية الديناميكية: تفاضل تلقائي معتمد على الشريط</a></li>
  <li><a href="#python-first" target="_blank" rel="noopener noreferrer">أولاً بايثون</a></li>
  <li><a href="#imperative-experiences" target="_blank" rel="noopener noreferrer">تجارب أمرية</a></li>
  <li><a href="#fast-and-lean" target="_blank" rel="noopener noreferrer">سريع وخفيف</a></li>
  <li><a href="#extensions-without-pain" target="_blank" rel="noopener noreferrer">توسعات بدون عناء</a></li>
<li><a href="#installation" target="_blank" rel="noopener noreferrer">التثبيت</a></li>
  <li><a href="#binaries" target="_blank" rel="noopener noreferrer">الحزم الجاهزة</a></li>
    <li><a href="#nvidia-jetson-platforms" target="_blank" rel="noopener noreferrer">منصات NVIDIA Jetson</a></li>
  <li><a href="#from-source" target="_blank" rel="noopener noreferrer">من المصدر</a></li>
    <li><a href="#prerequisites" target="_blank" rel="noopener noreferrer">المتطلبات الأساسية</a></li>
      <li><a href="#nvidia-cuda-support" target="_blank" rel="noopener noreferrer">دعم NVIDIA CUDA</a></li>
      <li><a href="#amd-rocm-support" target="_blank" rel="noopener noreferrer">دعم AMD ROCm</a></li>
      <li><a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">دعم وحدة معالجة الرسومات من Intel</a></li>
    <li><a href="#get-the-pytorch-source" target="_blank" rel="noopener noreferrer">الحصول على مصدر بايتورتش</a></li>
    <li><a href="#install-dependencies" target="_blank" rel="noopener noreferrer">تثبيت التبعيات</a></li>
    <li><a href="#install-pytorch" target="_blank" rel="noopener noreferrer">تثبيت بايتورتش</a></li>
      <li><a href="#adjust-build-options-optional" target="_blank" rel="noopener noreferrer">ضبط خيارات البناء (اختياري)</a></li>
  <li><a href="#docker-image" target="_blank" rel="noopener noreferrer">صورة Docker</a></li>
    <li><a href="#using-pre-built-images" target="_blank" rel="noopener noreferrer">استخدام الصور الجاهزة</a></li>
    <li><a href="#building-the-image-yourself" target="_blank" rel="noopener noreferrer">بناء الصورة بنفسك</a></li>
  <li><a href="#building-the-documentation" target="_blank" rel="noopener noreferrer">بناء التوثيق</a></li>
    <li><a href="#building-a-pdf" target="_blank" rel="noopener noreferrer">بناء PDF</a></li>
  <li><a href="#previous-versions" target="_blank" rel="noopener noreferrer">الإصدارات السابقة</a></li>
<li><a href="#getting-started" target="_blank" rel="noopener noreferrer">البدء</a></li>
<li><a href="#resources" target="_blank" rel="noopener noreferrer">الموارد</a></li>
<li><a href="#communication" target="_blank" rel="noopener noreferrer">التواصل</a></li>
<li><a href="#releases-and-contributing" target="_blank" rel="noopener noreferrer">الإصدارات والمساهمة</a></li>
<li><a href="#the-team" target="_blank" rel="noopener noreferrer">الفريق</a></li>
<li><a href="#license" target="_blank" rel="noopener noreferrer">الرخصة</a></li></p><p></ul><!-- tocstop --></p><h2>المزيد عن بايتورتش</h2></p><p><a href="https://pytorch.org/tutorials/beginner/basics/intro.html" target="_blank" rel="noopener noreferrer">تعلم أساسيات بايتورتش</a></p><p>على مستوى دقيق، بايتورتش هو مكتبة تتكون من المكونات التالية:</p><p>| المكون | الوصف |
| ---- | --- |
| <a href="https://pytorch.org/docs/stable/torch.html" target="_blank" rel="noopener noreferrer"><strong>torch</strong></a> | مكتبة موترات مثل NumPy، مع دعم قوي لوحدة معالجة الرسومات (GPU) |
| <a href="https://pytorch.org/docs/stable/autograd.html" target="_blank" rel="noopener noreferrer"><strong>torch.autograd</strong></a> | مكتبة تفاضل تلقائي تعتمد على الشريط تدعم جميع العمليات القابلة للتفاضل على الموترات في torch |
| <a href="https://pytorch.org/docs/stable/jit.html" target="_blank" rel="noopener noreferrer"><strong>torch.jit</strong></a> | حزمة ترجمة (TorchScript) لإنشاء نماذج قابلة للتسلسل والتحسين من كود بايتورتش |
| <a href="https://pytorch.org/docs/stable/nn.html" target="_blank" rel="noopener noreferrer"><strong>torch.nn</strong></a> | مكتبة شبكات عصبية متكاملة بعمق مع autograd ومصممة لأقصى درجات المرونة |
| <a href="https://pytorch.org/docs/stable/multiprocessing.html" target="_blank" rel="noopener noreferrer"><strong>torch.multiprocessing</strong></a> | معالجة متعددة في بايثون، مع مشاركة سحرية للذاكرة الخاصة بموترات torch بين العمليات. مفيد لتحميل البيانات والتدريب بطريقة Hogwild |
| <a href="https://pytorch.org/docs/stable/data.html" target="_blank" rel="noopener noreferrer"><strong>torch.utils</strong></a> | DataLoader ووظائف مساعدة أخرى للراحة |</p><p>عادةً ما يُستخدم بايتورتش كالتالي:</p><ul><li>بديل لـ NumPy للاستفادة من قوة وحدات معالجة الرسومات.</li>
<li>منصة بحث في التعلم العميق توفر أقصى قدر من المرونة والسرعة.</li></p><p></ul>توضيح أكثر:</p><h3>مكتبة موترات جاهزة لـ GPU</h3></p><p>إذا كنت تستخدم NumPy، إذًا أنت تستخدم الموترات (أو ما يُسمى ndarray).</p><p><img src="./docs/source/_static/img/tensor_illustration.png" alt="رسم توضيحي للموتر"></p><p>يوفر بايتورتش موترات يمكن أن تتواجد إما على وحدة المعالجة المركزية (CPU) أو وحدة معالجة الرسومات (GPU) ويُسرّع العمليات الحسابية بشكل كبير.</p><p>نحن نوفر مجموعة واسعة من إجراءات الموترات لتسريع وتلبية احتياجاتك في الحساب العلمي مثل التقطيع والفهرسة والعمليات الرياضية والجبر الخطي والتقليصات.
وهي سريعة!</p><h3>الشبكات العصبية الديناميكية: تفاضل تلقائي معتمد على الشريط</h3></p><p>يمتلك بايتورتش طريقة فريدة لبناء الشبكات العصبية: باستخدام وتشغيل مسجل شريط.</p><p>معظم الأطر مثل TensorFlow وTheano وCaffe وCNTK لديها نظرة ثابتة للعالم.
يجب بناء شبكة عصبية وإعادة استخدام نفس الهيكل مرارًا وتكرارًا.
تغيير سلوك الشبكة يعني أنه يجب البدء من الصفر.</p><p>مع بايتورتش، نستخدم تقنية تُسمى التفاضل التلقائي العكسي، والتي تسمح لك
بتغيير سلوك شبكتك بشكل عشوائي دون أي تأخير أو عبء. استوحينا ذلك
من عدة أوراق بحثية في هذا الموضوع، بالإضافة إلى أعمال حالية وسابقة مثل
<a href="https://github.com/twitter/torch-autograd" target="_blank" rel="noopener noreferrer">torch-autograd</a>،
<a href="https://github.com/HIPS/autograd" target="_blank" rel="noopener noreferrer">autograd</a>،
<a href="https://chainer.org" target="_blank" rel="noopener noreferrer">Chainer</a>، وغيرها.</p><p>مع أن هذه التقنية ليست حصرية لبايتورتش، إلا أنها من أسرع التطبيقات لها حتى الآن.
تحصل على أفضل سرعة ومرونة لأبحاثك المتقدمة.</p><p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="رسم توضيحي للرسم البياني الديناميكي"></p><h3>أولاً بايثون</h3></p><p>بايتورتش ليس مجرد ربط بايثون بإطار C++ ضخم.
بل بُني ليكون متكاملًا بعمق مع بايثون.
يمكنك استخدامه بشكل طبيعي كما تستخدم <a href="https://www.numpy.org/" target="_blank" rel="noopener noreferrer">NumPy</a> أو <a href="https://www.scipy.org/" target="_blank" rel="noopener noreferrer">SciPy</a> أو <a href="https://scikit-learn.org" target="_blank" rel="noopener noreferrer">scikit-learn</a> وغيرها.
يمكنك كتابة طبقات الشبكة العصبية الجديدة الخاصة بك في بايثون نفسه، باستخدام مكتباتك المفضلة
واستخدام حزم مثل <a href="https://cython.org/" target="_blank" rel="noopener noreferrer">Cython</a> و<a href="http://numba.pydata.org/" target="_blank" rel="noopener noreferrer">Numba</a>.
هدفنا ألا نعيد اختراع العجلة حيثما كان ذلك مناسبًا.</p><h3>تجارب أمرية</h3></p><p>تم تصميم بايتورتش ليكون بديهيًا، وخطيًا في التفكير، وسهل الاستخدام.
عندما تنفذ سطرًا من الكود، يتم تنفيذه فورًا. لا توجد نظرة غير متزامنة للعالم.
عندما تدخل في مصحح الأخطاء أو تتلقى رسائل خطأ وتتبع مكدس، يكون فهمها مباشرًا.
يشير تتبع المكدس بالضبط إلى المكان الذي تم فيه تعريف كودك.
نأمل ألا تقضي ساعات طويلة في تصحيح الكود بسبب تتبع مكدس سيء أو محركات تنفيذ غير شفافة وغير متزامنة.</p><h3>سريع وخفيف</h3></p><p>لدى بايتورتش عبء إطار عمل منخفض للغاية. نحن ندمج مكتبات التسريع
مثل <a href="https://software.intel.com/mkl" target="_blank" rel="noopener noreferrer">Intel MKL</a> وNVIDIA (<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">cuDNN</a>، <a href="https://developer.nvidia.com/nccl" target="_blank" rel="noopener noreferrer">NCCL</a>) لتحقيق أقصى سرعة.
في الجوهر، تعتمد موترات CPU وGPU وواجهات الشبكات العصبية
على أكواد ناضجة ومجربة لسنوات.</p><p>لذا، بايتورتش سريع جدًا — سواءً كنت تشغل شبكات عصبية صغيرة أو كبيرة.</p><p>استهلاك الذاكرة في بايتورتش فعال للغاية مقارنة بـ Torch أو بعض البدائل الأخرى.
لقد كتبنا مخصصات ذاكرة مخصصة لـ GPU لضمان أن
نماذج التعلم العميق الخاصة بك فعالة إلى أقصى حد في استهلاك الذاكرة.
هذا يمكّنك من تدريب نماذج تعلم عميق أكبر من ذي قبل.</p><h3>توسعات بدون عناء</h3></p><p>كتابة وحدات شبكات عصبية جديدة، أو التعامل مع واجهة برمجة تطبيقات موترات بايتورتش تم تصميمها لتكون مباشرة
وبأقل قدر من التجريدات.</p><p>يمكنك كتابة طبقات الشبكة العصبية الجديدة في بايثون باستخدام واجهة torch
<a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html" target="_blank" rel="noopener noreferrer">أو مكتباتك المفضلة المعتمدة على NumPy مثل SciPy</a>.</p><p>إذا رغبت في كتابة طبقاتك بـ C/C++، نوفر واجهة توسعة سهلة الاستخدام وفعالة وبأقل متطلبات كود.
لا حاجة لكتابة كود تغليف. يمكنك مشاهدة <a href="https://pytorch.org/tutorials/advanced/cpp_extension.html" target="_blank" rel="noopener noreferrer">دليل هنا</a> و<a href="https://github.com/pytorch/extension-cpp" target="_blank" rel="noopener noreferrer">مثال هنا</a>.</p><h2>التثبيت</h2></p><h3>الحزم الجاهزة</h3>
أوامر تثبيت الحزم الجاهزة عبر Conda أو pip متوفرة على موقعنا: <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">https://pytorch.org/get-started/locally/</a></p><p>
#### منصات NVIDIA Jetson</p><p>عجلات بايثون لمنصات Jetson Nano وJetson TX1/TX2 وJetson Xavier NX/AGX وJetson AGX Orin من NVIDIA متوفرة <a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048" target="_blank" rel="noopener noreferrer">هنا</a> وحاوية L4T منشورة <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch" target="_blank" rel="noopener noreferrer">هنا</a></p><p>تتطلب JetPack 4.2 وما فوق، ويتم صيانتها من قبل <a href="https://github.com/dusty-nv" target="_blank" rel="noopener noreferrer">@dusty-nv</a> و<a href="https://github.com/ptrblck" target="_blank" rel="noopener noreferrer">@ptrblck</a>.</p><h3>من المصدر</h3></p><p>#### المتطلبات الأساسية
إذا كنت تقوم بالتثبيت من المصدر، ستحتاج إلى:
<ul><li>بايثون 3.9 أو أحدث</li>
<li>مترجم يدعم C++17 بالكامل، مثل clang أو gcc (يتطلب gcc 9.4.0 أو أحدث على لينكس)</li>
<li>Visual Studio أو Visual Studio Build Tool (للويندوز فقط)</li></p><p></ul>\* يستخدم بايتورتش CI أدوات بناء Visual C++، والتي تأتي مع إصدارات Visual Studio Enterprise أو Professional أو Community. يمكنك أيضًا تثبيت أدوات البناء من
https://visualstudio.microsoft.com/visual-cpp-build-tools/. أدوات البناء <em>لا تأتي</em>
افتراضيًا مع Visual Studio Code.</p><p>مثال على إعداد البيئة موضح أدناه:</p><ul><li>لينكس:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>/bin/activate
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME></code></pre></p><ul><li>ويندوز:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>\Scripts\activate.bat
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME>
$ call "C:\Program Files\Microsoft Visual Studio\<VERSION>\Community\VC\Auxiliary\Build\vcvarsall.bat" x64</code></pre></p><p>##### دعم NVIDIA CUDA
إذا كنت ترغب في الترجمة مع دعم CUDA، <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">اختر إصدارًا مدعومًا من CUDA من جدول الدعم لدينا</a>، ثم قم بتثبيت التالي:
<ul><li><a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener noreferrer">NVIDIA CUDA</a></li>
<li><a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">NVIDIA cuDNN</a> v8.5 أو أحدث</li>
<li><a href="https://gist.github.com/ax3l/9489132" target="_blank" rel="noopener noreferrer">مترجم</a> متوافق مع CUDA</li></p><p></ul>ملاحظة: يمكنك الرجوع إلى <a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html" target="_blank" rel="noopener noreferrer">جدول دعم cuDNN</a> لإصدارات cuDNN مع CUDA المدعومة وبرامج تشغيل CUDA وأجهزة NVIDIA المختلفة.</p><p>إذا كنت ترغب في تعطيل دعم CUDA، صدّر متغير البيئة <code>USE_CUDA=0</code>.
قد تجد متغيرات بيئة أخرى مفيدة في <code>setup.py</code>.</p><p>إذا كنت تبني لمنصات NVIDIA Jetson (Jetson Nano, TX1, TX2, AGX Xavier)، تعليمات تثبيت بايتورتش لـ Jetson Nano متوفرة <a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/" target="_blank" rel="noopener noreferrer">هنا</a></p><p>##### دعم AMD ROCm
إذا كنت ترغب في الترجمة مع دعم ROCm، قم بتثبيت:
<ul><li><a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html" target="_blank" rel="noopener noreferrer">AMD ROCm</a> 4.0 أو أحدث</li>
<li>ROCm مدعوم حاليًا فقط على أنظمة لينكس.</li></p><p></ul>يفترض نظام البناء افتراضيًا أن ROCm مثبت في <code>/opt/rocm</code>. إذا كان ROCm مثبتًا في مجلد مختلف، يجب تعيين متغير البيئة <code>ROCM_PATH</code> إلى مجلد التثبيت. يكتشف نظام البناء تلقائيًا معمارية GPU من AMD. اختياريًا، يمكن ضبط معمارية AMD GPU بشكل صريح باستخدام متغير البيئة <code>PYTORCH_ROCM_ARCH</code> <a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus" target="_blank" rel="noopener noreferrer">معمارية AMD GPU</a></p><p>إذا كنت ترغب في تعطيل دعم ROCm، صدّر متغير البيئة <code>USE_ROCM=0</code>.
قد تجد متغيرات بيئة أخرى مفيدة في <code>setup.py</code>.</p><p>##### دعم وحدة معالجة الرسومات من Intel
إذا كنت ترغب في الترجمة مع دعم وحدة معالجة الرسومات من Intel، اتبع التالي:
<ul><li><a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html" target="_blank" rel="noopener noreferrer">متطلبات بايتورتش لوحدات معالجة الرسومات من Intel</a>.</li>
<li>وحدة معالجة الرسومات من Intel مدعومة على لينكس وويندوز.</li></p><p></ul>إذا كنت ترغب في تعطيل دعم وحدة معالجة الرسومات من Intel، صدّر متغير البيئة <code>USE_XPU=0</code>.
قد تجد متغيرات بيئة أخرى مفيدة في <code>setup.py</code>.</p><p>#### الحصول على مصدر بايتورتش
<pre><code class="language-bash">git clone https://github.com/pytorch/pytorch
cd pytorch
<h1>إذا كنت تحدث نسخة موجودة بالفعل</h1>
git submodule sync
git submodule update --init --recursive</code></pre></p><p>#### تثبيت التبعيات</p><p><strong>مشترك</strong></p><pre><code class="language-bash">conda install cmake ninja
<h1>شغل هذا الأمر من مجلد بايتورتش بعد استنساخ الكود المصدر من قسم "الحصول على مصدر بايتورتش" بالأعلى</h1>
pip install -r requirements.txt</code></pre></p><p><strong>على لينكس</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>CUDA فقط: أضف دعم LAPACK لـ GPU إذا لزم الأمر</h1>
<h1>تثبيت magma: شغل مع تفعيل بيئة conda. حدد إصدار CUDA للتثبيت</h1>
.ci/docker/common/install_magma_conda.sh 12.4</p><h1>(اختياري) إذا كنت تستخدم torch.compile مع inductor/triton، ثبت النسخة المطابقة من triton</h1>
<h1>شغل من مجلد pytorch بعد الاستنساخ</h1>
<h1>لدعم وحدة معالجة الرسومات من Intel، يرجى تصدير <code>USE_XPU=1</code> صراحة قبل تنفيذ الأمر.</h1>
make triton</code></pre></p><p><strong>على macOS</strong></p><pre><code class="language-bash"># أضف هذه الحزمة فقط على أجهزة المعالج intel x86
pip install mkl-static mkl-include
<h1>أضف هذه الحزم إذا كنت بحاجة إلى torch.distributed</h1>
conda install pkg-config libuv</code></pre></p><p><strong>على ويندوز</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>أضف هذه الحزم إذا كنت بحاجة إلى torch.distributed.</h1>
<h1>دعم الحزمة الموزعة على ويندوز ميزة تجريبية وقابلة للتغيير.</h1>
conda install -c conda-forge libuv=1.39</code></pre></p><p>#### تثبيت بايتورتش
<strong>على لينكس</strong></p><p>إذا كنت تترجم لـ AMD ROCm فعليك أولاً تشغيل هذا الأمر:
<pre><code class="language-bash"># شغل هذا فقط إذا كنت تترجم لـ ROCm
python tools/amd_build/build_amd.py</code></pre></p><p>تثبيت بايتورتش
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py develop</code></pre></p><p><strong>على macOS</strong></p><pre><code class="language-bash">python3 setup.py develop</code></pre></p><p><strong>على ويندوز</strong></p><p>إذا كنت ترغب في بناء كود بايثون قديم، يرجى الرجوع إلى <a href="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda" target="_blank" rel="noopener noreferrer">البناء على الكود القديم وCUDA</a></p><p><strong>بناء باستخدام CPU فقط</strong></p><p>في هذا الوضع ستعمل حسابات بايتورتش على وحدة المعالجة المركزية فقط، وليس وحدة معالجة الرسومات.</p><pre><code class="language-cmd">python setup.py develop</code></pre></p><p>ملاحظة حول OpenMP: التطبيق المطلوب لـ OpenMP هو Intel OpenMP (iomp). للربط مع iomp، ستحتاج إلى تحميل المكتبة يدويًا وضبط بيئة البناء عن طريق تعديل <code>CMAKE_INCLUDE_PATH</code> و<code>LIB</code>. التعليمات <a href="https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source" target="_blank" rel="noopener noreferrer">هنا</a> مثال لإعداد كل من MKL وIntel OpenMP. بدون هذه الإعدادات لـ CMake، سيتم استخدام Microsoft Visual C OpenMP runtime (vcomp).</p><p><strong>بناء باستخدام CUDA</strong></p><p>في هذا الوضع ستستفيد حسابات بايتورتش من وحدة معالجة الرسومات عبر CUDA لزيادة سرعة العمليات الحسابية.</p><p><a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm" target="_blank" rel="noopener noreferrer">NVTX</a> مطلوب لبناء بايتورتش مع CUDA.
NVTX جزء من توزيعة CUDA، حيث يسمى "Nsight Compute". لتثبيته على CUDA المثبت بالفعل، أعد تشغيل التثبيت وحدد المربع المناسب.
تأكد من أن CUDA مع Nsight Compute مثبّت بعد Visual Studio.</p><p>حاليًا، VS 2017 / 2019 وNinja مدعومون كمولدات لـ CMake. إذا تم اكتشاف <code>ninja.exe</code> في <code>PATH</code>، سيتم استخدام Ninja كمولد افتراضي، وإلا سيتم استخدام VS 2017/2019.
<br/> إذا تم اختيار Ninja كمولد، سيتم اختيار أحدث MSVC كأداة أساسية.</p><p>مكتبات إضافية مثل
<a href="https://developer.nvidia.com/magma" target="_blank" rel="noopener noreferrer">Magma</a>، <a href="https://github.com/oneapi-src/oneDNN" target="_blank" rel="noopener noreferrer">oneDNN، المعروف أيضًا باسم MKLDNN أو DNNL</a>، و<a href="https://github.com/mozilla/sccache" target="_blank" rel="noopener noreferrer">Sccache</a> غالبًا ما تكون مطلوبة. يرجى الرجوع إلى <a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers" target="_blank" rel="noopener noreferrer">installation-helper</a> لتثبيتها.</p><p>يمكنك الرجوع إلى سكربت <a href="https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat" target="_blank" rel="noopener noreferrer">build_pytorch.bat</a> لبعض إعدادات متغيرات البيئة الأخرى.</p><pre><code class="language-cmd">cmd</p><p>:: اضبط متغيرات البيئة بعد تحميل وفك ضغط حزمة mkl،
:: وإلا سيرمي CMake خطأ "Could NOT find OpenMP".
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%</p><p>:: اقرأ محتوى القسم السابق بعناية قبل المتابعة.
:: [اختياري] إذا رغبت في تجاوز أداة البناء الأساسية المستخدمة بواسطة Ninja وVisual Studio مع CUDA، شغل السكربت التالي.
:: سيتم تشغيل "Visual Studio 2019 Developer Command Prompt" تلقائيًا.
:: تأكد من وجود CMake >= 3.12 قبل ذلك إذا كنت تستخدم مولد Visual Studio.
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f "usebackq tokens=<em>" %i in (<code>"%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe" -version [15^,17^) -products </em> -latest -property installationPath</code>) do call "%i\VC\Auxiliary\Build\vcvarsall.bat" x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%</p><p>:: [اختياري] إذا رغبت في تجاوز مترجم مضيف CUDA
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe</p><p>python setup.py develop
</code></pre></p><p><strong>بناء لوحدة معالجة الرسومات من Intel</strong></p><p>في هذا الوضع سيتم بناء بايتورتش مع دعم وحدة معالجة الرسومات من Intel.</p><p>يرجى التأكد من أن <a href="#prerequisites" target="_blank" rel="noopener noreferrer">المتطلبات الأساسية المشتركة</a> وكذلك <a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">متطلبات وحدة معالجة الرسومات من Intel</a> مثبّتة بشكل صحيح ومتغيرات البيئة مضبوطة قبل بدء البناء. لدعم أدوات البناء، يتطلب <code>Visual Studio 2022</code>.</p><p>بعدها يمكن بناء بايتورتش بالأمر التالي:</p><pre><code class="language-cmd">:: أوامر CMD:
:: اضبط CMAKE_PREFIX_PATH للمساعدة في العثور على الحزم المناسبة
:: %CONDA_PREFIX% يعمل فقط بعد تنفيذ <code>conda activate custom_env</code></p><p>if defined CMAKE_PREFIX_PATH (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%"
) else (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library"
)</p><p>python setup.py develop</code></pre></p><p>##### ضبط خيارات البناء (اختياري)</p><p>يمكنك ضبط إعدادات متغيرات cmake بشكل اختياري (دون البناء أولاً)، من خلال التالي. مثلًا، يمكن ضبط مجلدات cuDNN أو BLAS المكتشفة مسبقًا بهذه الخطوة.</p><p>على لينكس
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py build --cmake-only
ccmake build  # أو cmake-gui build</code></pre></p><p>على macOS
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only
ccmake build  # أو cmake-gui build</code></pre></p><h3>صورة Docker</h3></p><p>#### استخدام الصور الجاهزة</p><p>يمكنك أيضًا سحب صورة Docker جاهزة من Docker Hub وتشغيلها مع docker v19.03+</p><pre><code class="language-bash">docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest</code></pre></p><p>يرجى ملاحظة أن بايتورتش يستخدم الذاكرة المشتركة لمشاركة البيانات بين العمليات، لذا إذا تم استخدام torch multiprocessing (مثلاً
لمحمل البيانات متعدد الخيوط) فإن حجم مقطع الذاكرة المشتركة الافتراضي الذي تعمل به الحاوية غير كافٍ، ويجب عليك
زيادة حجم الذاكرة المشتركة إما باستخدام <code>--ipc=host</code> أو خيار السطر <code>--shm-size</code> مع <code>nvidia-docker run</code>.</p><p>#### بناء الصورة بنفسك</p><p><strong>ملاحظة:</strong> يجب أن يتم البناء مع نسخة Docker > 18.06</p><p>يتم توفير ملف <code>Dockerfile</code> لبناء الصور مع دعم CUDA 11.1 وcuDNN v8.
يمكنك تمرير متغير make باسم <code>PYTHON_VERSION=x.y</code> لتحديد إصدار بايثون الذي سيستخدمه Miniconda، أو اتركه بدون تعيين لاستخدام الافتراضي.</p><pre><code class="language-bash">make -f docker.Makefile
<h1>الصور موسومة كـ docker.io/${your_docker_username}/pytorch</code></pre></h1></p><p>يمكنك أيضًا تمرير متغير البيئة <code>CMAKE_VARS="..."</code> لتحديد متغيرات CMake إضافية أثناء البناء.
انظر <a href="./setup.py" target="_blank" rel="noopener noreferrer">setup.py</a> لقائمة المتغيرات المتاحة.</p><pre><code class="language-bash">make -f docker.Makefile</code></pre></p><h3>بناء التوثيق</h3></p><p>لبناء التوثيق بصيغ مختلفة، ستحتاج إلى <a href="http://www.sphinx-doc.org" target="_blank" rel="noopener noreferrer">Sphinx</a>
وthème pytorch_sphinx_theme2.</p><p>قبل بناء التوثيق محليًا، تأكد من تثبيت <code>torch</code>
في بيئتك. للتعديلات الصغيرة، يمكنك تثبيت
الإصدار الليلي كما هو موضح في <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">البدء</a>.</p><p>للتعديلات الأكبر، مثل إضافة وحدة جديدة وسلاسل توثيق للوحدة الجديدة، قد تحتاج إلى تثبيت torch <a href="#from-source" target="_blank" rel="noopener noreferrer">من المصدر</a>.
انظر <a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines" target="_blank" rel="noopener noreferrer">إرشادات السلاسل التوضيحية</a>
للتعرف على معايير السلاسل التوضيحية.</p><pre><code class="language-bash">cd docs/
pip install -r requirements.txt
make html
make serve</code></pre></p><p>شغّل <code>make</code> للحصول على قائمة بجميع صيغ الإخراج المتاحة.</p><p>إذا حصلت على خطأ katex شغّل <code>npm install katex</code>. إذا استمر الخطأ، جرب
<code>npm install -g katex</code></p><blockquote>[!ملاحظة]</blockquote>
<blockquote>إذا قمت بتثبيت <code>nodejs</code> بواسطة مدير حزم مختلف (مثلاً،</blockquote>
<blockquote><code>conda</code>) فربما سيقوم <code>npm</code> بتثبيت نسخة من <code>katex</code> غير متوافقة</blockquote>
<blockquote>مع إصدار <code>nodejs</code> الخاص بك وسيفشل بناء التوثيق.</blockquote>
<blockquote>مجموعة إصدارات معروفة بأنها تعمل هي <code>node@6.13.1</code> و</blockquote>
<blockquote><code>katex@0.13.18</code>. لتثبيت الأخيرة مع <code>npm</code> يمكنك تشغيل</blockquote>
<blockquote>``<code>npm install -g katex@0.13.18<pre><code class="language-"></blockquote>
<blockquote>[!ملاحظة]</blockquote>
<blockquote>إذا رأيت خطأ عدم توافق numpy، شغّل:</blockquote>
<blockquote></code>`<code></blockquote>
<blockquote>pip install 'numpy<2'</blockquote>
<blockquote></code>`<code></blockquote></p><p>عند إجراء تغييرات على التبعيات المستخدمة في CI، عدل ملف
</code>.ci/docker/requirements-docs.txt<code>.</p><p>#### بناء PDF</p><p>لإنشاء PDF لجميع توثيقات بايتورتش، تأكد من تثبيت
</code>texlive<code> وLaTeX. على macOS، يمكنك تثبيتها باستخدام:
</code></pre>
brew install --cask mactex
</code>`<code></p><p>لإنشاء PDF:</p><ul><li>شغّل:</li></p><p>   </ul></code>`<code>
   make latexpdf
   </code>`<code></p><p>   هذا سينشئ الملفات اللازمة في مجلد </code>build/latex<code>.</p><ul><li>انتقل إلى هذا المجلد ونفذ:</li></p><p>   </ul></code>`<code>
   make LATEXOPTS="-interaction=nonstopmode"
   </code>`<code></p><p>   هذا سينتج </code>pytorch.pdf` بالمحتوى المطلوب. شغّل هذا
   الأمر مرة أخرى ليتم إنشاء جدول المحتويات والفهرس بشكل صحيح.</p><blockquote>[!ملاحظة]</blockquote>
<blockquote>لعرض جدول المحتويات، انتقل إلى <strong>Table of Contents</strong></blockquote>
<blockquote>في عارض PDF الخاص بك.</blockquote></p><h3>الإصدارات السابقة</h3></p><p>تعليمات التثبيت والحزم للإصدارات السابقة من بايتورتش يمكن العثور عليها
على <a href="https://pytorch.org/get-started/previous-versions" target="_blank" rel="noopener noreferrer">موقعنا</a>.</p><h2>البدء</h2></p><p>ثلاثة مصادر للبدء:
<ul><li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">الدروس: لتبدأ بفهم واستخدام بايتورتش</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">الأمثلة: كود بايتورتش سهل الفهم لجميع المجالات</a></li>
<li><a href="https://pytorch.org/docs/" target="_blank" rel="noopener noreferrer">مرجع واجهة البرمجة API</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md" target="_blank" rel="noopener noreferrer">المصطلحات</a></li></p><p></ul><h2>الموارد</h2></p><ul><li><a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">PyTorch.org</a></li>
<li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">دروس بايتورتش</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">أمثلة بايتورتش</a></li>
<li><a href="https://pytorch.org/hub/" target="_blank" rel="noopener noreferrer">نماذج بايتورتش</a></li>
<li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188" target="_blank" rel="noopener noreferrer">مقدمة في التعلم العميق مع بايتورتش من Udacity</a></li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229" target="_blank" rel="noopener noreferrer">مقدمة في تعلم الآلة مع بايتورتش من Udacity</a></li>
<li><a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch" target="_blank" rel="noopener noreferrer">الشبكات العصبية العميقة مع بايتورتش من Coursera</a></li>
<li><a href="https://twitter.com/PyTorch" target="_blank" rel="noopener noreferrer">تويتر بايتورتش</a></li>
<li><a href="https://pytorch.org/blog/" target="_blank" rel="noopener noreferrer">مدونة بايتورتش</a></li>
<li><a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw" target="_blank" rel="noopener noreferrer">قناة بايتورتش على يوتيوب</a></li></p><p></ul><h2>التواصل</h2>
<ul><li>المنتديات: مناقشة التطبيقات والبحث وغيره https://discuss.pytorch.org</li>
<li>قضايا GitHub: تقارير الأخطاء، طلبات الميزات، مشكلات التثبيت، RFCs، الأفكار، إلخ.</li>
<li>Slack: قناة <a href="https://pytorch.slack.com/" target="_blank" rel="noopener noreferrer">PyTorch Slack</a> تستضيف جمهورًا أساسيًا من مستخدمي ومطوري بايتورتش المتوسطين إلى المتقدمين للدردشة العامة والمناقشات والتعاون. إذا كنت مبتدئًا وتبحث عن مساعدة، الوسيلة الرئيسية هي <a href="https://discuss.pytorch.org" target="_blank" rel="noopener noreferrer">منتديات بايتورتش</a>. إذا كنت بحاجة لدعوة Slack، يرجى تعبئة هذا النموذج: https://goo.gl/forms/PP1AGvNHpSaJP8to1</li>
<li>النشرة البريدية: بريد إلكتروني من جهة واحدة مع إعلانات مهمة عن بايتورتش. يمكنك الاشتراك هنا: https://eepurl.com/cbG0rv</li>
<li>صفحة فيسبوك: إعلانات مهمة عن بايتورتش. https://www.facebook.com/pytorch</li>
<li>لإرشادات العلامة التجارية، يرجى زيارة موقعنا على <a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">pytorch.org</a></li></p><p></ul><h2>الإصدارات والمساهمة</h2></p><p>عادةً ما يصدر بايتورتش ثلاث إصدارات فرعية سنويًا. يرجى إبلاغنا إذا واجهت خطأ عبر <a href="https://github.com/pytorch/pytorch/issues" target="_blank" rel="noopener noreferrer">فتح قضية</a>.</p><p>نحن نقدّر جميع المساهمات. إذا كنت تخطط للمساهمة بإصلاحات للأخطاء، يرجى القيام بذلك دون أي نقاش إضافي.</p><p>إذا كنت تخطط للمساهمة بميزات جديدة أو وظائف مساعدة أو توسعات للنواة، يرجى أولاً فتح قضية ومناقشة الميزة معنا.
إرسال PR بدون نقاش قد يؤدي إلى رفضه لأننا قد نأخذ النواة في اتجاه مختلف عما تعلمه.</p><p>لمعرفة المزيد حول المساهمة في بايتورتش، يرجى زيارة <a href="CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">صفحة المساهمة</a>. لمزيد من المعلومات حول إصدارات بايتورتش، انظر <a href="RELEASE.md" target="_blank" rel="noopener noreferrer">صفحة الإصدارات</a>.</p><h2>الفريق</h2></p><p>بايتورتش مشروع مدفوع من المجتمع مع العديد من المهندسين والباحثين المهرة يساهمون فيه.</p><p>يتم صيانة بايتورتش حاليًا من قبل <a href="http://soumith.ch" target="_blank" rel="noopener noreferrer">Soumith Chintala</a>، <a href="https://github.com/gchanan" target="_blank" rel="noopener noreferrer">Gregory Chanan</a>، <a href="https://github.com/dzhulgakov" target="_blank" rel="noopener noreferrer">Dmytro Dzhulgakov</a>، <a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a>، و<a href="https://github.com/malfet" target="_blank" rel="noopener noreferrer">Nikita Shulga</a> مع مساهمات رئيسية من مئات الأفراد الموهوبين بأشكال ووسائل مختلفة.
قائمة غير شاملة ولكنها تنمو باستمرار يجب أن تذكر: <a href="https://github.com/killeent" target="_blank" rel="noopener noreferrer">Trevor Killeen</a>، <a href="https://github.com/chsasank" target="_blank" rel="noopener noreferrer">Sasank Chilamkurthy</a>، <a href="https://github.com/szagoruyko" target="_blank" rel="noopener noreferrer">Sergey Zagoruyko</a>، <a href="https://github.com/adamlerer" target="_blank" rel="noopener noreferrer">Adam Lerer</a>، <a href="https://github.com/fmassa" target="_blank" rel="noopener noreferrer">Francisco Massa</a>، <a href="https://github.com/alykhantejani" target="_blank" rel="noopener noreferrer">Alykhan Tejani</a>، <a href="https://github.com/lantiga" target="_blank" rel="noopener noreferrer">Luca Antiga</a>، <a href="https://github.com/albanD" target="_blank" rel="noopener noreferrer">Alban Desmaison</a>، <a href="https://github.com/andreaskoepf" target="_blank" rel="noopener noreferrer">Andreas Koepf</a>، <a href="https://github.com/jekbradbury" target="_blank" rel="noopener noreferrer">James Bradbury</a>، <a href="https://github.com/ebetica" target="_blank" rel="noopener noreferrer">Zeming Lin</a>، <a href="https://github.com/yuandong-tian" target="_blank" rel="noopener noreferrer">Yuandong Tian</a>، <a href="https://github.com/glample" target="_blank" rel="noopener noreferrer">Guillaume Lample</a>، <a href="https://github.com/Maratyszcza" target="_blank" rel="noopener noreferrer">Marat Dukhan</a>، <a href="https://github.com/ngimel" target="_blank" rel="noopener noreferrer">Natalia Gimelshein</a>، <a href="https://github.com/csarofeen" target="_blank" rel="noopener noreferrer">Christian Sarofeen</a>، <a href="https://github.com/martinraison" target="_blank" rel="noopener noreferrer">Martin Raison</a>، <a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a>، <a href="https://github.com/zdevito" target="_blank" rel="noopener noreferrer">Zachary Devito</a>.</p><p>ملاحظة: هذا المشروع غير مرتبط بـ <a href="https://github.com/hughperkins/pytorch" target="_blank" rel="noopener noreferrer">hughperkins/pytorch</a> الذي يحمل نفس الاسم. Hugh هو مساهم قيّم في مجتمع Torch وساعد في العديد من الأمور الخاصة بـ Torch وPyTorch.</p><h2>الرخصة</h2></p><p>بايتورتش تحت رخصة BSD، كما هو موضح في ملف <a href="LICENSE" target="_blank" rel="noopener noreferrer">LICENSE</a>.

---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/pytorch/pytorch/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>