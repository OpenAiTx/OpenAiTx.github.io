<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch - Read pytorch documentation in Simplified Chinese. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read pytorch documentation in Simplified Chinese. This project has 0 stars on GitHub.">
    <meta name="keywords" content="pytorch, Simplified Chinese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "pytorch",
  "description": "Read pytorch documentation in Simplified Chinese. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "pytorch"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/pytorch/pytorch/README-zh-CN.html",
  "sameAs": "https://raw.githubusercontent.com/pytorch/pytorch/master/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    pytorch
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Simplified Chinese</span>
                <span>by pytorch</span>
            </div>
        </div>
        
        <div class="content">
            <p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="PyTorch Logo"></p><p>--------------------------------------------------------------------------------</p><p>PyTorch 是一个 Python 包，提供了两个高级特性：
<ul><li>张量计算（类似于 NumPy），并具备强大的 GPU 加速能力</li>
<li>基于 tape 的自动微分系统构建的深度神经网络</li></p><p></ul>您可以根据需要重用您喜爱的 Python 包，如 NumPy、SciPy 和 Cython，以扩展 PyTorch。</p><p>我们的主干健康状况（持续集成信号）可在 <a href="https://hud.pytorch.org/ci/pytorch/pytorch/main" target="_blank" rel="noopener noreferrer">hud.pytorch.org</a> 查看。</p><p><!-- toc --></p><ul><li><a href="#more-about-pytorch" target="_blank" rel="noopener noreferrer">更多关于 PyTorch</a></li>
  <li><a href="#a-gpu-ready-tensor-library" target="_blank" rel="noopener noreferrer">GPU 就绪的张量库</a></li>
  <li><a href="#dynamic-neural-networks-tape-based-autograd" target="_blank" rel="noopener noreferrer">动态图神经网络：基于 Tape 的 Autograd</a></li>
  <li><a href="#python-first" target="_blank" rel="noopener noreferrer">Python 优先</a></li>
  <li><a href="#imperative-experiences" target="_blank" rel="noopener noreferrer">命令式体验</a></li>
  <li><a href="#fast-and-lean" target="_blank" rel="noopener noreferrer">快速且精简</a></li>
  <li><a href="#extensions-without-pain" target="_blank" rel="noopener noreferrer">无痛扩展</a></li>
<li><a href="#installation" target="_blank" rel="noopener noreferrer">安装</a></li>
  <li><a href="#binaries" target="_blank" rel="noopener noreferrer">二进制文件</a></li>
    <li><a href="#nvidia-jetson-platforms" target="_blank" rel="noopener noreferrer">NVIDIA Jetson 平台</a></li>
  <li><a href="#from-source" target="_blank" rel="noopener noreferrer">源码安装</a></li>
    <li><a href="#prerequisites" target="_blank" rel="noopener noreferrer">先决条件</a></li>
      <li><a href="#nvidia-cuda-support" target="_blank" rel="noopener noreferrer">NVIDIA CUDA 支持</a></li>
      <li><a href="#amd-rocm-support" target="_blank" rel="noopener noreferrer">AMD ROCm 支持</a></li>
      <li><a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">Intel GPU 支持</a></li>
    <li><a href="#get-the-pytorch-source" target="_blank" rel="noopener noreferrer">获取 PyTorch 源码</a></li>
    <li><a href="#install-dependencies" target="_blank" rel="noopener noreferrer">安装依赖</a></li>
    <li><a href="#install-pytorch" target="_blank" rel="noopener noreferrer">安装 PyTorch</a></li>
      <li><a href="#adjust-build-options-optional" target="_blank" rel="noopener noreferrer">调整构建选项（可选）</a></li>
  <li><a href="#docker-image" target="_blank" rel="noopener noreferrer">Docker 镜像</a></li>
    <li><a href="#using-pre-built-images" target="_blank" rel="noopener noreferrer">使用预构建镜像</a></li>
    <li><a href="#building-the-image-yourself" target="_blank" rel="noopener noreferrer">自行构建镜像</a></li>
  <li><a href="#building-the-documentation" target="_blank" rel="noopener noreferrer">构建文档</a></li>
    <li><a href="#building-a-pdf" target="_blank" rel="noopener noreferrer">生成 PDF</a></li>
  <li><a href="#previous-versions" target="_blank" rel="noopener noreferrer">历史版本</a></li>
<li><a href="#getting-started" target="_blank" rel="noopener noreferrer">快速上手</a></li>
<li><a href="#resources" target="_blank" rel="noopener noreferrer">资源</a></li>
<li><a href="#communication" target="_blank" rel="noopener noreferrer">交流沟通</a></li>
<li><a href="#releases-and-contributing" target="_blank" rel="noopener noreferrer">发布与贡献</a></li>
<li><a href="#the-team" target="_blank" rel="noopener noreferrer">团队</a></li>
<li><a href="#license" target="_blank" rel="noopener noreferrer">许可证</a></li></p><p></ul><!-- tocstop --></p><h2>更多关于 PyTorch</h2></p><p><a href="https://pytorch.org/tutorials/beginner/basics/intro.html" target="_blank" rel="noopener noreferrer">学习 PyTorch 基础知识</a></p><p>从细节上看，PyTorch 是由以下组件组成的库：</p><p>| 组件 | 描述 |
| ---- | --- |
| <a href="https://pytorch.org/docs/stable/torch.html" target="_blank" rel="noopener noreferrer"><strong>torch</strong></a> | 类似 NumPy 的张量库，具有强大的 GPU 支持 |
| <a href="https://pytorch.org/docs/stable/autograd.html" target="_blank" rel="noopener noreferrer"><strong>torch.autograd</strong></a> | 基于 tape 的自动微分库，支持 torch 中所有可微分张量操作 |
| <a href="https://pytorch.org/docs/stable/jit.html" target="_blank" rel="noopener noreferrer"><strong>torch.jit</strong></a> | 编译栈（TorchScript），可从 PyTorch 代码创建可序列化和可优化的模型 |
| <a href="https://pytorch.org/docs/stable/nn.html" target="_blank" rel="noopener noreferrer"><strong>torch.nn</strong></a> | 与 autograd 深度集成的神经网络库，设计上极为灵活 |
| <a href="https://pytorch.org/docs/stable/multiprocessing.html" target="_blank" rel="noopener noreferrer"><strong>torch.multiprocessing</strong></a> | Python 多进程，但可在进程间神奇地共享 torch 张量内存。用于数据加载和 Hogwild 训练非常有用 |
| <a href="https://pytorch.org/docs/stable/data.html" target="_blank" rel="noopener noreferrer"><strong>torch.utils</strong></a> | DataLoader 及其他便捷的实用函数 |</p><p>通常，PyTorch 的使用方式有以下两种：</p><ul><li>作为 NumPy 的替代，以利用 GPU 的强大计算力。</li>
<li>作为深度学习研究平台，提供最大灵活性和速度。</li></p><p></ul>进一步说明：</p><h3>GPU 就绪的张量库</h3></p><p>如果你用过 NumPy，那你就用过张量（即 ndarray）。</p><p><img src="./docs/source/_static/img/tensor_illustration.png" alt="Tensor illustration"></p><p>PyTorch 提供的张量可以存在于 CPU 或 GPU 上，并极大地加速计算。</p><p>我们提供了丰富的张量操作，以加速并满足您的科学计算需求，如切片、索引、数学运算、线性代数、归约操作等。
而且它们非常快！</p><h3>动态图神经网络：基于 Tape 的 Autograd</h3></p><p>PyTorch 构建神经网络有一种独特方式：使用并重放录音带。</p><p>大多数框架如 TensorFlow、Theano、Caffe 和 CNTK 都采用静态视图。
你需要构建神经网络，并反复复用相同结构。
如果要改变网络行为，就得从头再来。</p><p>在 PyTorch 中，我们采用了一种称为反向自动微分（reverse-mode auto-differentiation）的技术，允许你任意更改网络行为而无需任何延迟或开销。我们的灵感来自多篇相关研究论文，以及 <a href="https://github.com/twitter/torch-autograd" target="_blank" rel="noopener noreferrer">torch-autograd</a>、<a href="https://github.com/HIPS/autograd" target="_blank" rel="noopener noreferrer">autograd</a>、<a href="https://chainer.org" target="_blank" rel="noopener noreferrer">Chainer</a> 等当前和过往的项目。</p><p>虽然这种技术并非 PyTorch 独有，但目前 PyTorch 的实现是最快的之一。
你可以获得速度和灵活性的最佳结合，助力你的科研探索。</p><p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="Dynamic graph"></p><h3>Python 优先</h3></p><p>PyTorch 并不是一个绑定到庞大 C++ 框架的 Python 接口。
它本身就是为深度集成到 Python 而设计的。
你可以像使用 <a href="https://www.numpy.org/" target="_blank" rel="noopener noreferrer">NumPy</a> / <a href="https://www.scipy.org/" target="_blank" rel="noopener noreferrer">SciPy</a> / <a href="https://scikit-learn.org" target="_blank" rel="noopener noreferrer">scikit-learn</a> 那样自然地使用它。
你可以用 Python 直接编写新的神经网络层，使用你喜欢的库，
并利用 <a href="https://cython.org/" target="_blank" rel="noopener noreferrer">Cython</a> 和 <a href="http://numba.pydata.org/" target="_blank" rel="noopener noreferrer">Numba</a> 等工具包。
我们的目标是在合适的地方不重复造轮子。</p><h3>命令式体验</h3></p><p>PyTorch 设计直观，思路线性，易于使用。
你写的每一行代码都会立即执行，不存在异步视角。
当你调试或收到错误提示和堆栈信息时，理解它们非常直接。
堆栈信息会准确指向你代码的定义位置。
我们希望你不会因为糟糕的堆栈信息或异步且不透明的执行引擎而浪费调试时间。</p><h3>快速且精简</h3></p><p>PyTorch 框架开销极小。我们集成了诸如 <a href="https://software.intel.com/mkl" target="_blank" rel="noopener noreferrer">Intel MKL</a> 和 NVIDIA（<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">cuDNN</a>，<a href="https://developer.nvidia.com/nccl" target="_blank" rel="noopener noreferrer">NCCL</a>）等加速库以最大化速度。
其核心的 CPU 和 GPU 张量以及神经网络后端
都已经成熟，并经过多年测试。</p><p>因此，无论你运行小型还是大型神经网络，PyTorch 都非常快。</p><p>PyTorch 的内存使用相比 Torch 或其他一些替代品极为高效。
我们为 GPU 编写了自定义内存分配器，以确保
你的深度学习模型能最大限度地利用内存。
这使你能够训练更大的深度学习模型。</p><h3>无痛扩展</h3></p><p>编写新的神经网络模块或与 PyTorch 张量 API 交互被设计得非常简单，
并且抽象最少。</p><p>你可以使用 torch API 在 Python 中编写新的神经网络层，
<a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html" target="_blank" rel="noopener noreferrer">或你喜欢的基于 NumPy 的库，比如 SciPy</a>。</p><p>如果你想用 C/C++ 编写层，我们提供了高效且样板代码极少的便捷扩展 API。
无需编写包装代码。你可以查看<a href="https://pytorch.org/tutorials/advanced/cpp_extension.html" target="_blank" rel="noopener noreferrer">本教程</a>和<a href="https://github.com/pytorch/extension-cpp" target="_blank" rel="noopener noreferrer">本示例</a>。</p><h2>安装</h2></p><h3>二进制文件</h3>
通过 Conda 或 pip wheels 安装二进制文件的命令请见我们官网：<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">https://pytorch.org/get-started/locally/</a></p><p>#### NVIDIA Jetson 平台</p><p>NVIDIA 的 Jetson Nano、Jetson TX1/TX2、Jetson Xavier NX/AGX 和 Jetson AGX Orin 的 Python wheel 包可在<a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048" target="_blank" rel="noopener noreferrer">这里</a>获取，L4T 容器在<a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch" target="_blank" rel="noopener noreferrer">这里</a>发布。</p><p>需要 JetPack 4.2 及以上版本，由 <a href="https://github.com/dusty-nv" target="_blank" rel="noopener noreferrer">@dusty-nv</a> 和 <a href="https://github.com/ptrblck" target="_blank" rel="noopener noreferrer">@ptrblck</a> 维护。</p><h3>源码安装</h3></p><p>#### 先决条件
如果你打算源码安装，需要：
<ul><li>Python 3.9 或更高版本</li>
<li>完全支持 C++17 的编译器，如 clang 或 gcc（Linux 上需 gcc 9.4.0 或更高）</li>
<li>Visual Studio 或 Visual Studio Build Tool（仅限 Windows）</li></p><p></ul>\* PyTorch CI 使用 Visual C++ BuildTools，该工具包含在 Visual Studio Enterprise、Professional 或 Community 版中。也可从 https://visualstudio.microsoft.com/visual-cpp-build-tools/ 单独安装。默认情况下，Visual Studio Code 并不包含这些构建工具。</p><p>下面是环境设置示例：</p><ul><li>Linux:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>/bin/activate
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME></code></pre></p><ul><li>Windows:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>\Scripts\activate.bat
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME>
$ call "C:\Program Files\Microsoft Visual Studio\<VERSION>\Community\VC\Auxiliary\Build\vcvarsall.bat" x64</code></pre></p><p>##### NVIDIA CUDA 支持
若需编译带有 CUDA 支持的版本，请<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">从我们的支持矩阵中选择支持的 CUDA 版本</a>，然后安装以下内容：
<ul><li><a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener noreferrer">NVIDIA CUDA</a></li>
<li><a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">NVIDIA cuDNN</a> v8.5 或更高</li>
<li><a href="https://gist.github.com/ax3l/9489132" target="_blank" rel="noopener noreferrer">与 CUDA 兼容的编译器</a></li></p><p></ul>注意：你可以参考 <a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html" target="_blank" rel="noopener noreferrer">cuDNN 支持矩阵</a> 以了解 cuDNN 与各 CUDA 版本、驱动和 NVIDIA 硬件的对应关系。</p><p>若需禁用 CUDA 支持，请导出环境变量 <code>USE_CUDA=0</code>。
其他可能有用的环境变量可在 <code>setup.py</code> 中找到。</p><p>如果你为 NVIDIA Jetson 平台（Jetson Nano、TX1、TX2、AGX Xavier）构建，Jetson Nano 的 PyTorch 安装指南见<a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/" target="_blank" rel="noopener noreferrer">这里</a></p><p>##### AMD ROCm 支持
若需编译支持 ROCm，请安装
<ul><li><a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html" target="_blank" rel="noopener noreferrer">AMD ROCm</a> 4.0 及以上版本</li>
<li>ROCm 当前仅支持 Linux 系统。</li></p><p></ul>默认情况下，构建系统期望 ROCm 安装在 <code>/opt/rocm</code>。若安装在其他目录，需设置 <code>ROCM_PATH</code> 环境变量为 ROCm 安装路径。构建系统会自动检测 AMD GPU 架构，也可以通过 <code>PYTORCH_ROCM_ARCH</code> 环境变量手动指定 <a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus" target="_blank" rel="noopener noreferrer">AMD GPU 架构</a>。</p><p>若需禁用 ROCm 支持，请导出环境变量 <code>USE_ROCM=0</code>。
其他可用环境变量可在 <code>setup.py</code> 中查找。</p><p>##### Intel GPU 支持
若需编译支持 Intel GPU，请参考
<ul><li><a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html" target="_blank" rel="noopener noreferrer">Intel GPU 的 PyTorch 先决条件</a></li>
<li>Intel GPU 支持 Linux 和 Windows</li></p><p></ul>若需禁用 Intel GPU 支持，请导出环境变量 <code>USE_XPU=0</code>。
其他可用环境变量可在 <code>setup.py</code> 中查找。</p><p>#### 获取 PyTorch 源码
<pre><code class="language-bash">git clone https://github.com/pytorch/pytorch
cd pytorch
<h1>如果是更新现有仓库</h1>
git submodule sync
git submodule update --init --recursive</code></pre></p><p>#### 安装依赖</p><p><strong>通用</strong></p><pre><code class="language-bash">conda install cmake ninja
<h1>克隆源码后，在 PyTorch 目录下运行</h1>
pip install -r requirements.txt</code></pre></p><p><strong>Linux 下</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>仅 CUDA：如需为 GPU 增加 LAPACK 支持</h1>
<h1>magma 安装：需在激活的 conda 环境下运行，并指定 CUDA 版本</h1>
.ci/docker/common/install_magma_conda.sh 12.4</p><h1>（可选）如使用 torch.compile 的 inductor/triton，需安装相应版本的 triton</h1>
<h1>克隆后在 pytorch 目录下运行</h1>
<h1>若需 Intel GPU 支持，请在运行前显式 <code>export USE_XPU=1</code></h1>
make triton</code></pre></p><p><strong>MacOS 下</strong></p><pre><code class="language-bash"># 仅在 intel x86 处理器上添加
pip install mkl-static mkl-include
<h1>如需 torch.distributed，请添加这些包</h1>
conda install pkg-config libuv</code></pre></p><p><strong>Windows 下</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>如需 torch.distributed，请添加这些包。</h1>
<h1>Windows 下的分布式包为原型功能，可能变动。</h1>
conda install -c conda-forge libuv=1.39</code></pre></p><p>#### 安装 PyTorch
<strong>Linux 下</strong></p><p>若为 AMD ROCm 编译，请先运行：
<pre><code class="language-bash"># 仅当为 ROCm 编译时运行
python tools/amd_build/build_amd.py</code></pre></p><p>安装 PyTorch
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py develop</code></pre></p><p><strong>macOS 下</strong></p><pre><code class="language-bash">python3 setup.py develop</code></pre></p><p><strong>Windows 下</strong></p><p>如需构建旧版 python 代码，请参见 <a href="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda" target="_blank" rel="noopener noreferrer">Building on legacy code and CUDA</a></p><p><strong>仅 CPU 构建</strong></p><p>此模式下，PyTorch 计算将在 CPU 上运行，不使用 GPU。</p><pre><code class="language-cmd">python setup.py develop</code></pre></p><p>关于 OpenMP：建议使用 Intel OpenMP（iomp）。为链接 iomp，你需要手动下载库并通过调整 <code>CMAKE_INCLUDE_PATH</code> 和 <code>LIB</code> 设置编译环境。配置方法可参见<a href="https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source" target="_blank" rel="noopener noreferrer">这里</a>。若未配置，CMake 将使用 Microsoft Visual C 的 OpenMP 运行时（vcomp）。</p><p><strong>基于 CUDA 的构建</strong></p><p>此模式下，PyTorch 计算将通过 CUDA 利用 GPU 进行加速。</p><p><a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm" target="_blank" rel="noopener noreferrer">Pytorch 构建 CUDA 需 NVTX</a>。
NVTX 是 CUDA 安装包的一部分，称为 “Nsight Compute”。如需安装到已安装的 CUDA 上，请重新运行 CUDA 安装并勾选相关选项。
确保 CUDA（含 Nsight Compute）在 Visual Studio 之后安装。</p><p>目前，CMake 支持 VS 2017 / 2019 和 Ninja 作为生成器。若 <code>PATH</code> 中检测到 <code>ninja.exe</code>，则默认使用 Ninja，否则使用 VS 2017 / 2019。
<br/> 若选择 Ninja 作为生成器，则自动选择最新的 MSVC 作为底层工具链。</p><p>常用的其他库如
<a href="https://developer.nvidia.com/magma" target="_blank" rel="noopener noreferrer">Magma</a>、<a href="https://github.com/oneapi-src/oneDNN" target="_blank" rel="noopener noreferrer">oneDNN，又名 MKLDNN 或 DNNL</a> 和 <a href="https://github.com/mozilla/sccache" target="_blank" rel="noopener noreferrer">Sccache</a> 也常需安装。请参考 <a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers" target="_blank" rel="noopener noreferrer">installation-helper</a> 进行安装。</p><p>更多环境变量配置可参考 <a href="https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat" target="_blank" rel="noopener noreferrer">build_pytorch.bat</a> 脚本。</p><pre><code class="language-cmd">cmd</p><p>:: 下载并解压 mkl 包后设置环境变量，否则 CMake 会报错 <code>Could NOT find OpenMP</code>。
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%</p><p>:: 仔细阅读上一节内容再继续。
:: [可选] 若需覆盖 Ninja 和 Visual Studio 使用的底层工具集，请运行以下脚本块。
:: “Visual Studio 2019 Developer Command Prompt” 会自动启动。
:: 若用 Visual Studio 生成器，请确保 CMake >= 3.12。
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f "usebackq tokens=<em>" %i in (<code>"%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe" -version [15^,17^) -products </em> -latest -property installationPath</code>) do call "%i\VC\Auxiliary\Build\vcvarsall.bat" x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%</p><p>:: [可选] 若需覆盖 CUDA 主机编译器
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe</p><p>python setup.py develop
</code></pre></p><p><strong>Intel GPU 构建</strong></p><p>此模式下将构建支持 Intel GPU 的 PyTorch。</p><p>请确保<a href="#prerequisites" target="_blank" rel="noopener noreferrer">通用先决条件</a>以及<a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">Intel GPU 先决条件</a>已正确安装并配置好环境变量。构建工具需 <code>Visual Studio 2022</code>。</p><p>然后可用如下命令构建：</p><pre><code class="language-cmd">:: CMD 命令：
:: 设置 CMAKE_PREFIX_PATH 以帮助找到相应包
:: %CONDA_PREFIX% 仅在 <code>conda activate custom_env</code> 后有效</p><p>if defined CMAKE_PREFIX_PATH (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%"
) else (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library"
)</p><p>python setup.py develop</code></pre></p><p>##### 调整构建选项（可选）</p><p>你可以选择性地调整 cmake 变量配置（无需先构建），例如调整 CuDNN 或 BLAS 的预检测目录。</p><p>Linux 下
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py build --cmake-only
ccmake build  # 或 cmake-gui build</code></pre></p><p>macOS 下
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only
ccmake build  # 或 cmake-gui build</code></pre></p><h3>Docker 镜像</h3></p><p>#### 使用预构建镜像</p><p>你还可以从 Docker Hub 拉取预构建镜像，并用 docker v19.03+ 运行</p><pre><code class="language-bash">docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest</code></pre></p><p>请注意，PyTorch 利用共享内存进行进程间数据交换，因此如使用 torch 多进程（如多线程数据加载器），
容器的默认共享内存段大小不足，需通过 <code>--ipc=host</code> 或 <code>--shm-size</code> 命令行选项增大共享内存。</p><p>#### 自行构建镜像</p><p><strong>注意：</strong> 需用 docker 版本 > 18.06 构建</p><p>提供的 <code>Dockerfile</code> 支持构建带 CUDA 11.1 和 cuDNN v8 的镜像。
你可以通过 <code>PYTHON_VERSION=x.y</code> 变量指定 Miniconda 使用的 Python 版本，未指定则用默认版本。</p><pre><code class="language-bash">make -f docker.Makefile
<h1>镜像标签为 docker.io/${your_docker_username}/pytorch</code></pre></h1></p><p>也可以通过环境变量 <code>CMAKE_VARS="..."</code> 传递额外 CMake 变量以定制构建过程。
可见 <a href="./setup.py" target="_blank" rel="noopener noreferrer">setup.py</a> 获取可用变量列表。</p><pre><code class="language-bash">make -f docker.Makefile</code></pre></p><h3>构建文档</h3></p><p>要以多种格式构建文档，你需要 <a href="http://www.sphinx-doc.org" target="_blank" rel="noopener noreferrer">Sphinx</a>
和 pytorch_sphinx_theme2。</p><p>本地构建文档前，请确保环境中已安装 <code>torch</code>。
如只做小修小补，可按<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">快速上手</a>中所述安装 nightly 版。</p><p>如有更复杂修改，比如新增模块及文档字符串，可能需要<a href="#from-source" target="_blank" rel="noopener noreferrer">源码安装 torch</a>。
文档字符串规范见 <a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines" target="_blank" rel="noopener noreferrer">Docstring Guidelines</a>。</p><pre><code class="language-bash">cd docs/
pip install -r requirements.txt
make html
make serve</code></pre></p><p>运行 <code>make</code> 可查看所有可用输出格式。</p><p>如遇 katex 错误请运行 <code>npm install katex</code>。若仍有问题，试试
<code>npm install -g katex</code></p><blockquote>[!注意]</blockquote>
<blockquote>若用不同包管理器（如 conda）安装了 <code>nodejs</code>，则 <code>npm</code> 可能安装的 <code>katex</code> 版本与 <code>nodejs</code> 不兼容，导致构建失败。</blockquote>
<blockquote>已知可用的组合为 <code>node@6.13.1</code> 和 <code>katex@0.13.18</code>。全局安装可执行</blockquote>
<blockquote>``<code>npm install -g katex@0.13.18<pre><code class="language-"></blockquote>
<blockquote>[!注意]</blockquote>
<blockquote>若出现 numpy 兼容性错误，请运行：</blockquote>
<blockquote></code>`<code></blockquote>
<blockquote>pip install 'numpy<2'</blockquote>
<blockquote></code>`<code></blockquote></p><p>如修改了 CI 所需依赖，请编辑
</code>.ci/docker/requirements-docs.txt<code> 文件。</p><p>#### 生成 PDF</p><p>如需编译 PyTorch 全部文档为 PDF，请确保已安装
</code>texlive<code> 和 LaTeX。macOS 下可用：
</code></pre>
brew install --cask mactex
</code>`<code></p><p>生成 PDF 步骤：</p><ul><li>运行：</li></p><p>   </ul></code>`<code>
   make latexpdf
   </code>`<code></p><p>   这将在 </code>build/latex<code> 目录下生成相关文件。</p><ul><li>进入该目录，执行：</li></p><p>   </ul></code>`<code>
   make LATEXOPTS="-interaction=nonstopmode"
   </code>`<code></p><p>   这将生成包含所需内容的 </code>pytorch.pdf`。请再运行一次该命令以生成正确的目录和索引。</p><blockquote>[!注意]</blockquote>
<blockquote>如需查看目录，请在 PDF 阅读器中切换到<strong>目录</strong>视图。</blockquote></p><h3>历史版本</h3></p><p>历史版本的安装说明和二进制包可在
<a href="https://pytorch.org/get-started/previous-versions" target="_blank" rel="noopener noreferrer">官网</a> 查询。</p><h2>快速上手</h2></p><p>三步上手：
<ul><li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">教程：帮助你理解并使用 PyTorch</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">示例：涵盖各领域的易懂 PyTorch 代码</a></li>
<li><a href="https://pytorch.org/docs/" target="_blank" rel="noopener noreferrer">API 参考文档</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md" target="_blank" rel="noopener noreferrer">术语表</a></li></p><p></ul><h2>资源</h2></p><ul><li><a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">PyTorch.org</a></li>
<li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">PyTorch 教程</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">PyTorch 示例</a></li>
<li><a href="https://pytorch.org/hub/" target="_blank" rel="noopener noreferrer">PyTorch 模型</a></li>
<li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188" target="_blank" rel="noopener noreferrer">Udacity PyTorch 深度学习入门</a></li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229" target="_blank" rel="noopener noreferrer">Udacity PyTorch 机器学习入门</a></li>
<li><a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch" target="_blank" rel="noopener noreferrer">Coursera PyTorch 深度神经网络课程</a></li>
<li><a href="https://twitter.com/PyTorch" target="_blank" rel="noopener noreferrer">PyTorch 推特</a></li>
<li><a href="https://pytorch.org/blog/" target="_blank" rel="noopener noreferrer">PyTorch 博客</a></li>
<li><a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw" target="_blank" rel="noopener noreferrer">PyTorch YouTube</a></li></p><p></ul><h2>交流沟通</h2>
<ul><li>论坛：实现、科研等讨论 https://discuss.pytorch.org</li>
<li>GitHub Issues：Bug 报告、特性请求、安装问题、RFC、想法等。</li>
<li>Slack：<a href="https://pytorch.slack.com/" target="_blank" rel="noopener noreferrer">PyTorch Slack</a> 面向中高级 PyTorch 用户和开发者，适合普通聊天、线上讨论、协作等。新手建议优先使用 <a href="https://discuss.pytorch.org" target="_blank" rel="noopener noreferrer">PyTorch 论坛</a>。如需 Slack 邀请，请填写：https://goo.gl/forms/PP1AGvNHpSaJP8to1</li>
<li>邮件通讯：无垃圾邮件，只发 PyTorch 重要公告。订阅入口：https://eepurl.com/cbG0rv</li>
<li>Facebook 页面：PyTorch 重要公告。https://www.facebook.com/pytorch</li>
<li>品牌指南请访问 <a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">pytorch.org</a></li></p><p></ul><h2>发布与贡献</h2></p><p>通常，PyTorch 每年有三个小版本发布。若发现 bug，请<a href="https://github.com/pytorch/pytorch/issues" target="_blank" rel="noopener noreferrer">提交 issue</a>。</p><p>感谢所有贡献者。如计划提交 bug 修复，请直接提交，无需进一步讨论。</p><p>如计划贡献新特性、实用函数或核心扩展，请先提交 issue 与我们讨论。未经讨论直接发送 PR 可能会被拒绝，因为核心方向可能与你理解的不一致。</p><p>了解 PyTorch 贡献流程请见<a href="CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">贡献页面</a>。更多发布相关信息见<a href="RELEASE.md" target="_blank" rel="noopener noreferrer">发布页面</a>。</p><h2>团队</h2></p><p>PyTorch 是一个社区驱动的项目，有众多优秀工程师和研究人员参与贡献。</p><p>当前由 <a href="http://soumith.ch" target="_blank" rel="noopener noreferrer">Soumith Chintala</a>、<a href="https://github.com/gchanan" target="_blank" rel="noopener noreferrer">Gregory Chanan</a>、<a href="https://github.com/dzhulgakov" target="_blank" rel="noopener noreferrer">Dmytro Dzhulgakov</a>、<a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a>、<a href="https://github.com/malfet" target="_blank" rel="noopener noreferrer">Nikita Shulga</a> 维护，数百位才华横溢的开发者以各种方式作出重要贡献。
部分贡献者（不断增长的非详尽名单）：<a href="https://github.com/killeent" target="_blank" rel="noopener noreferrer">Trevor Killeen</a>、<a href="https://github.com/chsasank" target="_blank" rel="noopener noreferrer">Sasank Chilamkurthy</a>、<a href="https://github.com/szagoruyko" target="_blank" rel="noopener noreferrer">Sergey Zagoruyko</a>、<a href="https://github.com/adamlerer" target="_blank" rel="noopener noreferrer">Adam Lerer</a>、<a href="https://github.com/fmassa" target="_blank" rel="noopener noreferrer">Francisco Massa</a>、<a href="https://github.com/alykhantejani" target="_blank" rel="noopener noreferrer">Alykhan Tejani</a>、<a href="https://github.com/lantiga" target="_blank" rel="noopener noreferrer">Luca Antiga</a>、<a href="https://github.com/albanD" target="_blank" rel="noopener noreferrer">Alban Desmaison</a>、<a href="https://github.com/andreaskoepf" target="_blank" rel="noopener noreferrer">Andreas Koepf</a>、<a href="https://github.com/jekbradbury" target="_blank" rel="noopener noreferrer">James Bradbury</a>、<a href="https://github.com/ebetica" target="_blank" rel="noopener noreferrer">Zeming Lin</a>、<a href="https://github.com/yuandong-tian" target="_blank" rel="noopener noreferrer">Yuandong Tian</a>、<a href="https://github.com/glample" target="_blank" rel="noopener noreferrer">Guillaume Lample</a>、<a href="https://github.com/Maratyszcza" target="_blank" rel="noopener noreferrer">Marat Dukhan</a>、<a href="https://github.com/ngimel" target="_blank" rel="noopener noreferrer">Natalia Gimelshein</a>、<a href="https://github.com/csarofeen" target="_blank" rel="noopener noreferrer">Christian Sarofeen</a>、<a href="https://github.com/martinraison" target="_blank" rel="noopener noreferrer">Martin Raison</a>、<a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a>、<a href="https://github.com/zdevito" target="_blank" rel="noopener noreferrer">Zachary Devito</a>。</p><p>注意：本项目与同名的 <a href="https://github.com/hughperkins/pytorch" target="_blank" rel="noopener noreferrer">hughperkins/pytorch</a> 无关。Hugh 是 Torch 社区的重要贡献者，在 Torch 和 PyTorch 方面有诸多帮助。</p><h2>许可证</h2></p><p>PyTorch 采用 BSD 风格许可证，详见 <a href="LICENSE" target="_blank" rel="noopener noreferrer">LICENSE</a> 文件。

---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/pytorch/pytorch/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>