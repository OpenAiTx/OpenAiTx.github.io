<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch - Read pytorch documentation in Russian. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read pytorch documentation in Russian. This project has 0 stars on GitHub.">
    <meta name="keywords" content="pytorch, Russian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "pytorch",
  "description": "Read pytorch documentation in Russian. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "pytorch"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/pytorch/pytorch/README-ru.html",
  "sameAs": "https://raw.githubusercontent.com/pytorch/pytorch/master/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    pytorch
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Russian</span>
                <span>by pytorch</span>
            </div>
        </div>
        
        <div class="content">
            <p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="PyTorch Logo"></p><p>--------------------------------------------------------------------------------</p><p>PyTorch — это пакет на Python, предоставляющий две основные возможности:
<ul><li>Вычисления с тензорами (аналогично NumPy) с мощным ускорением на GPU</li>
<li>Глубокие нейронные сети, построенные на системе автодифференцирования с использованием ленты</li></p><p></ul>Вы можете повторно использовать ваши любимые Python-пакеты, такие как NumPy, SciPy и Cython, чтобы расширять возможности PyTorch по мере необходимости.</p><p>Сигналы здоровья основной ветки (Continuous Integration) можно найти на <a href="https://hud.pytorch.org/ci/pytorch/pytorch/main" target="_blank" rel="noopener noreferrer">hud.pytorch.org</a>.</p><p><!-- toc --></p><ul><li><a href="#more-about-pytorch" target="_blank" rel="noopener noreferrer">Подробнее о PyTorch</a></li>
  <li><a href="#a-gpu-ready-tensor-library" target="_blank" rel="noopener noreferrer">Тензорная библиотека с поддержкой GPU</a></li>
  <li><a href="#dynamic-neural-networks-tape-based-autograd" target="_blank" rel="noopener noreferrer">Динамические нейронные сети: автодифференцирование на основе ленты</a></li>
  <li><a href="#python-first" target="_blank" rel="noopener noreferrer">Python — в первую очередь</a></li>
  <li><a href="#imperative-experiences" target="_blank" rel="noopener noreferrer">Императивный опыт</a></li>
  <li><a href="#fast-and-lean" target="_blank" rel="noopener noreferrer">Быстрый и компактный</a></li>
  <li><a href="#extensions-without-pain" target="_blank" rel="noopener noreferrer">Расширения без боли</a></li>
<li><a href="#installation" target="_blank" rel="noopener noreferrer">Установка</a></li>
  <li><a href="#binaries" target="_blank" rel="noopener noreferrer">Бинарные файлы</a></li>
    <li><a href="#nvidia-jetson-platforms" target="_blank" rel="noopener noreferrer">Платформы NVIDIA Jetson</a></li>
  <li><a href="#from-source" target="_blank" rel="noopener noreferrer">Сборка из исходников</a></li>
    <li><a href="#prerequisites" target="_blank" rel="noopener noreferrer">Необходимые компоненты</a></li>
      <li><a href="#nvidia-cuda-support" target="_blank" rel="noopener noreferrer">Поддержка NVIDIA CUDA</a></li>
      <li><a href="#amd-rocm-support" target="_blank" rel="noopener noreferrer">Поддержка AMD ROCm</a></li>
      <li><a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">Поддержка Intel GPU</a></li>
    <li><a href="#get-the-pytorch-source" target="_blank" rel="noopener noreferrer">Получение исходников PyTorch</a></li>
    <li><a href="#install-dependencies" target="_blank" rel="noopener noreferrer">Установка зависимостей</a></li>
    <li><a href="#install-pytorch" target="_blank" rel="noopener noreferrer">Установка PyTorch</a></li>
      <li><a href="#adjust-build-options-optional" target="_blank" rel="noopener noreferrer">Настройка параметров сборки (опционально)</a></li>
  <li><a href="#docker-image" target="_blank" rel="noopener noreferrer">Образы Docker</a></li>
    <li><a href="#using-pre-built-images" target="_blank" rel="noopener noreferrer">Использование готовых образов</a></li>
    <li><a href="#building-the-image-yourself" target="_blank" rel="noopener noreferrer">Сборка образа самостоятельно</a></li>
  <li><a href="#building-the-documentation" target="_blank" rel="noopener noreferrer">Сборка документации</a></li>
    <li><a href="#building-a-pdf" target="_blank" rel="noopener noreferrer">Создание PDF</a></li>
  <li><a href="#previous-versions" target="_blank" rel="noopener noreferrer">Предыдущие версии</a></li>
<li><a href="#getting-started" target="_blank" rel="noopener noreferrer">Начало работы</a></li>
<li><a href="#resources" target="_blank" rel="noopener noreferrer">Ресурсы</a></li>
<li><a href="#communication" target="_blank" rel="noopener noreferrer">Коммуникация</a></li>
<li><a href="#releases-and-contributing" target="_blank" rel="noopener noreferrer">Выпуски и вклад</a></li>
<li><a href="#the-team" target="_blank" rel="noopener noreferrer">Команда</a></li>
<li><a href="#license" target="_blank" rel="noopener noreferrer">Лицензия</a></li></p><p></ul><!-- tocstop --></p><h2>Подробнее о PyTorch</h2></p><p><a href="https://pytorch.org/tutorials/beginner/basics/intro.html" target="_blank" rel="noopener noreferrer">Изучить основы PyTorch</a></p><p>На низком уровне PyTorch — это библиотека, состоящая из следующих компонентов:</p><p>| Компонент | Описание |
| ---- | --- |
| <a href="https://pytorch.org/docs/stable/torch.html" target="_blank" rel="noopener noreferrer"><strong>torch</strong></a> | Тензорная библиотека, аналогичная NumPy, с поддержкой GPU |
| <a href="https://pytorch.org/docs/stable/autograd.html" target="_blank" rel="noopener noreferrer"><strong>torch.autograd</strong></a> | Библиотека автоматического дифференцирования на основе ленты, поддерживающая все дифференцируемые операции с тензорами в torch |
| <a href="https://pytorch.org/docs/stable/jit.html" target="_blank" rel="noopener noreferrer"><strong>torch.jit</strong></a> | Стек компиляции (TorchScript) для создания сериализуемых и оптимизируемых моделей из кода PyTorch |
| <a href="https://pytorch.org/docs/stable/nn.html" target="_blank" rel="noopener noreferrer"><strong>torch.nn</strong></a> | Библиотека нейронных сетей, глубоко интегрированная с autograd, обеспечивающая максимальную гибкость |
| <a href="https://pytorch.org/docs/stable/multiprocessing.html" target="_blank" rel="noopener noreferrer"><strong>torch.multiprocessing</strong></a> | Многопроцессорность Python, но с магическим совместным использованием памяти тензоров между процессами. Полезно для загрузки данных и обучения методом Hogwild |
| <a href="https://pytorch.org/docs/stable/data.html" target="_blank" rel="noopener noreferrer"><strong>torch.utils</strong></a> | DataLoader и другие вспомогательные функции для удобства |</p><p>Обычно PyTorch используется как:</p><ul><li>Замена NumPy для использования мощности GPU.</li>
<li>Платформа для исследований в области глубокого обучения, обеспечивающая максимальную гибкость и скорость.</li></p><p></ul>Подробнее:</p><h3>Тензорная библиотека с поддержкой GPU</h3></p><p>Если вы используете NumPy, то вы уже работали с тензорами (также известными как ndarray).</p><p><img src="./docs/source/_static/img/tensor_illustration.png" alt="Tensor illustration"></p><p>PyTorch предоставляет тензоры, которые могут находиться как на CPU, так и на GPU, и значительно ускоряет вычисления.</p><p>Мы предоставляем широкий спектр рутин для работы с тензорами, чтобы ускорить и адаптировать ваши научные вычисления: срезы, индексация, математические операции, линейная алгебра, редукции.
И всё это — быстро!</p><h3>Динамические нейронные сети: автодифференцирование на основе ленты</h3></p><p>В PyTorch реализован уникальный способ построения нейронных сетей: использование и воспроизведение "ленточного магнитофона".</p><p>Большинство фреймворков, таких как TensorFlow, Theano, Caffe и CNTK, имеют статичный взгляд на мир.
Необходимо построить нейронную сеть и многократно использовать одну и ту же структуру.
Изменение поведения сети требует полной перестройки с нуля.</p><p>В PyTorch используется техника обратного автоматического дифференцирования, которая позволяет изменять поведение вашей сети произвольно, без задержек и накладных расходов. Наше вдохновение пришло из нескольких научных публикаций по этой теме, а также из существующих и прошлых проектов, таких как
<a href="https://github.com/twitter/torch-autograd" target="_blank" rel="noopener noreferrer">torch-autograd</a>,
<a href="https://github.com/HIPS/autograd" target="_blank" rel="noopener noreferrer">autograd</a>,
<a href="https://chainer.org" target="_blank" rel="noopener noreferrer">Chainer</a> и др.</p><p>Хотя эта техника не уникальна для PyTorch, здесь реализована одна из самых быстрых её версий на сегодняшний день.
Вы получаете лучшее сочетание скорости и гибкости для своих исследований.</p><p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="Dynamic graph"></p><h3>Python — в первую очередь</h3></p><p>PyTorch — это не просто Python-обёртка вокруг монолитного C++ фреймворка.
Он создан для глубокой интеграции с Python.
Вы можете использовать его так же естественно, как <a href="https://www.numpy.org/" target="_blank" rel="noopener noreferrer">NumPy</a> / <a href="https://www.scipy.org/" target="_blank" rel="noopener noreferrer">SciPy</a> / <a href="https://scikit-learn.org" target="_blank" rel="noopener noreferrer">scikit-learn</a> и др.
Вы можете писать новые слои нейронных сетей непосредственно на Python, используя любимые библиотеки
и такие пакеты, как <a href="https://cython.org/" target="_blank" rel="noopener noreferrer">Cython</a> и <a href="http://numba.pydata.org/" target="_blank" rel="noopener noreferrer">Numba</a>.
Наша цель — не изобретать велосипед там, где это не требуется.</p><h3>Императивный опыт</h3></p><p>PyTorch создан для интуитивного, линейного и простого в использовании подхода.
Когда вы выполняете строку кода, она действительно выполняется. Нет асинхронного представления мира.
Когда вы используете отладчик или получаете сообщения об ошибках и трассировки стека, их легко понять.
Трассировка указывает на то место, где был определён ваш код.
Мы надеемся, что вы никогда не потратите часы на отладку из-за плохих трассировок или асинхронных и непрозрачных движков выполнения.</p><h3>Быстрый и компактный</h3></p><p>PyTorch имеет минимальные накладные расходы фреймворка. Мы интегрируем библиотеки ускорения
такие как <a href="https://software.intel.com/mkl" target="_blank" rel="noopener noreferrer">Intel MKL</a> и NVIDIA (<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">cuDNN</a>, <a href="https://developer.nvidia.com/nccl" target="_blank" rel="noopener noreferrer">NCCL</a>), чтобы максимизировать скорость.
В основе лежат зрелые и проверенные временем бэкенды для тензоров и нейронных сетей на CPU и GPU.</p><p>Поэтому PyTorch очень быстр — независимо от размера вашей нейронной сети.</p><p>Использование памяти в PyTorch чрезвычайно эффективно по сравнению с Torch или некоторыми альтернативами.
Мы написали собственные распределители памяти для GPU, чтобы ваши модели глубокого обучения были максимально эффективны по памяти.
Это позволяет обучать более крупные модели, чем раньше.</p><h3>Расширения без боли</h3></p><p>Создание новых модулей нейронных сетей или интеграция с API тензоров PyTorch были разработаны максимально простыми и с минимальным уровнем абстракции.</p><p>Вы можете писать новые слои нейронных сетей на Python, используя API torch
<a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html" target="_blank" rel="noopener noreferrer">или ваши любимые библиотеки на базе NumPy, такие как SciPy</a>.</p><p>Если вы хотите писать свои слои на C/C++, мы предоставляем удобный API расширений, который эффективен и требует минимума шаблонного кода.
Не нужно писать обёртки. См. <a href="https://pytorch.org/tutorials/advanced/cpp_extension.html" target="_blank" rel="noopener noreferrer">учебник здесь</a> и <a href="https://github.com/pytorch/extension-cpp" target="_blank" rel="noopener noreferrer">пример здесь</a>.</p><h2>Установка</h2></p><h3>Бинарные файлы</h3>
Команды для установки бинарных файлов через Conda или pip wheels представлены на нашем сайте: <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">https://pytorch.org/get-started/locally/</a></p><p>
#### Платформы NVIDIA Jetson</p><p>Python-колёса для NVIDIA Jetson Nano, Jetson TX1/TX2, Jetson Xavier NX/AGX и Jetson AGX Orin доступны <a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048" target="_blank" rel="noopener noreferrer">здесь</a>, а контейнер L4T опубликован <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch" target="_blank" rel="noopener noreferrer">здесь</a></p><p>Требуется JetPack 4.2 и выше, поддержкой занимаются <a href="https://github.com/dusty-nv" target="_blank" rel="noopener noreferrer">@dusty-nv</a> и <a href="https://github.com/ptrblck" target="_blank" rel="noopener noreferrer">@ptrblck</a>.</p><h3>Сборка из исходников</h3></p><p>#### Необходимые компоненты
Если вы собираете из исходников, вам понадобится:
<ul><li>Python 3.9 или новее</li>
<li>Компилятор с полной поддержкой C++17, например clang или gcc (требуется gcc 9.4.0 или новее для Linux)</li>
<li>Visual Studio или Visual Studio Build Tool (только для Windows)</li></p><p></ul>\* PyTorch CI использует Visual C++ BuildTools, которые идут в составе Visual Studio Enterprise,
Professional или Community Editions. Вы также можете установить build tools с
https://visualstudio.microsoft.com/visual-cpp-build-tools/. Build tools <em>не входят</em>
в Visual Studio Code по умолчанию.</p><p>Пример настройки окружения:</p><ul><li>Linux:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>/bin/activate
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME></code></pre></p><ul><li>Windows:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>\Scripts\activate.bat
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME>
$ call "C:\Program Files\Microsoft Visual Studio\<VERSION>\Community\VC\Auxiliary\Build\vcvarsall.bat" x64</code></pre></p><p>##### Поддержка NVIDIA CUDA
Если вы хотите компилировать с поддержкой CUDA, <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">выберите поддерживаемую версию CUDA из нашей матрицы поддержки</a>, затем установите следующее:
<ul><li><a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener noreferrer">NVIDIA CUDA</a></li>
<li><a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">NVIDIA cuDNN</a> v8.5 или выше</li>
<li><a href="https://gist.github.com/ax3l/9489132" target="_blank" rel="noopener noreferrer">Компилятор</a>, совместимый с CUDA</li></p><p></ul>Примечание: Вы можете обратиться к <a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html" target="_blank" rel="noopener noreferrer">cuDNN Support Matrix</a> для сопоставления версий cuDNN, CUDA, драйверов и оборудования NVIDIA</p><p>Если вы хотите отключить поддержку CUDA, экспортируйте переменную окружения <code>USE_CUDA=0</code>.
Другие полезные переменные окружения можно найти в <code>setup.py</code>.</p><p>Если вы собираете для платформ NVIDIA Jetson (Jetson Nano, TX1, TX2, AGX Xavier), инструкция по установке PyTorch для Jetson Nano <a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/" target="_blank" rel="noopener noreferrer">доступна здесь</a></p><p>##### Поддержка AMD ROCm
Если вы хотите компилировать с поддержкой ROCm, установите
<ul><li><a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html" target="_blank" rel="noopener noreferrer">AMD ROCm</a> 4.0 и выше</li>
<li>ROCm поддерживается только в Linux.</li></p><p></ul>По умолчанию build system ожидает, что ROCm установлен в <code>/opt/rocm</code>. Если ROCm установлен в другом каталоге, переменная окружения <code>ROCM_PATH</code> должна указывать на каталог установки ROCm. Build system автоматически определяет архитектуру AMD GPU. Опционально, архитектуру AMD GPU можно явно указать через переменную окружения <code>PYTORCH_ROCM_ARCH</code> <a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus" target="_blank" rel="noopener noreferrer">AMD GPU architecture</a></p><p>Если вы хотите отключить поддержку ROCm, экспортируйте переменную окружения <code>USE_ROCM=0</code>.
Другие полезные переменные окружения можно найти в <code>setup.py</code>.</p><p>##### Поддержка Intel GPU
Если вы хотите компилировать с поддержкой Intel GPU, выполните следующие шаги:
<ul><li>Следуйте инструкции <a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html" target="_blank" rel="noopener noreferrer">PyTorch Prerequisites for Intel GPUs</a>.</li>
<li>Intel GPU поддерживается для Linux и Windows.</li></p><p></ul>Если вы хотите отключить поддержку Intel GPU, экспортируйте переменную окружения <code>USE_XPU=0</code>.
Другие полезные переменные окружения можно найти в <code>setup.py</code>.</p><p>#### Получение исходников PyTorch
<pre><code class="language-bash">git clone https://github.com/pytorch/pytorch
cd pytorch
<h1>если вы обновляете существующий репозиторий</h1>
git submodule sync
git submodule update --init --recursive</code></pre></p><p>#### Установка зависимостей</p><p><strong>Общие</strong></p><pre><code class="language-bash">conda install cmake ninja
<h1>Запустите эту команду из каталога PyTorch после клонирования исходного кода, как указано выше</h1>
pip install -r requirements.txt</code></pre></p><p><strong>В Linux</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>Только для CUDA: Добавьте поддержку LAPACK для GPU при необходимости</h1>
<h1>Установка magma: выполните в активированной среде conda, укажите версию CUDA</h1>
.ci/docker/common/install_magma_conda.sh 12.4</p><h1>(опционально) Если используется torch.compile с inductor/triton, установите подходящую версию triton</h1>
<h1>Запустите из каталога pytorch после клонирования</h1>
<h1>Для поддержки Intel GPU, явно выполните <code>export USE_XPU=1</code> перед запуском команды.</h1>
make triton</code></pre></p><p><strong>В MacOS</strong></p><pre><code class="language-bash"># Добавьте этот пакет только на машинах с процессором intel x86
pip install mkl-static mkl-include
<h1>Добавьте эти пакеты, если требуется torch.distributed</h1>
conda install pkg-config libuv</code></pre></p><p><strong>В Windows</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>Добавьте эти пакеты, если требуется torch.distributed.</h1>
<h1>Поддержка distributed пакета в Windows является экспериментальной и может изменяться.</h1>
conda install -c conda-forge libuv=1.39</code></pre></p><p>#### Установка PyTorch
<strong>В Linux</strong></p><p>Если вы компилируете для AMD ROCm, сначала выполните эту команду:
<pre><code class="language-bash"># Выполняйте только если собираете для ROCm
python tools/amd_build/build_amd.py</code></pre></p><p>Установите PyTorch
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py develop</code></pre></p><p><strong>В macOS</strong></p><pre><code class="language-bash">python3 setup.py develop</code></pre></p><p><strong>В Windows</strong></p><p>Если вы хотите собрать устаревший python-код, пожалуйста, обратитесь к <a href="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda" target="_blank" rel="noopener noreferrer">Building on legacy code and CUDA</a></p><p><strong>Сборки только для CPU</strong></p><p>В этом режиме вычисления PyTorch будут выполняться на CPU, а не на GPU.</p><pre><code class="language-cmd">python setup.py develop</code></pre></p><p>Примечание по OpenMP: Предпочтительная реализация OpenMP — Intel OpenMP (iomp). Чтобы подключить iomp, вам потребуется вручную скачать библиотеку и настроить окружение для сборки через переменные <code>CMAKE_INCLUDE_PATH</code> и <code>LIB</code>. Инструкция <a href="https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source" target="_blank" rel="noopener noreferrer">здесь</a> является примером настройки MKL и Intel OpenMP. Без этих настроек для CMake будет использоваться Microsoft Visual C OpenMP runtime (vcomp).</p><p><strong>Сборка с поддержкой CUDA</strong></p><p>В этом режиме вычисления PyTorch будут использовать ваш GPU через CUDA для ускорения вычислений.</p><p>Для сборки PyTorch с CUDA требуется <a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm" target="_blank" rel="noopener noreferrer">NVTX</a>.
NVTX входит в состав CUDA и называется "Nsight Compute". Чтобы установить его в уже установленную CUDA, выполните повторную установку CUDA и отметьте нужный пункт.
Убедитесь, что CUDA с Nsight Compute установлена после Visual Studio.</p><p>В настоящее время поддерживаются VS 2017 / 2019 и Ninja как генераторы CMake. Если <code>ninja.exe</code> найден в <code>PATH</code>, то Ninja будет использоваться по умолчанию, иначе — VS 2017 / 2019.
<br/> Если выбран Ninja, будет использоваться последняя версия MSVC как инструментальная цепочка.</p><p>Часто требуются дополнительные библиотеки:
<a href="https://developer.nvidia.com/magma" target="_blank" rel="noopener noreferrer">Magma</a>, <a href="https://github.com/oneapi-src/oneDNN" target="_blank" rel="noopener noreferrer">oneDNN, также известная как MKLDNN или DNNL</a>, и <a href="https://github.com/mozilla/sccache" target="_blank" rel="noopener noreferrer">Sccache</a>. См. <a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers" target="_blank" rel="noopener noreferrer">installation-helper</a> для их установки.</p><p>Вы можете также обратиться к скрипту <a href="https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat" target="_blank" rel="noopener noreferrer">build_pytorch.bat</a> для настройки других переменных окружения</p><pre><code class="language-cmd">cmd</p><p>:: Установите переменные окружения после загрузки и распаковки пакета mkl,
:: иначе CMake выдаст ошибку <code>Could NOT find OpenMP</code>.
set CMAKE_INCLUDE_PATH={Ваш каталог}\mkl\include
set LIB={Ваш каталог}\mkl\lib;%LIB%</p><p>:: Внимательно прочитайте предыдущий раздел перед продолжением.
:: [Опционально] Если хотите переопределить инструментальную цепочку Ninja и Visual Studio с CUDA, выполните следующий скрипт.
:: "Visual Studio 2019 Developer Command Prompt" будет запущен автоматически.
:: Убедитесь, что у вас установлена CMake >= 3.12 при использовании генератора Visual Studio.
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f "usebackq tokens=<em>" %i in (<code>"%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe" -version [15^,17^) -products </em> -latest -property installationPath</code>) do call "%i\VC\Auxiliary\Build\vcvarsall.bat" x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%</p><p>:: [Опционально] Если хотите переопределить компилятор-хост CUDA
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe</p><p>python setup.py develop
</code></pre></p><p><strong>Сборка для Intel GPU</strong></p><p>В этом режиме будет собран PyTorch с поддержкой Intel GPU.</p><p>Убедитесь, что <a href="#prerequisites" target="_blank" rel="noopener noreferrer">общие требования</a>, а также <a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">требования для Intel GPU</a> установлены и переменные окружения настроены. Для сборки требуется <code>Visual Studio 2022</code>.</p><p>Затем PyTorch можно собрать командой:</p><pre><code class="language-cmd">:: Команды CMD:
:: Установите CMAKE_PREFIX_PATH для поиска соответствующих пакетов
:: %CONDA_PREFIX% работает только после <code>conda activate custom_env</code></p><p>if defined CMAKE_PREFIX_PATH (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%"
) else (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library"
)</p><p>python setup.py develop</code></pre></p><p>##### Настройка параметров сборки (опционально)</p><p>Вы можете опционально настроить переменные cmake (без сборки), выполнив следующее. Например, можно настроить пути к каталогам CuDNN или BLAS.</p><p>В Linux
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py build --cmake-only
ccmake build  # или cmake-gui build</code></pre></p><p>В macOS
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only
ccmake build  # или cmake-gui build</code></pre></p><h3>Образы Docker</h3></p><p>#### Использование готовых образов</p><p>Вы также можете скачать готовый docker-образ из Docker Hub и запустить с docker v19.03+</p><pre><code class="language-bash">docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest</code></pre></p><p>Обратите внимание, что PyTorch использует общую память для передачи данных между процессами, поэтому если используется torch multiprocessing (например, для многопоточной загрузки данных), размер сегмента общей памяти по умолчанию в контейнере недостаточен, и его следует увеличить с помощью параметров <code>--ipc=host</code> или <code>--shm-size</code> в командной строке для <code>nvidia-docker run</code>.</p><p>#### Сборка образа самостоятельно</p><p><strong>ПРИМЕЧАНИЕ:</strong> Требуется версия docker > 18.06</p><p><code>Dockerfile</code> предоставлен для сборки образов с поддержкой CUDA 11.1 и cuDNN v8.
Вы можете передать переменную сборки <code>PYTHON_VERSION=x.y</code>, чтобы указать, какую версию Python использовать в Miniconda, либо не указывать и использовать версию по умолчанию.</p><pre><code class="language-bash">make -f docker.Makefile
<h1>образы маркируются как docker.io/${your_docker_username}/pytorch</code></pre></h1></p><p>Вы также можете передать переменную среды <code>CMAKE_VARS="..."</code> для указания дополнительных переменных CMake, которые будут переданы во время сборки.
См. <a href="./setup.py" target="_blank" rel="noopener noreferrer">setup.py</a> для списка доступных переменных.</p><pre><code class="language-bash">make -f docker.Makefile</code></pre></p><h3>Сборка документации</h3></p><p>Для сборки документации в различных форматах потребуется <a href="http://www.sphinx-doc.org" target="_blank" rel="noopener noreferrer">Sphinx</a>
и pytorch_sphinx_theme2.</p><p>Перед локальной сборкой документации убедитесь, что <code>torch</code> установлен в вашем окружении. Для мелких правок можно установить ночную версию, как описано в <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">Getting Started</a>.</p><p>Для более сложных изменений, например, добавления нового модуля и docstring для него, возможно, потребуется установить torch <a href="#from-source" target="_blank" rel="noopener noreferrer">из исходников</a>.
См. <a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines" target="_blank" rel="noopener noreferrer">Docstring Guidelines</a>
для стандартов docstring.</p><pre><code class="language-bash">cd docs/
pip install -r requirements.txt
make html
make serve</code></pre></p><p>Выполните <code>make</code>, чтобы получить список всех доступных форматов вывода.</p><p>Если появляется ошибка katex, выполните <code>npm install katex</code>.  Если не помогает, попробуйте
<code>npm install -g katex</code></p><blockquote>[!ПРИМЕЧАНИЕ]</blockquote>
<blockquote>Если вы устанавливали <code>nodejs</code> с помощью другого пакетного менеджера (например,</blockquote>
<blockquote><code>conda</code>), то <code>npm</code>, скорее всего, установит версию <code>katex</code>, несовместимую с вашей версией <code>nodejs</code>, и сборка документации завершится с ошибкой.</blockquote>
<blockquote>Известно, что работает комбинация <code>node@6.13.1</code> и</blockquote>
<blockquote><code>katex@0.13.18</code>. Для установки последнего выполните:</blockquote>
<blockquote>``<code>npm install -g katex@0.13.18<pre><code class="language-"></blockquote>
<blockquote>[!ПРИМЕЧАНИЕ]</blockquote>
<blockquote>Если появляется ошибка несовместимости numpy, выполните:</blockquote>
<blockquote></code>`<code></blockquote>
<blockquote>pip install 'numpy<2'</blockquote>
<blockquote></code>`<code></blockquote></p><p>При изменении зависимостей, используемых в CI, редактируйте
файл </code>.ci/docker/requirements-docs.txt<code>.</p><p>#### Создание PDF</p><p>Для компиляции PDF со всей документацией PyTorch убедитесь, что у вас установлены
</code>texlive<code> и LaTeX. В macOS можно установить их с помощью:
</code></pre>
brew install --cask mactex
</code>`<code></p><p>Для создания PDF:</p><ul><li>Выполните:</li></p><p>   </ul></code>`<code>
   make latexpdf
   </code>`<code></p><p>   Это сгенерирует необходимые файлы в каталоге </code>build/latex<code>.</p><ul><li>Перейдите в этот каталог и выполните:</li></p><p>   </ul></code>`<code>
   make LATEXOPTS="-interaction=nonstopmode"
   </code>`<code></p><p>   Это создаст файл </code>pytorch.pdf` с нужным содержанием. Выполните команду ещё раз, чтобы сгенерировать корректное оглавление и индекс.</p><blockquote>[!ПРИМЕЧАНИЕ]</blockquote>
<blockquote>Для просмотра оглавления переключитесь в режим <strong>Table of Contents</strong></blockquote>
<blockquote>в вашей PDF-читалке.</blockquote></p><h3>Предыдущие версии</h3></p><p>Инструкции по установке и бинарные файлы для предыдущих версий PyTorch доступны
<a href="https://pytorch.org/get-started/previous-versions" target="_blank" rel="noopener noreferrer">на нашем сайте</a>.</p><h2>Начало работы</h2></p><p>Три ссылки для быстрого старта:
<ul><li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">Учебники: начните с изучения и использования PyTorch</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">Примеры: простой и понятный код PyTorch для всех областей</a></li>
<li><a href="https://pytorch.org/docs/" target="_blank" rel="noopener noreferrer">API Reference</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md" target="_blank" rel="noopener noreferrer">Глоссарий</a></li></p><p></ul><h2>Ресурсы</h2></p><ul><li><a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">PyTorch.org</a></li>
<li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">Учебники PyTorch</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">Примеры PyTorch</a></li>
<li><a href="https://pytorch.org/hub/" target="_blank" rel="noopener noreferrer">Модели PyTorch</a></li>
<li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188" target="_blank" rel="noopener noreferrer">Введение в глубокое обучение с PyTorch от Udacity</a></li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229" target="_blank" rel="noopener noreferrer">Введение в машинное обучение с PyTorch от Udacity</a></li>
<li><a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch" target="_blank" rel="noopener noreferrer">Глубокие нейронные сети с PyTorch на Coursera</a></li>
<li><a href="https://twitter.com/PyTorch" target="_blank" rel="noopener noreferrer">PyTorch Twitter</a></li>
<li><a href="https://pytorch.org/blog/" target="_blank" rel="noopener noreferrer">PyTorch Blog</a></li>
<li><a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw" target="_blank" rel="noopener noreferrer">PyTorch YouTube</a></li></p><p></ul><h2>Коммуникация</h2>
<ul><li>Форумы: обсуждение реализаций, исследований и др. https://discuss.pytorch.org</li>
<li>GitHub Issues: сообщения об ошибках, запросы новых функций, проблемы с установкой, RFC, идеи и др.</li>
<li>Slack: <a href="https://pytorch.slack.com/" target="_blank" rel="noopener noreferrer">PyTorch Slack</a> предназначен для опытных пользователей и разработчиков PyTorch для общего чата, обсуждений, коллабораций и т.д. Новичкам рекомендуется <a href="https://discuss.pytorch.org" target="_blank" rel="noopener noreferrer">форум PyTorch</a>. Для приглашения в Slack заполните форму: https://goo.gl/forms/PP1AGvNHpSaJP8to1</li>
<li>Рассылка: только важные объявления о PyTorch, без спама. Подписаться можно здесь: https://eepurl.com/cbG0rv</li>
<li>Страница в Facebook: важные объявления о PyTorch. https://www.facebook.com/pytorch</li>
<li>Для ознакомления с руководством по бренду посетите наш сайт <a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">pytorch.org</a></li></p><p></ul><h2>Выпуски и вклад</h2></p><p>Обычно PyTorch выпускает три минорные версии в год. Если вы обнаружили ошибку, пожалуйста, <a href="https://github.com/pytorch/pytorch/issues" target="_blank" rel="noopener noreferrer">создайте issue</a>.</p><p>Мы ценим любой вклад. Если вы планируете внести исправления ошибок, делайте это без предварительного обсуждения.</p><p>Если вы планируете добавить новые функции, утилиты или расширения ядра, сначала откройте issue и обсудите с нами вашу идею.
Отправка PR без обсуждения может привести к его отклонению, если ваша идея не соответствует текущему направлению развития ядра.</p><p>Подробнее о том, как внести вклад в PyTorch, см. <a href="CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">Contribution page</a>. Подробнее о выпусках PyTorch — на <a href="RELEASE.md" target="_blank" rel="noopener noreferrer">Release page</a>.</p><h2>Команда</h2></p><p>PyTorch — проект, развиваемый сообществом, в который вносят вклад множество инженеров и исследователей.</p><p>В настоящее время PyTorch поддерживается <a href="http://soumith.ch" target="_blank" rel="noopener noreferrer">Soumith Chintala</a>, <a href="https://github.com/gchanan" target="_blank" rel="noopener noreferrer">Gregory Chanan</a>, <a href="https://github.com/dzhulgakov" target="_blank" rel="noopener noreferrer">Dmytro Dzhulgakov</a>, <a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a> и <a href="https://github.com/malfet" target="_blank" rel="noopener noreferrer">Nikita Shulga</a>, а также сотнями талантливых людей в различных формах и проявлениях.
В числе многих стоит отметить: <a href="https://github.com/killeent" target="_blank" rel="noopener noreferrer">Trevor Killeen</a>, <a href="https://github.com/chsasank" target="_blank" rel="noopener noreferrer">Sasank Chilamkurthy</a>, <a href="https://github.com/szagoruyko" target="_blank" rel="noopener noreferrer">Sergey Zagoruyko</a>, <a href="https://github.com/adamlerer" target="_blank" rel="noopener noreferrer">Adam Lerer</a>, <a href="https://github.com/fmassa" target="_blank" rel="noopener noreferrer">Francisco Massa</a>, <a href="https://github.com/alykhantejani" target="_blank" rel="noopener noreferrer">Alykhan Tejani</a>, <a href="https://github.com/lantiga" target="_blank" rel="noopener noreferrer">Luca Antiga</a>, <a href="https://github.com/albanD" target="_blank" rel="noopener noreferrer">Alban Desmaison</a>, <a href="https://github.com/andreaskoepf" target="_blank" rel="noopener noreferrer">Andreas Koepf</a>, <a href="https://github.com/jekbradbury" target="_blank" rel="noopener noreferrer">James Bradbury</a>, <a href="https://github.com/ebetica" target="_blank" rel="noopener noreferrer">Zeming Lin</a>, <a href="https://github.com/yuandong-tian" target="_blank" rel="noopener noreferrer">Yuandong Tian</a>, <a href="https://github.com/glample" target="_blank" rel="noopener noreferrer">Guillaume Lample</a>, <a href="https://github.com/Maratyszcza" target="_blank" rel="noopener noreferrer">Marat Dukhan</a>, <a href="https://github.com/ngimel" target="_blank" rel="noopener noreferrer">Natalia Gimelshein</a>, <a href="https://github.com/csarofeen" target="_blank" rel="noopener noreferrer">Christian Sarofeen</a>, <a href="https://github.com/martinraison" target="_blank" rel="noopener noreferrer">Martin Raison</a>, <a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a>, <a href="https://github.com/zdevito" target="_blank" rel="noopener noreferrer">Zachary Devito</a>.</p><p>Примечание: этот проект не связан с <a href="https://github.com/hughperkins/pytorch" target="_blank" rel="noopener noreferrer">hughperkins/pytorch</a> с тем же именем. Хью — ценный участник сообщества Torch и помогал во многих вещах, связанных с Torch и PyTorch.</p><h2>Лицензия</h2></p><p>PyTorch распространяется по лицензии BSD, как указано в файле <a href="LICENSE" target="_blank" rel="noopener noreferrer">LICENSE</a>.

---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/pytorch/pytorch/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>