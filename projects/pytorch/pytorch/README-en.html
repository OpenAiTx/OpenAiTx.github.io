<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch - Read pytorch documentation in English. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read pytorch documentation in English. This project has 0 stars on GitHub.">
    <meta name="keywords" content="pytorch, English, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "pytorch",
  "description": "Read pytorch documentation in English. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "pytorch"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/pytorch/pytorch/README-en.html",
  "sameAs": "https://raw.githubusercontent.com/pytorch/pytorch/master/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/pytorch/pytorch" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    pytorch
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">English</span>
                <span>by pytorch</span>
            </div>
        </div>
        
        <div class="content">
            <p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/pytorch-logo-dark.png" alt="PyTorch Logo"></p><p>--------------------------------------------------------------------------------</p><p>PyTorch 是一个 Python 包，提供了两个高级特性：
<ul><li>张量计算（类似于 NumPy），并具备强大的 GPU 加速能力</li>
<li>基于 tape 的自动微分系统构建的深度神经网络</li></p><p></ul>你可以复用你喜欢的 Python 包（如 NumPy、SciPy 和 Cython）在需要时扩展 PyTorch。</p><p>我们的主干健康状况（持续集成信号）可在 <a href="https://hud.pytorch.org/ci/pytorch/pytorch/main" target="_blank" rel="noopener noreferrer">hud.pytorch.org</a> 查看。</p><p><!-- toc --></p><ul><li><a href="#more-about-pytorch" target="_blank" rel="noopener noreferrer">更多关于 PyTorch</a></li>
  <li><a href="#a-gpu-ready-tensor-library" target="_blank" rel="noopener noreferrer">GPU 就绪的张量库</a></li>
  <li><a href="#dynamic-neural-networks-tape-based-autograd" target="_blank" rel="noopener noreferrer">动态图神经网络：基于 tape 的自动微分</a></li>
  <li><a href="#python-first" target="_blank" rel="noopener noreferrer">Python 优先</a></li>
  <li><a href="#imperative-experiences" target="_blank" rel="noopener noreferrer">命令式体验</a></li>
  <li><a href="#fast-and-lean" target="_blank" rel="noopener noreferrer">快速且精简</a></li>
  <li><a href="#extensions-without-pain" target="_blank" rel="noopener noreferrer">无痛扩展</a></li>
<li><a href="#installation" target="_blank" rel="noopener noreferrer">安装</a></li>
  <li><a href="#binaries" target="_blank" rel="noopener noreferrer">二进制包</a></li>
    <li><a href="#nvidia-jetson-platforms" target="_blank" rel="noopener noreferrer">NVIDIA Jetson 平台</a></li>
  <li><a href="#from-source" target="_blank" rel="noopener noreferrer">源码编译</a></li>
    <li><a href="#prerequisites" target="_blank" rel="noopener noreferrer">先决条件</a></li>
      <li><a href="#nvidia-cuda-support" target="_blank" rel="noopener noreferrer">NVIDIA CUDA 支持</a></li>
      <li><a href="#amd-rocm-support" target="_blank" rel="noopener noreferrer">AMD ROCm 支持</a></li>
      <li><a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">Intel GPU 支持</a></li>
    <li><a href="#get-the-pytorch-source" target="_blank" rel="noopener noreferrer">获取 PyTorch 源码</a></li>
    <li><a href="#install-dependencies" target="_blank" rel="noopener noreferrer">安装依赖</a></li>
    <li><a href="#install-pytorch" target="_blank" rel="noopener noreferrer">安装 PyTorch</a></li>
      <li><a href="#adjust-build-options-optional" target="_blank" rel="noopener noreferrer">调整构建选项（可选）</a></li>
  <li><a href="#docker-image" target="_blank" rel="noopener noreferrer">Docker 镜像</a></li>
    <li><a href="#using-pre-built-images" target="_blank" rel="noopener noreferrer">使用预构建镜像</a></li>
    <li><a href="#building-the-image-yourself" target="_blank" rel="noopener noreferrer">自行构建镜像</a></li>
  <li><a href="#building-the-documentation" target="_blank" rel="noopener noreferrer">构建文档</a></li>
    <li><a href="#building-a-pdf" target="_blank" rel="noopener noreferrer">构建 PDF</a></li>
  <li><a href="#previous-versions" target="_blank" rel="noopener noreferrer">历史版本</a></li>
<li><a href="#getting-started" target="_blank" rel="noopener noreferrer">快速入门</a></li>
<li><a href="#resources" target="_blank" rel="noopener noreferrer">资源</a></li>
<li><a href="#communication" target="_blank" rel="noopener noreferrer">交流</a></li>
<li><a href="#releases-and-contributing" target="_blank" rel="noopener noreferrer">版本与贡献</a></li>
<li><a href="#the-team" target="_blank" rel="noopener noreferrer">团队</a></li>
<li><a href="#license" target="_blank" rel="noopener noreferrer">许可证</a></li></p><p></ul><!-- tocstop --></p><h2>更多关于 PyTorch</h2></p><p><a href="https://pytorch.org/tutorials/beginner/basics/intro.html" target="_blank" rel="noopener noreferrer">学习 PyTorch 基础知识</a></p><p>在细粒度层面，PyTorch 是一个包含以下组件的库：</p><p>| 组件 | 描述 |
| ---- | --- |
| <a href="https://pytorch.org/docs/stable/torch.html" target="_blank" rel="noopener noreferrer"><strong>torch</strong></a> | 类似于 NumPy 的张量库，具备强大的 GPU 支持 |
| <a href="https://pytorch.org/docs/stable/autograd.html" target="_blank" rel="noopener noreferrer"><strong>torch.autograd</strong></a> | 基于 tape 的自动微分库，支持 torch 中所有可微分的张量操作 |
| <a href="https://pytorch.org/docs/stable/jit.html" target="_blank" rel="noopener noreferrer"><strong>torch.jit</strong></a> | 编译栈（TorchScript），可将 PyTorch 代码生成可序列化和可优化的模型 |
| <a href="https://pytorch.org/docs/stable/nn.html" target="_blank" rel="noopener noreferrer"><strong>torch.nn</strong></a> | 与 autograd 深度集成的神经网络库，设计极为灵活 |
| <a href="https://pytorch.org/docs/stable/multiprocessing.html" target="_blank" rel="noopener noreferrer"><strong>torch.multiprocessing</strong></a> | Python 多进程，但可实现进程间 torch 张量的内存共享。适用于数据加载和 Hogwild 训练 |
| <a href="https://pytorch.org/docs/stable/data.html" target="_blank" rel="noopener noreferrer"><strong>torch.utils</strong></a> | DataLoader 及其他便捷的工具函数 |</p><p>通常，PyTorch 可用作：</p><ul><li>NumPy 的替代品，以利用 GPU 的强大算力。</li>
<li>提供极致灵活性与速度的深度学习研究平台。</li></p><p></ul>进一步说明：</p><h3>GPU 就绪的张量库</h3></p><p>如果你用过 NumPy，你就用过张量（即 ndarray）。</p><p><img src="./docs/source/_static/img/tensor_illustration.png" alt="张量示意图"></p><p>PyTorch 提供的张量可以驻留在 CPU 或 GPU 上，并极大加速计算。</p><p>我们提供了丰富的张量操作例程，以加速并满足你的科学计算需求，
如切片、索引、数学运算、线性代数、归约等。
而且它们都非常快！</p><h3>动态图神经网络：基于 tape 的自动微分</h3></p><p>PyTorch 构建神经网络有一种独特方式：使用并重放一个“录音带”。</p><p>大多数框架如 TensorFlow、Theano、Caffe 和 CNTK 都采用静态方式。
你必须先构建一个神经网络结构，然后反复使用同一个结构。
如果想改变网络行为，就必须从头再来。</p><p>而在 PyTorch 中，我们使用了一种称为反向模式自动微分的技术，它允许你
随意更改网络行为，且零延迟、零开销。我们的灵感来自多篇相关研究论文，以及
<a href="https://github.com/twitter/torch-autograd" target="_blank" rel="noopener noreferrer">torch-autograd</a>、
<a href="https://github.com/HIPS/autograd" target="_blank" rel="noopener noreferrer">autograd</a>、
<a href="https://chainer.org" target="_blank" rel="noopener noreferrer">Chainer</a> 等当前及以往的相关工作。</p><p>尽管这种技术并非 PyTorch 独有，但我们拥有目前最快的实现之一。
你可以同时获得极致的速度与灵活性，助力你的前沿研究。</p><p><img src="https://github.com/pytorch/pytorch/raw/main/docs/source/_static/img/dynamic_graph.gif" alt="动态图"></p><h3>Python 优先</h3></p><p>PyTorch 并不是一个巨大的 C++ 框架的 Python 绑定。
它被设计为深度集成于 Python。
你可以像使用 <a href="https://www.numpy.org/" target="_blank" rel="noopener noreferrer">NumPy</a> / <a href="https://www.scipy.org/" target="_blank" rel="noopener noreferrer">SciPy</a> / <a href="https://scikit-learn.org" target="_blank" rel="noopener noreferrer">scikit-learn</a> 那样自然地使用它。
你可以用自己喜欢的库在 Python 中编写新的神经网络层，
并借助 <a href="https://cython.org/" target="_blank" rel="noopener noreferrer">Cython</a> 和 <a href="http://numba.pydata.org/" target="_blank" rel="noopener noreferrer">Numba</a> 等工具包。
我们的目标是在合适的地方不重复造轮子。</p><h3>命令式体验</h3></p><p>PyTorch 设计直观、逻辑线性、易于使用。
你写一行代码，就会立刻执行。没有异步世界的概念。
调试或遇到错误时，堆栈跟踪清晰指向代码定义位置。
我们希望你不必因为糟糕的堆栈跟踪或异步、晦涩的执行引擎而花费数小时调试代码。</p><h3>快速且精简</h3></p><p>PyTorch 框架开销极小。我们集成了
<a href="https://software.intel.com/mkl" target="_blank" rel="noopener noreferrer">Intel MKL</a> 以及 NVIDIA（<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">cuDNN</a>、<a href="https://developer.nvidia.com/nccl" target="_blank" rel="noopener noreferrer">NCCL</a>）等加速库以提升速度。
底层的 CPU/GPU 张量与神经网络后端
成熟且历经多年测试。</p><p>因此，无论是小型还是大型神经网络，PyTorch 都非常快。</p><p>PyTorch 的内存使用极为高效，相较于 Torch 或其他替代品。
我们为 GPU 编写了自定义内存分配器，确保
你的深度学习模型具备极致内存效率。
这让你能训练比以往更大的深度学习模型。</p><h3>无痛扩展</h3></p><p>编写新的神经网络模块或对接 PyTorch 的张量 API 都非常直接，
且抽象最小。</p><p>你可以用 torch API 直接在 Python 中编写新神经网络层，
<a href="https://pytorch.org/tutorials/advanced/numpy_extensions_tutorial.html" target="_blank" rel="noopener noreferrer">或用你喜欢的基于 NumPy 的库（如 SciPy）</a>。</p><p>如果你想用 C/C++ 编写层，我们也提供高效且样板代码极少的扩展 API。
无需编写包装代码。你可以参考<a href="https://pytorch.org/tutorials/advanced/cpp_extension.html" target="_blank" rel="noopener noreferrer">此教程</a>及<a href="https://github.com/pytorch/extension-cpp" target="_blank" rel="noopener noreferrer">此示例</a>。</p><h2>安装</h2></p><h3>二进制包</h3>
通过 Conda 或 pip wheels 安装二进制包的命令请见我们的官网：<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">https://pytorch.org/get-started/locally/</a></p><p>#### NVIDIA Jetson 平台</p><p>NVIDIA Jetson Nano、Jetson TX1/TX2、Jetson Xavier NX/AGX 和 Jetson AGX Orin 的 Python wheel 包在<a href="https://forums.developer.nvidia.com/t/pytorch-for-jetson-version-1-10-now-available/72048" target="_blank" rel="noopener noreferrer">这里</a>提供，L4T 容器发布在<a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/l4t-pytorch" target="_blank" rel="noopener noreferrer">这里</a>。</p><p>它们需要 JetPack 4.2 及以上版本，<a href="https://github.com/dusty-nv" target="_blank" rel="noopener noreferrer"> @dusty-nv </a> 和 <a href="https://github.com/ptrblck" target="_blank" rel="noopener noreferrer"> @ptrblck </a> 负责维护。</p><h3>源码编译</h3></p><p>#### 先决条件
如果你打算源码安装，你需要：
<ul><li>Python 3.9 或更高版本</li>
<li>完全支持 C++17 的编译器，如 clang 或 gcc（Linux 上需 gcc 9.4.0 或更高版本）</li>
<li>Visual Studio 或 Visual Studio Build Tool（仅限 Windows）</li></p><p></ul>\<em> PyTorch CI 使用 Visual C++ BuildTools，可通过 Visual Studio Enterprise、Professional 或 Community 版本获得。也可从 https://visualstudio.microsoft.com/visual-cpp-build-tools/ 单独安装。</em>Visual Studio Code* 默认不包含这些构建工具。</p><p>环境设置示例：</p><ul><li>Linux:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>/bin/activate
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME></code></pre></p><ul><li>Windows:</li></p><p></ul><pre><code class="language-bash">$ source <CONDA_INSTALL_DIR>\Scripts\activate.bat
$ conda create -y -n <CONDA_NAME>
$ conda activate <CONDA_NAME>
$ call "C:\Program Files\Microsoft Visual Studio\<VERSION>\Community\VC\Auxiliary\Build\vcvarsall.bat" x64</code></pre></p><p>##### NVIDIA CUDA 支持
若需编译 CUDA 支持，请<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">从支持矩阵中选择支持的 CUDA 版本</a>，然后安装以下组件：
<ul><li><a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener noreferrer">NVIDIA CUDA</a></li>
<li><a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener noreferrer">NVIDIA cuDNN</a> v8.5 或更高</li>
<li><a href="https://gist.github.com/ax3l/9489132" target="_blank" rel="noopener noreferrer">兼容 CUDA 的编译器</a></li></p><p></ul>注意：可参考 <a href="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/reference/support-matrix.html" target="_blank" rel="noopener noreferrer">cuDNN 支持矩阵</a> 查看 cuDNN 与各 CUDA、驱动及硬件的兼容性。</p><p>若要禁用 CUDA 支持，导出环境变量 <code>USE_CUDA=0</code>。
更多有用的环境变量见 <code>setup.py</code>。</p><p>若为 NVIDIA Jetson 平台（Jetson Nano、TX1、TX2、AGX Xavier）编译，Jetson Nano 的安装说明见<a href="https://devtalk.nvidia.com/default/topic/1049071/jetson-nano/pytorch-for-jetson-nano/" target="_blank" rel="noopener noreferrer">此处</a>。</p><p>##### AMD ROCm 支持
若需编译 ROCm 支持，安装
<ul><li><a href="https://rocm.docs.amd.com/en/latest/deploy/linux/quick_start.html" target="_blank" rel="noopener noreferrer">AMD ROCm</a> 4.0 或更高</li>
<li>ROCm 目前仅支持 Linux 系统。</li></p><p></ul>默认情况下构建系统期望 ROCm 安装在 <code>/opt/rocm</code>。如在其他目录，请设定 <code>ROCM_PATH</code> 环境变量。构建系统会自动检测 AMD GPU 架构，也可用 <code>PYTORCH_ROCM_ARCH</code> 显式指定<a href="https://rocm.docs.amd.com/projects/install-on-linux/en/latest/reference/system-requirements.html#supported-gpus" target="_blank" rel="noopener noreferrer">AMD GPU 架构</a>。</p><p>若要禁用 ROCm 支持，导出环境变量 <code>USE_ROCM=0</code>。
更多有用的环境变量见 <code>setup.py</code>。</p><p>##### Intel GPU 支持
如需编译 Intel GPU 支持，请参考
<ul><li><a href="https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpus.html" target="_blank" rel="noopener noreferrer">Intel GPU 的 PyTorch 先决条件</a>。</li>
<li>Intel GPU 支持 Linux 和 Windows。</li></p><p></ul>若要禁用 Intel GPU 支持，导出环境变量 <code>USE_XPU=0</code>。
更多有用的环境变量见 <code>setup.py</code>。</p><p>#### 获取 PyTorch 源码
<pre><code class="language-bash">git clone https://github.com/pytorch/pytorch
cd pytorch
<h1>如需更新已克隆仓库</h1>
git submodule sync
git submodule update --init --recursive</code></pre></p><p>#### 安装依赖</p><p><strong>通用</strong></p><pre><code class="language-bash">conda install cmake ninja
<h1>克隆源码后，在 PyTorch 目录下运行</h1>
pip install -r requirements.txt</code></pre></p><p><strong>Linux 下</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>仅 CUDA：如需为 GPU 添加 LAPACK 支持</h1>
<h1>安装 magma：需激活 conda 环境并指定 CUDA 版本</h1>
.ci/docker/common/install_magma_conda.sh 12.4</p><h1>（可选）如使用 torch.compile 的 inductor/triton，需安装匹配 triton 版本</h1>
<h1>在 pytorch 目录下运行</h1>
<h1>对于 Intel GPU 支持，请在运行前显式 <code>export USE_XPU=1</code></h1>
make triton</code></pre></p><p><strong>MacOS 下</strong></p><pre><code class="language-bash"># 仅在 Intel x86 处理器机器添加此包
pip install mkl-static mkl-include
<h1>如需 torch.distributed，添加以下包</h1>
conda install pkg-config libuv</code></pre></p><p><strong>Windows 下</strong></p><pre><code class="language-bash">pip install mkl-static mkl-include
<h1>如需 torch.distributed，添加以下包</h1>
<h1>Windows 上分布式包支持为原型功能，可能有变动</h1>
conda install -c conda-forge libuv=1.39</code></pre></p><p>#### 安装 PyTorch
<strong>Linux 下</strong></p><p>如为 AMD ROCm 编译，先运行：
<pre><code class="language-bash"># 仅 ROCm 编译时运行
python tools/amd_build/build_amd.py</code></pre></p><p>安装 PyTorch
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py develop</code></pre></p><p><strong>macOS 下</strong></p><pre><code class="language-bash">python3 setup.py develop</code></pre></p><p><strong>Windows 下</strong></p><p>如需构建旧版 Python 代码，请参考<a href="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#building-on-legacy-code-and-cuda" target="_blank" rel="noopener noreferrer">旧代码和 CUDA 构建说明</a></p><p><strong>仅 CPU 构建</strong></p><p>此模式下，PyTorch 计算将仅在 CPU 上运行。</p><pre><code class="language-cmd">python setup.py develop</code></pre></p><p>OpenMP 说明：推荐使用 Intel OpenMP (iomp)。如需链接 iomp，需手动下载库并通过设置 <code>CMAKE_INCLUDE_PATH</code> 和 <code>LIB</code> 配置构建环境。详细说明可参考<a href="https://github.com/pytorch/pytorch/blob/main/docs/source/notes/windows.rst#building-from-source" target="_blank" rel="noopener noreferrer">此处</a>。如未做此配置，则会使用 Microsoft Visual C 的 OpenMP 运行时 (vcomp)。</p><p><strong>CUDA 构建</strong></p><p>此模式下，PyTorch 计算将通过 CUDA 利用 GPU 加速。</p><p>编译 PyTorch CUDA 需 <a href="https://docs.nvidia.com/gameworks/content/gameworkslibrary/nvtx/nvidia_tools_extension_library_nvtx.htm" target="_blank" rel="noopener noreferrer">NVTX</a>，
NVTX 属于 CUDA 套件（名称为 "Nsight Compute"）。如需安装到已装 CUDA 上，请重新运行安装程序并勾选相应选项。
确保在 Visual Studio 安装后再安装包含 Nsight Compute 的 CUDA。</p><p>当前支持 VS 2017/2019 及 Ninja 作为 CMake 生成器。如果 <code>PATH</code> 中检测到 <code>ninja.exe</code>，则默认使用 Ninja，否则用 VS 2017/2019。
<br/> 若选用 Ninja，底层工具链会选用最新 MSVC。</p><p>还常需安装
<a href="https://developer.nvidia.com/magma" target="_blank" rel="noopener noreferrer">Magma</a>、<a href="https://github.com/oneapi-src/oneDNN" target="_blank" rel="noopener noreferrer">oneDNN（又名 MKLDNN 或 DNNL）</a>、<a href="https://github.com/mozilla/sccache" target="_blank" rel="noopener noreferrer">Sccache</a> 等库。请参考<a href="https://github.com/pytorch/pytorch/tree/main/.ci/pytorch/win-test-helpers/installation-helpers" target="_blank" rel="noopener noreferrer">安装助手</a>。</p><p>更多环境变量设置可参考 <a href="https://github.com/pytorch/pytorch/blob/main/.ci/pytorch/win-test-helpers/build_pytorch.bat" target="_blank" rel="noopener noreferrer">build_pytorch.bat</a> 脚本。</p><pre><code class="language-cmd">cmd</p><p>:: 下载并解压 mkl 包后设置环境变量，否则 CMake 会报找不到 OpenMP 错。
set CMAKE_INCLUDE_PATH={Your directory}\mkl\include
set LIB={Your directory}\mkl\lib;%LIB%</p><p>:: 阅读前述内容后操作。
:: [可选] 如需覆盖 Ninja 和 Visual Studio 下 CUDA 的工具链，请运行以下脚本块。
:: 将自动运行 "Visual Studio 2019 Developer Command Prompt"。
:: 如使用 Visual Studio 生成器，请确保 CMake >= 3.12。
set CMAKE_GENERATOR_TOOLSET_VERSION=14.27
set DISTUTILS_USE_SDK=1
for /f "usebackq tokens=<em>" %i in (<code>"%ProgramFiles(x86)%\Microsoft Visual Studio\Installer\vswhere.exe" -version [15^,17^) -products </em> -latest -property installationPath</code>) do call "%i\VC\Auxiliary\Build\vcvarsall.bat" x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%</p><p>:: [可选] 如需覆盖 CUDA host 编译器
set CUDAHOSTCXX=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.27.29110\bin\HostX64\x64\cl.exe</p><p>python setup.py develop
</code></pre></p><p><strong>Intel GPU 构建</strong></p><p>此模式下将构建支持 Intel GPU 的 PyTorch。</p><p>请确保<a href="#prerequisites" target="_blank" rel="noopener noreferrer">通用先决条件</a>及<a href="#intel-gpu-support" target="_blank" rel="noopener noreferrer">Intel GPU 先决条件</a>均已正确安装，并配置好环境变量。工具链需 <code>Visual Studio 2022</code>。</p><p>构建命令如下：</p><pre><code class="language-cmd">:: CMD 命令：
:: 设置 CMAKE_PREFIX_PATH 以便找到相关包
:: %CONDA_PREFIX% 仅在 <code>conda activate custom_env</code> 后有效</p><p>if defined CMAKE_PREFIX_PATH (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library;%CMAKE_PREFIX_PATH%"
) else (
    set "CMAKE_PREFIX_PATH=%CONDA_PREFIX%\Library"
)</p><p>python setup.py develop</code></pre></p><p>##### 调整构建选项（可选）</p><p>可选地（无需先构建），你可以调整 cmake 变量配置。例如，调整 CuDNN 或 BLAS 的目录可在此步骤完成。</p><p>Linux 下
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
python setup.py build --cmake-only
ccmake build  # 或 cmake-gui build</code></pre></p><p>macOS 下
<pre><code class="language-bash">export CMAKE_PREFIX_PATH="${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}"
MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py build --cmake-only
ccmake build  # 或 cmake-gui build</code></pre></p><h3>Docker 镜像</h3></p><p>#### 使用预构建镜像</p><p>你也可以从 Docker Hub 拉取预构建镜像并用 docker v19.03+ 运行</p><pre><code class="language-bash">docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest</code></pre></p><p>请注意，PyTorch 使用共享内存在进程间共享数据，因此如使用 torch 多进程（如多线程数据加载器），
容器默认的共享内存段大小可能不足，建议在运行时用 <code>--ipc=host</code> 或 <code>--shm-size</code> 选项调整。</p><p>#### 自行构建镜像</p><p><strong>注意：</strong> 必须使用 docker 18.06 以上版本构建</p><p><code>Dockerfile</code> 提供了带 CUDA 11.1 和 cuDNN v8 支持的镜像构建方案。
你可通过 <code>PYTHON_VERSION=x.y</code> 变量指定 Miniconda 使用的 Python 版本，未设置则用默认值。</p><pre><code class="language-bash">make -f docker.Makefile
<h1>镜像标签为 docker.io/${your_docker_username}/pytorch</code></pre></h1></p><p>你还可以通过 <code>CMAKE_VARS="..."</code> 环境变量传递额外 CMake 变量。
详情见 <a href="./setup.py" target="_blank" rel="noopener noreferrer">setup.py</a>。</p><pre><code class="language-bash">make -f docker.Makefile</code></pre></p><h3>构建文档</h3></p><p>要以多种格式构建文档，你需安装 <a href="http://www.sphinx-doc.org" target="_blank" rel="noopener noreferrer">Sphinx</a>
和 pytorch_sphinx_theme2。</p><p>本地构建前，请确保你的环境已安装 <code>torch</code>。如仅做小修可安装夜间版，方法见<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">快速入门</a>。</p><p>如需更复杂的修复（如添加新模块及文档字符串），可能需<a href="#from-source" target="_blank" rel="noopener noreferrer">源码安装 torch</a>。
文档字符串规范见<a href="https://github.com/pytorch/pytorch/wiki/Docstring-Guidelines" target="_blank" rel="noopener noreferrer">Docstring Guidelines</a>。</p><pre><code class="language-bash">cd docs/
pip install -r requirements.txt
make html
make serve</code></pre></p><p>运行 <code>make</code> 可查看所有可用输出格式。</p><p>如遇 katex 错误，运行 <code>npm install katex</code>。若仍报错，尝试
<code>npm install -g katex</code></p><blockquote>[!NOTE]</blockquote>
<blockquote>若你用其他包管理器（如 <code>conda</code>）安装了 <code>nodejs</code>，<code>npm</code> 可能安装了与你 nodejs 版本不兼容的 katex，导致文档构建失败。</blockquote>
<blockquote>已知可用版本组合为 <code>node@6.13.1</code> 和 <code>katex@0.13.18</code>。用 <code>npm</code> 安装后者命令如下：</blockquote>
<blockquote>``<code>npm install -g katex@0.13.18<pre><code class="language-"></blockquote>
<blockquote>[!NOTE]</blockquote>
<blockquote>如遇 numpy 不兼容错误，运行：</blockquote>
<blockquote></code>`<code></blockquote>
<blockquote>pip install 'numpy<2'</blockquote>
<blockquote></code>`<code></blockquote></p><p>如修改了 CI 依赖，请编辑 </code>.ci/docker/requirements-docs.txt<code> 文件。</p><p>#### 构建 PDF</p><p>要编译 PyTorch 全部文档为 PDF，需安装 </code>texlive<code> 和 LaTeX。macOS 可用：
</code></pre>
brew install --cask mactex
</code>`<code></p><p>生成 PDF 步骤：</p><ul><li>运行：</li></p><p>   </ul></code>`<code>
   make latexpdf
   </code>`<code></p><p>   这会在 </code>build/latex<code> 目录生成所需文件。</p><ul><li>进入该目录并执行：</li></p><p>   </ul></code>`<code>
   make LATEXOPTS="-interaction=nonstopmode"
   </code>`<code></p><p>   将生成 </code>pytorch.pdf`。再运行一次以正确生成目录和索引。</p><blockquote>[!NOTE]</blockquote>
<blockquote>若需查看目录，请在 PDF 阅读器中切换到<strong>目录</strong>视图。</blockquote></p><h3>历史版本</h3></p><p>以往 PyTorch 版本的安装说明和二进制包见
<a href="https://pytorch.org/get-started/previous-versions" target="_blank" rel="noopener noreferrer">官网</a>。</p><h2>快速入门</h2></p><p>三步助你上手：
<ul><li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">教程：了解并使用 PyTorch</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">示例：各领域易懂的 PyTorch 代码</a></li>
<li><a href="https://pytorch.org/docs/" target="_blank" rel="noopener noreferrer">API 参考手册</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/main/GLOSSARY.md" target="_blank" rel="noopener noreferrer">术语表</a></li></p><p></ul><h2>资源</h2></p><ul><li><a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">PyTorch.org</a></li>
<li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener noreferrer">PyTorch 教程</a></li>
<li><a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">PyTorch 示例</a></li>
<li><a href="https://pytorch.org/hub/" target="_blank" rel="noopener noreferrer">PyTorch 模型</a></li>
<li><a href="https://www.udacity.com/course/deep-learning-pytorch--ud188" target="_blank" rel="noopener noreferrer">Udacity 深度学习 PyTorch 入门</a></li>
<li><a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229" target="_blank" rel="noopener noreferrer">Udacity PyTorch 机器学习入门</a></li>
<li><a href="https://www.coursera.org/learn/deep-neural-networks-with-pytorch" target="_blank" rel="noopener noreferrer">Coursera PyTorch 深度神经网络</a></li>
<li><a href="https://twitter.com/PyTorch" target="_blank" rel="noopener noreferrer">PyTorch Twitter</a></li>
<li><a href="https://pytorch.org/blog/" target="_blank" rel="noopener noreferrer">PyTorch 博客</a></li>
<li><a href="https://www.youtube.com/channel/UCWXI5YeOsh03QvJ59PMaXFw" target="_blank" rel="noopener noreferrer">PyTorch YouTube</a></li></p><p></ul><h2>交流</h2>
<ul><li>论坛：实现、研究等讨论 https://discuss.pytorch.org</li>
<li>GitHub Issues：Bug 报告、特性请求、安装问题、RFC、建议等</li>
<li>Slack：<a href="https://pytorch.slack.com/" target="_blank" rel="noopener noreferrer">PyTorch Slack</a> 主要面向中高级 PyTorch 用户和开发者，适于一般讨论、协作等。如为初学者，建议优先用 <a href="https://discuss.pytorch.org" target="_blank" rel="noopener noreferrer">PyTorch 论坛</a>。如需 Slack 邀请，请填写此表：https://goo.gl/forms/PP1AGvNHpSaJP8to1</li>
<li>邮件简报：一条通道，推送 PyTorch 重要公告。可在此注册：https://eepurl.com/cbG0rv</li>
<li>Facebook 页面：PyTorch 重要公告 https://www.facebook.com/pytorch</li>
<li>品牌规范请见<a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">官网</a></li></p><p></ul><h2>版本与贡献</h2></p><p>PyTorch 通常每年有三个小版本发布。如遇 Bug，请<a href="https://github.com/pytorch/pytorch/issues" target="_blank" rel="noopener noreferrer">提交 Issue</a>。</p><p>欢迎所有贡献。若你计划贡献 Bug 修复，直接提交即可，无需进一步讨论。</p><p>如计划贡献新特性、实用函数或核心扩展，请先提交 Issue 与我们讨论，
直接提交 PR 可能会因方向不符而被拒。</p><p>了解更多 PyTorch 贡献方式，请见<a href="CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">贡献页面</a>。了解 PyTorch 版本信息请见<a href="RELEASE.md" target="_blank" rel="noopener noreferrer">版本说明</a>。</p><h2>团队</h2></p><p>PyTorch 是一个由社区驱动的项目，众多出色工程师和研究人员共同贡献。</p><p>当前主要由 <a href="http://soumith.ch" target="_blank" rel="noopener noreferrer">Soumith Chintala</a>、<a href="https://github.com/gchanan" target="_blank" rel="noopener noreferrer">Gregory Chanan</a>、<a href="https://github.com/dzhulgakov" target="_blank" rel="noopener noreferrer">Dmytro Dzhulgakov</a>、<a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a> 和 <a href="https://github.com/malfet" target="_blank" rel="noopener noreferrer">Nikita Shulga</a> 维护，数百名才华横溢的个人以各种方式做出贡献。
部分主要贡献者（不完全名单）：<a href="https://github.com/killeent" target="_blank" rel="noopener noreferrer">Trevor Killeen</a>、<a href="https://github.com/chsasank" target="_blank" rel="noopener noreferrer">Sasank Chilamkurthy</a>、<a href="https://github.com/szagoruyko" target="_blank" rel="noopener noreferrer">Sergey Zagoruyko</a>、<a href="https://github.com/adamlerer" target="_blank" rel="noopener noreferrer">Adam Lerer</a>、<a href="https://github.com/fmassa" target="_blank" rel="noopener noreferrer">Francisco Massa</a>、<a href="https://github.com/alykhantejani" target="_blank" rel="noopener noreferrer">Alykhan Tejani</a>、<a href="https://github.com/lantiga" target="_blank" rel="noopener noreferrer">Luca Antiga</a>、<a href="https://github.com/albanD" target="_blank" rel="noopener noreferrer">Alban Desmaison</a>、<a href="https://github.com/andreaskoepf" target="_blank" rel="noopener noreferrer">Andreas Koepf</a>、<a href="https://github.com/jekbradbury" target="_blank" rel="noopener noreferrer">James Bradbury</a>、<a href="https://github.com/ebetica" target="_blank" rel="noopener noreferrer">Zeming Lin</a>、<a href="https://github.com/yuandong-tian" target="_blank" rel="noopener noreferrer">Yuandong Tian</a>、<a href="https://github.com/glample" target="_blank" rel="noopener noreferrer">Guillaume Lample</a>、<a href="https://github.com/Maratyszcza" target="_blank" rel="noopener noreferrer">Marat Dukhan</a>、<a href="https://github.com/ngimel" target="_blank" rel="noopener noreferrer">Natalia Gimelshein</a>、<a href="https://github.com/csarofeen" target="_blank" rel="noopener noreferrer">Christian Sarofeen</a>、<a href="https://github.com/martinraison" target="_blank" rel="noopener noreferrer">Martin Raison</a>、<a href="https://github.com/ezyang" target="_blank" rel="noopener noreferrer">Edward Yang</a>、<a href="https://github.com/zdevito" target="_blank" rel="noopener noreferrer">Zachary Devito</a>。</p><p>注意：本项目与同名的 <a href="https://github.com/hughperkins/pytorch" target="_blank" rel="noopener noreferrer">hughperkins/pytorch</a> 无关。Hugh 是 Torch 社区的宝贵贡献者，为 Torch 和 PyTorch 做出了许多贡献。</p><h2>许可证</h2></p><p>PyTorch 采用 BSD 风格许可证，详见 <a href="LICENSE" target="_blank" rel="noopener noreferrer">LICENSE</a> 文件。

---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/pytorch/pytorch/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>