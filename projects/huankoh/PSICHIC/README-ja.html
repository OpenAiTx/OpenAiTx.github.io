<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PSICHIC - PSICHIC（サイキックと発音）- 配列データからタンパク質-リガンド相互作用フィンガープリントを学習するための物理化学的グラフニューラルネットワーク</title>
    <meta name="description" content="PSICHIC（サイキックと発音）- 配列データからタンパク質-リガンド相互作用フィンガープリントを学習するための物理化学的グラフニューラルネットワーク">
    <meta name="keywords" content="PSICHIC, Japanese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "PSICHIC",
  "description": "PSICHIC（サイキックと発音）- 配列データからタンパク質-リガンド相互作用フィンガープリントを学習するための物理化学的グラフニューラルネットワーク",
  "author": {
    "@type": "Person",
    "name": "huankoh"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 124
  },
  "url": "https://OpenAiTx.github.io/projects/huankoh/PSICHIC/README-ja.html",
  "sameAs": "https://raw.githubusercontent.com/huankoh/PSICHIC/main/README.md",
  "datePublished": "2026-01-26",
  "dateModified": "2026-01-26"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/huankoh/PSICHIC" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    PSICHIC
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 124 stars</span>
                <span class="language">Japanese</span>
                <span>by huankoh</span>
            </div>
        </div>
        
        <div class="content">
            <h2>PSICHIC: 配列データからタンパク質-リガンド相互作用フィンガープリントを学習する物理化学的グラフニューラルネットワーク <a href="https://www.nature.com/articles/s42256-024-00847-1" target="_blank" rel="noopener noreferrer">[Nature Machine Intelligence</a>]</h2></p><p><img src="https://raw.githubusercontent.com/huankoh/PSICHIC/main/image/PSICHIC.jpg" width="500"/></p><h2>PSICHIC ウェブサーバー <a href="http://www.psichicserver.com" target="_blank"><img src="https://raw.githubusercontent.com/huankoh/PSICHIC/main/image/crystal_ball.png" alt="PSICHIC Webserver" width="30"/></a></h2></p><p>朗報❗ PSICHICウェブサーバー（ベータ版）が利用可能になりました！ 🚀 タンパク質-リガンド相互作用解析の未来を <a href="https://www.psichicserver.com/" target="_blank" rel="noopener noreferrer">www.psichicserver.com</a> で体験してください。</p><p>_探索を始めましょう。あなたの次の発見が_ 🌐🔬 _すぐそこにあります！_</p><p><sub>注：このサーバーは論文の公式サーバーではありません。公式バージョンは以下のColabおよびローカル展開設定を参照してください。</sub></p><h2>PSICHIC バーチャルスクリーニングプラットフォーム <a href="https://colab.research.google.com/github/huankoh/PSICHIC/blob/main/PSICHIC.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></h2></p><ul><li><strong>配列データのみ</strong>：必要なのはタンパク質配列＋リガンドのSMILESペアだけです。</li>
<li><strong>高速スクリーニング</strong>：最大10万化合物を1時間で処理。</li>
<li><strong>詳細解析</strong>：PSICHIC搭載のファーマコフォアおよび標的変異解析で分子の洞察を発見。</li></p><p></ul><strong>アップデート:</strong> 選択性サブフォルダにJupyterノートブックを追加し、PSICHICによる選択性プロファイリングの使い方を示しています。</p><h2>PSICHIC ローカル展開の環境設定</h2>
<details>
<summary>PSICHICローカル開発環境の内容を表示/非表示</summary></p><p>現在、PSICHICはMacOS（OSX）、Linux、Windowsでの使用が検証されています。conda経由のインストール、あるいはより高速なmambaパッケージ・環境マネージャーの使用を推奨します。mambaはコマンド `<code>conda install mamba -n base -c conda-forge</code><code> でインストール可能です。condaまたはmambaを使ったセットアップ方法については、以下の該当コード行を参照してください。</p><pre><code class="language-">## OSX 
conda env create -f environment_osx.yml  # if mamba: mamba env create -f environment_osx.yml
<h2>LINUX or Windows GPU</h2>
conda env create -f environment_gpu.yml # if mamba: mamba env create -f environment_gpu.yml
conda activate psichic_fp
pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu118.html
<h2>LINUX or Windows CPU</h2>
conda env create -f environment_cpu.yml  # if mamba: mamba env create -f environment_cpu.yml
conda activate psichic_fp
pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cpu.html</code></pre></p><p>あるいは、環境設定に役立つコマンドライン（Linux上でPython 3.8でテスト済み）。 
<pre><code class="language-">conda create --name psichic_fp python=3.8
conda install pytorch==2.0.0 torchvision==0.15.0 torchaudio==2.0.0 pytorch-cuda=11.7 -c pytorch -c nvidia
conda install pyg -c pyg
conda install -c conda-forge rdkit==2022.09.5
pip install scipy biopython pandas biopandas timeout_decorator py3Dmol umap-learn plotly mplcursors lifelines reprint
pip install "fair-esm"</code></pre></p><h2>注釈付き配列データを用いたBYO-PSICHIC</h2></p><p>データフォルダにtrain、valid、testのcsvファイルを作成してください（例はdatasetフォルダを参照）。データフォルダには少なくともtrain.csvとtest.csvファイルが含まれている必要があります。注釈付きラベルに応じて、連続値ラベル（例：結合親和性）の場合は </code><code>--regression_task True</code><code>、二値クラスラベル（例：相互作用の有無）の場合は </code><code>--classification_task True</code><code>、多クラスラベルの場合はクラス数Cを指定して </code><code>--mclassification_task C</code><code>（例：当社のタンパク質-リガンド機能応答データセットを使用する場合は3）を使用してください。複数のラベルタイプを含むデータセットも可能であり、PSICHICを用いて複数のタンパク質-リガンド相互作用特性を予測することができます（以下のPSICHIC-MultiTaskを参照）。</p><pre><code class="language-">python main.py --datafolder annotated_folder --result_path result/annotated_result --regression_task True </code></pre></p><p>例えば、PDBBind v2020ベンチマークを用いたベンチマークデータセットでのBYO-PSICHICの使用：
<pre><code class="language-">python main.py --datafolder dataset/pdb2020 --result_path result/PDB2020_BENCHMARK --regression_task True </code></pre>
モデルおよびオプティマイザの設定は、PDBBind v2016を除くすべてのベンチマークデータセットで一貫しています。PDBBind v2016では、オプティマイザのトレーニングイテレーション数、betasおよびepsをそれぞれ30000、"(0.9,0.99)"、1e-5に変更したい場合、コマンドラインに </code><code>--total_iters 30000 --betas "(0.9,0.99)" --eps 1e-5</code><code> を追加してください。バイナリ分類タスクの場合は、</code><code>--regression_task True</code><code> を </code><code>--classification_task True</code><code> に置き換えてください。タンパク質機能効果データセットの場合は、</code><code>--regression_task True</code><code> を </code><code>--mclassification_task 3</code>` に置き換えてください。config.jsonファイル内のモデルハイパーパラメータは自由に調整してください。興味深い結果があればお知らせください！</p><h2>データセット構造とBYOフォーマットガイドライン</h2>
論文で参照しているすべてのデータセットはGoogleドライブで入手可能です（<a href="https://drive.google.com/drive/folders/1ZRpnwXtllCP89hjhfDuPivBlarBIXnmu?usp=sharing" target="_blank" rel="noopener noreferrer">Dataset</a>）。PSICHICのベンチマーク評価に使用したデータセットには、既定の分割設定に基づいて作成されたtrain、valid、testのCSVファイルがあります。Googleドライブリンクのデータセットセクションには、各データセットの目的を説明するREADME.mdが別途用意されています（これは論文の拡張データ表1に類似しています）。</p><p>BYO-PSICHICデータセット：BYO-PSICHICのトレーニングに興味がある場合、各ファイルは以下のような形式になっているはずです。検証用CSVファイルがなくても問題ありません。たとえば、結果を外部実験で適用する予定の場合です。</p><p>__結合親和性回帰__</p><p>| Protein | Ligand | regression_label | 
|:----------:|:----------:|:----------:|
| ISAFQAAYIGIE....  | C1CCCCC1  | 6.7 | 
| GGALVSVISAFQASV....  | O=C(C)Oc1ccccc1C(=O)O | 4.0 |
|...|...| ...|
| MIPSAYIGIEVLI... | CCO | 8.1 | </p><pre><code class="language-">python main.py --datafolder BYO_DATASET --result_path BYO_RESULT --regression_task True </code></pre></p><p>__二元相互作用の分類__</p><p>| タンパク質 | リガンド | 分類ラベル | 
|:----------:|:----------:|:----------:|
| ISAFQAAYIGIE....  | C1CCCCC1  | 1 | 
| GGALVSVISAFQASV.... | O=C(C)Oc1ccccc1C(=O)O | 0 |
|...|...| ...|
| MIPSAYIGIEVLI.... | CCO | 1 | </p><pre><code class="language-">python main.py --datafolder BYO_DATASET --result_path BYO_RESULT --classification_task True</code></pre></p><p>__機能的効果分類（三元分類）__</p><p>| タンパク質 | リガンド | multiclass_label | 
|:----------:|:----------:|:----------:|
| ISAFQAAYIGIE....  | C1CCCCC1  | -1 |  # アンタゴニスト
| GGALVSVISAFQASV.... | O=C(C)Oc1ccccc1C(=O)O | 0 | # 非結合体
|...|...| ...|
| MIPSAYIGIEVLI.... | CCO | 1 | # アゴニスト</p><pre><code class="language-">python main.py --datafolder BYO_DATASET --result_path BYO_RESULT --mclassification_task 3</code></pre></p><p>__マルチタスク PSICHIC__</p><p>| タンパク質 | リガンド | 回帰ラベル | 多クラスラベル | 
|:----------:|:----------:|:----------:|:----------:|
| ISAFQAAYIGIE....  | C1CCCCC1  | 6.7 | -1 |  # アンタゴニスト
| GGALVSVISAFQASV....  | O=C(C)Oc1ccccc1C(=O)O | 4.0 | 0 | # 非結合体
|...|...| ...|
| MIPSAYIGIEVLI.... | CCO | 8.1 | 1 | # アゴニスト</p><pre><code class="language-">python main.py --datafolder BYO_DATASET --result_path BYO_RESULT --regression_task True --mclassification_task 3</code></pre></p><p><strong>戦略的にデータセットを分割しますか？</strong> データセットフォルダ内のJupyterノートブックでは、ランダム分割、未見のタンパク質分割、および未見のリガンドスキャフォールド分割をどのように行い、PSICHICや他の手法の汎用性を評価するかを示しています。これは、BYO-PSICHICがあなたの注釈付き配列データで機能するかどうかを評価するのに役立ちます。
 
<h2>PSICHIC<sub>XL</sub>：大規模相互作用データセットにおけるマルチタスク予測トレーニング</h2>
PSICHIC<sub>XL</sub>は以前、事前学習済みマルチタスクPSICHICと呼ばれていました。PSICHIC<sub>A1R</sub>は以前、ファインチューニング済みマルチタスクPSICHICと呼ばれていました。PSICHIC<sub>XL</sub>は追加のトレーニングなしでそのまま使用できることを明確にするために名前を変更しました。ただし、PSICHIC<sub>XL</sub>は、特定のタンパク質ターゲットに特化したデータでファインチューニングすることで、仮想スクリーニングにおけるランキング能力を向上させる可能性があります。例えば、以下に示すA<sub>1</sub>R関連データを用いたPSICHIC<sub>A<sub>1</sub>R</sub>です。</p><h3>PSICHIC<sub>XL</sub>のトレーニング（プレプリントでの事前学習済みPSICHICとしても知られる）</h3>
<pre><code class="language-">python main.py --datafolder dataset/large_scale_interaction_dataset --result_path PSICHIC_MultiTask_Pretrain --lrate 1e-5 --sampling_col pretrain_sampling_weight --regression_task True --mclassification_task 3 --total_iters 300000 --evaluate_step 25000</code></pre>
<h3>PSICHIC<sub>XL</sub>をPSICHIC<sub>A<sub>1</sub>R</sub>（別名：PreprintでのFine-tuned PSICHIC）にファインチューニング  </h3>
A<sub>1</sub>R関連タンパク質に対して、PSICHIC<sub>XL</sub>のアプリケーション層のみを1000回イテレーションでファインチューニングします。コマンドは以下の通りです：
<pre><code class="language-">python main.py --regression_task True --mclassification_task 3 --datafolder dataset/A1R_FineTune --result_path PSICHIC_A1R_FineTune --lrate 1e-5 --total_iters 1000 --finetune_modules "['reg_out','mcls_out']" --trained_model_path trained_weights/multitask_PSICHIC</code></pre>
広範な相互作用データセットでトレーニングされたPSICHICバージョンをPSICHIC<sub>XL</sub>に、A<sub>1</sub>Rデータに焦点を当てたサブセットをPSICHIC<sub>A<sub>1</sub>R</sub>に名称変更しました。以前は、PSICHIC<sub>XL</sub>とPSICHIC<sub>A<sub>1</sub>R</sub>はそれぞれ事前学習済みPSICHICとファインチューニング済みPSICHICとして知られていました。この変更は、PSICHIC<sub>XL</sub>の広範な適用性とPSICHIC<sub>A<sub>1</sub>R</sub>のA1Rに特化した強調をより正確に反映しています。</p><p>他のタンパク質の場合は、大規模相互作用データセットから関連のないタンパク質や非結合体を除外し、PSICHICを他の実験に適用できます。
</details></p><h2>参考文献</h2></p><p>詳細については、当研究をご参照ください： </p><pre><code class="language-">PSICHIC: physicochemical graph neural network for learning protein-ligand interaction fingerprints from sequence data
Huan Yee Koh, Anh T.N. Nguyen, Shirui Pan, Lauren T. May, Geoffrey I. Webb
bioRxiv 2023.09.17.558145; doi: https://doi.org/10.1101/2023.09.17.558145</code></pre></p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-01-26

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/huankoh/PSICHIC/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-01-26 
    </div>
    
</body>
</html>