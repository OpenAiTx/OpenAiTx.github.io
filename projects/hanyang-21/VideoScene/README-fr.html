<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VideoScene - [CVPR 2025 Highlight] VideoScene : Distillation d&#39;un mod&#232;le de diffusion vid&#233;o pour g&#233;n&#233;rer des sc&#232;nes 3D en une seule &#233;tape</title>
    <meta name="description" content="[CVPR 2025 Highlight] VideoScene : Distillation d&#39;un mod&#232;le de diffusion vid&#233;o pour g&#233;n&#233;rer des sc&#232;nes 3D en une seule &#233;tape">
    <meta name="keywords" content="VideoScene, French, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "VideoScene",
  "description": "[CVPR 2025 Highlight] VideoScene : Distillation d'un modèle de diffusion vidéo pour générer des scènes 3D en une seule étape",
  "author": {
    "@type": "Person",
    "name": "hanyang-21"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 301
  },
  "url": "https://OpenAiTx.github.io/projects/hanyang-21/VideoScene/README-fr.html",
  "sameAs": "https://raw.githubusercontent.com/hanyang-21/VideoScene/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/hanyang-21/VideoScene" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    VideoScene
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 301 stars</span>
                <span class="language">French</span>
                <span>by hanyang-21</span>
            </div>
        </div>
        
        <div class="content">
            <p><p align="center">
  <h1 align="center">VideoScene : Distillation d’un modèle de diffusion vidéo pour générer des scènes 3D en une seule étape</h1>
  <p align="center">
    <a href="https://hanyang-21.github.io/">Hanyang Wang</a><sup>*</sup>,
    <a href="https://liuff19.github.io/">Fangfu Liu</a><sup>*</sup>,
    <a href="https://github.com/hanyang-21/VideoScene">Jiawei Chi</a>,
    <a href="https://duanyueqi.github.io/">Yueqi Duan</a>
    <br>
    <sup>*</sup>Contribution Équivalente.
    <br>
    Université Tsinghua
  </p>
  <h3 align="center">CVPR 2025 Highlight 🔥</h3>
  <h5 align="center"></p><p><a href="https://arxiv.org/abs/2504.01956" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/Arxiv-2403.20309-b31b1b.svg?logo=arXiv" alt="arXiv"></a> 
<a href="https://hanyang-21.github.io/VideoScene" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/Project-Website-green.svg" alt="Home Page"></a>
<a><img src='https://img.shields.io/badge/License-MIT-blue'></a>
<a href='https://mp.weixin.qq.com/s/u6OUo5mHKPG6I3yYJPMC8Q'><img src='https://img.shields.io/badge/%E5%BE%AE%E4%BF%A1-%E4%B8%AD%E6%96%87%E4%BB%8B%E7%BB%8D-green'></a></p><p></h5>
  <!-- <h3 align="center"><a href="https://arxiv.org/abs/">Article</a> | <a href="">Page du projet</a> | <a href="">Modèles pré-entraînés</a> </h3> -->
<!--   <div align="center">
    <a href="https://news.ycombinator.com/item?id=41222655">
      <img
        alt="Mis en avant sur Hacker News"
        src="https://hackerbadge.vercel.app/api?id=41222655&type=dark"
      />
    </a>
  </div> --></p></p><p><div align="center">
VideoScene est un modèle de diffusion vidéo en une étape qui comble le fossé entre la vidéo et la 3D.
</div>
</br></p><p>
https://github.com/user-attachments/assets/dca733b1-b78f-49ac-ae47-5d1b1e8a689b</p><p>S’appuyant sur <a href="https://github.com/liuff19/ReconX" target="_blank" rel="noopener noreferrer">ReconX</a>, VideoScene a réalisé une avancée version turbo.</p><h2>Installation</h2></p><p>Pour commencer, clonez ce projet, créez un environnement virtuel conda utilisant Python 3.10+, et installez les dépendances :</p><ul><li>Cloner VideoScene.</li>
</ul><pre><code class="language-bash">git clone https://github.com/hanyang-21/VideoScene
cd VideoScene</code></pre>
<ul><li>Créez l'environnement, ici nous montrons un exemple utilisant conda.</li></p><p></ul><pre><code class="language-bash">conda create -y -n videoscene python=3.10
conda activate videoscene
pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt</code></pre>
<ul><li>Optionnel, compiler les noyaux cuda pour RoPE (comme dans CroCo v2).</li></p><p></ul><pre><code class="language-bash"># NoPoSplat relies on RoPE positional embeddings for which you can compile some cuda kernels for faster runtime.
cd src/model/encoder/backbone/croco/curope/
python setup.py build_ext --inplace
cd ../../../../../..</code></pre></p><h2>Acquisition des jeux de données</h2></p><h3>RealEstate10K et ACID</h3></p><p>Notre VideoScene utilise les mêmes jeux de données d'entraînement que pixelSplat. Ci-dessous, nous citons les <a href="https://github.com/dcharatan/pixelsplat?tab=readme-ov-file#acquiring-datasets" target="_blank" rel="noopener noreferrer">instructions détaillées</a> de pixelSplat pour obtenir les jeux de données.</p><blockquote>pixelSplat a été entraîné en utilisant des versions des jeux de données RealEstate10k et ACID découpées en morceaux d’environ 100 Mo pour une utilisation sur des systèmes de fichiers de clusters serveurs. De petits sous-ensembles des jeux de données Real Estate 10k et ACID dans ce format peuvent être trouvés <a href="https://drive.google.com/drive/folders/1joiezNCyQK2BvWMnfwHJpm2V77c7iYGe?usp=sharing" target="_blank" rel="noopener noreferrer">ici</a>. Pour les utiliser, il suffit de les décompresser dans un dossier <code>datasets</code> nouvellement créé à la racine du projet.</blockquote></p><blockquote>Si vous souhaitez convertir des versions téléchargées des jeux de données Real Estate 10k et ACID au format que nous utilisons, vous pouvez utiliser les <a href="https://github.com/dcharatan/real_estate_10k_tools" target="_blank" rel="noopener noreferrer">scripts ici</a>. Contactez-nous (pixelSplat) si vous souhaitez les versions complètes de nos jeux de données traités, qui pèsent environ 500 Go et 160 Go pour Real Estate 10k et ACID respectivement.</blockquote></p><h2>Téléchargement des checkpoints</h2></p><ul><li>téléchargez nos <a href="https://wisemodel.cn/models/hanyang/VideoScene/file" target="_blank" rel="noopener noreferrer">poids pré-entraînés</a> (<code>VideoScene/checkpoints/model.safetensors</code> et <code>VideoScene/checkpoints/prompt_embeds.pt</code>), et sauvegardez-les dans <code>checkpoints</code>.</li></p><p><li>pour des entrées d’images personnalisées, récupérez les modèles pré-entraînés NoPoSplat <a href="https://huggingface.co/botaoye/NoPoSplat/resolve/main/mixRe10kDl3dv_512x512.ckpt" target="_blank" rel="noopener noreferrer">ici</a>, et sauvegardez-les dans <code>checkpoints/noposplat</code>.</li></p><p>
<li>pour les jeux de données RealEstate10K, récupérez les modèles pré-entraînés MVSplat <a href="https://drive.google.com/drive/folders/14_E_5R6ojOWnLSrSVLVEMHnTiKsfddjU" target="_blank" rel="noopener noreferrer">ici</a>, et sauvegardez-les dans <code>checkpoints/mvsplat</code>.</li></p><p></ul><h2>Exécution du code</h2></p><h3>Démonstration Gradio</h3>
Dans cette démonstration, vous pouvez exécuter VideoScene sur votre machine pour générer une vidéo avec des vues d’entrée non posées.</p><ul><li>sélectionnez des paires d’images représentant la même scène et cliquez sur "RUN" pour obtenir une vidéo de la scène.</li></p><p></ul><pre><code class="language-bash">python -m noposplat.src.app \
    checkpointing.load=checkpoints/noposplat/mixRe10kDl3dv_512x512.ckpt \
    test.video=checkpoints/model.safetensors</p><h1>also "bash demo.sh"</code></pre></h1>
<ul><li>la vidéo générée sera stockée dans <code>outputs/gradio</code></li></p><p></ul><h3>Inférence</h3></p><p>Pour générer des vidéos sur les ensembles de données RealEstate10K, nous utilisons un modèle préentraîné <a href="https://github.com/donydchen/mvsplat" target="_blank" rel="noopener noreferrer">MVSplat</a>,</p><ul><li>exécutez ce qui suit :</li></p><p></ul><pre><code class="language-bash"># re10k
python -m mvsplat.src.main +experiment=re10k \
checkpointing.load=checkpoints/mvsplat/re10k.ckpt \
mode=test \
dataset/view_sampler=evaluation \
dataset.view_sampler.index_path=mvsplat/assets/evaluation_index_re10k_video.json \
test.save_video=true \
test.save_image=false \
test.compute_scores=false \
test.video=checkpoints/model.safetensors</p><h1>also "bash inference.sh"</code></pre></h1></p><ul><li>la vidéo générée sera stockée sous <code>outputs/test</code></li></p><p>
</ul><h2>BibTeX</h2></p><pre><code class="language-bibtex">@misc{wang2025videoscenedistillingvideodiffusion,
      title={VideoScene: Distilling Video Diffusion Model to Generate 3D Scenes in One Step}, 
      author={Hanyang Wang and Fangfu Liu and Jiawei Chi and Yueqi Duan},
      year={2025},
      eprint={2504.01956},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2504.01956}, 
}</code></pre></p><h2>Remerciements</h2></p><p>Ce projet est développé avec plusieurs dépôts fantastiques : <a href="https://github.com/liuff19/ReconX" target="_blank" rel="noopener noreferrer">ReconX</a>, <a href="https://github.com/donydchen/mvsplat" target="_blank" rel="noopener noreferrer">MVSplat</a>, <a href="https://github.com/cvg/NoPoSplat" target="_blank" rel="noopener noreferrer">NoPoSplat</a>, <a href="https://github.com/THUDM/CogVideo" target="_blank" rel="noopener noreferrer">CogVideo</a>, et <a href="https://github.com/feizc/CogvideX-Interpolation" target="_blank" rel="noopener noreferrer">CogvideX-Interpolation</a>. Un grand merci à ces projets pour leurs excellentes contributions !</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-08-07

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/hanyang-21/VideoScene/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>