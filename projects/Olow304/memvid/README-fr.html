<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>memvid - Read memvid documentation in French. This project has 6194 stars on GitHub.</title>
    <meta name="description" content="Read memvid documentation in French. This project has 6194 stars on GitHub.">
    <meta name="keywords" content="memvid, French, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "memvid",
  "description": "Read memvid documentation in French. This project has 6194 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "Olow304"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 6194
  },
  "url": "https://OpenAiTx.github.io/projects/Olow304/memvid/README-fr.html",
  "sameAs": "https://raw.githubusercontent.com/Olow304/memvid/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/Olow304/memvid" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    memvid
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 6194 stars</span>
                <span class="language">French</span>
                <span>by Olow304</span>
            </div>
        </div>
        
        <div class="content">
            <h1>Memvid - Mémoire IA Basée sur la Vidéo 🧠📹</h1></p><p><strong>La solution légère et révolutionnaire pour la mémoire IA à grande échelle</strong></p><p><a href="https://pypi.org/project/memvid/" target="_blank" rel="noopener noreferrer"><img src="https://badge.fury.io/py/memvid.svg" alt="PyPI version"></a>
<a href="https://opensource.org/licenses/MIT" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT"></a>
<a href="https://www.python.org/downloads/" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/python-3.8+-blue.svg" alt="Python 3.8+"></a>
<a href="https://github.com/psf/black" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/code%20style-black-000000.svg" alt="Code style: black"></a></p><p>Memvid révolutionne la gestion de la mémoire pour l’IA en encodant les données textuelles en vidéos, permettant une <strong>recherche sémantique ultra-rapide</strong> sur des millions de fragments de texte avec des <strong>temps de récupération inférieurs à la seconde</strong>. Contrairement aux bases de données vectorielles traditionnelles qui consomment énormément de RAM et de stockage, Memvid compresse votre base de connaissance en fichiers vidéo compacts tout en maintenant un accès instantané à toute information.</p><h2>🎥 Démonstration</h2></p><p>https://github.com/user-attachments/assets/ec550e93-e9c4-459f-a8a1-46e122b5851e</p><h2>✨ Principales fonctionnalités</h2></p><ul><li>🎥 <strong>Vidéo comme Base de Données</strong> : Stockez des millions de fragments de texte dans un seul fichier MP4</li>
<li>🔍 <strong>Recherche Sémantique</strong> : Trouvez le contenu pertinent avec des requêtes en langage naturel</li>
<li>💬 <strong>Chat Intégré</strong> : Interface conversationnelle avec des réponses contextuelles</li>
<li>📚 <strong>Support PDF</strong> : Import et indexation directe de documents PDF</li>
<li>🚀 <strong>Récupération Rapide</strong> : Recherche en moins d’une seconde sur des ensembles de données massifs</li>
<li>💾 <strong>Stockage Efficace</strong> : Compression 10x par rapport aux bases de données classiques</li>
<li>🔌 <strong>LLMs Modulaire</strong> : Fonctionne avec OpenAI, Anthropic ou des modèles locaux</li>
<li>🌐 <strong>Offline-First</strong> : Aucune connexion Internet nécessaire après la génération des vidéos</li>
<li>🔧 <strong>API Simple</strong> : Commencez en seulement 3 lignes de code</li></p><p></ul><h2>🎯 Cas d’utilisation</h2></p><ul><li><strong>📖 Bibliothèques Numériques</strong> : Indexez des milliers de livres dans un seul fichier vidéo</li>
<li><strong>🎓 Contenus Éducatifs</strong> : Créez des mémoires vidéo consultables pour les supports de cours</li>
<li><strong>📰 Archives de Presse</strong> : Compressez des années d’articles dans des bases de données vidéo faciles à gérer</li>
<li><strong>💼 Connaissance d’Entreprise</strong> : Construisez des bases de connaissances consultables à l’échelle de l’entreprise</li>
<li><strong>🔬 Publications Scientifiques</strong> : Recherche sémantique rapide dans la littérature scientifique</li>
<li><strong>📝 Notes Personnelles</strong> : Transformez vos notes en assistant IA consultable</li></p><p></ul><h2>🚀 Pourquoi Memvid ?</h2></p><h3>Innovation Révolutionnaire</h3>
<ul><li><strong>Vidéo comme Base de Données</strong> : Stockez des millions de fragments de texte dans un seul fichier MP4</li>
<li><strong>Récupération Instantanée</strong> : Recherche sémantique en moins d’une seconde sur de grands ensembles de données</li>
<li><strong>Efficacité de Stockage 10x</strong> : La compression vidéo réduit considérablement l’empreinte mémoire</li>
<li><strong>Zéro Infrastructure</strong> : Pas de serveur de base de données, juste des fichiers que vous pouvez copier n’importe où</li>
<li><strong>Offline-First</strong> : Fonctionne entièrement hors-ligne une fois les vidéos générées</li></p><p></ul><h3>Architecture Légère</h3>
<ul><li><strong>Dépendances Minimales</strong> : Fonctionnalité principale en ~1000 lignes de Python</li>
<li><strong>Optimisé CPU</strong> : Fonctionne efficacement sans nécessiter de GPU</li>
<li><strong>Portable</strong> : Un seul fichier vidéo contient toute votre base de connaissance</li>
<li><strong>Diffusable</strong> : Les vidéos peuvent être diffusées depuis un stockage cloud</li></p><p></ul><h2>📦 Installation</h2></p><h3>Installation Rapide</h3>
<pre><code class="language-bash">pip install memvid</code></pre></p><h3>Pour le support PDF</h3>
<pre><code class="language-bash">pip install memvid PyPDF2</code></pre></p><h3>Configuration recommandée (Environnement Virtuel)</h3>
<pre><code class="language-bash"># Créer un nouveau dossier de projet
mkdir my-memvid-project
cd my-memvid-project</p><h1>Créer un environnement virtuel</h1>
python -m venv venv</p><h1>L’activer</h1>
<h1>Sur macOS/Linux :</h1>
source venv/bin/activate
<h1>Sur Windows :</h1>
venv\Scripts\activate</p><h1>Installer memvid</h1>
pip install memvid</p><h1>Pour le support PDF :</h1>
pip install PyPDF2</code></pre></p><h2>🎯 Démarrage Rapide</h2></p><h3>Utilisation de Base</h3>
<pre><code class="language-python">from memvid import MemvidEncoder, MemvidChat</p><h1>Créer une mémoire vidéo à partir de fragments de texte</h1>
chunks = ["Fait important 1", "Fait important 2", "Détails d’un événement historique"]
encoder = MemvidEncoder()
encoder.add_chunks(chunks)
encoder.build_video("memory.mp4", "memory_index.json")</p><h1>Discuter avec votre mémoire</h1>
chat = MemvidChat("memory.mp4", "memory_index.json")
chat.start_session()
response = chat.chat("Que sais-tu des événements historiques ?")
print(response)</code></pre></p><h3>Créer une mémoire à partir de documents</h3>
<pre><code class="language-python">from memvid import MemvidEncoder
import os</p><h1>Charger des documents</h1>
encoder = MemvidEncoder(chunk_size=512, overlap=50)</p><h1>Ajouter des fichiers texte</h1>
for file in os.listdir("documents"):
    with open(f"documents/{file}", "r") as f:
        encoder.add_text(f.read(), metadata={"source": file})</p><h1>Générer une vidéo optimisée</h1>
encoder.build_video(
    "knowledge_base.mp4",
    "knowledge_index.json",
    fps=30,  # Plus de FPS = plus de fragments par seconde
    frame_size=512  # Plus grande taille de frame = plus de données par frame
)</code></pre></p><h3>Recherche & Récupération Avancées</h3>
<pre><code class="language-python">from memvid import MemvidRetriever</p><h1>Initialiser le récupérateur</h1>
retriever = MemvidRetriever("knowledge_base.mp4", "knowledge_index.json")</p><h1>Recherche sémantique</h1>
results = retriever.search("algorithmes d’apprentissage automatique", top_k=5)
for chunk, score in results:
    print(f"Score : {score:.3f} | {chunk[:100]}...")</p><h1>Obtenir une fenêtre de contexte</h1>
context = retriever.get_context("expliquer les réseaux de neurones", max_tokens=2000)
print(context)</code></pre></p><h3>Interface Chat Interactive</h3>
<pre><code class="language-python">from memvid import MemvidInteractive</p><h1>Lancer l’interface chat interactive</h1>
interactive = MemvidInteractive("knowledge_base.mp4", "knowledge_index.json")
interactive.run()  # Ouvre l’interface web sur http://localhost:7860</code></pre></p><h3>Tester avec file_chat.py</h3>
Le script <code>examples/file_chat.py</code> fournit un moyen complet de tester Memvid avec vos propres documents :</p><pre><code class="language-bash"># Traiter un dossier de documents
python examples/file_chat.py --input-dir /path/to/documents --provider google</p><h1>Traiter des fichiers spécifiques</h1>
python examples/file_chat.py --files doc1.txt doc2.pdf --provider openai</p><h1>Utiliser la compression H.265 (nécessite Docker)</h1>
python examples/file_chat.py --input-dir docs/ --codec h265 --provider google</p><h1>Fragmentation personnalisée pour les gros documents</h1>
python examples/file_chat.py --files large.pdf --chunk-size 2048 --overlap 32 --provider google</p><h1>Charger une mémoire existante</h1>
python examples/file_chat.py --load-existing output/my_memory --provider google</code></pre></p><h3>Exemple Complet : Discuter avec un livre PDF</h3>
<pre><code class="language-bash"># 1. Créer un nouveau dossier et configurer l’environnement
mkdir book-chat-demo
cd book-chat-demo
python -m venv venv
source venv/bin/activate  # Sur Windows : venv\Scripts\activate</p><h1>2. Installer les dépendances</h1>
pip install memvid PyPDF2</p><h1>3. Créer book_chat.py</h1>
cat > book_chat.py << 'EOF'
from memvid import MemvidEncoder, chat_with_memory
import os</p><h1>Votre fichier PDF</h1>
book_pdf = "book.pdf"  # Remplacez par le chemin de votre PDF</p><h1>Construire la mémoire vidéo</h1>
encoder = MemvidEncoder()
encoder.add_pdf(book_pdf)
encoder.build_video("book_memory.mp4", "book_index.json")</p><h1>Discuter avec le livre</h1>
api_key = os.getenv("OPENAI_API_KEY")  # Optionnel : pour les réponses IA</code></pre>python
chat_with_memory("book_memory.mp4", "book_index.json", api_key=api_key)
EOF</p><h1>4. Exécutez-le</h1>
export OPENAI_API_KEY="votre-clé-api"  # Optionnel
python book_chat.py
<pre><code class="language-">
<h2>🛠️ Configuration avancée</h2></p><h3>Embeddings personnalisés</code></pre>python</h3>
from sentence_transformers import SentenceTransformer</p><h1>Utiliser un modèle d'embedding personnalisé</h1>
custom_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
encoder = MemvidEncoder(embedding_model=custom_model)
<pre><code class="language-">
<h3>Optimisation vidéo</code></pre>python</h3>
<h1>Pour une compression maximale</h1>
encoder.build_video(
    "compressed.mp4",
    "index.json",
    fps=60,  # Plus d'images par seconde
    frame_size=256,  # Images plus petites
    video_codec='h265',  # Meilleure compression
    crf=28  # Qualité de compression (plus bas = meilleure qualité)
)
<pre><code class="language-">
<h3>Traitement distribué</code></pre>python</h3>
<h1>Traiter de grands ensembles de données en parallèle</h1>
encoder = MemvidEncoder(n_workers=8)
encoder.add_chunks_parallel(massive_chunk_list)
<pre><code class="language-">
<h2>🐛 Dépannage</h2></p><h3>Problèmes courants</h3></p><p><strong>ModuleNotFoundError: No module named 'memvid'</strong></code></pre>bash
<h1>Assurez-vous d'utiliser le bon Python</h1>
which python  # Doit afficher le chemin de votre environnement virtuel
<h1>Sinon, activez votre environnement virtuel :</h1>
source venv/bin/activate  # Sous Windows : venv\Scripts\activate
<pre><code class="language-">
<strong>ImportError: PyPDF2 is required for PDF support</strong></code></pre>bash
pip install PyPDF2
<pre><code class="language-">
<strong>Problèmes de clé API LLM</strong></code></pre>bash
<h1>Définir votre clé API (à obtenir sur https://platform.openai.com)</h1>
export GOOGLE_API_KEY="AIzaSyB1-..."  # macOS/Linux
<h1>Ou sous Windows :</h1>
set GOOGLE_API_KEY=AIzaSyB1-...
<pre><code class="language-">
<strong>Traitement de PDF volumineux</strong></code></pre>python
<h1>Pour les très gros PDF, utilisez des tailles de fragments plus petites</h1>
encoder = MemvidEncoder()
encoder.add_pdf("large_book.pdf", chunk_size=400, overlap=50)
<pre><code class="language-">
<h2>🤝 Contribuer</h2></p><p>Nous accueillons les contributions ! Veuillez consulter notre <a href="https://raw.githubusercontent.com/Olow304/memvid/main/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">Guide de contribution</a> pour plus de détails.
</code></pre>bash
<h1>Exécuter les tests</h1>
pytest tests/</p><h1>Exécuter avec la couverture</h1>
pytest --cov=memvid tests/</p><h1>Formater le code</h1>
black memvid/
<pre><code class="language-">
<h2>🆚 Comparaison avec les solutions traditionnelles</h2></p><p>| Fonctionnalité        | Memvid    | Bases de données vectorielles | Bases de données traditionnelles |
|----------------------|-----------|------------------------------|----------------------------------|
| Efficacité de stockage | ⭐⭐⭐⭐⭐    | ⭐⭐                          | ⭐⭐⭐                             |
| Complexité de mise en place | Simple | Complexe                     | Complexe                        |
| Recherche sémantique  | ✅        | ✅                           | ❌                              |
| Utilisation hors ligne| ✅        | ❌                           | ✅                              |
| Portabilité           | Basé sur fichier | Basé sur serveur             | Basé sur serveur                |
| Scalabilité           | Millions  | Millions                    | Milliards                       |
| Coût                  | Gratuit   | $$$$                        | $$$                             |</p><h2>📚 Exemples</h2></p><p>Consultez le répertoire <a href="https://raw.githubusercontent.com/Olow304/memvid/main/examples/" target="_blank" rel="noopener noreferrer">examples/</a> pour :
<ul><li>Construire une mémoire à partir de dumps Wikipedia</li>
<li>Créer une base de connaissances personnelle</li>
<li>Prise en charge multilingue</li>
<li>Mises à jour mémoire en temps réel</li>
<li>Intégration avec les LLMs populaires</li></p><p></ul><h2>🆘 Obtenir de l'aide</h2></p><ul><li>📖 <a href="https://github.com/olow304/memvid/wiki" target="_blank" rel="noopener noreferrer">Documentation</a> - Guides complets</li>
<li>💬 <a href="https://github.com/olow304/memvid/discussions" target="_blank" rel="noopener noreferrer">Discussions</a> - Posez vos questions</li>
<li>🐛 <a href="https://github.com/olow304/memvid/issues" target="_blank" rel="noopener noreferrer">Suivi des problèmes</a> - Signalez des bugs</li>
<li>🌟 <a href="https://github.com/olow304/memvid/discussions/categories/show-and-tell" target="_blank" rel="noopener noreferrer">Show & Tell</a> - Partagez vos projets</li></p><p></ul><h2>🔗 Liens</h2></p><ul><li><a href="https://github.com/olow304/memvid" target="_blank" rel="noopener noreferrer">Dépôt GitHub</a></li>
<li><a href="https://pypi.org/project/memvid" target="_blank" rel="noopener noreferrer">Paquet PyPI</a></li>
<li><a href="https://github.com/olow304/memvid/releases" target="_blank" rel="noopener noreferrer">Changelog</a></li></p><p>
</ul><h2>📄 Licence</h2></p><p>Licence MIT - voir le fichier <a href="https://raw.githubusercontent.com/Olow304/memvid/main/LICENSE" target="_blank" rel="noopener noreferrer">LICENSE</a> pour plus de détails.</p><h2>🙏 Remerciements</h2></p><p>Créé par <a href="https://github.com/olow304" target="_blank" rel="noopener noreferrer">Olow304</a> et la communauté Memvid.</p><p>Développé avec ❤️ grâce à :
<ul><li><a href="https://www.sbert.net/" target="_blank" rel="noopener noreferrer">sentence-transformers</a> - Embeddings de pointe pour la recherche sémantique</li>
<li><a href="https://opencv.org/" target="_blank" rel="noopener noreferrer">OpenCV</a> - Vision par ordinateur et traitement vidéo</li>
<li><a href="https://github.com/lincolnloop/python-qrcode" target="_blank" rel="noopener noreferrer">qrcode</a> - Génération de QR codes</li>
<li><a href="https://github.com/facebookresearch/faiss" target="_blank" rel="noopener noreferrer">FAISS</a> - Recherche de similarité efficace</li>
<li><a href="https://github.com/py-pdf/pypdf" target="_blank" rel="noopener noreferrer">PyPDF2</a> - Extraction de texte PDF</li></p><p></ul>Un grand merci à tous les contributeurs qui améliorent Memvid !</p><hr></p><p><strong>Prêt à révolutionner la gestion de la mémoire de votre IA ? Installez Memvid et commencez à bâtir !</strong> 🚀</code></pre>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-08

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Olow304/memvid/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>