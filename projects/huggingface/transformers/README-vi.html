<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>transformers - Read transformers documentation in Vietnamese. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read transformers documentation in Vietnamese. This project has 0 stars on GitHub.">
    <meta name="keywords" content="transformers, Vietnamese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "transformers",
  "description": "Read transformers documentation in Vietnamese. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "huggingface"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/huggingface/transformers/README-vi.html",
  "sameAs": "https://raw.githubusercontent.com/huggingface/transformers/master/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    transformers
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Vietnamese</span>
                <span>by huggingface</span>
            </div>
        </div>
        
        <div class="content">
            <p><!---
Bản quyền 2020 Nhóm HuggingFace. Đã đăng ký mọi quyền.</p><p>Được cấp phép theo Giấy phép Apache, Phiên bản 2.0 ("Giấy phép");
bạn không được sử dụng tệp này ngoại trừ tuân thủ Giấy phép.
Bạn có thể lấy một bản sao của Giấy phép tại</p><p>    http://www.apache.org/licenses/LICENSE-2.0</p><p>Trừ khi luật pháp yêu cầu hoặc được đồng ý bằng văn bản, phần mềm
phân phối theo Giấy phép này được phân phối "NGUYÊN TRẠNG",
KHÔNG CÓ BẤT KỲ BẢO ĐẢM NÀO, cả rõ ràng lẫn ngụ ý.
Xem Giấy phép để biết các quy định về quyền hạn và
giới hạn theo Giấy phép.
--></p><p><p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Thư viện Hugging Face Transformers" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p></p><p><p align="center">
    <a href="https://huggingface.com/models"><img alt="Checkpoints trên Hub" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen"></a>
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Tài liệu" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="Phát hành trên GitHub" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p></p><p><h4 align="center">
    <p>
        <b>English</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">简体中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">繁體中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">한국어</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">Español</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">日本語</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">हिन्दी</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">Русский</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">Рortuguês</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">తెలుగు</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">Français</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Tiếng Việt</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">العربية</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">اردو</a> |
    </p>
</h4></p><p><h3 align="center">
    <p>Mô hình pretrained tiên tiến nhất cho suy luận và huấn luyện</p>
</h3></p><p><h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3></p><p>Transformers là một thư viện các mô hình văn bản, thị giác máy tính, âm thanh, video và đa phương thức đã được huấn luyện sẵn cho mục đích suy luận và huấn luyện. Sử dụng Transformers để tinh chỉnh mô hình trên dữ liệu của bạn, xây dựng các ứng dụng suy luận và cho các trường hợp sử dụng AI tạo sinh trên nhiều phương thức khác nhau.</p><p>Có hơn 500.000+ <a href="https://huggingface.co/models?library=transformers&sort=trending" target="_blank" rel="noopener noreferrer">checkpoint mô hình</a> Transformers trên <a href="https://huggingface.com/models" target="_blank" rel="noopener noreferrer">Hugging Face Hub</a> mà bạn có thể sử dụng.</p><p>Khám phá <a href="https://huggingface.com/" target="_blank" rel="noopener noreferrer">Hub</a> ngay hôm nay để tìm một mô hình và sử dụng Transformers để bắt đầu ngay lập tức.</p><h2>Cài đặt</h2></p><p>Transformers làm việc với Python 3.9+ <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">PyTorch</a> 2.1+, <a href="https://www.tensorflow.org/install/pip" target="_blank" rel="noopener noreferrer">TensorFlow</a> 2.6+, và <a href="https://flax.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Flax</a> 0.4.1+.</p><p>Tạo và kích hoạt một môi trường ảo với <a href="https://docs.python.org/3/library/venv.html" target="_blank" rel="noopener noreferrer">venv</a> hoặc <a href="https://docs.astral.sh/uv/" target="_blank" rel="noopener noreferrer">uv</a>, một trình quản lý gói và dự án Python nhanh dựa trên Rust.</p><pre><code class="language-py"># venv
python -m venv .my-env
source .my-env/bin/activate
<h1>uv</h1>
uv venv .my-env
source .my-env/bin/activate</code></pre></p><p>Cài đặt Transformers trong môi trường ảo của bạn.</p><pre><code class="language-py"># pip
pip install "transformers[torch]"</p><h1>uv</h1>
uv pip install "transformers[torch]"</code></pre></p><p>Cài đặt Transformers từ mã nguồn nếu bạn muốn cập nhật những thay đổi mới nhất của thư viện hoặc có ý định đóng góp phát triển. Tuy nhiên, phiên bản <em>mới nhất</em> có thể không ổn định. Hãy mở <a href="https://github.com/huggingface/transformers/issues" target="_blank" rel="noopener noreferrer">issue</a> nếu bạn gặp lỗi.</p><pre><code class="language-shell">git clone https://github.com/huggingface/transformers.git
cd transformers</p><h1>pip</h1>
pip install .[torch]</p><h1>uv</h1>
uv pip install .[torch]</code></pre></p><h2>Khởi động nhanh</h2></p><p>Bắt đầu với Transformers ngay lập tức với API <a href="https://huggingface.co/docs/transformers/pipeline_tutorial" target="_blank" rel="noopener noreferrer">Pipeline</a>. <code>Pipeline</code> là một lớp suy luận cấp cao hỗ trợ các tác vụ văn bản, âm thanh, thị giác và đa phương thức. Nó xử lý tiền xử lý đầu vào và trả về đầu ra phù hợp.</p><p>Khởi tạo một pipeline và chỉ định mô hình sử dụng cho sinh văn bản. Mô hình sẽ được tải về và lưu vào bộ nhớ đệm để có thể sử dụng lại dễ dàng. Cuối cùng, truyền vào một đoạn văn bản để mô hình sinh kết quả.</p><pre><code class="language-py">from transformers import pipeline</p><p>pipeline = pipeline(task="text-generation", model="Qwen/Qwen2.5-1.5B")
pipeline("the secret to baking a really good cake is ")
[{'generated_text': 'the secret to baking a really good cake is 1) to use the right ingredients and 2) to follow the recipe exactly. the recipe for the cake is as follows: 1 cup of sugar, 1 cup of flour, 1 cup of milk, 1 cup of butter, 1 cup of eggs, 1 cup of chocolate chips. if you want to make 2 cakes, how much sugar do you need? To make 2 cakes, you will need 2 cups of sugar.'}]</code></pre></p><p>Để trò chuyện với một mô hình, cách sử dụng cũng tương tự. Sự khác biệt duy nhất là bạn cần xây dựng lịch sử hội thoại (đầu vào cho <code>Pipeline</code>) giữa bạn và hệ thống.</p><blockquote>[!TIP]</blockquote>
<blockquote>Bạn cũng có thể trò chuyện với mô hình trực tiếp từ dòng lệnh.</blockquote>
<blockquote><pre><code class="language-shell">> transformers chat Qwen/Qwen2.5-0.5B-Instruct</blockquote>
<blockquote>``<code></blockquote>
</code></pre>py
import torch
from transformers import pipeline</p><p>chat = [
    {"role": "system", "content": "Bạn là một robot hài hước, trả treo như tưởng tượng của Hollywood năm 1986."},
    {"role": "user", "content": "Này, bạn có thể gợi ý vài điều thú vị để làm ở New York không?"}
]</p><p>pipeline = pipeline(task="text-generation", model="meta-llama/Meta-Llama-3-8B-Instruct", torch_dtype=torch.bfloat16, device_map="auto")
response = pipeline(chat, max_new_tokens=512)
print(response[0]["generated_text"][-1]["content"])
<pre><code class="language-">
Mở rộng các ví dụ bên dưới để xem </code>Pipeline<code> hoạt động với các phương thức và tác vụ khác nhau như thế nào.</p><p><details>
<summary>Nhận diện giọng nói tự động</summary>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="automatic-speech-recognition", model="openai/whisper-large-v3")
pipeline("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
<pre><code class="language-">
</details></p><p><details>
<summary>Phân loại hình ảnh</summary></p><p><h3 align="center">
    <a><img src="https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="image-classification", model="facebook/dinov2-small-imagenet1k-1-layer")
pipeline("https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png")
[{'label': 'macaw', 'score': 0.997848391532898},
 {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',
  'score': 0.0016551691805943847},
 {'label': 'lorikeet', 'score': 0.00018523589824326336},
 {'label': 'African grey, African gray, Psittacus erithacus',
  'score': 7.85409429227002e-05},
 {'label': 'quail', 'score': 5.502637941390276e-05}]
<pre><code class="language-">
</details></p><p><details>
<summary>Hỏi đáp hình ảnh</summary></p><p>
<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="visual-question-answering", model="Salesforce/blip-vqa-base")
pipeline(
    image="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg",
    question="What is in the image?",
)
[{'answer': 'statue of liberty'}]
<pre><code class="language-">
</details></p><h2>Tại sao nên sử dụng Transformers?</h2></p><ul><li>Mô hình tiên tiến dễ sử dụng:</li>
    <li>Hiệu năng cao đối với các tác vụ hiểu & sinh ngôn ngữ tự nhiên, thị giác máy tính, âm thanh, video và đa phương thức.</li>
    <li>Giảm rào cản cho các nhà nghiên cứu, kỹ sư và lập trình viên.</li>
    <li>Chỉ cần học ba lớp trừu tượng hướng người dùng.</li>
    <li>API thống nhất cho tất cả các mô hình đã huấn luyện sẵn.</li></p><p><li>Giảm chi phí tính toán, giảm dấu chân carbon:</li>
    <li>Chia sẻ mô hình đã huấn luyện thay vì huấn luyện lại từ đầu.</li>
    <li>Giảm thời gian tính toán và chi phí sản xuất.</li>
    <li>Hàng chục kiến trúc mô hình với hơn 1 triệu checkpoint pretrained trên mọi phương thức.</li></p><p><li>Tự do chọn framework phù hợp cho mọi giai đoạn vòng đời mô hình:</li>
    <li>Huấn luyện mô hình tiên tiến chỉ với 3 dòng lệnh.</li>
    <li>Dễ dàng chuyển mô hình giữa PyTorch/JAX/TF2.0.</li>
    <li>Chọn framework phù hợp cho huấn luyện, đánh giá và sản xuất.</li></p><p><li>Dễ dàng tùy chỉnh mô hình hoặc ví dụ cho nhu cầu của bạn:</li>
    <li>Cung cấp ví dụ cho từng kiến trúc để tái tạo kết quả đã công bố.</li>
    <li>Lõi mô hình được lộ ra một cách nhất quán.</li>
    <li>File mô hình có thể dùng độc lập với thư viện để thử nghiệm nhanh.</li></p><p></ul><a target="_blank" href="https://huggingface.co/enterprise">
    <img alt="Hugging Face Enterprise Hub" src="https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925">
</a><br></p><h2>Khi nào KHÔNG nên sử dụng Transformers?</h2></p><ul><li>Thư viện này không phải là một bộ công cụ mô-đun các khối xây dựng mạng nơ-ron. Mã nguồn trong file mô hình không được tái cấu trúc với các trừu tượng bổ sung, nhằm giúp các nhà nghiên cứu có thể thử nghiệm nhanh trên từng mô hình mà không cần đi sâu vào nhiều lớp trừu tượng/file khác.</li>
<li>API huấn luyện được tối ưu để làm việc với mô hình PyTorch mà Transformers cung cấp. Nếu cần vòng lặp máy học tổng quát, bạn nên dùng thư viện khác như <a href="https://huggingface.co/docs/accelerate" target="_blank" rel="noopener noreferrer">Accelerate</a>.</li>
<li><a href="https://github.com/huggingface/transformers/tree/main/examples" target="_blank" rel="noopener noreferrer">Các script ví dụ</a> chỉ là <em>ví dụ</em>. Chúng có thể không hoạt động ngay với trường hợp sử dụng của bạn và bạn cần điều chỉnh lại mã nguồn.</li></p><p></ul><h2>100 dự án sử dụng Transformers</h2></p><p>Transformers không chỉ là một bộ công cụ sử dụng mô hình pretrained, mà còn là một cộng đồng các dự án xây dựng xung quanh nó và
Hugging Face Hub. Chúng tôi muốn Transformers giúp các lập trình viên, nhà nghiên cứu, sinh viên, giảng viên, kỹ sư, và bất kỳ ai khác xây dựng dự án mơ ước của họ.</p><p>Để kỷ niệm Transformers đạt 100.000 stars, chúng tôi muốn tôn vinh cộng đồng với trang <a href="./awesome-transformers.md" target="_blank" rel="noopener noreferrer">awesome-transformers</a> liệt kê 100 dự án tuyệt vời xây dựng bằng Transformers.</p><p>Nếu bạn sở hữu hoặc sử dụng một dự án xứng đáng nằm trong danh sách này, hãy mở PR để bổ sung nhé!</p><h2>Một số mô hình ví dụ</h2></p><p>Bạn có thể thử hầu hết các mô hình trực tiếp trên <a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">trang mô hình trên Hub</a>.</p><p>Mở rộng từng phương thức bên dưới để xem một số mô hình ví dụ cho các trường hợp sử dụng khác nhau.</p><p><details>
<summary>Âm thanh</summary></p><ul><li>Phân loại âm thanh với <a href="https://huggingface.co/openai/whisper-large-v3-turbo" target="_blank" rel="noopener noreferrer">Whisper</a></li>
<li>Nhận diện giọng nói tự động với <a href="https://huggingface.co/UsefulSensors/moonshine" target="_blank" rel="noopener noreferrer">Moonshine</a></li>
<li>Phát hiện từ khóa với <a href="https://huggingface.co/superb/wav2vec2-base-superb-ks" target="_blank" rel="noopener noreferrer">Wav2Vec2</a></li>
<li>Chuyển đổi lời nói sang lời nói với <a href="https://huggingface.co/kyutai/moshiko-pytorch-bf16" target="_blank" rel="noopener noreferrer">Moshi</a></li>
<li>Văn bản sang âm thanh với <a href="https://huggingface.co/facebook/musicgen-large" target="_blank" rel="noopener noreferrer">MusicGen</a></li>
<li>Văn bản sang giọng nói với <a href="https://huggingface.co/suno/bark" target="_blank" rel="noopener noreferrer">Bark</a></li></p><p></ul></details></p><p><details>
<summary>Thị giác máy tính</summary></p><ul><li>Sinh mặt nạ tự động với <a href="https://huggingface.co/facebook/sam-vit-base" target="_blank" rel="noopener noreferrer">SAM</a></li>
<li>Ước lượng độ sâu với <a href="https://huggingface.co/apple/DepthPro-hf" target="_blank" rel="noopener noreferrer">DepthPro</a></li>
<li>Phân loại hình ảnh với <a href="https://huggingface.co/facebook/dinov2-base" target="_blank" rel="noopener noreferrer">DINO v2</a></li>
<li>Phát hiện keypoint với <a href="https://huggingface.co/magic-leap-community/superglue_outdoor" target="_blank" rel="noopener noreferrer">SuperGlue</a></li>
<li>Ghép keypoint với <a href="https://huggingface.co/magic-leap-community/superglue" target="_blank" rel="noopener noreferrer">SuperGlue</a></li>
<li>Phát hiện vật thể với <a href="https://huggingface.co/PekingU/rtdetr_v2_r50vd" target="_blank" rel="noopener noreferrer">RT-DETRv2</a></li>
<li>Ước lượng tư thế với <a href="https://huggingface.co/usyd-community/vitpose-base-simple" target="_blank" rel="noopener noreferrer">VitPose</a></li>
<li>Phân đoạn đa năng với <a href="https://huggingface.co/shi-labs/oneformer_ade20k_swin_large" target="_blank" rel="noopener noreferrer">OneFormer</a></li>
<li>Phân loại video với <a href="https://huggingface.co/MCG-NJU/videomae-large" target="_blank" rel="noopener noreferrer">VideoMAE</a></li></p><p></ul></details></p><p><details>
<summary>Đa phương thức</summary></p><ul><li>Âm thanh hoặc văn bản sang văn bản với <a href="https://huggingface.co/Qwen/Qwen2-Audio-7B" target="_blank" rel="noopener noreferrer">Qwen2-Audio</a></li>
<li>Hỏi đáp tài liệu với <a href="https://huggingface.co/microsoft/layoutlmv3-base" target="_blank" rel="noopener noreferrer">LayoutLMv3</a></li>
<li>Hình ảnh hoặc văn bản sang văn bản với <a href="https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct" target="_blank" rel="noopener noreferrer">Qwen-VL</a></li>
<li>Sinh chú thích hình ảnh với <a href="https://huggingface.co/Salesforce/blip2-opt-2.7b" target="_blank" rel="noopener noreferrer">BLIP-2</a></li>
<li>Hiểu tài liệu dựa trên OCR với <a href="https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf" target="_blank" rel="noopener noreferrer">GOT-OCR2</a></li>
<li>Hỏi đáp bảng với <a href="https://huggingface.co/google/tapas-base" target="_blank" rel="noopener noreferrer">TAPAS</a></li>
<li>Hiểu và sinh đa phương thức thống nhất với <a href="https://huggingface.co/BAAI/Emu3-Gen" target="_blank" rel="noopener noreferrer">Emu3</a></li>
<li>Thị giác sang văn bản với <a href="https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf" target="_blank" rel="noopener noreferrer">Llava-OneVision</a></li>
<li>Hỏi đáp hình ảnh với <a href="https://huggingface.co/llava-hf/llava-1.5-7b-hf" target="_blank" rel="noopener noreferrer">Llava</a></li>
<li>Phân đoạn biểu thức tham chiếu hình ảnh với <a href="https://huggingface.co/microsoft/kosmos-2-patch14-224" target="_blank" rel="noopener noreferrer">Kosmos-2</a></li></p><p></ul></details></p><p><details>
<summary>Xử lý ngôn ngữ tự nhiên (NLP)</summary></p><ul><li>Điền từ thiếu với <a href="https://huggingface.co/answerdotai/ModernBERT-base" target="_blank" rel="noopener noreferrer">ModernBERT</a></li>
<li>Nhận diện thực thể có tên với <a href="https://huggingface.co/google/gemma-2-2b" target="_blank" rel="noopener noreferrer">Gemma</a></li>
<li>Hỏi đáp với <a href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1" target="_blank" rel="noopener noreferrer">Mixtral</a></li>
<li>Tóm tắt với <a href="https://huggingface.co/facebook/bart-large-cnn" target="_blank" rel="noopener noreferrer">BART</a></li>
<li>Dịch với <a href="https://huggingface.co/google-t5/t5-base" target="_blank" rel="noopener noreferrer">T5</a></li>
<li>Sinh văn bản với <a href="https://huggingface.co/meta-llama/Llama-3.2-1B" target="_blank" rel="noopener noreferrer">Llama</a></li>
<li>Phân loại văn bản với <a href="https://huggingface.co/Qwen/Qwen2.5-0.5B" target="_blank" rel="noopener noreferrer">Qwen</a></li></p><p></ul></details></p><h2>Trích dẫn</h2></p><p>Chúng tôi hiện đã có <a href="https://www.aclweb.org/anthology/2020.emnlp-demos.6/" target="_blank" rel="noopener noreferrer">bài báo</a> bạn có thể trích dẫn cho thư viện 🤗 Transformers:</code></pre>bibtex
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
</code>``

---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/huggingface/transformers/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>