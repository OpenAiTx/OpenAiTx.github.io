<!DOCTYPE html>
<html lang="nl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>transformers - Read transformers documentation in Dutch. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read transformers documentation in Dutch. This project has 0 stars on GitHub.">
    <meta name="keywords" content="transformers, Dutch, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "transformers",
  "description": "Read transformers documentation in Dutch. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "huggingface"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/huggingface/transformers/README-nl.html",
  "sameAs": "https://raw.githubusercontent.com/huggingface/transformers/master/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    transformers
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Dutch</span>
                <span>by huggingface</span>
            </div>
        </div>
        
        <div class="content">
            <p><!---
Copyright 2020 The HuggingFace Team. Alle rechten voorbehouden.</p><p>Gelicenseerd onder de Apache License, Version 2.0 (de "Licentie");
u mag dit bestand niet gebruiken behalve in overeenstemming met de Licentie.
U kunt een kopie van de Licentie verkrijgen op</p><p>    http://www.apache.org/licenses/LICENSE-2.0</p><p>Tenzij vereist door toepasselijk recht of schriftelijk overeengekomen, wordt software
gedistribueerd onder de Licentie op een "AS IS" BASIS,
ZONDER ENIGE GARANTIES OF VOORWAARDEN, expliciet of impliciet.
Zie de Licentie voor de specifieke taal die van toepassing is op
toestemmingen en beperkingen onder de Licentie.
--></p><p><p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Hugging Face Transformers Library" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p></p><p><p align="center">
    <a href="https://huggingface.com/models"><img alt="Checkpoints op Hub" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen"></a>
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Documentatie" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p></p><p><h4 align="center">
    <p>
        <b>English</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">简体中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">繁體中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">한국어</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">Español</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">日本語</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">हिन्दी</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">Русский</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">Рortuguês</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">తెలుగు</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">Français</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Tiếng Việt</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">العربية</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">اردو</a> |
    </p>
</h4></p><p><h3 align="center">
    <p>State-of-the-art voorgetrainde modellen voor inferentie en training</p>
</h3></p><p><h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3></p><p>Transformers is een bibliotheek van voorgetrainde tekst-, computer vision-, audio-, video- en multimodale modellen voor inferentie en training. Gebruik Transformers om modellen te fine-tunen op jouw data, inferentie-applicaties te bouwen, en voor generatieve AI-toepassingen over meerdere modaliteiten.</p><p>Er zijn meer dan 500K+ Transformers <a href="https://huggingface.co/models?library=transformers&sort=trending" target="_blank" rel="noopener noreferrer">model checkpoints</a> op de <a href="https://huggingface.com/models" target="_blank" rel="noopener noreferrer">Hugging Face Hub</a> die je kunt gebruiken.</p><p>Verken vandaag nog de <a href="https://huggingface.com/" target="_blank" rel="noopener noreferrer">Hub</a> om een model te vinden en gebruik Transformers om direct aan de slag te gaan.</p><h2>Installatie</h2></p><p>Transformers werkt met Python 3.9+ <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">PyTorch</a> 2.1+, <a href="https://www.tensorflow.org/install/pip" target="_blank" rel="noopener noreferrer">TensorFlow</a> 2.6+, en <a href="https://flax.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Flax</a> 0.4.1+.</p><p>Maak en activeer een virtuele omgeving met <a href="https://docs.python.org/3/library/venv.html" target="_blank" rel="noopener noreferrer">venv</a> of <a href="https://docs.astral.sh/uv/" target="_blank" rel="noopener noreferrer">uv</a>, een snelle Rust-gebaseerde package- en projectmanager voor Python.</p><pre><code class="language-py"># venv
python -m venv .my-env
source .my-env/bin/activate
<h1>uv</h1>
uv venv .my-env
source .my-env/bin/activate</code></pre></p><p>Installeer Transformers in je virtuele omgeving.</p><pre><code class="language-py"># pip
pip install "transformers[torch]"</p><h1>uv</h1>
uv pip install "transformers[torch]"</code></pre></p><p>Installeer Transformers vanaf de bron als je de laatste wijzigingen in de bibliotheek wilt hebben of wilt bijdragen. Houd er echter rekening mee dat de <em>laatste</em> versie mogelijk niet stabiel is. Voel je vrij om een <a href="https://github.com/huggingface/transformers/issues" target="_blank" rel="noopener noreferrer">issue</a> te openen als je een fout tegenkomt.</p><pre><code class="language-shell">git clone https://github.com/huggingface/transformers.git
cd transformers</p><h1>pip</h1>
pip install .[torch]</p><h1>uv</h1>
uv pip install .[torch]</code></pre></p><h2>Snelstart</h2></p><p>Begin direct met Transformers via de <a href="https://huggingface.co/docs/transformers/pipeline_tutorial" target="_blank" rel="noopener noreferrer">Pipeline</a> API. De <code>Pipeline</code> is een high-level inferentieklasse die tekst-, audio-, vision- en multimodale taken ondersteunt. Het verzorgt de preprocessing van de input en geeft de juiste output terug.</p><p>Maak een pipeline aan en geef het model op voor tekstgeneratie. Het model wordt gedownload en gecachet zodat je het gemakkelijk opnieuw kunt gebruiken. Geef vervolgens wat tekst om het model te laten starten.</p><pre><code class="language-py">from transformers import pipeline</p><p>pipeline = pipeline(task="text-generation", model="Qwen/Qwen2.5-1.5B")
pipeline("het geheim van het bakken van een echt goede taart is ")
[{'generated_text': 'het geheim van het bakken van een echt goede taart is 1) het gebruiken van de juiste ingrediënten en 2) het exact volgen van het recept. het recept voor de taart is als volgt: 1 kop suiker, 1 kop bloem, 1 kop melk, 1 kop boter, 1 kop eieren, 1 kop chocoladestukjes. als je 2 taarten wilt maken, hoeveel suiker heb je dan nodig? Om 2 taarten te maken heb je 2 kopjes suiker nodig.'}]</code></pre></p><p>Om met een model te chatten is het gebruikspatroon hetzelfde. Het enige verschil is dat je een chathistorie (de input voor <code>Pipeline</code>) moet opbouwen tussen jou en het systeem.</p><blockquote>[!TIP]</blockquote>
<blockquote>Je kunt ook rechtstreeks vanaf de commandoregel chatten met een model.</blockquote>
<blockquote><pre><code class="language-shell">> transformers chat Qwen/Qwen2.5-0.5B-Instruct</blockquote>
<blockquote>``<code></blockquote>
</code></pre>py
import torch
from transformers import pipeline</p><p>chat = [
    {"role": "system", "content": "Je bent een pittige, bijdehante robot zoals bedacht door Hollywood rond 1986."},
    {"role": "user", "content": "Hé, kun je me wat leuke dingen vertellen om te doen in New York?"}
]</p><p>pipeline = pipeline(task="text-generation", model="meta-llama/Meta-Llama-3-8B-Instruct", torch_dtype=torch.bfloat16, device_map="auto")
response = pipeline(chat, max_new_tokens=512)
print(response[0]["generated_text"][-1]["content"])
<pre><code class="language-">
Vouw de onderstaande voorbeelden uit om te zien hoe </code>Pipeline<code> werkt voor verschillende modaliteiten en taken.</p><p><details>
<summary>Automatische spraakherkenning</summary>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="automatic-speech-recognition", model="openai/whisper-large-v3")
pipeline("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
<pre><code class="language-">
</details></p><p><details>
<summary>Beeldclassificatie</summary></p><p><h3 align="center">
    <a><img src="https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="image-classification", model="facebook/dinov2-small-imagenet1k-1-layer")
pipeline("https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png")
[{'label': 'ara', 'score': 0.997848391532898},
 {'label': 'zwavelkuifkaketoe, Kakatoe galerita, Cacatua galerita',
  'score': 0.0016551691805943847},
 {'label': 'lorikeet', 'score': 0.00018523589824326336},
 {'label': 'grijze roodstaart, Psittacus erithacus',
  'score': 7.85409429227002e-05},
 {'label': 'kwartel', 'score': 5.502637941390276e-05}]
<pre><code class="language-">
</details></p><p><details>
<summary>Visueel vraag-antwoord</summary></p><p>
<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="visual-question-answering", model="Salesforce/blip-vqa-base")
pipeline(
    image="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg",
    question="Wat staat er op de afbeelding?",
)
[{'answer': 'vrijheidsbeeld'}]
<pre><code class="language-">
</details></p><h2>Waarom zou ik Transformers gebruiken?</h2></p><ul><li>Gebruiksvriendelijke state-of-the-art modellen:</li>
    <li>Hoge prestaties op natural language understanding & generation, computer vision, audio, video en multimodale taken.</li>
    <li>Lage instapdrempel voor onderzoekers, ingenieurs en ontwikkelaars.</li>
    <li>Weinig gebruikersgerichte abstracties met slechts drie klassen om te leren.</li>
    <li>Een uniforme API voor al onze voorgetrainde modellen.</li></p><p><li>Lagere rekenkosten, kleinere ecologische voetafdruk:</li>
    <li>Deel getrainde modellen in plaats van vanaf nul te trainen.</li>
    <li>Verminder rekentijd en productiekosten.</li>
    <li>Tientallen modelarchitecturen met 1M+ voorgetrainde checkpoints over alle modaliteiten.</li></p><p><li>Kies het juiste framework voor elk deel van de levenscyclus van een model:</li>
    <li>Train state-of-the-art modellen in 3 regels code.</li>
    <li>Verplaats een enkel model eenvoudig tussen PyTorch/JAX/TF2.0 frameworks.</li>
    <li>Kies het juiste framework voor training, evaluatie en productie.</li></p><p><li>Pas eenvoudig een model of voorbeeld aan je wensen aan:</li>
    <li>We bieden voorbeelden voor elke architectuur om de resultaten van de oorspronkelijke auteurs te reproduceren.</li>
    <li>De interne werking van modellen is zo consistent mogelijk toegankelijk gemaakt.</li>
    <li>Modelfiles kunnen onafhankelijk van de bibliotheek worden gebruikt voor snelle experimenten.</li></p><p></ul><a target="_blank" href="https://huggingface.co/enterprise">
    <img alt="Hugging Face Enterprise Hub" src="https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925">
</a><br></p><h2>Waarom zou ik Transformers niet gebruiken?</h2></p><ul><li>Deze bibliotheek is geen modulaire toolbox van bouwstenen voor neurale netwerken. De code in de modelbestanden is opzettelijk niet geherstructureerd met extra abstracties, zodat onderzoekers snel kunnen itereren op elk van de modellen zonder extra abstracties/bestanden.</li>
<li>De trainings-API is geoptimaliseerd om te werken met PyTorch-modellen die door Transformers worden geleverd. Voor algemene machine learning-loops kun je beter een andere bibliotheek zoals <a href="https://huggingface.co/docs/accelerate" target="_blank" rel="noopener noreferrer">Accelerate</a> gebruiken.</li>
<li>De <a href="(https://github.com/huggingface/transformers/tree/main/examples" target="_blank" rel="noopener noreferrer">voorbeeldscripts</a>) zijn slechts <em>voorbeelden</em>. Ze werken mogelijk niet direct voor jouw specifieke toepassing en je zult de code moeten aanpassen.</li></p><p></ul><h2>100 projecten die Transformers gebruiken</h2></p><p>Transformers is meer dan alleen een toolkit om voorgetrainde modellen te gebruiken; het is een community van projecten eromheen, samen met de Hugging Face Hub. We willen met Transformers ontwikkelaars, onderzoekers, studenten, docenten, ingenieurs en iedereen in staat stellen hun droomprojecten te bouwen.</p><p>Om Transformers' 100.000 sterren te vieren, wilden we de spotlight op de community zetten met de <a href="./awesome-transformers.md" target="_blank" rel="noopener noreferrer">awesome-transformers</a>-pagina, waarop 100 geweldige projecten staan die met Transformers zijn gebouwd.</p><p>Als je een project hebt of gebruikt dat volgens jou op de lijst hoort, open dan een PR om het toe te voegen!</p><h2>Voorbeeldmodellen</h2></p><p>Je kunt de meeste van onze modellen direct testen op hun <a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">Hub modelpagina's</a>.</p><p>Vouw elke modaliteit hieronder uit om enkele voorbeeldmodellen voor verschillende toepassingen te bekijken.</p><p><details>
<summary>Audio</summary></p><ul><li>Audioclassificatie met <a href="https://huggingface.co/openai/whisper-large-v3-turbo" target="_blank" rel="noopener noreferrer">Whisper</a></li>
<li>Automatische spraakherkenning met <a href="https://huggingface.co/UsefulSensors/moonshine" target="_blank" rel="noopener noreferrer">Moonshine</a></li>
<li>Keyword spotting met <a href="https://huggingface.co/superb/wav2vec2-base-superb-ks" target="_blank" rel="noopener noreferrer">Wav2Vec2</a></li>
<li>Spraak naar spraak generatie met <a href="https://huggingface.co/kyutai/moshiko-pytorch-bf16" target="_blank" rel="noopener noreferrer">Moshi</a></li>
<li>Tekst naar audio met <a href="https://huggingface.co/facebook/musicgen-large" target="_blank" rel="noopener noreferrer">MusicGen</a></li>
<li>Tekst naar spraak met <a href="https://huggingface.co/suno/bark" target="_blank" rel="noopener noreferrer">Bark</a></li></p><p></ul></details></p><p><details>
<summary>Computer vision</summary></p><ul><li>Automatische maskergeneratie met <a href="https://huggingface.co/facebook/sam-vit-base" target="_blank" rel="noopener noreferrer">SAM</a></li>
<li>Diepte-inschatting met <a href="https://huggingface.co/apple/DepthPro-hf" target="_blank" rel="noopener noreferrer">DepthPro</a></li>
<li>Beeldclassificatie met <a href="https://huggingface.co/facebook/dinov2-base" target="_blank" rel="noopener noreferrer">DINO v2</a></li>
<li>Keypoint-detectie met <a href="https://huggingface.co/magic-leap-community/superglue_outdoor" target="_blank" rel="noopener noreferrer">SuperGlue</a></li>
<li>Keypoint-matching met <a href="https://huggingface.co/magic-leap-community/superglue" target="_blank" rel="noopener noreferrer">SuperGlue</a></li>
<li>Objectdetectie met <a href="https://huggingface.co/PekingU/rtdetr_v2_r50vd" target="_blank" rel="noopener noreferrer">RT-DETRv2</a></li>
<li>Pose schatting met <a href="https://huggingface.co/usyd-community/vitpose-base-simple" target="_blank" rel="noopener noreferrer">VitPose</a></li>
<li>Universele segmentatie met <a href="https://huggingface.co/shi-labs/oneformer_ade20k_swin_large" target="_blank" rel="noopener noreferrer">OneFormer</a></li>
<li>Video classificatie met <a href="https://huggingface.co/MCG-NJU/videomae-large" target="_blank" rel="noopener noreferrer">VideoMAE</a></li></p><p></ul></details></p><p><details>
<summary>Multimodaal</summary></p><ul><li>Audio of tekst naar tekst met <a href="https://huggingface.co/Qwen/Qwen2-Audio-7B" target="_blank" rel="noopener noreferrer">Qwen2-Audio</a></li>
<li>Document vraag-antwoord met <a href="https://huggingface.co/microsoft/layoutlmv3-base" target="_blank" rel="noopener noreferrer">LayoutLMv3</a></li>
<li>Beeld of tekst naar tekst met <a href="https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct" target="_blank" rel="noopener noreferrer">Qwen-VL</a></li>
<li>Beeldbeschrijving met <a href="https://huggingface.co/Salesforce/blip2-opt-2.7b" target="_blank" rel="noopener noreferrer">BLIP-2</a></li>
<li>OCR-gebaseerd documentbegrip met <a href="https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf" target="_blank" rel="noopener noreferrer">GOT-OCR2</a></li>
<li>Tabelvraagbeantwoording met <a href="https://huggingface.co/google/tapas-base" target="_blank" rel="noopener noreferrer">TAPAS</a></li>
<li>Geünificeerd multimodaal begrip en generatie met <a href="https://huggingface.co/BAAI/Emu3-Gen" target="_blank" rel="noopener noreferrer">Emu3</a></li>
<li>Vision naar tekst met <a href="https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf" target="_blank" rel="noopener noreferrer">Llava-OneVision</a></li>
<li>Visueel vraag-antwoord met <a href="https://huggingface.co/llava-hf/llava-1.5-7b-hf" target="_blank" rel="noopener noreferrer">Llava</a></li>
<li>Visuele verwijzende expressie segmentatie met <a href="https://huggingface.co/microsoft/kosmos-2-patch14-224" target="_blank" rel="noopener noreferrer">Kosmos-2</a></li></p><p></ul></details></p><p><details>
<summary>NLP</summary></p><ul><li>Gemaskeerde woordaanvulling met <a href="https://huggingface.co/answerdotai/ModernBERT-base" target="_blank" rel="noopener noreferrer">ModernBERT</a></li>
<li>Naam entiteit herkenning met <a href="https://huggingface.co/google/gemma-2-2b" target="_blank" rel="noopener noreferrer">Gemma</a></li>
<li>Vraagbeantwoording met <a href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1" target="_blank" rel="noopener noreferrer">Mixtral</a></li>
<li>Samenvatten met <a href="https://huggingface.co/facebook/bart-large-cnn" target="_blank" rel="noopener noreferrer">BART</a></li>
<li>Vertalen met <a href="https://huggingface.co/google-t5/t5-base" target="_blank" rel="noopener noreferrer">T5</a></li>
<li>Tekstgeneratie met <a href="https://huggingface.co/meta-llama/Llama-3.2-1B" target="_blank" rel="noopener noreferrer">Llama</a></li>
<li>Tekstclassificatie met <a href="https://huggingface.co/Qwen/Qwen2.5-0.5B" target="_blank" rel="noopener noreferrer">Qwen</a></li></p><p></ul></details></p><h2>Citeren</h2></p><p>We hebben nu een <a href="https://www.aclweb.org/anthology/2020.emnlp-demos.6/" target="_blank" rel="noopener noreferrer">paper</a> die je kunt citeren voor de 🤗 Transformers-bibliotheek:</code></pre>bibtex
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
</code>``

---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/huggingface/transformers/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>