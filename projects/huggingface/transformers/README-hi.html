<!DOCTYPE html>
<html lang="hi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>transformers - Read transformers documentation in Hindi. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read transformers documentation in Hindi. This project has 0 stars on GitHub.">
    <meta name="keywords" content="transformers, Hindi, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "transformers",
  "description": "Read transformers documentation in Hindi. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "huggingface"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/huggingface/transformers/README-hi.html",
  "sameAs": "https://raw.githubusercontent.com/huggingface/transformers/master/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    transformers
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Hindi</span>
                <span>by huggingface</span>
            </div>
        </div>
        
        <div class="content">
            <p><!---
Copyright 2020 The HuggingFace Team. All rights reserved.</p><p>Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at</p><p>    http://www.apache.org/licenses/LICENSE-2.0</p><p>Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--></p><p><p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Hugging Face Transformers Library" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p></p><p><p align="center">
    <a href="https://huggingface.com/models"><img alt="Checkpoints on Hub" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen"></a>
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p></p><p><h4 align="center">
    <p>
        <b>English</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">简体中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">繁體中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">한국어</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">Español</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">日本語</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">हिन्दी</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">Русский</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">Рortuguês</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">తెలుగు</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">Français</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Tiếng Việt</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">العربية</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">اردو</a> |
    </p>
</h4></p><p><h3 align="center">
    <p>इन्फरेंस और ट्रेनिंग के लिए अत्याधुनिक प्रीट्रेंड मॉडल</p>
</h3></p><p><h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3></p><p>Transformers एक प्रीट्रेंड टेक्स्ट, कंप्यूटर विज़न, ऑडियो, वीडियो, और मल्टीमोडल मॉडल्स की लाइब्रेरी है, जिसका उपयोग इन्फरेंस और ट्रेनिंग के लिए किया जाता है। Transformers का उपयोग अपने डेटा पर मॉडल्स को फाइन-ट्यून करने, इन्फरेंस एप्लिकेशन बनाने, और मल्टीपल मोडैलिटी में जनरेटिव एआई उपयोग मामलों के लिए करें।</p><p><a href="https://huggingface.com/models" target="_blank" rel="noopener noreferrer">Hugging Face Hub</a> पर 500K+ से अधिक Transformers <a href="https://huggingface.co/models?library=transformers&sort=trending" target="_blank" rel="noopener noreferrer">मॉडल चेकपॉइंट्स</a> उपलब्ध हैं, जिनका आप उपयोग कर सकते हैं।</p><p>आज ही <a href="https://huggingface.com/" target="_blank" rel="noopener noreferrer">Hub</a> को एक्सप्लोर करें, कोई मॉडल खोजें और Transformers का उपयोग करके तुरंत शुरुआत करें।</p><h2>इंस्टॉलेशन</h2></p><p>Transformers, Python 3.9+ <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">PyTorch</a> 2.1+, <a href="https://www.tensorflow.org/install/pip" target="_blank" rel="noopener noreferrer">TensorFlow</a> 2.6+, और <a href="https://flax.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Flax</a> 0.4.1+ के साथ काम करता है।</p><p><a href="https://docs.python.org/3/library/venv.html" target="_blank" rel="noopener noreferrer">venv</a> या <a href="https://docs.astral.sh/uv/" target="_blank" rel="noopener noreferrer">uv</a> (एक तेज़ Rust-आधारित Python पैकेज और प्रोजेक्ट मैनेजर) से एक वर्चुअल एनवायरनमेंट बनाएँ और सक्रिय करें।</p><pre><code class="language-py"># venv
python -m venv .my-env
source .my-env/bin/activate
<h1>uv</h1>
uv venv .my-env
source .my-env/bin/activate</code></pre></p><p>अपने वर्चुअल एनवायरनमेंट में Transformers इंस्टॉल करें।</p><pre><code class="language-py"># pip
pip install "transformers[torch]"</p><h1>uv</h1>
uv pip install "transformers[torch]"</code></pre></p><p>यदि आप लाइब्रेरी में नवीनतम बदलाव चाहते हैं या योगदान देने में रुचि रखते हैं तो स्रोत से Transformers इंस्टॉल करें। हालाँकि, <em>नवीनतम</em> संस्करण स्थिर नहीं हो सकता है। यदि आपको कोई त्रुटि मिलती है तो बेझिझक <a href="https://github.com/huggingface/transformers/issues" target="_blank" rel="noopener noreferrer">issue</a> खोलें।</p><pre><code class="language-shell">git clone https://github.com/huggingface/transformers.git
cd transformers</p><h1>pip</h1>
pip install .[torch]</p><h1>uv</h1>
uv pip install .[torch]</code></pre></p><h2>क्विकस्टार्ट</h2></p><p><a href="https://huggingface.co/docs/transformers/pipeline_tutorial" target="_blank" rel="noopener noreferrer">Pipeline</a> API के साथ तुरंत Transformers का उपयोग शुरू करें। <code>Pipeline</code> एक उच्च स्तरीय इन्फरेंस क्लास है जो टेक्स्ट, ऑडियो, विज़न, और मल्टीमोडल टास्क्स को सपोर्ट करती है। यह इनपुट का प्रीप्रोसेसिंग संभालता है और उचित आउटपुट लौटाता है।</p><p>पाइपलाइन इंस्टैंसिएट करें और टेक्स्ट जनरेशन के लिए उपयोग होने वाला मॉडल स्पेसिफाई करें। मॉडल डाउनलोड और कैश हो जाता है ताकि आप इसे आसानी से फिर से उपयोग कर सकें। अंत में, मॉडल को प्रॉम्प्ट करने के लिए कुछ टेक्स्ट पास करें।</p><pre><code class="language-py">from transformers import pipeline</p><p>pipeline = pipeline(task="text-generation", model="Qwen/Qwen2.5-1.5B")
pipeline("the secret to baking a really good cake is ")
[{'generated_text': 'the secret to baking a really good cake is 1) to use the right ingredients and 2) to follow the recipe exactly. the recipe for the cake is as follows: 1 cup of sugar, 1 cup of flour, 1 cup of milk, 1 cup of butter, 1 cup of eggs, 1 cup of chocolate chips. if you want to make 2 cakes, how much sugar do you need? To make 2 cakes, you will need 2 cups of sugar.'}]</code></pre></p><p>किसी मॉडल के साथ चैट करने के लिए, उपयोग पैटर्न वही है। फर्क सिर्फ इतना है कि आपको अपने और सिस्टम के बीच एक चैट हिस्ट्री (जो <code>Pipeline</code> को इनपुट दी जाती है) बनानी होगी।</p><blockquote>[!TIP]</blockquote>
<blockquote>आप कमांड लाइन से भी सीधे किसी मॉडल के साथ चैट कर सकते हैं।</blockquote>
<blockquote><pre><code class="language-shell">> transformers chat Qwen/Qwen2.5-0.5B-Instruct</blockquote>
<blockquote>``<code></blockquote>
</code></pre>py
import torch
from transformers import pipeline</p><p>chat = [
    {"role": "system", "content": "You are a sassy, wise-cracking robot as imagined by Hollywood circa 1986."},
    {"role": "user", "content": "Hey, can you tell me any fun things to do in New York?"}
]</p><p>pipeline = pipeline(task="text-generation", model="meta-llama/Meta-Llama-3-8B-Instruct", torch_dtype=torch.bfloat16, device_map="auto")
response = pipeline(chat, max_new_tokens=512)
print(response[0]["generated_text"][-1]["content"])
<pre><code class="language-">
नीचे दिए गए उदाहरणों का विस्तार करें यह देखने के लिए कि </code>Pipeline<code> विभिन्न मोडैलिटी और कार्यों के लिए कैसे काम करता है।</p><p><details>
<summary>स्वचालित स्पीच रिकग्निशन</summary>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="automatic-speech-recognition", model="openai/whisper-large-v3")
pipeline("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
<pre><code class="language-">
</details></p><p><details>
<summary>इमेज क्लासिफिकेशन</summary></p><p><h3 align="center">
    <a><img src="https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="image-classification", model="facebook/dinov2-small-imagenet1k-1-layer")
pipeline("https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png")
[{'label': 'macaw', 'score': 0.997848391532898},
 {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',
  'score': 0.0016551691805943847},
 {'label': 'lorikeet', 'score': 0.00018523589824326336},
 {'label': 'African grey, African gray, Psittacus erithacus',
  'score': 7.85409429227002e-05},
 {'label': 'quail', 'score': 5.502637941390276e-05}]
<pre><code class="language-">
</details></p><p><details>
<summary>विज़ुअल क्वेश्चन आंसरिंग</summary></p><p>
<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="visual-question-answering", model="Salesforce/blip-vqa-base")
pipeline(
    image="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg",
    question="What is in the image?",
)
[{'answer': 'statue of liberty'}]
<pre><code class="language-">
</details></p><h2>मुझे Transformers का उपयोग क्यों करना चाहिए?</h2></p><ul><li>उपयोग में आसान अत्याधुनिक मॉडल्स:</li>
    <li>नेचुरल लैंग्वेज अंडरस्टैंडिंग और जनरेशन, कंप्यूटर विज़न, ऑडियो, वीडियो, और मल्टीमोडल टास्क्स में उच्च प्रदर्शन।</li>
    <li>शोधकर्ताओं, इंजीनियरों और डेवलपर्स के लिए कम बाधाएं।</li>
    <li>केवल तीन क्लासेस के साथ कम यूज़र-फेसिंग एब्स्ट्रैक्शन्स।</li>
    <li>हमारे सभी प्रीट्रेंड मॉडल्स के लिए एकीकृत API।</li></p><p><li>कम कंप्यूट लागत, छोटा कार्बन फुटप्रिंट:</li>
    <li>शुरुआत से ट्रेनिंग करने के बजाय ट्रेंड मॉडल्स साझा करें।</li>
    <li>कंप्यूट समय और प्रोडक्शन लागत कम करें।</li>
    <li>सभी मोडैलिटी में 1M+ प्रीट्रेंड चेकपॉइंट्स के साथ दर्जनों मॉडल आर्किटेक्चर।</li></p><p><li>मॉडल के जीवनकाल के हर हिस्से के लिए सही फ्रेमवर्क चुनें:</li>
    <li>3 लाइनों के कोड में अत्याधुनिक मॉडल्स को ट्रेन करें।</li>
    <li>एक ही मॉडल को PyTorch/JAX/TF2.0 फ्रेमवर्क्स के बीच इच्छानुसार मूव करें।</li>
    <li>ट्रेनिंग, मूल्यांकन और उत्पादन के लिए सही फ्रेमवर्क चुनें।</li></p><p><li>आसानी से किसी मॉडल या उदाहरण को अपनी आवश्यकता के अनुसार अनुकूलित करें:</li>
    <li>हम प्रत्येक आर्किटेक्चर के लिए ऐसे उदाहरण प्रदान करते हैं, जिससे आप मूल लेखकों द्वारा प्रकाशित परिणामों को पुन: उत्पन्न कर सकें।</li>
    <li>मॉडल इंटरनल्स को यथासंभव सुसंगत रूप से एक्सपोज़ किया गया है।</li>
    <li>त्वरित प्रयोगों के लिए मॉडल फाइल्स को लाइब्रेरी से स्वतंत्र रूप से उपयोग किया जा सकता है।</li></p><p></ul><a target="_blank" href="https://huggingface.co/enterprise">
    <img alt="Hugging Face Enterprise Hub" src="https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925">
</a><br></p><h2>मुझे Transformers का उपयोग क्यों नहीं करना चाहिए?</h2></p><ul><li>यह लाइब्रेरी न्यूरल नेट्स के लिए बिल्डिंग ब्लॉक्स का एक मॉड्यूलर टूलबॉक्स नहीं है। मॉडल फाइल्स में कोड को जानबूझकर अतिरिक्त एब्स्ट्रैक्शन्स के साथ रिफैक्टर नहीं किया गया है, ताकि शोधकर्ता प्रत्येक मॉडल पर जल्दी से काम कर सकें।</li>
<li>ट्रेनिंग API को विशेष रूप से Transformers द्वारा प्रदान किए गए PyTorch मॉडल्स के साथ काम करने के लिए ऑप्टिमाइज़ किया गया है। सामान्य मशीन लर्निंग लूप्स के लिए, आपको <a href="https://huggingface.co/docs/accelerate" target="_blank" rel="noopener noreferrer">Accelerate</a> जैसी अन्य लाइब्रेरी का उपयोग करना चाहिए।</li>
<li><a href="(https://github.com/huggingface/transformers/tree/main/examples" target="_blank" rel="noopener noreferrer">उदाहरण स्क्रिप्ट्स</a>) केवल <em>उदाहरण</em> हैं। वे जरूरी नहीं कि आपके विशिष्ट उपयोग मामले पर तुरंत काम करें, और आपको इसे काम करने के लिए कोड को अनुकूलित करना होगा।</li></p><p></ul><h2>Transformers का उपयोग करने वाले 100 प्रोजेक्ट्स</h2></p><p>Transformers केवल प्रीट्रेंड मॉडल्स का टूलकिट नहीं है, बल्कि यह इसके चारों ओर बने प्रोजेक्ट्स और Hugging Face Hub की एक कम्युनिटी है। हम चाहते हैं कि Transformers डेवलपर्स, शोधकर्ताओं, छात्रों, प्रोफेसरों, इंजीनियरों और अन्य सभी को उनके ड्रीम प्रोजेक्ट्स बनाने में सक्षम बनाए।</p><p>Transformers के 100,000 स्टार्स सेलिब्रेट करने के लिए, हम कम्युनिटी के <a href="./awesome-transformers.md" target="_blank" rel="noopener noreferrer">awesome-transformers</a> पेज पर बने 100 अद्भुत प्रोजेक्ट्स को उजागर करना चाहते हैं।</p><p>यदि आप किसी ऐसे प्रोजेक्ट के मालिक हैं या उपयोग करते हैं, जिसे आपको लगता है कि इस सूची का हिस्सा होना चाहिए, तो कृपया इसे जोड़ने के लिए PR खोलें!</p><h2>उदाहरण मॉडल्स</h2></p><p>आप हमारे अधिकांश मॉडल्स को सीधे उनके <a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">Hub मॉडल पेजेज़</a> पर टेस्ट कर सकते हैं।</p><p>नीचे प्रत्येक मोडैलिटी का विस्तार करें और विभिन्न उपयोग मामलों के लिए कुछ उदाहरण मॉडल्स देखें।</p><p><details>
<summary>ऑडियो</summary></p><ul><li><a href="https://huggingface.co/openai/whisper-large-v3-turbo" target="_blank" rel="noopener noreferrer">Whisper</a> के साथ ऑडियो क्लासिफिकेशन</li>
<li><a href="https://huggingface.co/UsefulSensors/moonshine" target="_blank" rel="noopener noreferrer">Moonshine</a> के साथ स्वचालित स्पीच रिकग्निशन</li>
<li><a href="https://huggingface.co/superb/wav2vec2-base-superb-ks" target="_blank" rel="noopener noreferrer">Wav2Vec2</a> के साथ कीवर्ड स्पॉटिंग</li>
<li><a href="https://huggingface.co/kyutai/moshiko-pytorch-bf16" target="_blank" rel="noopener noreferrer">Moshi</a> के साथ स्पीच टू स्पीच जनरेशन</li>
<li><a href="https://huggingface.co/facebook/musicgen-large" target="_blank" rel="noopener noreferrer">MusicGen</a> के साथ टेक्स्ट टू ऑडियो</li>
<li><a href="https://huggingface.co/suno/bark" target="_blank" rel="noopener noreferrer">Bark</a> के साथ टेक्स्ट टू स्पीच</li></p><p></ul></details></p><p><details>
<summary>कंप्यूटर विज़न</summary></p><ul><li><a href="https://huggingface.co/facebook/sam-vit-base" target="_blank" rel="noopener noreferrer">SAM</a> के साथ स्वचालित मास्क जनरेशन</li>
<li><a href="https://huggingface.co/apple/DepthPro-hf" target="_blank" rel="noopener noreferrer">DepthPro</a> के साथ डेप्थ एस्टीमेशन</li>
<li><a href="https://huggingface.co/facebook/dinov2-base" target="_blank" rel="noopener noreferrer">DINO v2</a> के साथ इमेज क्लासिफिकेशन</li>
<li><a href="https://huggingface.co/magic-leap-community/superglue_outdoor" target="_blank" rel="noopener noreferrer">SuperGlue</a> के साथ कीपॉइंट डिटेक्शन</li>
<li><a href="https://huggingface.co/magic-leap-community/superglue" target="_blank" rel="noopener noreferrer">SuperGlue</a> के साथ कीपॉइंट मैचिंग</li>
<li><a href="https://huggingface.co/PekingU/rtdetr_v2_r50vd" target="_blank" rel="noopener noreferrer">RT-DETRv2</a> के साथ ऑब्जेक्ट डिटेक्शन</li>
<li><a href="https://huggingface.co/usyd-community/vitpose-base-simple" target="_blank" rel="noopener noreferrer">VitPose</a> के साथ पोज़ एस्टीमेशन</li>
<li><a href="https://huggingface.co/shi-labs/oneformer_ade20k_swin_large" target="_blank" rel="noopener noreferrer">OneFormer</a> के साथ यूनिवर्सल सेगमेंटेशन</li>
<li><a href="https://huggingface.co/MCG-NJU/videomae-large" target="_blank" rel="noopener noreferrer">VideoMAE</a> के साथ वीडियो क्लासिफिकेशन</li></p><p></ul></details></p><p><details>
<summary>मल्टीमोडल</summary></p><ul><li><a href="https://huggingface.co/Qwen/Qwen2-Audio-7B" target="_blank" rel="noopener noreferrer">Qwen2-Audio</a> के साथ ऑडियो या टेक्स्ट टू टेक्स्ट</li>
<li><a href="https://huggingface.co/microsoft/layoutlmv3-base" target="_blank" rel="noopener noreferrer">LayoutLMv3</a> के साथ डॉक्युमेंट क्वेश्चन आंसरिंग</li>
<li><a href="https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct" target="_blank" rel="noopener noreferrer">Qwen-VL</a> के साथ इमेज या टेक्स्ट टू टेक्स्ट</li>
<li><a href="https://huggingface.co/Salesforce/blip2-opt-2.7b" target="_blank" rel="noopener noreferrer">BLIP-2</a> के साथ इमेज कैप्शनिंग</li>
<li><a href="https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf" target="_blank" rel="noopener noreferrer">GOT-OCR2</a> के साथ OCR-आधारित डॉक्युमेंट समझ</li>
<li><a href="https://huggingface.co/google/tapas-base" target="_blank" rel="noopener noreferrer">TAPAS</a> के साथ टेबल क्वेश्चन आंसरिंग</li>
<li><a href="https://huggingface.co/BAAI/Emu3-Gen" target="_blank" rel="noopener noreferrer">Emu3</a> के साथ एकीकृत मल्टीमोडल समझ और जनरेशन</li>
<li><a href="https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf" target="_blank" rel="noopener noreferrer">Llava-OneVision</a> के साथ विज़न टू टेक्स्ट</li>
<li><a href="https://huggingface.co/llava-hf/llava-1.5-7b-hf" target="_blank" rel="noopener noreferrer">Llava</a> के साथ विज़ुअल क्वेश्चन आंसरिंग</li>
<li><a href="https://huggingface.co/microsoft/kosmos-2-patch14-224" target="_blank" rel="noopener noreferrer">Kosmos-2</a> के साथ विज़ुअल रेफरिंग एक्सप्रेशन सेगमेंटेशन</li></p><p></ul></details></p><p><details>
<summary>NLP</summary></p><ul><li><a href="https://huggingface.co/answerdotai/ModernBERT-base" target="_blank" rel="noopener noreferrer">ModernBERT</a> के साथ मास्क्ड वर्ड कंप्लीशन</li>
<li><a href="https://huggingface.co/google/gemma-2-2b" target="_blank" rel="noopener noreferrer">Gemma</a> के साथ नामित इकाई पहचान</li>
<li><a href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1" target="_blank" rel="noopener noreferrer">Mixtral</a> के साथ क्वेश्चन आंसरिंग</li>
<li><a href="https://huggingface.co/facebook/bart-large-cnn" target="_blank" rel="noopener noreferrer">BART</a> के साथ समरीकरण</li>
<li><a href="https://huggingface.co/google-t5/t5-base" target="_blank" rel="noopener noreferrer">T5</a> के साथ अनुवाद</li>
<li><a href="https://huggingface.co/meta-llama/Llama-3.2-1B" target="_blank" rel="noopener noreferrer">Llama</a> के साथ टेक्स्ट जनरेशन</li>
<li><a href="https://huggingface.co/Qwen/Qwen2.5-0.5B" target="_blank" rel="noopener noreferrer">Qwen</a> के साथ टेक्स्ट क्लासिफिकेशन</li></p><p></ul></details></p><h2>संदर्भ</h2></p><p>अब हमारे पास 🤗 Transformers लाइब्रेरी के लिए एक <a href="https://www.aclweb.org/anthology/2020.emnlp-demos.6/" target="_blank" rel="noopener noreferrer">पेपर</a> है, जिसे आप संदर्भित कर सकते हैं:</code></pre>bibtex
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
</code>``

---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/huggingface/transformers/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>