<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>transformers - Read transformers documentation in Italian. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read transformers documentation in Italian. This project has 0 stars on GitHub.">
    <meta name="keywords" content="transformers, Italian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "transformers",
  "description": "Read transformers documentation in Italian. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "huggingface"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/huggingface/transformers/README-it.html",
  "sameAs": "https://raw.githubusercontent.com/huggingface/transformers/master/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    transformers
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Italian</span>
                <span>by huggingface</span>
            </div>
        </div>
        
        <div class="content">
            <p><!---
Copyright 2020 The HuggingFace Team. All rights reserved.</p><p>Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at</p><p>    http://www.apache.org/licenses/LICENSE-2.0</p><p>Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--></p><p><p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Hugging Face Transformers Library" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p></p><p><p align="center">
    <a href="https://huggingface.com/models"><img alt="Checkpoints on Hub" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen"></a>
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adottato-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p></p><p><h4 align="center">
    <p>
        <b>English</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">简体中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">繁體中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">한국어</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">Español</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">日本語</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">हिन्दी</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">Русский</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">Рortuguês</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">తెలుగు</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">Français</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Tiếng Việt</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">العربية</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">اردو</a> |
    </p>
</h4></p><p><h3 align="center">
    <p>Modelli preaddestrati all’avanguardia per inferenza e addestramento</p>
</h3></p><p><h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3></p><p>Transformers è una libreria di modelli preaddestrati per testo, visione artificiale, audio, video e multimodale per inferenza e addestramento. Usa Transformers per fare fine-tuning sui tuoi dati, costruire applicazioni di inferenza e per casi d’uso di AI generativa su diverse modalità.</p><p>Ci sono oltre 500.000+ <a href="https://huggingface.co/models?library=transformers&sort=trending" target="_blank" rel="noopener noreferrer">checkpoint di modelli Transformers</a> disponibili su <a href="https://huggingface.com/models" target="_blank" rel="noopener noreferrer">Hugging Face Hub</a>.</p><p>Esplora subito l’<a href="https://huggingface.com/" target="_blank" rel="noopener noreferrer">Hub</a> per trovare un modello e utilizzare Transformers per partire subito.</p><h2>Installazione</h2></p><p>Transformers funziona con Python 3.9+, <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">PyTorch</a> 2.1+, <a href="https://www.tensorflow.org/install/pip" target="_blank" rel="noopener noreferrer">TensorFlow</a> 2.6+ e <a href="https://flax.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Flax</a> 0.4.1+.</p><p>Crea e attiva un ambiente virtuale con <a href="https://docs.python.org/3/library/venv.html" target="_blank" rel="noopener noreferrer">venv</a> o <a href="https://docs.astral.sh/uv/" target="_blank" rel="noopener noreferrer">uv</a>, un veloce gestore di pacchetti e progetti Python basato su Rust.</p><pre><code class="language-py"># venv
python -m venv .my-env
source .my-env/bin/activate
<h1>uv</h1>
uv venv .my-env
source .my-env/bin/activate</code></pre></p><p>Installa Transformers nel tuo ambiente virtuale.</p><pre><code class="language-py"># pip
pip install "transformers[torch]"</p><h1>uv</h1>
uv pip install "transformers[torch]"</code></pre></p><p>Installa Transformers dal sorgente se vuoi le ultime modifiche nella libreria o se sei interessato a contribuire. Tuttavia, la versione <em>latest</em> potrebbe non essere stabile. Sentiti libero di aprire una <a href="https://github.com/huggingface/transformers/issues" target="_blank" rel="noopener noreferrer">issue</a> se riscontri un errore.</p><pre><code class="language-shell">git clone https://github.com/huggingface/transformers.git
cd transformers</p><h1>pip</h1>
pip install .[torch]</p><h1>uv</h1>
uv pip install .[torch]</code></pre></p><h2>Avvio rapido</h2></p><p>Inizia subito con Transformers grazie all’API <a href="https://huggingface.co/docs/transformers/pipeline_tutorial" target="_blank" rel="noopener noreferrer">Pipeline</a>. <code>Pipeline</code> è una classe di alto livello per l’inferenza che supporta attività su testo, audio, visione e multimodale. Si occupa del preprocessing dell’input e restituisce l’output appropriato.</p><p>Istanzia una pipeline e specifica il modello da usare per la generazione di testo. Il modello viene scaricato e memorizzato in cache così puoi riutilizzarlo facilmente. Infine, passa del testo per stimolare il modello.</p><pre><code class="language-py">from transformers import pipeline</p><p>pipeline = pipeline(task="text-generation", model="Qwen/Qwen2.5-1.5B")
pipeline("the secret to baking a really good cake is ")
[{'generated_text': 'the secret to baking a really good cake is 1) to use the right ingredients and 2) to follow the recipe exactly. the recipe for the cake is as follows: 1 cup of sugar, 1 cup of flour, 1 cup of milk, 1 cup of butter, 1 cup of eggs, 1 cup of chocolate chips. if you want to make 2 cakes, how much sugar do you need? To make 2 cakes, you will need 2 cups of sugar.'}]</code></pre></p><p>Per chattare con un modello, il pattern di utilizzo è lo stesso. L’unica differenza è che devi costruire una cronologia della chat (l’input per <code>Pipeline</code>) tra te e il sistema.</p><blockquote>[!TIP]</blockquote>
<blockquote>Puoi anche chattare con un modello direttamente dalla riga di comando.</blockquote>
<blockquote><pre><code class="language-shell">> transformers chat Qwen/Qwen2.5-0.5B-Instruct</blockquote>
<blockquote>``<code></blockquote>
</code></pre>py
import torch
from transformers import pipeline</p><p>chat = [
    {"role": "system", "content": "Sei un robot spiritoso e sarcastico come immaginato da Hollywood nel 1986."},
    {"role": "user", "content": "Ehi, puoi dirmi qualche cosa divertente da fare a New York?"}
]</p><p>pipeline = pipeline(task="text-generation", model="meta-llama/Meta-Llama-3-8B-Instruct", torch_dtype=torch.bfloat16, device_map="auto")
response = pipeline(chat, max_new_tokens=512)
print(response[0]["generated_text"][-1]["content"])
<pre><code class="language-">
Espandi gli esempi qui sotto per vedere come funziona </code>Pipeline<code> per diverse modalità e attività.</p><p><details>
<summary>Riconoscimento automatico del parlato</summary>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="automatic-speech-recognition", model="openai/whisper-large-v3")
pipeline("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
<pre><code class="language-">
</details></p><p><details>
<summary>Classificazione immagini</summary></p><p><h3 align="center">
    <a><img src="https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="image-classification", model="facebook/dinov2-small-imagenet1k-1-layer")
pipeline("https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png")
[{'label': 'macaw', 'score': 0.997848391532898},
 {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',
  'score': 0.0016551691805943847},
 {'label': 'lorikeet', 'score': 0.00018523589824326336},
 {'label': 'African grey, African gray, Psittacus erithacus',
  'score': 7.85409429227002e-05},
 {'label': 'quail', 'score': 5.502637941390276e-05}]
<pre><code class="language-">
</details></p><p><details>
<summary>Visual question answering</summary></p><p>
<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="visual-question-answering", model="Salesforce/blip-vqa-base")
pipeline(
    image="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg",
    question="What is in the image?",
)
[{'answer': 'statue of liberty'}]
<pre><code class="language-">
</details></p><h2>Perché dovrei usare Transformers?</h2></p><ul><li>Modelli all’avanguardia facili da usare:</li>
    <li>Alte prestazioni su comprensione e generazione del linguaggio naturale, visione artificiale, audio, video e attività multimodali.</li>
    <li>Basso livello di accesso per ricercatori, ingegneri e sviluppatori.</li>
    <li>Poche astrazioni rivolte all’utente con solo tre classi da imparare.</li>
    <li>API unificata per utilizzare tutti i nostri modelli preaddestrati.</li></p><p><li>Riduci i costi computazionali, minore impatto ambientale:</li>
    <li>Condividi modelli addestrati invece di addestrare da zero.</li>
    <li>Riduci il tempo di calcolo e i costi di produzione.</li>
    <li>Decine di architetture di modelli con oltre 1 milione di checkpoint preaddestrati su tutte le modalità.</li></p><p><li>Scegli il framework giusto per ogni fase del ciclo di vita di un modello:</li>
    <li>Addestra modelli all’avanguardia in 3 righe di codice.</li>
    <li>Sposta un singolo modello tra i framework PyTorch/JAX/TF2.0 a piacere.</li>
    <li>Scegli il framework adatto per addestramento, valutazione e produzione.</li></p><p><li>Personalizza facilmente un modello o un esempio secondo le tue esigenze:</li>
    <li>Forniamo esempi per ogni architettura per riprodurre i risultati pubblicati dagli autori originali.</li>
    <li>Gli interni dei modelli sono esposti in modo il più possibile coerente.</li>
    <li>I file dei modelli possono essere usati indipendentemente dalla libreria per esperimenti rapidi.</li></p><p></ul><a target="_blank" href="https://huggingface.co/enterprise">
    <img alt="Hugging Face Enterprise Hub" src="https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925">
</a><br></p><h2>Perché non dovrei usare Transformers?</h2></p><ul><li>Questa libreria non è una toolbox modulare di componenti per reti neurali. Il codice nei file dei modelli non è rifattorizzato con ulteriori astrazioni di proposito, così i ricercatori possono iterare rapidamente su ciascun modello senza immergersi in astrazioni/file aggiuntivi.</li>
<li>L’API di training è ottimizzata per funzionare con i modelli PyTorch forniti da Transformers. Per cicli generici di machine learning, dovresti usare un’altra libreria come <a href="https://huggingface.co/docs/accelerate" target="_blank" rel="noopener noreferrer">Accelerate</a>.</li>
<li>Gli <a href="(https://github.com/huggingface/transformers/tree/main/examples" target="_blank" rel="noopener noreferrer">script di esempio</a>) sono solo <em>esempi</em>. Potrebbero non funzionare subito per il tuo caso d’uso specifico e dovrai adattare il codice perché funzioni.</li></p><p></ul><h2>100 progetti che usano Transformers</h2></p><p>Transformers è più di un toolkit per usare modelli preaddestrati, è una comunità di progetti costruiti attorno ad esso e all’Hugging Face Hub. Vogliamo che Transformers consenta a sviluppatori, ricercatori, studenti, professori, ingegneri e chiunque altro di costruire i propri progetti da sogno.</p><p>Per celebrare le 100.000 stelle di Transformers, vogliamo mettere in luce la comunità con la pagina <a href="./awesome-transformers.md" target="_blank" rel="noopener noreferrer">awesome-transformers</a> che elenca 100 progetti incredibili costruiti con Transformers.</p><p>Se possiedi o usi un progetto che pensi debba far parte della lista, apri una PR per aggiungerlo!</p><h2>Modelli di esempio</h2></p><p>Puoi provare la maggior parte dei nostri modelli direttamente sulle loro <a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">pagine modello sul Hub</a>.</p><p>Espandi ogni modalità qui sotto per vedere alcuni modelli di esempio per vari casi d’uso.</p><p><details>
<summary>Audio</summary></p><ul><li>Classificazione audio con <a href="https://huggingface.co/openai/whisper-large-v3-turbo" target="_blank" rel="noopener noreferrer">Whisper</a></li>
<li>Riconoscimento automatico del parlato con <a href="https://huggingface.co/UsefulSensors/moonshine" target="_blank" rel="noopener noreferrer">Moonshine</a></li>
<li>Riconoscimento di parole chiave con <a href="https://huggingface.co/superb/wav2vec2-base-superb-ks" target="_blank" rel="noopener noreferrer">Wav2Vec2</a></li>
<li>Generazione da voce a voce con <a href="https://huggingface.co/kyutai/moshiko-pytorch-bf16" target="_blank" rel="noopener noreferrer">Moshi</a></li>
<li>Da testo ad audio con <a href="https://huggingface.co/facebook/musicgen-large" target="_blank" rel="noopener noreferrer">MusicGen</a></li>
<li>Da testo a parlato con <a href="https://huggingface.co/suno/bark" target="_blank" rel="noopener noreferrer">Bark</a></li></p><p></ul></details></p><p><details>
<summary>Visione artificiale</summary></p><ul><li>Generazione automatica di maschere con <a href="https://huggingface.co/facebook/sam-vit-base" target="_blank" rel="noopener noreferrer">SAM</a></li>
<li>Stima della profondità con <a href="https://huggingface.co/apple/DepthPro-hf" target="_blank" rel="noopener noreferrer">DepthPro</a></li>
<li>Classificazione immagini con <a href="https://huggingface.co/facebook/dinov2-base" target="_blank" rel="noopener noreferrer">DINO v2</a></li>
<li>Rilevamento di keypoint con <a href="https://huggingface.co/magic-leap-community/superglue_outdoor" target="_blank" rel="noopener noreferrer">SuperGlue</a></li>
<li>Associazione di keypoint con <a href="https://huggingface.co/magic-leap-community/superglue" target="_blank" rel="noopener noreferrer">SuperGlue</a></li>
<li>Rilevamento oggetti con <a href="https://huggingface.co/PekingU/rtdetr_v2_r50vd" target="_blank" rel="noopener noreferrer">RT-DETRv2</a></li>
<li>Stima delle pose con <a href="https://huggingface.co/usyd-community/vitpose-base-simple" target="_blank" rel="noopener noreferrer">VitPose</a></li>
<li>Segmentazione universale con <a href="https://huggingface.co/shi-labs/oneformer_ade20k_swin_large" target="_blank" rel="noopener noreferrer">OneFormer</a></li>
<li>Classificazione video con <a href="https://huggingface.co/MCG-NJU/videomae-large" target="_blank" rel="noopener noreferrer">VideoMAE</a></li></p><p></ul></details></p><p><details>
<summary>Multimodale</summary></p><ul><li>Da audio o testo a testo con <a href="https://huggingface.co/Qwen/Qwen2-Audio-7B" target="_blank" rel="noopener noreferrer">Qwen2-Audio</a></li>
<li>Domande su documenti con <a href="https://huggingface.co/microsoft/layoutlmv3-base" target="_blank" rel="noopener noreferrer">LayoutLMv3</a></li>
<li>Da immagine o testo a testo con <a href="https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct" target="_blank" rel="noopener noreferrer">Qwen-VL</a></li>
<li>Captioning immagini con <a href="https://huggingface.co/Salesforce/blip2-opt-2.7b" target="_blank" rel="noopener noreferrer">BLIP-2</a></li>
<li>Comprensione di documenti basata su OCR con <a href="https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf" target="_blank" rel="noopener noreferrer">GOT-OCR2</a></li>
<li>Domande su tabelle con <a href="https://huggingface.co/google/tapas-base" target="_blank" rel="noopener noreferrer">TAPAS</a></li>
<li>Comprensione e generazione multimodale unificata con <a href="https://huggingface.co/BAAI/Emu3-Gen" target="_blank" rel="noopener noreferrer">Emu3</a></li>
<li>Da visione a testo con <a href="https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf" target="_blank" rel="noopener noreferrer">Llava-OneVision</a></li>
<li>Visual question answering con <a href="https://huggingface.co/llava-hf/llava-1.5-7b-hf" target="_blank" rel="noopener noreferrer">Llava</a></li>
<li>Segmentazione di espressioni visive riferite con <a href="https://huggingface.co/microsoft/kosmos-2-patch14-224" target="_blank" rel="noopener noreferrer">Kosmos-2</a></li></p><p></ul></details></p><p><details>
<summary>NLP</summary></p><ul><li>Completamento di parole mascherate con <a href="https://huggingface.co/answerdotai/ModernBERT-base" target="_blank" rel="noopener noreferrer">ModernBERT</a></li>
<li>Riconoscimento di entità nominate con <a href="https://huggingface.co/google/gemma-2-2b" target="_blank" rel="noopener noreferrer">Gemma</a></li>
<li>Question answering con <a href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1" target="_blank" rel="noopener noreferrer">Mixtral</a></li>
<li>Sintesi con <a href="https://huggingface.co/facebook/bart-large-cnn" target="_blank" rel="noopener noreferrer">BART</a></li>
<li>Traduzione con <a href="https://huggingface.co/google-t5/t5-base" target="_blank" rel="noopener noreferrer">T5</a></li>
<li>Generazione di testo con <a href="https://huggingface.co/meta-llama/Llama-3.2-1B" target="_blank" rel="noopener noreferrer">Llama</a></li>
<li>Classificazione di testo con <a href="https://huggingface.co/Qwen/Qwen2.5-0.5B" target="_blank" rel="noopener noreferrer">Qwen</a></li></p><p></ul></details></p><h2>Citazione</h2></p><p>Ora abbiamo un <a href="https://www.aclweb.org/anthology/2020.emnlp-demos.6/" target="_blank" rel="noopener noreferrer">paper</a> che puoi citare per la libreria 🤗 Transformers:</code></pre>bibtex
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
</code>``

---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/huggingface/transformers/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>