<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>transformers - Read transformers documentation in Simplified Chinese. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read transformers documentation in Simplified Chinese. This project has 0 stars on GitHub.">
    <meta name="keywords" content="transformers, Simplified Chinese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "transformers",
  "description": "Read transformers documentation in Simplified Chinese. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "huggingface"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/huggingface/transformers/README-zh-CN.html",
  "sameAs": "https://raw.githubusercontent.com/huggingface/transformers/master/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    transformers
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Simplified Chinese</span>
                <span>by huggingface</span>
            </div>
        </div>
        
        <div class="content">
            <p><!---
Copyright 2020 The HuggingFace Team. All rights reserved.</p><p>Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at</p><p>    http://www.apache.org/licenses/LICENSE-2.0</p><p>Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--></p><p><p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Hugging Face Transformers Library" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p></p><p><p align="center">
    <a href="https://huggingface.com/models"><img alt="Checkpoints on Hub" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen"></a>
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p></p><p><h4 align="center">
    <p>
        <b>English</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">简体中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">繁體中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">한국어</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">Español</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">日本語</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">हिन्दी</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">Русский</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">Рortuguês</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">తెలుగు</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">Français</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Tiếng Việt</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">العربية</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">اردو</a> |
    </p>
</h4></p><p><h3 align="center">
    <p>最先进的预训练模型，适用于推理和训练</p>
</h3></p><p><h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3></p><p>Transformers 是一个包含预训练文本、计算机视觉、音频、视频及多模态模型的库，可用于推理和训练。使用 Transformers 可以在你的数据上微调模型，构建推理应用，并支持多模态生成式 AI 应用场景。</p><p>在 <a href="https://huggingface.com/models" target="_blank" rel="noopener noreferrer">Hugging Face Hub</a> 上有超过 50 万个 Transformers <a href="https://huggingface.co/models?library=transformers&sort=trending" target="_blank" rel="noopener noreferrer">模型检查点</a> 可供使用。</p><p>立即探索 <a href="https://huggingface.com/" target="_blank" rel="noopener noreferrer">Hub</a>，查找合适的模型，用 Transformers 帮助你立刻开始。</p><h2>安装</h2></p><p>Transformers 支持 Python 3.9+，<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">PyTorch</a> 2.1+，<a href="https://www.tensorflow.org/install/pip" target="_blank" rel="noopener noreferrer">TensorFlow</a> 2.6+，以及 <a href="https://flax.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Flax</a> 0.4.1+。</p><p>推荐使用 <a href="https://docs.python.org/3/library/venv.html" target="_blank" rel="noopener noreferrer">venv</a> 或 <a href="https://docs.astral.sh/uv/" target="_blank" rel="noopener noreferrer">uv</a>，即基于 Rust 的快速 Python 包和项目管理器，创建并激活虚拟环境。</p><pre><code class="language-py"># venv
python -m venv .my-env
source .my-env/bin/activate
<h1>uv</h1>
uv venv .my-env
source .my-env/bin/activate</code></pre></p><p>在你的虚拟环境中安装 Transformers。</p><pre><code class="language-py"># pip
pip install "transformers[torch]"</p><h1>uv</h1>
uv pip install "transformers[torch]"</code></pre></p><p>如果你希望体验库中最新的更改或者有意参与贡献，可以从源码安装 Transformers。但<em>最新</em>版本可能不稳定。如果遇到错误，欢迎提交 <a href="https://github.com/huggingface/transformers/issues" target="_blank" rel="noopener noreferrer">issue</a>。</p><pre><code class="language-shell">git clone https://github.com/huggingface/transformers.git
cd transformers</p><h1>pip</h1>
pip install .[torch]</p><h1>uv</h1>
uv pip install .[torch]</code></pre></p><h2>快速开始</h2></p><p>通过 <a href="https://huggingface.co/docs/transformers/pipeline_tutorial" target="_blank" rel="noopener noreferrer">Pipeline</a> API 立即开始使用 Transformers。<code>Pipeline</code> 是一个高级推理类，支持文本、音频、视觉和多模态任务。它自动处理输入的预处理并返回相应的输出。</p><p>实例化一个 pipeline，并指定用于文本生成的模型。模型会被下载并缓存，方便你后续重复使用。最后，传入一些文本以提示模型。</p><pre><code class="language-py">from transformers import pipeline</p><p>pipeline = pipeline(task="text-generation", model="Qwen/Qwen2.5-1.5B")
pipeline("the secret to baking a really good cake is ")
[{'generated_text': 'the secret to baking a really good cake is 1) to use the right ingredients and 2) to follow the recipe exactly. the recipe for the cake is as follows: 1 cup of sugar, 1 cup of flour, 1 cup of milk, 1 cup of butter, 1 cup of eggs, 1 cup of chocolate chips. if you want to make 2 cakes, how much sugar do you need? To make 2 cakes, you will need 2 cups of sugar.'}]</code></pre></p><p>与模型进行对话的用法也是一样的。唯一的区别是你需要构建一段对话历史（即 <code>Pipeline</code> 的输入），包括你和系统之间的对话。</p><blockquote>[!TIP]</blockquote>
<blockquote>你也可以直接从命令行与模型对话。</blockquote>
<blockquote><pre><code class="language-shell">> transformers chat Qwen/Qwen2.5-0.5B-Instruct</blockquote>
<blockquote>``<code></blockquote>
</code></pre>py
import torch
from transformers import pipeline</p><p>chat = [
    {"role": "system", "content": "你是一个好斗、机智、爱吐槽的机器人，风格如 1986 年好莱坞电影中的形象。"},
    {"role": "user", "content": "嘿，你能告诉我在纽约有什么有趣的事情可以做吗？"}
]</p><p>pipeline = pipeline(task="text-generation", model="meta-llama/Meta-Llama-3-8B-Instruct", torch_dtype=torch.bfloat16, device_map="auto")
response = pipeline(chat, max_new_tokens=512)
print(response[0]["generated_text"][-1]["content"])
<pre><code class="language-">
展开下方示例，了解 </code>Pipeline<code> 在不同模态和任务下的使用方式。</p><p><details>
<summary>自动语音识别</summary>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="automatic-speech-recognition", model="openai/whisper-large-v3")
pipeline("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
<pre><code class="language-">
</details></p><p><details>
<summary>图像分类</summary></p><p><h3 align="center">
    <a><img src="https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="image-classification", model="facebook/dinov2-small-imagenet1k-1-layer")
pipeline("https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png")
[{'label': 'macaw', 'score': 0.997848391532898},
 {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',
  'score': 0.0016551691805943847},
 {'label': 'lorikeet', 'score': 0.00018523589824326336},
 {'label': 'African grey, African gray, Psittacus erithacus',
  'score': 7.85409429227002e-05},
 {'label': 'quail', 'score': 5.502637941390276e-05}]
<pre><code class="language-">
</details></p><p><details>
<summary>视觉问答</summary></p><p>
<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="visual-question-answering", model="Salesforce/blip-vqa-base")
pipeline(
    image="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg",
    question="图片里是什么？",
)
[{'answer': 'statue of liberty'}]
<pre><code class="language-">
</details></p><h2>为什么要使用 Transformers？</h2></p><ul><li>易于使用的最先进模型：</li>
    <li>在自然语言理解与生成、计算机视觉、音频、视频和多模态任务上表现优异。</li>
    <li>研究人员、工程师和开发者易于上手。</li>
    <li>仅需学习三个用户相关的抽象类。</li>
    <li>提供统一的 API 使用所有预训练模型。</li></p><p><li>降低计算成本，减少碳足迹：</li>
    <li>共享训练好的模型，无需从零开始训练。</li>
    <li>减少计算时间和生产成本。</li>
    <li>数十种模型架构，跨所有模态有超过 100 万个预训练检查点。</li></p><p><li>为模型生命周期的每一步选择合适的框架：</li>
    <li>用三行代码训练最先进的模型。</li>
    <li>可随意在 PyTorch/JAX/TF2.0 框架之间迁移同一个模型。</li>
    <li>针对训练、评估和生产选择合适的框架。</li></p><p><li>轻松定制模型或示例以满足你的需求：</li>
    <li>我们为每个架构提供示例，帮助你复现原作者发布的结果。</li>
    <li>尽可能保持模型内部结构一致性开放。</li>
    <li>模型文件可独立于库使用，便于快速实验。</li></p><p></ul><a target="_blank" href="https://huggingface.co/enterprise">
    <img alt="Hugging Face Enterprise Hub" src="https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925">
</a><br></p><h2>为什么不应该使用 Transformers？</h2></p><ul><li>本库不是神经网络的模块化构建工具箱。模型文件中的代码故意未引入额外抽象，便于研究人员直接迭代每个模型，无需深入额外抽象/文件。</li>
<li>训练 API 针对 Transformers 提供的 PyTorch 模型进行了优化。如需通用的机器学习循环，建议使用 <a href="https://huggingface.co/docs/accelerate" target="_blank" rel="noopener noreferrer">Accelerate</a> 等其他库。</li>
<li><a href="(https://github.com/huggingface/transformers/tree/main/examples" target="_blank" rel="noopener noreferrer">示例脚本</a>) 仅为<em>示例</em>。它们未必能直接应用于你的具体场景，你需要自行调整代码以适配。</li></p><p></ul><h2>100 个基于 Transformers 的项目</h2></p><p>Transformers 不仅仅是一个预训练模型工具包，更是一个围绕 Hugging Face Hub 构建的社区。我们希望 Transformers 能帮助开发者、研究员、学生、教授、工程师及所有人实现他们的理想项目。</p><p>为庆祝 Transformers 获得 10 万星，我们特别推出了 <a href="./awesome-transformers.md" target="_blank" rel="noopener noreferrer">awesome-transformers</a> 页面，列出了 100 个用 Transformers 构建的杰出项目。</p><p>如果你拥有或使用的项目认为值得上榜，请提交 PR 添加它！</p><h2>示例模型</h2></p><p>你可以直接在 <a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">Hub 模型页面</a> 测试我们的大多数模型。</p><p>展开下方每个模态，查看不同应用场景下的部分示例模型。</p><p><details>
<summary>音频</summary></p><ul><li>使用 <a href="https://huggingface.co/openai/whisper-large-v3-turbo" target="_blank" rel="noopener noreferrer">Whisper</a> 进行音频分类</li>
<li>使用 <a href="https://huggingface.co/UsefulSensors/moonshine" target="_blank" rel="noopener noreferrer">Moonshine</a> 进行自动语音识别</li>
<li>使用 <a href="https://huggingface.co/superb/wav2vec2-base-superb-ks" target="_blank" rel="noopener noreferrer">Wav2Vec2</a> 进行关键词检测</li>
<li>使用 <a href="https://huggingface.co/kyutai/moshiko-pytorch-bf16" target="_blank" rel="noopener noreferrer">Moshi</a> 进行语音到语音生成</li>
<li>使用 <a href="https://huggingface.co/facebook/musicgen-large" target="_blank" rel="noopener noreferrer">MusicGen</a> 文本生成音频</li>
<li>使用 <a href="https://huggingface.co/suno/bark" target="_blank" rel="noopener noreferrer">Bark</a> 文本转语音</li></p><p></ul></details></p><p><details>
<summary>计算机视觉</summary></p><ul><li>使用 <a href="https://huggingface.co/facebook/sam-vit-base" target="_blank" rel="noopener noreferrer">SAM</a> 自动生成掩码</li>
<li>使用 <a href="https://huggingface.co/apple/DepthPro-hf" target="_blank" rel="noopener noreferrer">DepthPro</a> 进行深度估计</li>
<li>使用 <a href="https://huggingface.co/facebook/dinov2-base" target="_blank" rel="noopener noreferrer">DINO v2</a> 进行图像分类</li>
<li>使用 <a href="https://huggingface.co/magic-leap-community/superglue_outdoor" target="_blank" rel="noopener noreferrer">SuperGlue</a> 关键点检测</li>
<li>使用 <a href="https://huggingface.co/magic-leap-community/superglue" target="_blank" rel="noopener noreferrer">SuperGlue</a> 关键点匹配</li>
<li>使用 <a href="https://huggingface.co/PekingU/rtdetr_v2_r50vd" target="_blank" rel="noopener noreferrer">RT-DETRv2</a> 目标检测</li>
<li>使用 <a href="https://huggingface.co/usyd-community/vitpose-base-simple" target="_blank" rel="noopener noreferrer">VitPose</a> 姿态估计</li>
<li>使用 <a href="https://huggingface.co/shi-labs/oneformer_ade20k_swin_large" target="_blank" rel="noopener noreferrer">OneFormer</a> 通用分割</li>
<li>使用 <a href="https://huggingface.co/MCG-NJU/videomae-large" target="_blank" rel="noopener noreferrer">VideoMAE</a> 视频分类</li></p><p></ul></details></p><p><details>
<summary>多模态</summary></p><ul><li>使用 <a href="https://huggingface.co/Qwen/Qwen2-Audio-7B" target="_blank" rel="noopener noreferrer">Qwen2-Audio</a> 音频或文本转文本</li>
<li>使用 <a href="https://huggingface.co/microsoft/layoutlmv3-base" target="_blank" rel="noopener noreferrer">LayoutLMv3</a> 文档问答</li>
<li>使用 <a href="https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct" target="_blank" rel="noopener noreferrer">Qwen-VL</a> 图像或文本转文本</li>
<li>使用 <a href="https://huggingface.co/Salesforce/blip2-opt-2.7b" target="_blank" rel="noopener noreferrer">BLIP-2</a> 图像描述生成</li>
<li>使用 <a href="https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf" target="_blank" rel="noopener noreferrer">GOT-OCR2</a> 基于 OCR 的文档理解</li>
<li>使用 <a href="https://huggingface.co/google/tapas-base" target="_blank" rel="noopener noreferrer">TAPAS</a> 表格问答</li>
<li>使用 <a href="https://huggingface.co/BAAI/Emu3-Gen" target="_blank" rel="noopener noreferrer">Emu3</a> 统一多模态理解与生成</li>
<li>使用 <a href="https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf" target="_blank" rel="noopener noreferrer">Llava-OneVision</a> 视觉转文本</li>
<li>使用 <a href="https://huggingface.co/llava-hf/llava-1.5-7b-hf" target="_blank" rel="noopener noreferrer">Llava</a> 视觉问答</li>
<li>使用 <a href="https://huggingface.co/microsoft/kosmos-2-patch14-224" target="_blank" rel="noopener noreferrer">Kosmos-2</a> 视觉指表达分割</li></p><p></ul></details></p><p><details>
<summary>NLP</summary></p><ul><li>使用 <a href="https://huggingface.co/answerdotai/ModernBERT-base" target="_blank" rel="noopener noreferrer">ModernBERT</a> 掩码词填充</li>
<li>使用 <a href="https://huggingface.co/google/gemma-2-2b" target="_blank" rel="noopener noreferrer">Gemma</a> 命名实体识别</li>
<li>使用 <a href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1" target="_blank" rel="noopener noreferrer">Mixtral</a> 问答</li>
<li>使用 <a href="https://huggingface.co/facebook/bart-large-cnn" target="_blank" rel="noopener noreferrer">BART</a> 摘要生成</li>
<li>使用 <a href="https://huggingface.co/google-t5/t5-base" target="_blank" rel="noopener noreferrer">T5</a> 翻译</li>
<li>使用 <a href="https://huggingface.co/meta-llama/Llama-3.2-1B" target="_blank" rel="noopener noreferrer">Llama</a> 文本生成</li>
<li>使用 <a href="https://huggingface.co/Qwen/Qwen2.5-0.5B" target="_blank" rel="noopener noreferrer">Qwen</a> 文本分类</li></p><p></ul></details></p><h2>引用</h2></p><p>我们现在有一篇可用于引用 🤗 Transformers 库的 <a href="https://www.aclweb.org/anthology/2020.emnlp-demos.6/" target="_blank" rel="noopener noreferrer">论文</a>：</code></pre>bibtex
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
</code>``

---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/huggingface/transformers/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>