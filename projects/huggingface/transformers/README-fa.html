<!DOCTYPE html>
<html lang="fa">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>transformers - Read transformers documentation in Persian. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read transformers documentation in Persian. This project has 0 stars on GitHub.">
    <meta name="keywords" content="transformers, Persian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "transformers",
  "description": "Read transformers documentation in Persian. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "huggingface"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/huggingface/transformers/README-fa.html",
  "sameAs": "https://raw.githubusercontent.com/huggingface/transformers/master/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    transformers
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Persian</span>
                <span>by huggingface</span>
            </div>
        </div>
        
        <div class="content">
            <p><!---
Copyright 2020 The HuggingFace Team. All rights reserved.</p><p>تحت مجوز آپاچی نسخه ۲.۰ (مجوز)؛
شما نمی‌توانید از این فایل استفاده کنید مگر طبق شرایط مجوز.
شما می‌توانید یک نسخه از مجوز را در آدرس زیر دریافت کنید:</p><p>    http://www.apache.org/licenses/LICENSE-2.0</p><p>مگر در مواردی که طبق قوانین لازم‌الاجرا یا به صورت مکتوب توافق شده باشد، نرم‌افزار
توزیع‌شده تحت این مجوز به صورت "همان‌گونه که هست" ارائه می‌شود،
بدون هیچ‌گونه ضمانت، چه به صورت صریح و چه ضمنی.
برای مشاهده مجوز مربوط به مجوزها و محدودیت‌ها به مجوز مراجعه کنید.
--></p><p><p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="کتابخانه ترنسفورمرز هاجینگ‌فیس" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p></p><p><p align="center">
    <a href="https://huggingface.com/models"><img alt="چک‌پوینت‌ها در هاب" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen"></a>
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="بیلد" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="گیت‌هاب" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="مستندات" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="انتشار گیت‌هاب" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p></p><p><h4 align="center">
    <p>
        <b>English</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">简体中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">繁體中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">한국어</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">Español</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">日本語</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">हिन्दी</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">Русский</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">Рortuguês</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">తెలుగు</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">Français</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Tiếng Việt</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">العربية</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">اردو</a> |
    </p>
</h4></p><p><h3 align="center">
    <p>مدل‌های پیش‌آموزش دیده پیشرفته برای استنتاج و آموزش</p>
</h3></p><p><h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3></p><p>ترنسفورمرز یک کتابخانه از مدل‌های پیش‌آموزش دیده متنی، بینایی کامپیوتری، صوتی، ویدئویی و چندوجهی برای استنتاج و آموزش است. از ترنسفورمرز برای ریزتنظیم مدل‌ها بر داده‌های خود، ساخت برنامه‌های استنتاج و استفاده در موارد هوش مصنوعی مولد در چندین حوزه استفاده کنید.</p><p>بیش از ۵۰۰ هزار <a href="https://huggingface.co/models?library=transformers&sort=trending" target="_blank" rel="noopener noreferrer">چک‌پوینت مدل</a> در <a href="https://huggingface.com/models" target="_blank" rel="noopener noreferrer">هاب هاجینگ‌فیس</a> وجود دارد که می‌توانید استفاده کنید.</p><p>امروز <a href="https://huggingface.com/" target="_blank" rel="noopener noreferrer">هاب</a> را بررسی کنید تا یک مدل پیدا کنید و با ترنسفورمرز کار خود را فوراً شروع کنید.</p><h2>نصب</h2></p><p>ترنسفورمرز با Python 3.9+، <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">PyTorch</a> 2.1+، <a href="https://www.tensorflow.org/install/pip" target="_blank" rel="noopener noreferrer">TensorFlow</a> 2.6+ و <a href="https://flax.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Flax</a> 0.4.1+ کار می‌کند.</p><p>یک محیط مجازی با <a href="https://docs.python.org/3/library/venv.html" target="_blank" rel="noopener noreferrer">venv</a> یا <a href="https://docs.astral.sh/uv/" target="_blank" rel="noopener noreferrer">uv</a> ایجاد و فعال کنید؛ uv یک مدیر بسته و پروژه پایتون مبتنی بر Rust است.</p><pre><code class="language-py"># venv
python -m venv .my-env
source .my-env/bin/activate
<h1>uv</h1>
uv venv .my-env
source .my-env/bin/activate</code></pre></p><p>ترنسفورمرز را در محیط مجازی خود نصب کنید.</p><pre><code class="language-py"># pip
pip install "transformers[torch]"</p><h1>uv</h1>
uv pip install "transformers[torch]"</code></pre></p><p>اگر مایل به دریافت آخرین تغییرات در کتابخانه هستید یا می‌خواهید مشارکت کنید، ترنسفورمرز را از سورس نصب کنید. با این حال، نسخه <em>جدیدترین</em> ممکن است پایدار نباشد. اگر با خطایی مواجه شدید، می‌توانید یک <a href="https://github.com/huggingface/transformers/issues" target="_blank" rel="noopener noreferrer">issue</a> باز کنید.</p><pre><code class="language-shell">git clone https://github.com/huggingface/transformers.git
cd transformers</p><h1>pip</h1>
pip install .[torch]</p><h1>uv</h1>
uv pip install .[torch]</code></pre></p><h2>شروع سریع</h2></p><p>با API <a href="https://huggingface.co/docs/transformers/pipeline_tutorial" target="_blank" rel="noopener noreferrer">Pipeline</a> بلافاصله با ترنسفورمرز شروع به کار کنید. <code>Pipeline</code> یک کلاس استنتاج سطح بالا است که از وظایف متنی، صوتی، تصویری و چندوجهی پشتیبانی می‌کند. این کلاس پیش‌پردازش ورودی را انجام می‌دهد و خروجی مناسب را بازمی‌گرداند.</p><p>یک پایپ‌لاین نمونه‌سازی کنید و مدل مورد استفاده را برای تولید متن مشخص کنید. مدل دانلود و کش می‌شود تا به راحتی بتوانید مجدداً از آن استفاده کنید. در نهایت، متنی را برای مدل ارسال کنید.</p><pre><code class="language-py">from transformers import pipeline</p><p>pipeline = pipeline(task="text-generation", model="Qwen/Qwen2.5-1.5B")
pipeline("the secret to baking a really good cake is ")
[{'generated_text': 'the secret to baking a really good cake is 1) to use the right ingredients and 2) to follow the recipe exactly. the recipe for the cake is as follows: 1 cup of sugar, 1 cup of flour, 1 cup of milk, 1 cup of butter, 1 cup of eggs, 1 cup of chocolate chips. if you want to make 2 cakes, how much sugar do you need? To make 2 cakes, you will need 2 cups of sugar.'}]</code></pre></p><p>برای چت با یک مدل، الگوی استفاده مشابه است. تنها تفاوت این است که باید یک تاریخچه چت (ورودی به <code>Pipeline</code>) بین خود و سیستم بسازید.</p><blockquote>[!TIP]</blockquote>
<blockquote>شما همچنین می‌توانید مستقیماً از خط فرمان با مدل چت کنید.</blockquote>
<blockquote><pre><code class="language-shell">> transformers chat Qwen/Qwen2.5-0.5B-Instruct</blockquote>
<blockquote>``<code></blockquote>
</code></pre>py
import torch
from transformers import pipeline</p><p>chat = [
    {"role": "system", "content": "شما یک ربات شوخ‌طبع و حاضر جواب هستید که هالیوود در سال ۱۹۸۶ تصور کرده است."},
    {"role": "user", "content": "سلام، می‌تونی چند کار سرگرم‌کننده در نیویورک پیشنهاد بدی؟"}
]</p><p>pipeline = pipeline(task="text-generation", model="meta-llama/Meta-Llama-3-8B-Instruct", torch_dtype=torch.bfloat16, device_map="auto")
response = pipeline(chat, max_new_tokens=512)
print(response[0]["generated_text"][-1]["content"])
<pre><code class="language-">
برای مشاهده نحوه کارکرد </code>Pipeline<code> برای حوزه‌ها و وظایف مختلف، مثال‌های زیر را گسترش دهید.</p><p><details>
<summary>شناسایی خودکار گفتار</summary>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="automatic-speech-recognition", model="openai/whisper-large-v3")
pipeline("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
<pre><code class="language-">
</details></p><p><details>
<summary>رده‌بندی تصویر</summary></p><p><h3 align="center">
    <a><img src="https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="image-classification", model="facebook/dinov2-small-imagenet1k-1-layer")
pipeline("https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png")
[{'label': 'macaw', 'score': 0.997848391532898},
 {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',
  'score': 0.0016551691805943847},
 {'label': 'lorikeet', 'score': 0.00018523589824326336},
 {'label': 'African grey, African gray, Psittacus erithacus',
  'score': 7.85409429227002e-05},
 {'label': 'quail', 'score': 5.502637941390276e-05}]
<pre><code class="language-">
</details></p><p><details>
<summary>پاسخ به پرسش تصویری</summary></p><p>
<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="visual-question-answering", model="Salesforce/blip-vqa-base")
pipeline(
    image="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg",
    question="What is in the image?",
)
[{'answer': 'statue of liberty'}]
<pre><code class="language-">
</details></p><h2>چرا باید از ترنسفورمرز استفاده کنم؟</h2></p><ul><li>مدل‌های پیشرفته و آسان برای استفاده:</li>
    <li>عملکرد بالا در درک و تولید زبان طبیعی، بینایی کامپیوتری، صوت، ویدئو و وظایف چندوجهی.</li>
    <li>سد ورود پایین برای پژوهشگران، مهندسان و توسعه‌دهندگان.</li>
    <li>تنها سه کلاس برای یادگیری با انتزاع‌های کاربرپسند کم.</li>
    <li>یک API یکپارچه برای استفاده از تمامی مدل‌های پیش‌آموزش دیده.</li></p><p><li>هزینه محاسبات پایین‌تر، ردپای کربنی کمتر:</li>
    <li>به اشتراک‌گذاری مدل‌های آموزش‌دیده به جای آموزش از ابتدا.</li>
    <li>کاهش زمان محاسباتی و هزینه‌های تولید.</li>
    <li>ده‌ها معماری مدل با بیش از ۱ میلیون چک‌پوینت پیش‌آموزش دیده در همه حوزه‌ها.</li></p><p><li>انتخاب چارچوب مناسب برای هر بخش از چرخه عمر مدل:</li>
    <li>آموزش مدل‌های پیشرفته تنها در ۳ خط کد.</li>
    <li>انتقال یک مدل میان چارچوب‌های PyTorch/JAX/TF2.0 به دلخواه.</li>
    <li>انتخاب چارچوب مناسب برای آموزش، ارزیابی و تولید.</li></p><p><li>سفارشی‌سازی آسان مدل یا مثال متناسب با نیازهای شما:</li>
    <li>برای هر معماری مثال‌هایی جهت بازتولید نتایج نویسندگان اصلی ارائه شده است.</li>
    <li>ساختار داخلی مدل‌ها تا حد ممکن شفاف ارائه شده است.</li>
    <li>فایل‌های مدل می‌توانند مستقل از کتابخانه برای آزمایش‌های سریع استفاده شوند.</li></p><p></ul><a target="_blank" href="https://huggingface.co/enterprise">
    <img alt="هاب سازمانی هاجینگ‌فیس" src="https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925">
</a><br></p><h2>چرا نباید از ترنسفورمرز استفاده کنم؟</h2></p><ul><li>این کتابخانه یک جعبه ابزار ماژولار برای ساخت شبکه‌های عصبی نیست. کد فایل‌های مدل عمداً با انتزاع‌های اضافی بازنویسی نشده است تا پژوهشگران بتوانند سریعاً بر روی هر مدل بدون ورود به لایه‌های انتزاعی اضافی/فایل‌های دیگر تکرار و آزمایش کنند.</li>
<li>API آموزش برای کار با مدل‌های PyTorch ارائه شده توسط ترنسفورمرز بهینه شده است. برای حلقه‌های یادگیری ماشین عمومی، باید از کتابخانه دیگری مانند <a href="https://huggingface.co/docs/accelerate" target="_blank" rel="noopener noreferrer">Accelerate</a> استفاده کنید.</li>
<li><a href="https://github.com/huggingface/transformers/tree/main/examples" target="_blank" rel="noopener noreferrer">اسکریپت‌های نمونه</a> تنها <em>مثال</em> هستند. ممکن است به صورت آماده برای مورد استفاده خاص شما کار نکنند و نیاز به تطبیق کد برای کاربرد خود دارید.</li></p><p></ul><h2>۱۰۰ پروژه با استفاده از ترنسفورمرز</h2></p><p>ترنسفورمرز صرفاً یک ابزار برای استفاده از مدل‌های پیش‌آموزش دیده نیست، بلکه جامعه‌ای از پروژه‌ها حول آن و هاب هاجینگ‌فیس است. ما می‌خواهیم ترنسفورمرز به توسعه‌دهندگان، پژوهشگران، دانشجویان، اساتید، مهندسان و هر فرد دیگری کمک کند تا پروژه رؤیایی خود را بسازند.</p><p>برای جشن گرفتن ۱۰۰ هزار ستاره ترنسفورمرز، می‌خواستیم با صفحه <a href="./awesome-transformers.md" target="_blank" rel="noopener noreferrer">awesome-transformers</a> به پروژه‌های شگفت‌انگیز جامعه که با ترنسفورمرز ساخته شده‌اند بپردازیم.</p><p>اگر مالک یا کاربر پروژه‌ای هستید که فکر می‌کنید باید در این فهرست باشد، لطفاً یک PR باز کنید تا اضافه شود!</p><h2>مدل‌های نمونه</h2></p><p>می‌توانید اکثر مدل‌های ما را مستقیماً در صفحات مدل <a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">هاب</a> تست کنید.</p><p>برای مشاهده مدل‌های نمونه حوزه‌های مختلف، هر بخش را گسترش دهید.</p><p><details>
<summary>صوت</summary></p><ul><li>رده‌بندی صوت با <a href="https://huggingface.co/openai/whisper-large-v3-turbo" target="_blank" rel="noopener noreferrer">Whisper</a></li>
<li>شناسایی خودکار گفتار با <a href="https://huggingface.co/UsefulSensors/moonshine" target="_blank" rel="noopener noreferrer">Moonshine</a></li>
<li>تشخیص واژه کلیدی با <a href="https://huggingface.co/superb/wav2vec2-base-superb-ks" target="_blank" rel="noopener noreferrer">Wav2Vec2</a></li>
<li>تولید گفتار به گفتار با <a href="https://huggingface.co/kyutai/moshiko-pytorch-bf16" target="_blank" rel="noopener noreferrer">Moshi</a></li>
<li>متن به صوت با <a href="https://huggingface.co/facebook/musicgen-large" target="_blank" rel="noopener noreferrer">MusicGen</a></li>
<li>متن به گفتار با <a href="https://huggingface.co/suno/bark" target="_blank" rel="noopener noreferrer">Bark</a></li></p><p></ul></details></p><p><details>
<summary>بینایی کامپیوتری</summary></p><ul><li>تولید ماسک خودکار با <a href="https://huggingface.co/facebook/sam-vit-base" target="_blank" rel="noopener noreferrer">SAM</a></li>
<li>تخمین عمق با <a href="https://huggingface.co/apple/DepthPro-hf" target="_blank" rel="noopener noreferrer">DepthPro</a></li>
<li>رده‌بندی تصویر با <a href="https://huggingface.co/facebook/dinov2-base" target="_blank" rel="noopener noreferrer">DINO v2</a></li>
<li>تشخیص نقاط کلیدی با <a href="https://huggingface.co/magic-leap-community/superglue_outdoor" target="_blank" rel="noopener noreferrer">SuperGlue</a></li>
<li>تطبیق نقاط کلیدی با <a href="https://huggingface.co/magic-leap-community/superglue" target="_blank" rel="noopener noreferrer">SuperGlue</a></li>
<li>شناسایی اشیاء با <a href="https://huggingface.co/PekingU/rtdetr_v2_r50vd" target="_blank" rel="noopener noreferrer">RT-DETRv2</a></li>
<li>تخمین وضعیت بدن با <a href="https://huggingface.co/usyd-community/vitpose-base-simple" target="_blank" rel="noopener noreferrer">VitPose</a></li>
<li>بخش‌بندی سراسری با <a href="https://huggingface.co/shi-labs/oneformer_ade20k_swin_large" target="_blank" rel="noopener noreferrer">OneFormer</a></li>
<li>رده‌بندی ویدئو با <a href="https://huggingface.co/MCG-NJU/videomae-large" target="_blank" rel="noopener noreferrer">VideoMAE</a></li></p><p></ul></details></p><p><details>
<summary>چندوجهی</summary></p><ul><li>صوت یا متن به متن با <a href="https://huggingface.co/Qwen/Qwen2-Audio-7B" target="_blank" rel="noopener noreferrer">Qwen2-Audio</a></li>
<li>پاسخ به پرسش متنی اسناد با <a href="https://huggingface.co/microsoft/layoutlmv3-base" target="_blank" rel="noopener noreferrer">LayoutLMv3</a></li>
<li>تصویر یا متن به متن با <a href="https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct" target="_blank" rel="noopener noreferrer">Qwen-VL</a></li>
<li>شرح تصویر با <a href="https://huggingface.co/Salesforce/blip2-opt-2.7b" target="_blank" rel="noopener noreferrer">BLIP-2</a></li>
<li>درک اسناد مبتنی بر OCR با <a href="https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf" target="_blank" rel="noopener noreferrer">GOT-OCR2</a></li>
<li>پاسخ به پرسش جدولی با <a href="https://huggingface.co/google/tapas-base" target="_blank" rel="noopener noreferrer">TAPAS</a></li>
<li>درک و تولید چندوجهی یکپارچه با <a href="https://huggingface.co/BAAI/Emu3-Gen" target="_blank" rel="noopener noreferrer">Emu3</a></li>
<li>بینایی به متن با <a href="https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf" target="_blank" rel="noopener noreferrer">Llava-OneVision</a></li>
<li>پاسخ به پرسش تصویری با <a href="https://huggingface.co/llava-hf/llava-1.5-7b-hf" target="_blank" rel="noopener noreferrer">Llava</a></li>
<li>بخش‌بندی اشاره بصری با <a href="https://huggingface.co/microsoft/kosmos-2-patch14-224" target="_blank" rel="noopener noreferrer">Kosmos-2</a></li></p><p></ul></details></p><p><details>
<summary>پردازش زبان طبیعی (NLP)</summary></p><ul><li>تکمیل واژه مخفی با <a href="https://huggingface.co/answerdotai/ModernBERT-base" target="_blank" rel="noopener noreferrer">ModernBERT</a></li>
<li>تشخیص موجودیت نام‌دار با <a href="https://huggingface.co/google/gemma-2-2b" target="_blank" rel="noopener noreferrer">Gemma</a></li>
<li>پاسخ به پرسش با <a href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1" target="_blank" rel="noopener noreferrer">Mixtral</a></li>
<li>خلاصه‌سازی با <a href="https://huggingface.co/facebook/bart-large-cnn" target="_blank" rel="noopener noreferrer">BART</a></li>
<li>ترجمه با <a href="https://huggingface.co/google-t5/t5-base" target="_blank" rel="noopener noreferrer">T5</a></li>
<li>تولید متن با <a href="https://huggingface.co/meta-llama/Llama-3.2-1B" target="_blank" rel="noopener noreferrer">Llama</a></li>
<li>رده‌بندی متن با <a href="https://huggingface.co/Qwen/Qwen2.5-0.5B" target="_blank" rel="noopener noreferrer">Qwen</a></li></p><p></ul></details></p><h2>ارجاع</h2></p><p>اکنون یک <a href="https://www.aclweb.org/anthology/2020.emnlp-demos.6/" target="_blank" rel="noopener noreferrer">مقاله</a> برای کتابخانه 🤗 Transformers داریم که می‌توانید به آن ارجاع دهید:</code></pre>bibtex
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
</code>``</p><p>
---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/huggingface/transformers/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>