<!DOCTYPE html>
<html lang="id">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>transformers - Read transformers documentation in Indonesian. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read transformers documentation in Indonesian. This project has 0 stars on GitHub.">
    <meta name="keywords" content="transformers, Indonesian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "transformers",
  "description": "Read transformers documentation in Indonesian. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "huggingface"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/huggingface/transformers/README-id.html",
  "sameAs": "https://raw.githubusercontent.com/huggingface/transformers/master/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    transformers
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Indonesian</span>
                <span>by huggingface</span>
            </div>
        </div>
        
        <div class="content">
            <p><!---
Copyright 2020 The HuggingFace Team. All rights reserved.</p><p>Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at</p><p>    http://www.apache.org/licenses/LICENSE-2.0</p><p>Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--></p><p><p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Hugging Face Transformers Library" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p></p><p><p align="center">
    <a href="https://huggingface.com/models"><img alt="Checkpoints on Hub" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen"></a>
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p></p><p><h4 align="center">
    <p>
        <b>English</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">简体中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">繁體中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">한국어</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">Español</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">日本語</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">हिन्दी</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">Русский</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">Рortuguês</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">తెలుగు</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">Français</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Tiếng Việt</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">العربية</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">اردو</a> |
    </p>
</h4></p><p><h3 align="center">
    <p>Model pralatih mutakhir untuk inferensi dan pelatihan</p>
</h3></p><p><h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3></p><p>Transformers adalah pustaka model pralatih untuk teks, computer vision, audio, video, dan multimodal untuk inferensi dan pelatihan. Gunakan Transformers untuk fine-tuning model pada data Anda, membangun aplikasi inferensi, dan untuk berbagai kasus penggunaan AI generatif di banyak modalitas.</p><p>Terdapat lebih dari 500K+ <a href="https://huggingface.co/models?library=transformers&sort=trending" target="_blank" rel="noopener noreferrer">checkpoint model Transformers</a> di <a href="https://huggingface.com/models" target="_blank" rel="noopener noreferrer">Hugging Face Hub</a> yang dapat Anda gunakan.</p><p>Jelajahi <a href="https://huggingface.com/" target="_blank" rel="noopener noreferrer">Hub</a> hari ini untuk menemukan model dan gunakan Transformers agar Anda dapat langsung memulai.</p><h2>Instalasi</h2></p><p>Transformers bekerja dengan Python 3.9+, <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">PyTorch</a> 2.1+, <a href="https://www.tensorflow.org/install/pip" target="_blank" rel="noopener noreferrer">TensorFlow</a> 2.6+, dan <a href="https://flax.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Flax</a> 0.4.1+.</p><p>Buat dan aktifkan lingkungan virtual dengan <a href="https://docs.python.org/3/library/venv.html" target="_blank" rel="noopener noreferrer">venv</a> atau <a href="https://docs.astral.sh/uv/" target="_blank" rel="noopener noreferrer">uv</a>, sebuah manajer paket dan proyek Python berbasis Rust yang cepat.</p><pre><code class="language-py"># venv
python -m venv .my-env
source .my-env/bin/activate
<h1>uv</h1>
uv venv .my-env
source .my-env/bin/activate</code></pre></p><p>Instal Transformers di lingkungan virtual Anda.</p><pre><code class="language-py"># pip
pip install "transformers[torch]"</p><h1>uv</h1>
uv pip install "transformers[torch]"</code></pre></p><p>Instal Transformers dari sumber jika Anda menginginkan perubahan terbaru di pustaka atau tertarik untuk berkontribusi. Namun, versi <em>terbaru</em> mungkin tidak stabil. Silakan buka <a href="https://github.com/huggingface/transformers/issues" target="_blank" rel="noopener noreferrer">issue</a> jika Anda menemukan error.</p><pre><code class="language-shell">git clone https://github.com/huggingface/transformers.git
cd transformers</p><h1>pip</h1>
pip install .[torch]</p><h1>uv</h1>
uv pip install .[torch]</code></pre></p><h2>Quickstart</h2></p><p>Mulai dengan Transformers secara langsung menggunakan API <a href="https://huggingface.co/docs/transformers/pipeline_tutorial" target="_blank" rel="noopener noreferrer">Pipeline</a>. <code>Pipeline</code> adalah kelas inferensi tingkat tinggi yang mendukung tugas teks, audio, vision, dan multimodal. Pipeline menangani pra-pemrosesan input dan mengembalikan output yang sesuai.</p><p>Inisialisasi pipeline dan tentukan model yang digunakan untuk text generation. Model akan diunduh dan disimpan di cache sehingga Anda bisa menggunakannya kembali dengan mudah. Terakhir, masukkan teks untuk memicu model.</p><pre><code class="language-py">from transformers import pipeline</p><p>pipeline = pipeline(task="text-generation", model="Qwen/Qwen2.5-1.5B")
pipeline("the secret to baking a really good cake is ")
[{'generated_text': 'the secret to baking a really good cake is 1) to use the right ingredients and 2) to follow the recipe exactly. the recipe for the cake is as follows: 1 cup of sugar, 1 cup of flour, 1 cup of milk, 1 cup of butter, 1 cup of eggs, 1 cup of chocolate chips. if you want to make 2 cakes, how much sugar do you need? To make 2 cakes, you will need 2 cups of sugar.'}]</code></pre></p><p>Untuk bercakap-cakap dengan model, pola penggunaannya sama. Perbedaannya hanyalah Anda perlu membangun riwayat percakapan (input untuk <code>Pipeline</code>) antara Anda dan sistem.</p><blockquote>[!TIP]</blockquote>
<blockquote>Anda juga bisa bercakap-cakap dengan model langsung dari command line.</blockquote>
<blockquote><pre><code class="language-shell">> transformers chat Qwen/Qwen2.5-0.5B-Instruct</blockquote>
<blockquote>``<code></blockquote>
</code></pre>py
import torch
from transformers import pipeline</p><p>chat = [
    {"role": "system", "content": "Anda adalah robot sarkastik dan suka bercanda seperti yang dibayangkan Hollywood tahun 1986."},
    {"role": "user", "content": "Hei, bisakah kamu memberitahu saya hal-hal seru yang bisa dilakukan di New York?"}
]</p><p>pipeline = pipeline(task="text-generation", model="meta-llama/Meta-Llama-3-8B-Instruct", torch_dtype=torch.bfloat16, device_map="auto")
response = pipeline(chat, max_new_tokens=512)
print(response[0]["generated_text"][-1]["content"])
<pre><code class="language-">
Ekspand contoh di bawah ini untuk melihat bagaimana </code>Pipeline<code> bekerja pada berbagai modalitas dan tugas.</p><p><details>
<summary>Pengenalan ucapan otomatis</summary>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="automatic-speech-recognition", model="openai/whisper-large-v3")
pipeline("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
<pre><code class="language-">
</details></p><p><details>
<summary>Klasifikasi gambar</summary></p><p><h3 align="center">
    <a><img src="https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="image-classification", model="facebook/dinov2-small-imagenet1k-1-layer")
pipeline("https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png")
[{'label': 'macaw', 'score': 0.997848391532898},
 {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',
  'score': 0.0016551691805943847},
 {'label': 'lorikeet', 'score': 0.00018523589824326336},
 {'label': 'African grey, African gray, Psittacus erithacus',
  'score': 7.85409429227002e-05},
 {'label': 'quail', 'score': 5.502637941390276e-05}]
<pre><code class="language-">
</details></p><p><details>
<summary>Visual question answering</summary></p><p>
<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="visual-question-answering", model="Salesforce/blip-vqa-base")
pipeline(
    image="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg",
    question="What is in the image?",
)
[{'answer': 'statue of liberty'}]
<pre><code class="language-">
</details></p><h2>Mengapa saya harus menggunakan Transformers?</h2></p><ul><li>Model mutakhir yang mudah digunakan:</li>
    <li>Kinerja tinggi pada pemahaman & generasi bahasa alami, computer vision, audio, video, dan tugas multimodal.</li>
    <li>Hambatan masuk rendah bagi peneliti, engineer, dan developer.</li>
    <li>Hanya sedikit abstraksi yang harus dipelajari, cukup tiga kelas utama.</li>
    <li>API terpadu untuk semua model pralatih yang kami sediakan.</li></p><p><li>Mengurangi biaya komputasi, jejak karbon lebih kecil:</li>
    <li>Bagikan model yang sudah dilatih daripada melatih dari awal.</li>
    <li>Kurangi waktu komputasi dan biaya produksi.</li>
    <li>Puluhan arsitektur model dengan 1M+ checkpoint pralatih di semua modalitas.</li></p><p><li>Pilih kerangka kerja yang tepat untuk setiap tahap siklus hidup model:</li>
    <li>Latih model mutakhir hanya dengan 3 baris kode.</li>
    <li>Pindahkan satu model antara kerangka PyTorch/JAX/TF2.0 dengan mudah.</li>
    <li>Pilih kerangka kerja yang sesuai untuk pelatihan, evaluasi, dan produksi.</li></p><p><li>Mudah menyesuaikan model atau contoh dengan kebutuhan Anda:</li>
    <li>Kami menyediakan contoh untuk setiap arsitektur agar hasil penelitian asli bisa direproduksi.</li>
    <li>Internal model diekspos secara konsisten.</li>
    <li>File model bisa digunakan secara independen dari pustaka untuk eksperimen cepat.</li></p><p></ul><a target="_blank" href="https://huggingface.co/enterprise">
    <img alt="Hugging Face Enterprise Hub" src="https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925">
</a><br></p><h2>Mengapa saya tidak harus menggunakan Transformers?</h2></p><ul><li>Pustaka ini bukan toolbox modular untuk membangun neural net. Kode dalam file model memang tidak direfaktor dengan abstraksi tambahan, agar peneliti bisa cepat berinovasi pada masing-masing model tanpa harus mempelajari abstraksi/file tambahan.</li>
<li>API pelatihan dioptimalkan untuk bekerja dengan model PyTorch yang disediakan oleh Transformers. Untuk loop machine learning generik, Anda sebaiknya menggunakan pustaka lain seperti <a href="https://huggingface.co/docs/accelerate" target="_blank" rel="noopener noreferrer">Accelerate</a>.</li>
<li><a href="(https://github.com/huggingface/transformers/tree/main/examples" target="_blank" rel="noopener noreferrer">Script contoh</a>) hanya <em>contoh</em>. Mungkin tidak bekerja langsung untuk kasus Anda dan Anda harus menyesuaikan kode agar sesuai.</li></p><p></ul><h2>100 proyek menggunakan Transformers</h2></p><p>Transformers lebih dari sekadar toolkit untuk model pralatih, ini adalah komunitas proyek yang dibangun di sekitarnya dan Hugging Face Hub. Kami ingin Transformers memberdayakan developer, peneliti, mahasiswa, dosen, engineer, dan siapa pun untuk membangun proyek impian mereka.</p><p>Untuk merayakan Transformers 100.000 bintang, kami ingin menyoroti komunitas melalui halaman <a href="./awesome-transformers.md" target="_blank" rel="noopener noreferrer">awesome-transformers</a> yang mencantumkan 100 proyek luar biasa yang dibangun dengan Transformers.</p><p>Jika Anda memiliki atau menggunakan proyek yang menurut Anda layak masuk dalam daftar, silakan ajukan PR untuk menambahkannya!</p><h2>Contoh model</h2></p><p>Anda dapat mencoba sebagian besar model kami langsung di <a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">halaman model Hub</a>.</p><p>Ekspand setiap modalitas di bawah ini untuk melihat beberapa contoh model untuk berbagai kasus penggunaan.</p><p><details>
<summary>Audio</summary></p><ul><li>Klasifikasi audio dengan <a href="https://huggingface.co/openai/whisper-large-v3-turbo" target="_blank" rel="noopener noreferrer">Whisper</a></li>
<li>Pengenalan ucapan otomatis dengan <a href="https://huggingface.co/UsefulSensors/moonshine" target="_blank" rel="noopener noreferrer">Moonshine</a></li>
<li>Keyword spotting dengan <a href="https://huggingface.co/superb/wav2vec2-base-superb-ks" target="_blank" rel="noopener noreferrer">Wav2Vec2</a></li>
<li>Speech to speech generation dengan <a href="https://huggingface.co/kyutai/moshiko-pytorch-bf16" target="_blank" rel="noopener noreferrer">Moshi</a></li>
<li>Teks ke audio dengan <a href="https://huggingface.co/facebook/musicgen-large" target="_blank" rel="noopener noreferrer">MusicGen</a></li>
<li>Teks ke suara dengan <a href="https://huggingface.co/suno/bark" target="_blank" rel="noopener noreferrer">Bark</a></li></p><p></ul></details></p><p><details>
<summary>Computer vision</summary></p><ul><li>Pembentukan mask otomatis dengan <a href="https://huggingface.co/facebook/sam-vit-base" target="_blank" rel="noopener noreferrer">SAM</a></li>
<li>Estimasi kedalaman dengan <a href="https://huggingface.co/apple/DepthPro-hf" target="_blank" rel="noopener noreferrer">DepthPro</a></li>
<li>Klasifikasi gambar dengan <a href="https://huggingface.co/facebook/dinov2-base" target="_blank" rel="noopener noreferrer">DINO v2</a></li>
<li>Deteksi keypoint dengan <a href="https://huggingface.co/magic-leap-community/superglue_outdoor" target="_blank" rel="noopener noreferrer">SuperGlue</a></li>
<li>Keypoint matching dengan <a href="https://huggingface.co/magic-leap-community/superglue" target="_blank" rel="noopener noreferrer">SuperGlue</a></li>
<li>Deteksi objek dengan <a href="https://huggingface.co/PekingU/rtdetr_v2_r50vd" target="_blank" rel="noopener noreferrer">RT-DETRv2</a></li>
<li>Estimasi pose dengan <a href="https://huggingface.co/usyd-community/vitpose-base-simple" target="_blank" rel="noopener noreferrer">VitPose</a></li>
<li>Segmentasi universal dengan <a href="https://huggingface.co/shi-labs/oneformer_ade20k_swin_large" target="_blank" rel="noopener noreferrer">OneFormer</a></li>
<li>Klasifikasi video dengan <a href="https://huggingface.co/MCG-NJU/videomae-large" target="_blank" rel="noopener noreferrer">VideoMAE</a></li></p><p></ul></details></p><p><details>
<summary>Multimodal</summary></p><ul><li>Audio atau teks ke teks dengan <a href="https://huggingface.co/Qwen/Qwen2-Audio-7B" target="_blank" rel="noopener noreferrer">Qwen2-Audio</a></li>
<li>Document question answering dengan <a href="https://huggingface.co/microsoft/layoutlmv3-base" target="_blank" rel="noopener noreferrer">LayoutLMv3</a></li>
<li>Gambar atau teks ke teks dengan <a href="https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct" target="_blank" rel="noopener noreferrer">Qwen-VL</a></li>
<li>Image captioning <a href="https://huggingface.co/Salesforce/blip2-opt-2.7b" target="_blank" rel="noopener noreferrer">BLIP-2</a></li>
<li>Pemahaman dokumen berbasis OCR dengan <a href="https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf" target="_blank" rel="noopener noreferrer">GOT-OCR2</a></li>
<li>Table question answering dengan <a href="https://huggingface.co/google/tapas-base" target="_blank" rel="noopener noreferrer">TAPAS</a></li>
<li>Pemahaman dan generasi multimodal terpadu dengan <a href="https://huggingface.co/BAAI/Emu3-Gen" target="_blank" rel="noopener noreferrer">Emu3</a></li>
<li>Vision ke teks dengan <a href="https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf" target="_blank" rel="noopener noreferrer">Llava-OneVision</a></li>
<li>Visual question answering dengan <a href="https://huggingface.co/llava-hf/llava-1.5-7b-hf" target="_blank" rel="noopener noreferrer">Llava</a></li>
<li>Segmentasi ekspresi rujukan visual dengan <a href="https://huggingface.co/microsoft/kosmos-2-patch14-224" target="_blank" rel="noopener noreferrer">Kosmos-2</a></li></p><p></ul></details></p><p><details>
<summary>NLP</summary></p><ul><li>Penyelesaian kata tersembunyi dengan <a href="https://huggingface.co/answerdotai/ModernBERT-base" target="_blank" rel="noopener noreferrer">ModernBERT</a></li>
<li>Named entity recognition dengan <a href="https://huggingface.co/google/gemma-2-2b" target="_blank" rel="noopener noreferrer">Gemma</a></li>
<li>Question answering dengan <a href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1" target="_blank" rel="noopener noreferrer">Mixtral</a></li>
<li>Ringkasan dengan <a href="https://huggingface.co/facebook/bart-large-cnn" target="_blank" rel="noopener noreferrer">BART</a></li>
<li>Translasi dengan <a href="https://huggingface.co/google-t5/t5-base" target="_blank" rel="noopener noreferrer">T5</a></li>
<li>Generasi teks dengan <a href="https://huggingface.co/meta-llama/Llama-3.2-1B" target="_blank" rel="noopener noreferrer">Llama</a></li>
<li>Klasifikasi teks dengan <a href="https://huggingface.co/Qwen/Qwen2.5-0.5B" target="_blank" rel="noopener noreferrer">Qwen</a></li></p><p></ul></details></p><h2>Sitasi</h2></p><p>Kami kini memiliki <a href="https://www.aclweb.org/anthology/2020.emnlp-demos.6/" target="_blank" rel="noopener noreferrer">makalah</a> yang dapat Anda kutip untuk pustaka 🤗 Transformers:</code></pre>bibtex
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
</code>``

---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/huggingface/transformers/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>