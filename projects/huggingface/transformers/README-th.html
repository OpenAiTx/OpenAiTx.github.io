<!DOCTYPE html>
<html lang="th">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>transformers - Read transformers documentation in Thai. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read transformers documentation in Thai. This project has 0 stars on GitHub.">
    <meta name="keywords" content="transformers, Thai, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "transformers",
  "description": "Read transformers documentation in Thai. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "huggingface"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/huggingface/transformers/README-th.html",
  "sameAs": "https://raw.githubusercontent.com/huggingface/transformers/master/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/huggingface/transformers" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    transformers
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Thai</span>
                <span>by huggingface</span>
            </div>
        </div>
        
        <div class="content">
            <p><!---
Copyright 2020 The HuggingFace Team. สงวนลิขสิทธิ์ทั้งหมด</p><p>ได้รับอนุญาตภายใต้ Apache License, Version 2.0 ("ใบอนุญาต");
คุณไม่สามารถใช้ไฟล์นี้ได้หากไม่ได้ปฏิบัติตามใบอนุญาต
คุณสามารถขอสำเนาใบอนุญาตได้ที่</p><p>    http://www.apache.org/licenses/LICENSE-2.0</p><p>เว้นแต่กฎหมายจะกำหนดไว้หรือมีการตกลงเป็นลายลักษณ์อักษร ซอฟต์แวร์
ที่แจกจ่ายภายใต้ใบอนุญาตนี้จะถูกแจกจ่าย "ตามสภาพ"
โดยไม่มีการรับประกันใดๆ ไม่ว่าจะแสดงออกหรือโดยนัย
ดูใบอนุญาตสำหรับข้อกำหนดเฉพาะที่ควบคุมสิทธิ์และ
ข้อจำกัดภายใต้ใบอนุญาต
--></p><p><p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Hugging Face Transformers Library" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p></p><p><p align="center">
    <a href="https://huggingface.com/models"><img alt="Checkpoints on Hub" src="https://img.shields.io/endpoint?url=https://huggingface.co/api/shields/models&color=brightgreen"></a>
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p></p><p><h4 align="center">
    <p>
        <b>English</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">简体中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">繁體中文</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">한국어</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">Español</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">日本語</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">हिन्दी</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">Русский</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">Рortuguês</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">తెలుగు</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">Français</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_de.md">Deutsch</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Tiếng Việt</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">العربية</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">اردو</a> |
    </p>
</h4></p><p><h3 align="center">
    <p>โมเดลปรีเทรนล้ำสมัยสำหรับการอินเฟอเรนซ์และการฝึกสอน</p>
</h3></p><p><h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3></p><p>Transformers คือไลบรารีโมเดลปรีเทรนสำหรับข้อความ, วิสัยทัศน์คอมพิวเตอร์, เสียง, วิดีโอ และมัลติโหมด สำหรับการอินเฟอเรนซ์และฝึกสอน ใช้ Transformers เพื่อจูนโมเดลกับข้อมูลของคุณ, สร้างแอปพลิเคชันอินเฟอเรนซ์ และเพื่อกรณีการใช้งาน AI แบบสร้างสรรค์ในหลายรูปแบบ</p><p>มีโมเดล Transformers <a href="https://huggingface.co/models?library=transformers&sort=trending" target="_blank" rel="noopener noreferrer">จุดตรวจโมเดล</a> มากกว่า 500,000+ บน <a href="https://huggingface.com/models" target="_blank" rel="noopener noreferrer">Hugging Face Hub</a> ให้คุณเลือกใช้งาน</p><p>สำรวจ <a href="https://huggingface.com/" target="_blank" rel="noopener noreferrer">Hub</a> วันนี้เพื่อค้นหาโมเดลและใช้ Transformers เพื่อเริ่มต้นได้ทันที</p><h2>การติดตั้ง</h2></p><p>Transformers ทำงานร่วมกับ Python 3.9+, <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">PyTorch</a> 2.1+, <a href="https://www.tensorflow.org/install/pip" target="_blank" rel="noopener noreferrer">TensorFlow</a> 2.6+ และ <a href="https://flax.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">Flax</a> 0.4.1+</p><p>สร้างและเปิดใช้งาน virtual environment ด้วย <a href="https://docs.python.org/3/library/venv.html" target="_blank" rel="noopener noreferrer">venv</a> หรือ <a href="https://docs.astral.sh/uv/" target="_blank" rel="noopener noreferrer">uv</a> ซึ่งเป็นตัวจัดการแพคเกจและโปรเจกต์ Python ที่เขียนด้วยภาษา Rust</p><pre><code class="language-py"># venv
python -m venv .my-env
source .my-env/bin/activate
<h1>uv</h1>
uv venv .my-env
source .my-env/bin/activate</code></pre></p><p>ติดตั้ง Transformers ใน virtual environment ของคุณ</p><pre><code class="language-py"># pip
pip install "transformers[torch]"</p><h1>uv</h1>
uv pip install "transformers[torch]"</code></pre></p><p>ติดตั้ง Transformers จากซอร์ส หากคุณต้องการการเปลี่ยนแปลงล่าสุดในไลบรารีหรือสนใจจะร่วมพัฒนา อย่างไรก็ตาม <em>เวอร์ชันล่าสุด</em> อาจไม่เสถียร หากคุณพบข้อผิดพลาดสามารถเปิด <a href="https://github.com/huggingface/transformers/issues" target="_blank" rel="noopener noreferrer">issue</a> ได้</p><pre><code class="language-shell">git clone https://github.com/huggingface/transformers.git
cd transformers</p><h1>pip</h1>
pip install .[torch]</p><h1>uv</h1>
uv pip install .[torch]</code></pre></p><h2>เริ่มต้นอย่างรวดเร็ว</h2></p><p>เริ่มใช้ Transformers ได้ทันทีด้วย API <a href="https://huggingface.co/docs/transformers/pipeline_tutorial" target="_blank" rel="noopener noreferrer">Pipeline</a> <code>Pipeline</code> เป็นคลาสอินเฟอเรนซ์ระดับสูงที่รองรับงานข้อความ, เสียง, วิสัยทัศน์ และมัลติโหมด โดยจะจัดการการประมวลผลล่วงหน้าของอินพุตและคืนค่าผลลัพธ์ที่เหมาะสม</p><p>สร้าง pipeline และระบุโมเดลที่ใช้สำหรับการสร้างข้อความ โมเดลจะถูกดาวน์โหลดและแคชเพื่อให้ใช้งานซ้ำได้ง่าย สุดท้าย ส่งข้อความไปกระตุ้นโมเดล</p><pre><code class="language-py">from transformers import pipeline</p><p>pipeline = pipeline(task="text-generation", model="Qwen/Qwen2.5-1.5B")
pipeline("the secret to baking a really good cake is ")
[{'generated_text': 'the secret to baking a really good cake is 1) to use the right ingredients and 2) to follow the recipe exactly. the recipe for the cake is as follows: 1 cup of sugar, 1 cup of flour, 1 cup of milk, 1 cup of butter, 1 cup of eggs, 1 cup of chocolate chips. if you want to make 2 cakes, how much sugar do you need? To make 2 cakes, you will need 2 cups of sugar.'}]</code></pre></p><p>หากต้องการสนทนากับโมเดล รูปแบบการใช้งานจะเหมือนเดิม ต่างกันเพียงแค่คุณต้องสร้างประวัติการสนทนา (อินพุตสำหรับ <code>Pipeline</code>) ระหว่างคุณกับระบบ</p><blockquote>[!TIP]</blockquote>
<blockquote>คุณสามารถแชทกับโมเดลได้โดยตรงจาก command line</blockquote>
<blockquote><pre><code class="language-shell">> transformers chat Qwen/Qwen2.5-0.5B-Instruct</blockquote>
<blockquote>``<code></blockquote>
</code></pre>py
import torch
from transformers import pipeline</p><p>chat = [
    {"role": "system", "content": "You are a sassy, wise-cracking robot as imagined by Hollywood circa 1986."},
    {"role": "user", "content": "Hey, can you tell me any fun things to do in New York?"}
]</p><p>pipeline = pipeline(task="text-generation", model="meta-llama/Meta-Llama-3-8B-Instruct", torch_dtype=torch.bfloat16, device_map="auto")
response = pipeline(chat, max_new_tokens=512)
print(response[0]["generated_text"][-1]["content"])
<pre><code class="language-">
ขยายตัวอย่างด้านล่างเพื่อดูว่า </code>Pipeline<code> ทำงานอย่างไรสำหรับแต่ละโมดัลลิตี้และงาน</p><p><details>
<summary>การรู้จำเสียงพูดอัตโนมัติ</summary>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="automatic-speech-recognition", model="openai/whisper-large-v3")
pipeline("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
<pre><code class="language-">
</details></p><p><details>
<summary>การจำแนกภาพ</summary></p><p><h3 align="center">
    <a><img src="https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="image-classification", model="facebook/dinov2-small-imagenet1k-1-layer")
pipeline("https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png")
[{'label': 'macaw', 'score': 0.997848391532898},
 {'label': 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita',
  'score': 0.0016551691805943847},
 {'label': 'lorikeet', 'score': 0.00018523589824326336},
 {'label': 'African grey, African gray, Psittacus erithacus',
  'score': 7.85409429227002e-05},
 {'label': 'quail', 'score': 5.502637941390276e-05}]
<pre><code class="language-">
</details></p><p><details>
<summary>การตอบคำถามด้วยภาพ</summary></p><p>
<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg"></a>
</h3>
</code></pre>py
from transformers import pipeline</p><p>pipeline = pipeline(task="visual-question-answering", model="Salesforce/blip-vqa-base")
pipeline(
    image="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/idefics-few-shot.jpg",
    question="What is in the image?",
)
[{'answer': 'statue of liberty'}]
<pre><code class="language-">
</details></p><h2>ทำไมจึงควรใช้ Transformers?</h2></p><ul><li>โมเดลล้ำสมัยที่ใช้งานง่าย:</li>
    <li>ประสิทธิภาพสูงสำหรับการเข้าใจและสร้างภาษาธรรมชาติ, วิสัยทัศน์คอมพิวเตอร์, เสียง, วิดีโอ และงานมัลติโหมด</li>
    <li>ลดข้อจำกัดสำหรับนักวิจัย, วิศวกร และนักพัฒนา</li>
    <li>มี abstraction สำหรับผู้ใช้เพียง 3 คลาสหลักเท่านั้น</li>
    <li>API เดียวสำหรับใช้โมเดลปรีเทรนทั้งหมด</li></p><p><li>ลดค่าใช้จ่ายในการประมวลผล, ลดคาร์บอนฟุตพรินต์:</li>
    <li>แชร์โมเดลที่ฝึกแล้ว แทนการฝึกใหม่ตั้งแต่ต้น</li>
    <li>ลดเวลาในการประมวลผลและต้นทุนการผลิต</li>
    <li>สถาปัตยกรรมโมเดลหลายสิบแบบและจุดตรวจปรีเทรนมากกว่า 1 ล้านจุดสำหรับทุกโมดัลลิตี้</li></p><p><li>เลือกเฟรมเวิร์กที่เหมาะสมสำหรับทุกช่วงชีวิตของโมเดล:</li>
    <li>ฝึกโมเดลล้ำสมัยใน 3 บรรทัดโค้ด</li>
    <li>ย้ายโมเดลเดียวกันระหว่าง PyTorch/JAX/TF2.0 ได้อย่างอิสระ</li>
    <li>เลือกเฟรมเวิร์กที่เหมาะสมสำหรับการฝึก, ประเมินผล และการนำไปใช้จริง</li></p><p><li>ปรับแต่งโมเดลหรือโค้ดตัวอย่างได้อย่างง่ายดาย:</li>
    <li>เรามีตัวอย่างสำหรับแต่ละสถาปัตยกรรมเพื่อสร้างซ้ำผลลัพธ์ที่ผู้แต่งดั้งเดิมเผยแพร่</li>
    <li>เปิดเผยโครงสร้างภายในของโมเดลให้มากที่สุดเท่าที่ทำได้</li>
    <li>ไฟล์โมเดลสามารถนำไปใช้แยกจากไลบรารีเพื่อทดลองอย่างรวดเร็ว</li></p><p></ul><a target="_blank" href="https://huggingface.co/enterprise">
    <img alt="Hugging Face Enterprise Hub" src="https://github.com/user-attachments/assets/247fb16d-d251-4583-96c4-d3d76dda4925">
</a><br></p><h2>ทำไมถึงอาจไม่ควรใช้ Transformers?</h2></p><ul><li>ไลบรารีนี้ไม่ใช่กล่องเครื่องมือโมดูลาร์สำหรับสร้าง neural net โค้ดในไฟล์โมเดลไม่ได้ถูก refactor ด้วย abstraction เพิ่มเติมโดยตั้งใจ เพื่อให้นักวิจัยสามารถทดลองกับแต่ละโมเดลได้อย่างรวดเร็วโดยไม่ต้องเรียนรู้ abstraction/ไฟล์เพิ่ม</li>
<li>API ฝึกสอนได้ถูกปรับแต่งให้เหมาะกับโมเดล PyTorch ที่ให้มาโดย Transformers สำหรับ loop machine learning ทั่วไป คุณควรใช้ไลบรารีอื่น เช่น <a href="https://huggingface.co/docs/accelerate" target="_blank" rel="noopener noreferrer">Accelerate</a></li>
<li><a href="(https://github.com/huggingface/transformers/tree/main/examples" target="_blank" rel="noopener noreferrer">สคริปต์ตัวอย่าง</a>) เป็นเพียง <em>ตัวอย่าง</em> เท่านั้น อาจไม่สามารถใช้กับกรณีเฉพาะของคุณได้ทันที คุณจำเป็นต้องปรับแต่งโค้ดเพื่อให้เหมาะสม</li></p><p></ul><h2>100 โปรเจกต์ที่ใช้ Transformers</h2></p><p>Transformers ไม่ใช่แค่เครื่องมือสำหรับใช้โมเดลปรีเทรน แต่ยังเป็นชุมชนของโปรเจกต์ที่สร้างขึ้นรอบๆ และ Hugging Face Hub เราต้องการให้ Transformers ช่วยให้นักพัฒนา นักวิจัย นักศึกษา อาจารย์ วิศวกร และใครก็ตามสามารถสร้างโปรเจกต์ในฝันได้</p><p>เพื่อฉลอง Transformers ครบ 100,000 ดาว เราขอเน้นย้ำถึงชุมชนผ่านหน้า <a href="./awesome-transformers.md" target="_blank" rel="noopener noreferrer">awesome-transformers</a> ซึ่งรวบรวม 100 โปรเจกต์ที่น่าทึ่งที่สร้างด้วย Transformers</p><p>หากคุณเป็นเจ้าของหรือใช้โปรเจกต์ที่คิดว่าสมควรอยู่ในรายชื่อ กรุณาส่ง PR เพื่อเพิ่มได้เลย!</p><h2>ตัวอย่างโมเดล</h2></p><p>คุณสามารถทดลองโมเดลส่วนใหญ่ของเราได้โดยตรงใน <a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">หน้ารายละเอียดโมเดลบน Hub</a></p><p>ขยายแต่ละหมวดด้านล่างเพื่อดูตัวอย่างโมเดลสำหรับการใช้งานหลากหลาย</p><p><details>
<summary>เสียง</summary></p><ul><li>การจำแนกเสียงด้วย <a href="https://huggingface.co/openai/whisper-large-v3-turbo" target="_blank" rel="noopener noreferrer">Whisper</a></li>
<li>การรู้จำเสียงพูดอัตโนมัติด้วย <a href="https://huggingface.co/UsefulSensors/moonshine" target="_blank" rel="noopener noreferrer">Moonshine</a></li>
<li>การตรวจจับคำสำคัญด้วย <a href="https://huggingface.co/superb/wav2vec2-base-superb-ks" target="_blank" rel="noopener noreferrer">Wav2Vec2</a></li>
<li>การสร้างเสียงต่อเสียงด้วย <a href="https://huggingface.co/kyutai/moshiko-pytorch-bf16" target="_blank" rel="noopener noreferrer">Moshi</a></li>
<li>การแปลงข้อความเป็นเสียงด้วย <a href="https://huggingface.co/facebook/musicgen-large" target="_blank" rel="noopener noreferrer">MusicGen</a></li>
<li>การแปลงข้อความเป็นเสียงพูดด้วย <a href="https://huggingface.co/suno/bark" target="_blank" rel="noopener noreferrer">Bark</a></li></p><p></ul></details></p><p><details>
<summary>วิสัยทัศน์คอมพิวเตอร์</summary></p><ul><li>การสร้าง mask อัตโนมัติด้วย <a href="https://huggingface.co/facebook/sam-vit-base" target="_blank" rel="noopener noreferrer">SAM</a></li>
<li>การประมาณความลึกด้วย <a href="https://huggingface.co/apple/DepthPro-hf" target="_blank" rel="noopener noreferrer">DepthPro</a></li>
<li>การจำแนกภาพด้วย <a href="https://huggingface.co/facebook/dinov2-base" target="_blank" rel="noopener noreferrer">DINO v2</a></li>
<li>การตรวจจับจุดสำคัญด้วย <a href="https://huggingface.co/magic-leap-community/superglue_outdoor" target="_blank" rel="noopener noreferrer">SuperGlue</a></li>
<li>การจับคู่จุดสำคัญด้วย <a href="https://huggingface.co/magic-leap-community/superglue" target="_blank" rel="noopener noreferrer">SuperGlue</a></li>
<li>การตรวจจับวัตถุด้วย <a href="https://huggingface.co/PekingU/rtdetr_v2_r50vd" target="_blank" rel="noopener noreferrer">RT-DETRv2</a></li>
<li>การประมาณท่าทางด้วย <a href="https://huggingface.co/usyd-community/vitpose-base-simple" target="_blank" rel="noopener noreferrer">VitPose</a></li>
<li>การแบ่งเซ็กเมนต์แบบสากลด้วย <a href="https://huggingface.co/shi-labs/oneformer_ade20k_swin_large" target="_blank" rel="noopener noreferrer">OneFormer</a></li>
<li>การจำแนกวิดีโอด้วย <a href="https://huggingface.co/MCG-NJU/videomae-large" target="_blank" rel="noopener noreferrer">VideoMAE</a></li></p><p></ul></details></p><p><details>
<summary>มัลติโหมด</summary></p><ul><li>เสียงหรือข้อความเป็นข้อความด้วย <a href="https://huggingface.co/Qwen/Qwen2-Audio-7B" target="_blank" rel="noopener noreferrer">Qwen2-Audio</a></li>
<li>การตอบคำถามเอกสารด้วย <a href="https://huggingface.co/microsoft/layoutlmv3-base" target="_blank" rel="noopener noreferrer">LayoutLMv3</a></li>
<li>ภาพหรือข้อความเป็นข้อความด้วย <a href="https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct" target="_blank" rel="noopener noreferrer">Qwen-VL</a></li>
<li>การบรรยายภาพด้วย <a href="https://huggingface.co/Salesforce/blip2-opt-2.7b" target="_blank" rel="noopener noreferrer">BLIP-2</a></li>
<li>ความเข้าใจเอกสารด้วย OCR ด้วย <a href="https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf" target="_blank" rel="noopener noreferrer">GOT-OCR2</a></li>
<li>การตอบคำถามตารางด้วย <a href="https://huggingface.co/google/tapas-base" target="_blank" rel="noopener noreferrer">TAPAS</a></li>
<li>ความเข้าใจและสร้างมัลติโหมดแบบรวมด้วย <a href="https://huggingface.co/BAAI/Emu3-Gen" target="_blank" rel="noopener noreferrer">Emu3</a></li>
<li>วิสัยทัศน์สู่ข้อความด้วย <a href="https://huggingface.co/llava-hf/llava-onevision-qwen2-0.5b-ov-hf" target="_blank" rel="noopener noreferrer">Llava-OneVision</a></li>
<li>การตอบคำถามด้วยภาพด้วย <a href="https://huggingface.co/llava-hf/llava-1.5-7b-hf" target="_blank" rel="noopener noreferrer">Llava</a></li>
<li>การแบ่งเซ็กเมนต์ตามนิยามในภาพด้วย <a href="https://huggingface.co/microsoft/kosmos-2-patch14-224" target="_blank" rel="noopener noreferrer">Kosmos-2</a></li></p><p></ul></details></p><p><details>
<summary>ประมวลผลภาษาธรรมชาติ (NLP)</summary></p><ul><li>การเติมคำที่หายไปด้วย <a href="https://huggingface.co/answerdotai/ModernBERT-base" target="_blank" rel="noopener noreferrer">ModernBERT</a></li>
<li>การรู้จำชื่อเอนทิตีด้วย <a href="https://huggingface.co/google/gemma-2-2b" target="_blank" rel="noopener noreferrer">Gemma</a></li>
<li>การตอบคำถามด้วย <a href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1" target="_blank" rel="noopener noreferrer">Mixtral</a></li>
<li>การสรุปเนื้อหาด้วย <a href="https://huggingface.co/facebook/bart-large-cnn" target="_blank" rel="noopener noreferrer">BART</a></li>
<li>การแปลภาษาด้วย <a href="https://huggingface.co/google-t5/t5-base" target="_blank" rel="noopener noreferrer">T5</a></li>
<li>การสร้างข้อความด้วย <a href="https://huggingface.co/meta-llama/Llama-3.2-1B" target="_blank" rel="noopener noreferrer">Llama</a></li>
<li>การจำแนกข้อความด้วย <a href="https://huggingface.co/Qwen/Qwen2.5-0.5B" target="_blank" rel="noopener noreferrer">Qwen</a></li></p><p></ul></details></p><h2>การอ้างอิง</h2></p><p>ขณะนี้เรามี <a href="https://www.aclweb.org/anthology/2020.emnlp-demos.6/" target="_blank" rel="noopener noreferrer">เปเปอร์</a> ที่คุณสามารถใช้อ้างอิงไลบรารี 🤗 Transformers ได้:</code></pre>bibtex
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
</code>``</p><p>
---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/huggingface/transformers/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>