<!DOCTYPE html>
<html lang="id">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>verl - Read verl documentation in Indonesian. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read verl documentation in Indonesian. This project has 0 stars on GitHub.">
    <meta name="keywords" content="verl, Indonesian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "verl",
  "description": "Read verl documentation in Indonesian. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "volcengine"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/volcengine/verl/README-id.html",
  "sameAs": "https://raw.githubusercontent.com/volcengine/verl/master/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/volcengine/verl" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    verl
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Indonesian</span>
                <span>by volcengine</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align="center">
 👋 Hai, semuanya!
    verl adalah library pelatihan RL yang diprakarsai oleh <b>Tim ByteDance Seed</b> dan dikelola oleh komunitas verl.
    <br>
    <br>
</div></p><p><div align="center"></p><p><a href="https://deepwiki.com/volcengine/verl" target="_blank" rel="noopener noreferrer"><img src="https://devin.ai/assets/deepwiki-badge.png" alt="Ask DeepWiki.com" height="20"/></a>
<a href="https://github.com/volcengine/verl/stargazers" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/github/stars/volcengine/verl" alt="GitHub Repo stars"></a>
<a href="https://twitter.com/verl_project" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/twitter/follow/verl_project" alt="Twitter"></a>
<a href="https://join.slack.com/t/verlgroup/shared_invite/zt-2w5p9o4c3-yy0x2Q56s_VlGLsJ93A6vA"><img src="https://img.shields.io/badge/Slack-verl-blueviolet?logo=slack&amp"></a>
<a href="https://arxiv.org/pdf/2409.19256"><img src="https://img.shields.io/static/v1?label=EuroSys&message=Paper&color=red"></a>
<a href="https://verl.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/documentation-blue" alt="Documentation"></a>
<a href="https://raw.githubusercontent.com/eric-haibin-lin/verl-community/refs/heads/main/WeChat.JPG"><img src="https://img.shields.io/badge/微信-green?logo=wechat&amp"></a></p><p></div></p><p><img src="https://github.com/user-attachments/assets/c42e675e-497c-4508-8bb9-093ad4d1f216" alt="seed logo"></p><p><h1 style="text-align: center;">verl: Volcano Engine Reinforcement Learning untuk LLM</h1></p><p>verl adalah library pelatihan RL yang fleksibel, efisien, dan siap produksi untuk model bahasa besar (LLM).</p><p>verl merupakan versi open-source dari makalah <strong><a href="https://arxiv.org/abs/2409.19256v2" target="_blank" rel="noopener noreferrer">HybridFlow: A Flexible and Efficient RLHF Framework</a></strong>.</p><p>verl fleksibel dan mudah digunakan dengan:</p><ul><li><strong>Ekstensi mudah untuk berbagai algoritma RL</strong>: Model pemrograman hybrid-controller memungkinkan representasi fleksibel dan eksekusi efisien alur data post-training yang kompleks. Bangun alur data RL seperti GRPO, PPO hanya dengan beberapa baris kode.</li></p><p><li><strong>Integrasi mulus infrastruktur LLM yang ada dengan API modular</strong>: Memisahkan komputasi dan dependensi data, memungkinkan integrasi mulus dengan framework LLM yang sudah ada, seperti FSDP, Megatron-LM, vLLM, SGLang, dll.</li></p><p><li><strong>Pemetaan perangkat yang fleksibel</strong>: Mendukung berbagai penempatan model pada berbagai GPU untuk pemanfaatan sumber daya yang efisien dan skalabilitas di berbagai ukuran klaster.</li></p><p><li>Integrasi siap pakai dengan model HuggingFace populer</li></p><p></ul>verl cepat dengan:</p><ul><li><strong>Throughput mutakhir (state-of-the-art)</strong>: Integrasi engine pelatihan dan inferensi LLM SOTA serta throughput RL SOTA.</li></p><p><li><strong>Resharding model aktor yang efisien dengan 3D-HybridEngine</strong>: Menghilangkan redundansi memori dan secara signifikan mengurangi overhead komunikasi saat transisi antara fase pelatihan dan generasi.</li></p><p></ul></p></p><h2>Berita Terbaru</h2></p><ul><li>[2025/06] verl dengan backend Megatron mendukung model MoE besar seperti <a href="https://verl.readthedocs.io/en/latest/perf/dpsk.html" target="_blank" rel="noopener noreferrer">DeepSeek-671b dan Qwen3-236b</a>.</li>
<li>[2025/06] Tim verl akan menyampaikan pembaruan proyek terbaru di <a href="https://www.lfasiallc.com/pytorch-day-china/" target="_blank" rel="noopener noreferrer">PyTorch Day China</a> pada 7 Juni. Temui tim pengembang kami di Beijing!</li>
<li>[2025/05] <a href="https://arxiv.org/abs/2409.06957" target="_blank" rel="noopener noreferrer">PF-PPO</a>, diterima di ICML 2025, kini didukung di verl! PF-PPO meningkatkan efisiensi dan robustness pembelajaran kebijakan dengan memfilter sinyal reward yang berpotensi noise dan menggunakan kembali pengalaman berkualitas tinggi melalui replay buffer.</li>
<li>[2025/04] Kami akan memberikan tutorial tentang teknik post-training terbaru dan panduan pemrograman verl di <a href="https://iclr.cc/virtual/2025/calendar?filter_events=Expo+Talk+Panel&filter_rooms=" target="_blank" rel="noopener noreferrer">ICLR 2025 Expo</a>, <a href="https://open-foundation-model.github.io/" target="_blank" rel="noopener noreferrer">SCI-FM workshop</a> dan <a href="https://lu.ma/d23nyynm" target="_blank" rel="noopener noreferrer">LMSys afterparty</a>. Materi presentasi tersedia <a href="https://github.com/eric-haibin-lin/verl-community/tree/main/iclr25" target="_blank" rel="noopener noreferrer">di sini</a>.</li>
<li>[2025/04] Laporan teknis <a href="https://github.com/ByteDance-Seed/Seed-Thinking-v1.5/blob/main/seed-thinking-v1.5.pdf" target="_blank" rel="noopener noreferrer">Seed-Thinking-v1.5</a> telah dirilis! Dilatih dengan verl, Seed-Thinking-v1.5 mencapai 86.7 pada AIME 2024, 55.0 pada Codeforces dan 77.3 pada GPQA, menunjukkan kemampuan reasoning yang sangat baik di bidang STEM dan pemrograman. Selain tugas reasoning, metode ini juga menunjukkan generalisasi yang luar biasa di berbagai domain.</li>
<li>[2025/04] Makalah <a href="https://arxiv.org/pdf/2504.05118" target="_blank" rel="noopener noreferrer">VAPO</a> (value-based augmented PPO) membahas metode RL terbaru kami untuk model reasoning. Dilatih dari model Qwen-32B-base, VAPO mencapai 60.4 pada AIME 2024, mengungguli DAPO-32B.</li>
<li>[2025/03] verl v0.3.0.post1 dirilis! Lihat <a href="https://github.com/volcengine/verl/releases/" target="_blank" rel="noopener noreferrer">catatan rilis</a> untuk detailnya. Mencapai <a href="https://tongyx361.github.io/blogs/posts/verl-intro/#/verl-flexible-and-efficient-rl-for-llms" target="_blank" rel="noopener noreferrer">~1.4x percepatan</a> dibandingkan versi sebelumnya.</li>
<li>[2025/03] <a href="https://dapo-sia.github.io/" target="_blank" rel="noopener noreferrer">DAPO</a> adalah algoritma RL SOTA open-source yang mencapai 50 poin di AIME 2024 berbasis model pra-latih Qwen2.5-32B, melampaui SOTA sebelumnya dari DeepSeek's GRPO (DeepSeek-R1-Zero-Qwen-32B). Pelatihan DAPO sepenuhnya menggunakan verl dan kode reproduksi kini tersedia di <code>recipe/dapo</code>.</li>
</ul><details><summary> lebih... </summary>
<ul>
  <ul><li>[2025/05] verl akan dipresentasikan di <a href="https://a2m.msup.com.cn/home/?aid=4488&city=shanghai" target="_blank" rel="noopener noreferrer">A2M Shanghai</a> pada 16-17 Mei.</li>
  <li>[2025/05] verl akan dipresentasikan di <a href="https://paris2025.gosim.org/" target="_blank" rel="noopener noreferrer">GOSIM x PyTorch Day 2025</a>. Sampai jumpa di Paris! </li>
  <li>[2025/03] Kami memperkenalkan model pemrograman verl di <a href="https://mp.weixin.qq.com/s/n77GibL2corAtQHtVEAzfg" target="_blank" rel="noopener noreferrer">vLLM Beijing Meetup</a> dan <a href="https://github.com/eric-haibin-lin/verl-community/blob/main/slides/verl-lmsys-meetup.pdf" target="_blank" rel="noopener noreferrer">pengantar & pembaruan verl</a> di <a href="https://lu.ma/ntjrr7ig" target="_blank" rel="noopener noreferrer">SGLang-LMSYS Org Meetup</a> di Sunnyvale pertengahan Maret.</li>
  <li>[2025/03] Kami akan mempresentasikan verl(HybridFlow) di EuroSys 2025. Sampai jumpa di Rotterdam!</li>
  <li>[2025/02] verl v0.2.0.post2 dirilis!</li>
  <li>[2025/02] Kami mempresentasikan verl di <a href="https://lu.ma/ji7atxux">Bytedance/NVIDIA/Anyscale Ray Meetup</a>. Sampai jumpa di San Jose!</li>
  <li>[2025/01] <a href="https://team.doubao.com/zh/special/doubao_1_5_pro" target="_blank" rel="noopener noreferrer">Doubao-1.5-pro</a> dirilis dengan performa SOTA pada LLM & VLM. Model preview RL scaling dilatih menggunakan verl, mencapai performa setara OpenAI O1 pada benchmark matematika (70.0 pass@1 di AIME).</li>
  <li>[2024/12] verl dipresentasikan di Ray Forward 2024. Slide tersedia <a href="https://github.com/eric-haibin-lin/verl-community/blob/main/slides/Ray_Forward_2024_%E5%B7%AB%E9%94%A1%E6%96%8C.pdf">di sini</a></li>
  <li>[2024/12] Tim mempresentasikan <a href="https://neurips.cc/Expo/Conferences/2024/workshop/100677">Post-training LLMs: From Algorithms to Infrastructure</a> di NeurIPS 2024. <a href="https://github.com/eric-haibin-lin/verl-data/tree/neurips">Slide</a> dan <a href="https://neurips.cc/Expo/Conferences/2024/workshop/100677">video</a> tersedia.</li>
  <li>[2024/10] verl dipresentasikan di Ray Summit. <a href="https://www.youtube.com/watch?v=MrhMcXkXvJU&list=PLzTswPQNepXntmT8jr9WaNfqQ60QwW7-U&index=37">Video Youtube</a> tersedia.</li>
  <li>[2024/08] HybridFlow (verl) diterima di EuroSys 2025.</li>
</ul></ul>   
</details></p><h2>Fitur Utama</h2></p><ul><li><strong>FSDP</strong>, <strong>FSDP2</strong> dan <strong>Megatron-LM</strong> untuk pelatihan.</li>
<li><strong>vLLM</strong>, <strong>SGLang</strong> dan <strong>HF Transformers</strong> untuk generasi rollout.</li>
<li>Kompatibel dengan Hugging Face Transformers dan Modelscope Hub: <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/grpo_trainer/run_qwen3-8b.sh" target="_blank" rel="noopener noreferrer">Qwen-3</a>, Qwen-2.5, Llama3.1, Gemma2, DeepSeek-LLM, dll.</li>
<li>Fine-tuning terawasi.</li>
<li>Pembelajaran penguatan dengan <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/ppo_trainer/" target="_blank" rel="noopener noreferrer">PPO</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/grpo_trainer/" target="_blank" rel="noopener noreferrer">GRPO</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/remax_trainer/" target="_blank" rel="noopener noreferrer">ReMax</a>, <a href="https://verl.readthedocs.io/en/latest/examples/config.html#algorithm" target="_blank" rel="noopener noreferrer">REINFORCE++</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/rloo_trainer/" target="_blank" rel="noopener noreferrer">RLOO</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/prime/" target="_blank" rel="noopener noreferrer">PRIME</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/dapo/" target="_blank" rel="noopener noreferrer">DAPO</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/drgrpo" target="_blank" rel="noopener noreferrer">DrGRPO</a>, dll.</li>
  <li>Mendukung reward berbasis model dan reward berbasis fungsi (verifiable reward) untuk matematika, <a href="https://github.com/volcengine/verl/tree/main/recipe/dapo" target="_blank" rel="noopener noreferrer">coding</a>, dll.</li>
  <li>Mendukung model vision-language (VLM) dan <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/grpo_trainer/run_qwen2_5_vl-7b.sh" target="_blank" rel="noopener noreferrer">multi-modal RL</a> dengan Qwen2.5-vl, Kimi-VL</li>
  <li><a href="https://github.com/volcengine/verl/tree/main/examples/sglang_multiturn" target="_blank" rel="noopener noreferrer">Multi-turn dengan tool calling</a></li>
<li>Resep alignment LLM seperti <a href="https://github.com/volcengine/verl/tree/main/recipe/sppo" target="_blank" rel="noopener noreferrer">Self-play preference optimization (SPPO)</a></li>
<li>Flash attention 2, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/ppo_trainer/run_qwen2-7b_seq_balance.sh" target="_blank" rel="noopener noreferrer">sequence packing</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/ppo_trainer/run_deepseek7b_llm_sp2.sh" target="_blank" rel="noopener noreferrer">sequence parallelism</a> melalui DeepSpeed Ulysses, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/sft/gsm8k/run_qwen_05_peft.sh" target="_blank" rel="noopener noreferrer">LoRA</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/sft/gsm8k/run_qwen_05_sp2_liger.sh" target="_blank" rel="noopener noreferrer">Liger-kernel</a>.</li>
<li>Menskalakan hingga model 671B dan ratusan GPU dengan <a href="https://github.com/volcengine/verl/pull/1467" target="_blank" rel="noopener noreferrer">expert parallelism</a></li>
<li>Dukungan multi-gpu <a href="https://verl.readthedocs.io/en/latest/advance/ppo_lora.html" target="_blank" rel="noopener noreferrer">LoRA RL</a> untuk menghemat memori.</li>
<li>Pelacakan eksperimen dengan wandb, swanlab, mlflow dan tensorboard.</li></p><p></ul><h2>Fitur dan Perubahan Mendatang</h2></p><ul><li>Roadmap https://github.com/volcengine/verl/issues/710</li>
<li>Optimasi DeepSeek 671b dengan Megatron v0.11 https://github.com/volcengine/verl/issues/708</li>
<li>Rollout multi-turn dan optimasi penggunaan tools https://github.com/volcengine/verl/issues/1882</li>
<li>Interaksi lingkungan https://github.com/volcengine/verl/issues/1172</li>
<li>Daftar breaking changes sejak v0.3 https://github.com/volcengine/verl/discussions/943, entropy_coeff default ke 0</li>
<li>Lora untuk RL https://github.com/volcengine/verl/pull/1127 </li></p><p></ul><h2>Memulai</h2></p><p><a href="https://verl.readthedocs.io/en/latest/index.html"><b>Dokumentasi</b></a></p><p><strong>Quickstart:</strong></p><ul><li><a href="https://verl.readthedocs.io/en/latest/start/install.html" target="_blank" rel="noopener noreferrer">Instalasi</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/start/quickstart.html" target="_blank" rel="noopener noreferrer">Quickstart</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/hybrid_flow.html" target="_blank" rel="noopener noreferrer">Panduan Pemrograman</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/algo/ppo.html" target="_blank" rel="noopener noreferrer">PPO di verl</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/algo/grpo.html" target="_blank" rel="noopener noreferrer">GRPO di verl</a></li></p><p></ul><strong>Menjalankan contoh PPO langkah demi langkah:</strong></p><ul><li><a href="https://verl.readthedocs.io/en/latest/preparation/prepare_data.html" target="_blank" rel="noopener noreferrer">Persiapan Data untuk Post-Training</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/preparation/reward_function.html" target="_blank" rel="noopener noreferrer">Implementasi Fungsi Reward untuk Dataset</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/examples/ppo_code_architecture.html" target="_blank" rel="noopener noreferrer">Arsitektur Contoh PPO</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/examples/config.html" target="_blank" rel="noopener noreferrer">Penjelasan Konfigurasi</a></li></p><p></ul><strong>Baseline algoritma yang dapat direproduksi:</strong></p><ul><li><a href="https://verl.readthedocs.io/en/latest/algo/baseline.html" target="_blank" rel="noopener noreferrer">Performa RL pada coding, matematika</a></li></p><p></ul><strong>Untuk penjelasan kode dan penggunaan lanjutan (ekstensi):</strong></p><ul><li>PPO Trainer dan Workers</li>
  <li><a href="https://verl.readthedocs.io/en/latest/workers/ray_trainer.html" target="_blank" rel="noopener noreferrer">PPO Ray Trainer</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/workers/fsdp_workers.html" target="_blank" rel="noopener noreferrer">PyTorch FSDP Backend</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener noreferrer">Megatron-LM Backend</a></li></p><p><li>Penggunaan Lanjutan dan Ekstensi</li>
  <li><a href="https://verl.readthedocs.io/en/latest/advance/fsdp_extension.html" target="_blank" rel="noopener noreferrer">Menambah Model dengan FSDP Backend</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/advance/megatron_extension.html" target="_blank" rel="noopener noreferrer">Menambah Model dengan Megatron-LM Backend</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/sglang_multiturn/multiturn.html" target="_blank" rel="noopener noreferrer">Dukungan Multi-turn Rollout</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/sglang_multiturn/search_tool_example.html" target="_blank" rel="noopener noreferrer">Integrasi Search Tool</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/examples/sandbox_fusion_example.html" target="_blank" rel="noopener noreferrer">Integrasi Sandbox Fusion</a></li>
  <li><a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/split_placement" target="_blank" rel="noopener noreferrer">Deployment menggunakan Sumber Daya GPU Terpisah</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/advance/dpo_extension.html" target="_blank" rel="noopener noreferrer">Perluas ke Algoritma RL(HF) Lainnya</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/advance/placement.html" target="_blank" rel="noopener noreferrer">Tutorial desain API Ray</a></li></p><p></ul><strong>Blog dari komunitas</strong></p><ul><li><a href="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/multi-turn/verl-multiturn-rollout-Release.md" target="_blank" rel="noopener noreferrer">SGLang, verl, OpenBMB dan Universitas Tsinghua: Pelopor End-to-End Multi-Turn RLHF</a></li>
<li><a href="https://rocm.blogs.amd.com/artificial-intelligence/verl-large-scale/README.html" target="_blank" rel="noopener noreferrer">Reinforcement Learning dari Human Feedback di GPU AMD dengan integrasi verl dan ROCm</a></li>
<li><a href="https://mp.weixin.qq.com/s/7nbqxk4knMGd-hQE9ls2tA" target="_blank" rel="noopener noreferrer">veMLP x verl ：Eksplorasi pelatihan reinforcement learning</a></li>
<li><a href="https://www.volcengine.com/docs/6459/1463942" target="_blank" rel="noopener noreferrer">Praktik terbaik pelatihan RL terdistribusi GRPO menggunakan verl</a></li>
<li><a href="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/readme.md" target="_blank" rel="noopener noreferrer">Analisis asli HybridFlow verl</a></li>
<li><a href="https://team.doubao.com/en/blog/%E6%9C%80%E9%AB%98%E6%8F%90%E5%8D%8720%E5%80%8D%E5%90%9E%E5%90%90%E9%87%8F-%E8%B1%86%E5%8C%85%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9B%A2%E9%98%9F%E5%8F%91%E5%B8%83%E5%85%A8%E6%96%B0-rlhf-%E6%A1%86%E6%9E%B6-%E7%8E%B0%E5%B7%B2%E5%BC%80%E6%BA%90" target="_blank" rel="noopener noreferrer">Hingga 20x peningkatan throughput! Tim Doubao merilis framework RLHF baru, kini open-source!</a></li></p><p></ul><h2>Panduan Penyetelan Performa</h2></p><p>Performa sangat penting untuk algoritma RL on-policy. Kami telah menulis <a href="https://verl.readthedocs.io/en/latest/perf/perf_tuning.html" target="_blank" rel="noopener noreferrer">panduan penyetelan performa</a> yang detail untuk membantu Anda mengoptimalkan performa.</p><h2>Upgrade ke vLLM >= v0.8.2</h2></p><p>verl kini mendukung vLLM>=0.8.2 saat menggunakan FSDP sebagai backend pelatihan. Silakan lihat <a href="https://github.com/volcengine/verl/blob/main/docs/README_vllm0.8.md" target="_blank" rel="noopener noreferrer">dokumen ini</a> untuk panduan instalasi dan informasi lebih lanjut. Hindari vllm 0.7.x, karena mengandung bug yang dapat menyebabkan OOM dan error tak terduga.</p><h2>Gunakan SGLang Terbaru</h2></p><p>SGLang didukung penuh di verl, dan Grup RL SGLang bekerja membangun fitur unik seperti multi-turn agentic RL, VLM RLHF, RL berbasis server, dan partial rollout. Silakan lihat <a href="https://verl.readthedocs.io/en/latest/workers/sglang_worker.html" target="_blank" rel="noopener noreferrer">dokumen ini</a> untuk panduan instalasi dan info lebih lanjut.</p><h2>Upgrade ke FSDP2</h2></p><p>verl sepenuhnya mengadopsi FSDP2! FSDP2 direkomendasikan oleh tim torch distributed, memberikan throughput dan penggunaan memori lebih baik, serta dapat digabung dengan fitur lain (misal torch.compile). Untuk mengaktifkan FSDP2, cukup gunakan verl main dan atur opsi berikut:
<pre><code class="language-">actor_rollout_ref.ref.strategy=fsdp2
actor_rollout_ref.actor.strategy=fsdp2
critic.strategy=fsdp2 
reward_model.strategy=fsdp2 </code></pre>
Selain itu, offloading CPU FSDP2 kompatibel dengan akumulasi gradien. Anda dapat mengaktifkannya untuk menghemat memori dengan <code>actor_rollout_ref.actor.offload_policy=True</code>. Detail selengkapnya di https://github.com/volcengine/verl/pull/1026</p><h2>Dukungan AMD (Kernel ROCm)</h2></p><p>verl kini mendukung FSDP sebagai engine pelatihan (dukungan Megatron segera hadir) serta terintegrasi dengan vLLM dan SGLang sebagai engine inferensi. Silakan lihat <a href="https://github.com/volcengine/verl/blob/main/docs/amd_tutorial/amd_build_dockerfile_page.rst" target="_blank" rel="noopener noreferrer">dokumen ini</a> untuk panduan instalasi dan info lebih lanjut, serta <a href="https://github.com/volcengine/verl/blob/main/docs/amd_tutorial/amd_vllm_page.rst" target="_blank" rel="noopener noreferrer">dokumen ini</a> untuk tuning performa vLLM pada ROCm.</p><h2>Sitasi dan Pengakuan</h2></p><p>Jika Anda merasa proyek ini bermanfaat, silakan kutip:</p><ul><li><a href="https://arxiv.org/abs/2409.19256v2" target="_blank" rel="noopener noreferrer">HybridFlow: A Flexible and Efficient RLHF Framework</a></li>
<li><a href="https://i.cs.hku.hk/~cwu/papers/gmsheng-NL2Code24.pdf" target="_blank" rel="noopener noreferrer">A Framework for Training Large Language Models for Code Generation via Proximal Policy Optimization</a></li></p><p></ul><pre><code class="language-bibtex">@article{sheng2024hybridflow,
  title   = {HybridFlow: A Flexible and Efficient RLHF Framework},
  author  = {Guangming Sheng and Chi Zhang and Zilingfeng Ye and Xibin Wu and Wang Zhang and Ru Zhang and Yanghua Peng and Haibin Lin and Chuan Wu},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2409.19256}
}</code></pre></p><p>verl terinspirasi dari desain Nemo-Aligner, Deepspeed-chat, dan OpenRLHF. Proyek ini diadopsi dan dikontribusi oleh Bytedance, Anyscale, LMSys.org, <a href="https://github.com/QwenLM/" target="_blank" rel="noopener noreferrer">Tim Qwen Alibaba</a>, Shanghai AI Lab, Universitas Tsinghua, UC Berkeley, UCLA, UIUC, University of Hong Kong, ke.com, <a href="https://www.all-hands.dev/" target="_blank" rel="noopener noreferrer">All Hands AI</a>, <a href="http://modelbest.cn/" target="_blank" rel="noopener noreferrer">ModelBest</a>, OpenPipe, JD AI Lab, Microsoft Research, <a href="https://www.stepfun.com/" target="_blank" rel="noopener noreferrer">StepFun</a>, Amazon, Linkedin, Meituan, <a href="https://www.camel-ai.org/" target="_blank" rel="noopener noreferrer">Camel-AI</a>, <a href="https://github.com/OpenManus" target="_blank" rel="noopener noreferrer">OpenManus</a>, Xiaomi, Prime Intellect, NVIDIA research, <a href="https://www.baichuan-ai.com/home" target="_blank" rel="noopener noreferrer">Baichuan</a>, <a href="https://www.xiaohongshu.com/" target="_blank" rel="noopener noreferrer">RedNote</a>, <a href="https://www.swiss-ai.org/" target="_blank" rel="noopener noreferrer">SwissAI</a>, <a href="https://www.moonshot-ai.com/" target="_blank" rel="noopener noreferrer">Moonshot AI (Kimi)</a>, Baidu, Snowflake, dan banyak lagi.</p><h2>Karya-karya Keren Menggunakan verl</h2></p><ul><li><a href="https://github.com/Jiayi-Pan/TinyZero" target="_blank" rel="noopener noreferrer">TinyZero</a>: reproduksi resep <strong>DeepSeek R1 Zero</strong> untuk tugas reasoning <img src="https://img.shields.io/github/stars/Jiayi-Pan/TinyZero" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/NovaSky-AI/SkyThought" target="_blank" rel="noopener noreferrer">SkyThought</a>: Pelatihan RL untuk Sky-T1-7B oleh tim NovaSky AI. <img src="https://img.shields.io/github/stars/NovaSky-AI/SkyThought" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/hkust-nlp/simpleRL-reason" target="_blank" rel="noopener noreferrer">simpleRL-reason</a>: SimpleRL-Zoo: Investigasi dan Penjinakan Zero Reinforcement Learning untuk Open Base Models in the Wild <img src="https://img.shields.io/github/stars/hkust-nlp/simpleRL-reason" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/hiyouga/EasyR1" target="_blank" rel="noopener noreferrer">Easy-R1</a>: Framework pelatihan RL <strong>multi-modal</strong> <img src="https://img.shields.io/github/stars/hiyouga/EasyR1" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/OpenManus/OpenManus-RL" target="_blank" rel="noopener noreferrer">OpenManus-RL</a>: Framework tuning RL Agen LLM untuk multi lingkungan agen. <img src="https://img.shields.io/github/stars/OpenManus/OpenManus-RL" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/agentica-project/rllm" target="_blank" rel="noopener noreferrer">rllm</a>: pelatihan RL async dengan <a href="https://github.com/agentica-project/verl-pipeline" target="_blank" rel="noopener noreferrer">verl-pipeline</a> <img src="https://img.shields.io/github/stars/agentica-project/rllm" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/PRIME-RL/PRIME" target="_blank" rel="noopener noreferrer">PRIME</a>: Reinforcement proses melalui reward implisit <img src="https://img.shields.io/github/stars/PRIME-RL/PRIME" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/ZihanWang314/ragen" target="_blank" rel="noopener noreferrer">RAGEN</a>: framework pelatihan <strong>agen</strong> reasoning umum <img src="https://img.shields.io/github/stars/ZihanWang314/ragen" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/PeterGriffinJin/Search-R1" target="_blank" rel="noopener noreferrer">Search-R1</a>: RL dengan reasoning dan <strong>searching (tool-call)</strong> LLM interleaved <img src="https://img.shields.io/github/stars/PeterGriffinJin/Search-R1" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/pat-jj/DeepRetrieval" target="_blank" rel="noopener noreferrer">DeepRetrieval</a>: Pelatihan RL <strong>Agen Pencarian</strong> dengan <strong>Search/Retrieval Outcome</strong> <img src="https://img.shields.io/github/stars/pat-jj/DeepRetrieval" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/Agent-RL/ReSearch" target="_blank" rel="noopener noreferrer">ReSearch</a>: Belajar <strong>Re</strong>ason dengan <strong>Search</strong> untuk LLM melalui RL <img src="https://img.shields.io/github/stars/Agent-RL/ReSearch" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/ganler/code-r1" target="_blank" rel="noopener noreferrer">Code-R1</a>: Mereproduksi R1 untuk <strong>Kode</strong> dengan Reward Andal <img src="https://img.shields.io/github/stars/ganler/code-r1" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/SkyworkAI/Skywork-OR1" target="_blank" rel="noopener noreferrer">Skywork-OR1</a>: Seri Skywork open reasoner <img src="https://img.shields.io/github/stars/SkyworkAI/Skywork-OR1" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/GAIR-NLP/ToRL" target="_blank" rel="noopener noreferrer">ToRL</a>: Menskalakan RL terintegrasi tool <img src="https://img.shields.io/github/stars/GAIR-NLP/ToRL" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/langfengQ/verl-agent" target="_blank" rel="noopener noreferrer">verl-agent</a>: Framework pelatihan skalabel untuk <strong>agen LLM/VLM long-horizon</strong>, beserta algoritma baru <strong>GiGPO</strong> <img src="https://img.shields.io/github/stars/langfengQ/verl-agent" alt="GitHub Repo stars"></li>
<li><a href="https://arxiv.org/abs/2409.06957" target="_blank" rel="noopener noreferrer">PF-PPO</a>: Policy Filtration untuk PPO berdasarkan reliabilitas sinyal reward demi RLHF yang lebih efisien dan robust.</li>
<li><a href="https://github.com/ritzz-ai/GUI-R1" target="_blank" rel="noopener noreferrer">GUI-R1</a>: <strong>GUI-R1</strong>: Model Aksi Vision-Language Generalis R1-style Untuk <strong>Agen GUI</strong> <img src="https://img.shields.io/github/stars/ritzz-ai/GUI-R1" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/GAIR-NLP/DeepResearcher" target="_blank" rel="noopener noreferrer">DeepResearcher</a>: Menskalakan deep research melalui RL di lingkungan nyata <img src="https://img.shields.io/github/stars/GAIR-NLP/DeepResearcher" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/RAGEN-AI/VAGEN" target="_blank" rel="noopener noreferrer">VAGEN</a>: Melatih agen VLM dengan RL multi-turn <img src="https://img.shields.io/github/stars/RAGEN-AI/VAGEN" alt="GitHub Repo stars"></li>
<li><a href="https://retool-rl.github.io/" target="_blank" rel="noopener noreferrer">ReTool</a>: ReTool: reinforcement learning untuk penggunaan tool strategis pada LLM. Kode segera dirilis...</li>
<li><a href="https://arxiv.org/abs/2505.02387" target="_blank" rel="noopener noreferrer">RM-R1</a>: RL pelatihan model reward reasoning <img src="https://img.shields.io/github/stars/RM-R1-UIUC/RM-R1" alt="GitHub Repo stars"></li>
<li><a href="https://arxiv.org/abs/2505.03335" target="_blank" rel="noopener noreferrer">Absolute Zero Reasoner</a>: Framework self-play tanpa data kurasi manusia untuk reasoning<img src="https://img.shields.io/github/stars/LeapLabTHU/Absolute-Zero-Reasoner" alt="GitHub Repo stars"></li>
<li><a href="https://arxiv.org/pdf/2504.14945" target="_blank" rel="noopener noreferrer">LUFFY</a>: Belajar Reasoning di bawah Off-Policy Guidance<img src="https://img.shields.io/github/stars/ElliottYan/LUFFY" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/TIGER-AI-Lab/verl-tool" target="_blank" rel="noopener noreferrer">verl-tool</a>: Framework pelatihan tool-agent yang terintegrasi dan mudah diperluas berbasis verl<img src="https://img.shields.io/github/stars/TIGER-AI-Lab/verl-tool" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/zwhe99/DeepMath" target="_blank" rel="noopener noreferrer">DeepMath</a>: DeepMath-103K data dan seri model untuk reasoning matematika<img src="https://img.shields.io/github/stars/zwhe99/DeepMath" alt="GitHub Repo stars"></li></p><p></ul>dan masih banyak lagi karya keren lainnya di <a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/README.md" target="_blank" rel="noopener noreferrer">recipe</a>.
<h2>Panduan Kontribusi</h2></p><p>Kontribusi dari komunitas sangat kami sambut! Silakan cek <a href="https://github.com/volcengine/verl/issues/710" target="_blank" rel="noopener noreferrer">roadmap proyek</a> dan <a href="https://github.com/volcengine/verl/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22good%20first%20issue%22" target="_blank" rel="noopener noreferrer">good first issues</a> untuk melihat di mana Anda bisa berkontribusi.</p><h3>Linting dan Formatting Kode</h3></p><p>Kami menggunakan pre-commit untuk membantu meningkatkan kualitas kode. Untuk menginisialisasi pre-commit, jalankan:</p><pre><code class="language-bash">pip install pre-commit
pre-commit install</code></pre></p><p>Untuk mengatasi error CI secara lokal, Anda dapat menjalankan pre-commit secara manual dengan:</p><pre><code class="language-bash">pre-commit run</code></pre></p><h3>Menambahkan Tes CI</h3></p><p>Jika memungkinkan, tambahkan tes CI untuk fitur baru Anda:</p><ul><li>Temukan file workflow yml yang paling relevan, biasanya sesuai dengan config default <code>hydra</code> (misal <code>ppo_trainer</code>, <code>ppo_megatron_trainer</code>, <code>sft_trainer</code>, dll).</li>
<li>Tambahkan pola path terkait ke bagian <code>paths</code> jika belum ada.</li>
<li>Minimalkan beban kerja skrip tes (lihat contoh skrip yang sudah ada).</li></p><p></ul><h2>Tentang <a href="https://team.doubao.com/" target="_blank" rel="noopener noreferrer">Tim ByteDance Seed</a></h2></p><p>Didirikan pada 2023, Tim ByteDance Seed berdedikasi untuk menciptakan model AI foundation paling maju di industri. Tim ini bercita-cita menjadi tim riset kelas dunia dan berkontribusi signifikan pada kemajuan ilmu pengetahuan dan masyarakat. Anda dapat mengenal Tim ByteDance Seed lebih lanjut melalui kanal-kanal berikut 👇
<div>
  <a href="https://team.doubao.com/">
    <img src="https://img.shields.io/badge/Website-%231e37ff?style=for-the-badge&logo=bytedance&logoColor=white"></a>
  <a href="https://github.com/user-attachments/assets/469535a8-42f2-4797-acdf-4f7a1d4a0c3e">
    <img src="https://img.shields.io/badge/WeChat-07C160?style=for-the-badge&logo=wechat&logoColor=white"></a>
 <a href="https://www.xiaohongshu.com/user/profile/668e7e15000000000303157d?xsec_token=ABl2-aqekpytY6A8TuxjrwnZskU-6BsMRE_ufQQaSAvjc%3D&xsec_source=pc_search">
    <img src="https://img.shields.io/badge/Xiaohongshu-%23FF2442?style=for-the-badge&logo=xiaohongshu&logoColor=white"></a>
  <a href="https://www.zhihu.com/org/dou-bao-da-mo-xing-tuan-dui/">
    <img src="https://img.shields.io/badge/zhihu-%230084FF?style=for-the-badge&logo=zhihu&logoColor=white"></a></p><p></div>
<hr></p><p>Kami sedang MEMBUKA LOWONGAN! Kirimkan <a href="mailto:haibin.lin@bytedance.com" target="_blank" rel="noopener noreferrer">email</a> jika Anda tertarik dengan peluang magang/FTE di RL untuk agen.

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-07

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/volcengine/verl/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>