<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>verl - Read verl documentation in Russian. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read verl documentation in Russian. This project has 0 stars on GitHub.">
    <meta name="keywords" content="verl, Russian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "verl",
  "description": "Read verl documentation in Russian. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "volcengine"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/volcengine/verl/README-ru.html",
  "sameAs": "https://raw.githubusercontent.com/volcengine/verl/master/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/volcengine/verl" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    verl
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Russian</span>
                <span>by volcengine</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align="center">
 👋 Привет, всем! 
    verl — это библиотека для обучения с подкреплением (RL), инициированная <b>командой ByteDance Seed</b> и поддерживаемая сообществом verl.
    <br>
    <br>
</div></p><p><div align="center"></p><p><a href="https://deepwiki.com/volcengine/verl" target="_blank" rel="noopener noreferrer"><img src="https://devin.ai/assets/deepwiki-badge.png" alt="Ask DeepWiki.com" height="20"/></a>
<a href="https://github.com/volcengine/verl/stargazers" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/github/stars/volcengine/verl" alt="GitHub Repo stars"></a>
<a href="https://twitter.com/verl_project" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/twitter/follow/verl_project" alt="Twitter"></a>
<a href="https://join.slack.com/t/verlgroup/shared_invite/zt-2w5p9o4c3-yy0x2Q56s_VlGLsJ93A6vA"><img src="https://img.shields.io/badge/Slack-verl-blueviolet?logo=slack&amp"></a>
<a href="https://arxiv.org/pdf/2409.19256"><img src="https://img.shields.io/static/v1?label=EuroSys&message=Paper&color=red"></a>
<a href="https://verl.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/documentation-blue" alt="Документация"></a>
<a href="https://raw.githubusercontent.com/eric-haibin-lin/verl-community/refs/heads/main/WeChat.JPG"><img src="https://img.shields.io/badge/微信-green?logo=wechat&amp"></a></p><p></div></p><p><img src="https://github.com/user-attachments/assets/c42e675e-497c-4508-8bb9-093ad4d1f216" alt="seed logo"></p><p><h1 style="text-align: center;">verl: Volcano Engine Reinforcement Learning для LLM</h1></p><p>verl — это гибкая, эффективная и готовая к промышленному использованию библиотека RL для обучения крупных языковых моделей (LLM).</p><p>verl — это открытая версия статьи <strong><a href="https://arxiv.org/abs/2409.19256v2" target="_blank" rel="noopener noreferrer">HybridFlow: A Flexible and Efficient RLHF Framework</a></strong>.</p><p>verl отличается гибкостью и простотой:</p><ul><li><strong>Простое расширение различных RL-алгоритмов</strong>: Гибридная модель контроллера позволяет гибко представлять и эффективно выполнять сложные пайплайны пост-обучения. Сборка RL пайплайнов, таких как GRPO, PPO, возможна в несколько строк кода.</li></p><p><li><strong>Бесшовная интеграция существующей LLM-инфраструктуры с модульными API</strong>: Разделяет вычислительные и датовые зависимости, позволяя интеграцию с существующими LLM-фреймворками, такими как FSDP, Megatron-LM, vLLM, SGLang и др.</li></p><p><li><strong>Гибкое распределение устройств</strong>: Поддерживает различные размещения моделей на разных GPU для эффективного использования ресурсов и масштабирования на кластерах разного размера.</li></p><p><li>Готовая интеграция с популярными моделями HuggingFace</li></p><p></ul>verl быстрый благодаря:</p><ul><li><strong>Передовой пропускной способности</strong>: Интеграция с передовыми движками обучения и вывода LLM и современная производительность RL.</li></p><p><li><strong>Эффективный пересчет актор-моделей с помощью 3D-HybridEngine</strong>: Устраняет избыточность памяти и значительно снижает затраты на коммуникацию при переходах между фазами обучения и генерации.</li></p><p></ul></p></p><h2>Новости</h2></p><ul><li>[2025/06] verl с бэкендом Megatron поддерживает большие MoE-модели, такие как <a href="https://verl.readthedocs.io/en/latest/perf/dpsk.html" target="_blank" rel="noopener noreferrer">DeepSeek-671b и Qwen3-236b</a>.</li>
<li>[2025/06] команда verl представит последние обновления проекта на <a href="https://www.lfasiallc.com/pytorch-day-china/" target="_blank" rel="noopener noreferrer">PyTorch Day China</a> 7 июня. Встречайте нашу команду в Пекине!</li>
<li>[2025/05] <a href="https://arxiv.org/abs/2409.06957" target="_blank" rel="noopener noreferrer">PF-PPO</a>, принятый на ICML 2025, теперь поддерживается в verl! PF-PPO повышает эффективность и надежность обучения политик, фильтруя шумные сигналы награды и повторно используя качественный опыт через replay buffer.</li>
<li>[2025/04] Мы проведём туториал по современным пост-тренинговым техникам и программированию для verl на <a href="https://iclr.cc/virtual/2025/calendar?filter_events=Expo+Talk+Panel&filter_rooms=" target="_blank" rel="noopener noreferrer">ICLR 2025 Expo</a>, <a href="https://open-foundation-model.github.io/" target="_blank" rel="noopener noreferrer">SCI-FM workshop</a> и <a href="https://lu.ma/d23nyynm" target="_blank" rel="noopener noreferrer">LMSys afterparty</a>. Материалы доступны <a href="https://github.com/eric-haibin-lin/verl-community/tree/main/iclr25" target="_blank" rel="noopener noreferrer">здесь</a>.</li>
<li>[2025/04] Выпущен технический отчёт <a href="https://github.com/ByteDance-Seed/Seed-Thinking-v1.5/blob/main/seed-thinking-v1.5.pdf" target="_blank" rel="noopener noreferrer">Seed-Thinking-v1.5</a>! Модель обучена с помощью verl, Seed-Thinking-v1.5 достигает 86.7 на AIME 2024, 55.0 на Codeforces и 77.3 на GPQA, демонстрируя отличные способности к рассуждению в STEM и программировании. Метод также показывает хорошую обобщаемость в разных доменах.</li>
<li>[2025/04] <a href="https://arxiv.org/pdf/2504.05118" target="_blank" rel="noopener noreferrer">VAPO</a> (value-based augmented PPO) — статья о нашем новом RL-методе для моделей рассуждения. Модель VAPO, обученная на Qwen-32B-base, достигает 60.4 на AIME 2024, опережая DAPO-32B.</li>
<li>[2025/03] Выпущен verl v0.3.0.post1! См. <a href="https://github.com/volcengine/verl/releases/" target="_blank" rel="noopener noreferrer">заметки о релизе</a>. Скорость работы <a href="https://tongyx361.github.io/blogs/posts/verl-intro/#/verl-flexible-and-efficient-rl-for-llms" target="_blank" rel="noopener noreferrer">~1.4x выше</a> по сравнению с предыдущими версиями.</li>
<li>[2025/03] <a href="https://dapo-sia.github.io/" target="_blank" rel="noopener noreferrer">DAPO</a> — открытый SOTA RL-алгоритм, достигающий 50 баллов на AIME 2024 на модели Qwen2.5-32B, превосходя предыдущий SOTA DeepSeek GRPO (DeepSeek-R1-Zero-Qwen-32B). DAPO обучается полностью на базе verl, код воспроизведения доступен в <code>recipe/dapo</code>.</li>
</ul><details><summary> ещё... </summary>
<ul>
  <ul><li>[2025/05] verl будет представлен на <a href="https://a2m.msup.com.cn/home/?aid=4488&city=shanghai" target="_blank" rel="noopener noreferrer">A2M Shanghai</a> 16–17 мая.</li>
  <li>[2025/05] verl будет представлен на <a href="https://paris2025.gosim.org/" target="_blank" rel="noopener noreferrer">GOSIM x PyTorch Day 2025</a>. Увидимся в Париже! </li>
  <li>[2025/03] Мы представили программную модель verl на <a href="https://mp.weixin.qq.com/s/n77GibL2corAtQHtVEAzfg" target="_blank" rel="noopener noreferrer">vLLM Beijing Meetup</a> и <a href="https://github.com/eric-haibin-lin/verl-community/blob/main/slides/verl-lmsys-meetup.pdf" target="_blank" rel="noopener noreferrer">обзор verl</a> на <a href="https://lu.ma/ntjrr7ig" target="_blank" rel="noopener noreferrer">SGLang-LMSYS Org Meetup</a> в Саннивейле в марте.</li>
  <li>[2025/03] Мы представим verl (HybridFlow) на EuroSys 2025. Увидимся в Роттердаме!</li>
  <li>[2025/02] Выпущен verl v0.2.0.post2!</li>
  <li>[2025/02] Мы представили verl на <a href="https://lu.ma/ji7atxux">Bytedance/NVIDIA/Anyscale Ray Meetup</a>. До встречи в Сан-Хосе!</li>
  <li>[2025/01] <a href="https://team.doubao.com/zh/special/doubao_1_5_pro" target="_blank" rel="noopener noreferrer">Doubao-1.5-pro</a> выпущен с SOTA-уровнем производительности на LLM и VLM. RL-модель обучена с помощью verl, достигнув уровня OpenAI O1 на математических бенчмарках (70.0 pass@1 на AIME).</li>
  <li>[2024/12] verl был представлен на Ray Forward 2024. Слайды доступны <a href="https://github.com/eric-haibin-lin/verl-community/blob/main/slides/Ray_Forward_2024_%E5%B7%AB%E9%94%A1%E6%96%8C.pdf">здесь</a></li>
  <li>[2024/12] Команда представила <a href="https://neurips.cc/Expo/Conferences/2024/workshop/100677">Post-training LLMs: From Algorithms to Infrastructure</a> на NeurIPS 2024. <a href="https://github.com/eric-haibin-lin/verl-data/tree/neurips">Слайды</a> и <a href="https://neurips.cc/Expo/Conferences/2024/workshop/100677">видео</a> доступны.</li>
  <li>[2024/10] verl был представлен на Ray Summit. <a href="https://www.youtube.com/watch?v=MrhMcXkXvJU&list=PLzTswPQNepXntmT8jr9WaNfqQ60QwW7-U&index=37">Видео на Youtube</a> доступно.</li>
  <li>[2024/08] HybridFlow (verl) принят на EuroSys 2025.</li>
</ul></ul>   
</details></p><h2>Ключевые возможности</h2></p><ul><li><strong>FSDP</strong>, <strong>FSDP2</strong> и <strong>Megatron-LM</strong> для обучения.</li>
<li><strong>vLLM</strong>, <strong>SGLang</strong> и <strong>HF Transformers</strong> для генерации rollout.</li>
<li>Совместимость с Hugging Face Transformers и Modelscope Hub: <a href="https://github.com/volcengine/verl/blob/main/examples/grpo_trainer/run_qwen3-8b.sh" target="_blank" rel="noopener noreferrer">Qwen-3</a>, Qwen-2.5, Llama3.1, Gemma2, DeepSeek-LLM и др.</li>
<li>Супервизионное дообучение.</li>
<li>Обучение с подкреплением: <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/ppo_trainer/" target="_blank" rel="noopener noreferrer">PPO</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/grpo_trainer/" target="_blank" rel="noopener noreferrer">GRPO</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/remax_trainer/" target="_blank" rel="noopener noreferrer">ReMax</a>, <a href="https://verl.readthedocs.io/en/latest/examples/config.html#algorithm" target="_blank" rel="noopener noreferrer">REINFORCE++</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/rloo_trainer/" target="_blank" rel="noopener noreferrer">RLOO</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/prime/" target="_blank" rel="noopener noreferrer">PRIME</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/dapo/" target="_blank" rel="noopener noreferrer">DAPO</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/drgrpo" target="_blank" rel="noopener noreferrer">DrGRPO</a>, и др.</li>
  <li>Поддержка моделей награды и функций награды (верифицируемая награда) для математики, <a href="https://github.com/volcengine/verl/tree/main/recipe/dapo" target="_blank" rel="noopener noreferrer">программирования</a> и др.</li>
  <li>Поддержка vision-language моделей (VLMs) и <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/grpo_trainer/run_qwen2_5_vl-7b.sh" target="_blank" rel="noopener noreferrer">мультимодального RL</a> с Qwen2.5-vl, Kimi-VL</li>
  <li><a href="https://github.com/volcengine/verl/tree/main/examples/sglang_multiturn" target="_blank" rel="noopener noreferrer">Мультиходовой RL с вызовом инструментов</a></li>
<li>Рецепты выравнивания LLM, например, <a href="https://github.com/volcengine/verl/tree/main/recipe/sppo" target="_blank" rel="noopener noreferrer">Self-play preference optimization (SPPO)</a></li>
<li>Flash attention 2, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/ppo_trainer/run_qwen2-7b_seq_balance.sh" target="_blank" rel="noopener noreferrer">sequence packing</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/ppo_trainer/run_deepseek7b_llm_sp2.sh" target="_blank" rel="noopener noreferrer">sequence parallelism</a> через DeepSpeed Ulysses, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/sft/gsm8k/run_qwen_05_peft.sh" target="_blank" rel="noopener noreferrer">LoRA</a>, <a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/sft/gsm8k/run_qwen_05_sp2_liger.sh" target="_blank" rel="noopener noreferrer">Liger-kernel</a>.</li>
<li>Масштабируемость до моделей 671B и сотен GPU с помощью <a href="https://github.com/volcengine/verl/pull/1467" target="_blank" rel="noopener noreferrer">expert parallelism</a></li>
<li>Мульти-GPU <a href="https://verl.readthedocs.io/en/latest/advance/ppo_lora.html" target="_blank" rel="noopener noreferrer">LoRA RL</a> для экономии памяти.</li>
<li>Трекинг экспериментов: wandb, swanlab, mlflow и tensorboard.</li></p><p></ul><h2>Грядущие возможности и изменения</h2></p><ul><li>Дорожная карта https://github.com/volcengine/verl/issues/710</li>
<li>Оптимизации DeepSeek 671b с Megatron v0.11 https://github.com/volcengine/verl/issues/708</li>
<li>Мультиходовой rollout и инструменты https://github.com/volcengine/verl/issues/1882</li>
<li>Взаимодействие с окружением https://github.com/volcengine/verl/issues/1172</li>
<li>Список breaking changes после v0.3 https://github.com/volcengine/verl/discussions/943, по умолчанию entropy_coeff = 0</li>
<li>Lora для RL https://github.com/volcengine/verl/pull/1127 </li></p><p></ul><h2>Быстрый старт</h2></p><p><a href="https://verl.readthedocs.io/en/latest/index.html"><b>Документация</b></a></p><p><strong>Quickstart:</strong></p><ul><li><a href="https://verl.readthedocs.io/en/latest/start/install.html" target="_blank" rel="noopener noreferrer">Установка</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/start/quickstart.html" target="_blank" rel="noopener noreferrer">Быстрый старт</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/hybrid_flow.html" target="_blank" rel="noopener noreferrer">Руководство по программированию</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/algo/ppo.html" target="_blank" rel="noopener noreferrer">PPO в verl</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/algo/grpo.html" target="_blank" rel="noopener noreferrer">GRPO в verl</a></li></p><p></ul><strong>Пошаговый запуск PPO-примера:</strong></p><ul><li><a href="https://verl.readthedocs.io/en/latest/preparation/prepare_data.html" target="_blank" rel="noopener noreferrer">Подготовка данных для постобучения</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/preparation/reward_function.html" target="_blank" rel="noopener noreferrer">Реализация функции награды для датасета</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/examples/ppo_code_architecture.html" target="_blank" rel="noopener noreferrer">Архитектура примера PPO</a></li>
<li><a href="https://verl.readthedocs.io/en/latest/examples/config.html" target="_blank" rel="noopener noreferrer">Объяснение конфигурации</a></li></p><p></ul><strong>Воспроизводимые RL-базовые алгоритмы:</strong></p><ul><li><a href="https://verl.readthedocs.io/en/latest/algo/baseline.html" target="_blank" rel="noopener noreferrer">RL-производительность на программировании и математике</a></li></p><p></ul><strong>Для объяснения кода и продвинутого использования (расширение):</strong></p><ul><li>PPO Trainer и воркеры</li>
  <li><a href="https://verl.readthedocs.io/en/latest/workers/ray_trainer.html" target="_blank" rel="noopener noreferrer">PPO Ray Trainer</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/workers/fsdp_workers.html" target="_blank" rel="noopener noreferrer">PyTorch FSDP Backend</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener noreferrer">Megatron-LM Backend</a></li></p><p><li>Продвинутое использование и расширение</li>
  <li><a href="https://verl.readthedocs.io/en/latest/advance/fsdp_extension.html" target="_blank" rel="noopener noreferrer">Добавление моделей с FSDP Backend</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/advance/megatron_extension.html" target="_blank" rel="noopener noreferrer">Добавление моделей с Megatron-LM Backend</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/sglang_multiturn/multiturn.html" target="_blank" rel="noopener noreferrer">Мультиходовая поддержка rollout</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/sglang_multiturn/search_tool_example.html" target="_blank" rel="noopener noreferrer">Интеграция инструментов поиска</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/examples/sandbox_fusion_example.html" target="_blank" rel="noopener noreferrer">Интеграция Sandbox Fusion</a></li>
  <li><a href="https://raw.githubusercontent.com/volcengine/verl/main/examples/split_placement" target="_blank" rel="noopener noreferrer">Деплой с отдельными GPU-ресурсами</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/advance/dpo_extension.html" target="_blank" rel="noopener noreferrer">Расширение на другие RL(HF) алгоритмы</a></li>
  <li><a href="https://verl.readthedocs.io/en/latest/advance/placement.html" target="_blank" rel="noopener noreferrer">Туториал по дизайну Ray API</a></li></p><p></ul><strong>Блоги от сообщества</strong></p><ul><li><a href="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/multi-turn/verl-multiturn-rollout-Release.md" target="_blank" rel="noopener noreferrer">SGLang, verl, OpenBMB и Университет Цинхуа: Новаторский сквозной Multi-Turn RLHF</a></li>
<li><a href="https://rocm.blogs.amd.com/artificial-intelligence/verl-large-scale/README.html" target="_blank" rel="noopener noreferrer">Обучение с подкреплением по человеческой обратной связи на AMD GPU с verl и интеграцией ROCm</a></li>
<li><a href="https://mp.weixin.qq.com/s/7nbqxk4knMGd-hQE9ls2tA" target="_blank" rel="noopener noreferrer">veMLP x verl ：Использование обучения с подкреплением</a></li>
<li><a href="https://www.volcengine.com/docs/6459/1463942" target="_blank" rel="noopener noreferrer">Лучшие практики распределённого обучения с подкреплением GRPO в verl</a></li>
<li><a href="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/readme.md" target="_blank" rel="noopener noreferrer">HybridFlow verl: разбор оригинала</a></li>
<li><a href="https://team.doubao.com/en/blog/%E6%9C%80%E9%AB%98%E6%8F%90%E5%8D%8720%E5%80%8D%E5%90%9E%E5%90%90%E9%87%8F-%E8%B1%86%E5%8C%85%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9B%A2%E9%98%9F%E5%8F%91%E5%B8%83%E5%85%A8%E6%96%B0-rlhf-%E6%A1%86%E6%9E%B6-%E7%8E%B0%E5%B7%B2%E5%BC%80%E6%BA%90" target="_blank" rel="noopener noreferrer">Увеличение пропускной способности до 20 раз! Команда Doubao выпускает новую RLHF-рамку — открытый исходный код!</a></li></p><p></ul><h2>Руководство по оптимизации производительности</h2></p><p>Производительность критична для RL-алгоритмов с политикой on-policy. Мы подготовили подробное <a href="https://verl.readthedocs.io/en/latest/perf/perf_tuning.html" target="_blank" rel="noopener noreferrer">руководство по оптимизации производительности</a>, чтобы помочь вам оптимизировать работу.</p><h2>Переход на vLLM >= v0.8.2</h2></p><p>verl теперь поддерживает vLLM>=0.8.2 при использовании FSDP в качестве тренингового бэкенда. См. <a href="https://github.com/volcengine/verl/blob/main/docs/README_vllm0.8.md" target="_blank" rel="noopener noreferrer">этот документ</a> для инструкции по установке и подробностей. Избегайте использования vllm 0.7.x — там есть баги, ведущие к OOM и ошибкам.</p><h2>Используйте последнюю версию SGLang</h2></p><p>SGLang полностью поддерживается verl, и группа SGLang RL активно разрабатывает уникальные возможности: multi-turn агентный RL, VLM RLHF, серверный RL и частичный rollout. См. <a href="https://verl.readthedocs.io/en/latest/workers/sglang_worker.html" target="_blank" rel="noopener noreferrer">этот документ</a> для инструкции по установке и подробностей.</p><h2>Переход на FSDP2</h2></p><p>verl полностью поддерживает FSDP2! FSDP2 рекомендован командой torch distributed, обеспечивает лучшую пропускную способность и использование памяти, а также компонуется с другими возможностями (например, torch.compile). Для включения FSDP2 используйте verl main и задайте такие параметры:
<pre><code class="language-">actor_rollout_ref.ref.strategy=fsdp2
actor_rollout_ref.actor.strategy=fsdp2
critic.strategy=fsdp2 
reward_model.strategy=fsdp2 </code></pre>
Также, FSDP2 с CPU offload совместим с градиентным накоплением. Включите <code>actor_rollout_ref.actor.offload_policy=True</code> для экономии памяти. Подробнее: https://github.com/volcengine/verl/pull/1026</p><h2>Поддержка AMD (ROCm Kernel)</h2></p><p>verl теперь поддерживает FSDP как движок обучения (поддержка Megatron скоро), а также интеграцию с vLLM и SGLang как движками вывода. См. <a href="https://github.com/volcengine/verl/blob/main/docs/amd_tutorial/amd_build_dockerfile_page.rst" target="_blank" rel="noopener noreferrer">этот документ</a> для установки и <a href="https://github.com/volcengine/verl/blob/main/docs/amd_tutorial/amd_vllm_page.rst" target="_blank" rel="noopener noreferrer">этот документ</a> для настройки производительности vLLM на ROCm.</p><h2>Цитирование и благодарности</h2></p><p>Если проект был вам полезен, пожалуйста, цитируйте:</p><ul><li><a href="https://arxiv.org/abs/2409.19256v2" target="_blank" rel="noopener noreferrer">HybridFlow: A Flexible and Efficient RLHF Framework</a></li>
<li><a href="https://i.cs.hku.hk/~cwu/papers/gmsheng-NL2Code24.pdf" target="_blank" rel="noopener noreferrer">A Framework for Training Large Language Models for Code Generation via Proximal Policy Optimization</a></li></p><p></ul><pre><code class="language-bibtex">@article{sheng2024hybridflow,
  title   = {HybridFlow: A Flexible and Efficient RLHF Framework},
  author  = {Guangming Sheng and Chi Zhang and Zilingfeng Ye and Xibin Wu and Wang Zhang and Ru Zhang and Yanghua Peng and Haibin Lin and Chuan Wu},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2409.19256}
}</code></pre></p><p>verl вдохновлён дизайном Nemo-Aligner, Deepspeed-chat и OpenRLHF. Проект поддерживается и развивается такими компаниями и организациями, как Bytedance, Anyscale, LMSys.org, <a href="https://github.com/QwenLM/" target="_blank" rel="noopener noreferrer">команда Alibaba Qwen</a>, Shanghai AI Lab, Университет Цинхуа, UC Berkeley, UCLA, UIUC, University of Hong Kong, ke.com, <a href="https://www.all-hands.dev/" target="_blank" rel="noopener noreferrer">All Hands AI</a>, <a href="http://modelbest.cn/" target="_blank" rel="noopener noreferrer">ModelBest</a>, OpenPipe, JD AI Lab, Microsoft Research, <a href="https://www.stepfun.com/" target="_blank" rel="noopener noreferrer">StepFun</a>, Amazon, Linkedin, Meituan, <a href="https://www.camel-ai.org/" target="_blank" rel="noopener noreferrer">Camel-AI</a>, <a href="https://github.com/OpenManus" target="_blank" rel="noopener noreferrer">OpenManus</a>, Xiaomi, Prime Intellect, NVIDIA research, <a href="https://www.baichuan-ai.com/home" target="_blank" rel="noopener noreferrer">Baichuan</a>, <a href="https://www.xiaohongshu.com/" target="_blank" rel="noopener noreferrer">RedNote</a>, <a href="https://www.swiss-ai.org/" target="_blank" rel="noopener noreferrer">SwissAI</a>, <a href="https://www.moonshot-ai.com/" target="_blank" rel="noopener noreferrer">Moonshot AI (Kimi)</a>, Baidu, Snowflake и др.</p><h2>Лучшие проекты на базе verl</h2></p><ul><li><a href="https://github.com/Jiayi-Pan/TinyZero" target="_blank" rel="noopener noreferrer">TinyZero</a>: воспроизведение рецепта <strong>DeepSeek R1 Zero</strong> для задач рассуждения <img src="https://img.shields.io/github/stars/Jiayi-Pan/TinyZero" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/NovaSky-AI/SkyThought" target="_blank" rel="noopener noreferrer">SkyThought</a>: RL-обучение для Sky-T1-7B от команды NovaSky AI <img src="https://img.shields.io/github/stars/NovaSky-AI/SkyThought" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/hkust-nlp/simpleRL-reason" target="_blank" rel="noopener noreferrer">simpleRL-reason</a>: SimpleRL-Zoo: исследование и управление Zero RL для открытых моделей <img src="https://img.shields.io/github/stars/hkust-nlp/simpleRL-reason" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/hiyouga/EasyR1" target="_blank" rel="noopener noreferrer">Easy-R1</a>: <strong>Мультимодальная</strong> RL-рамка <img src="https://img.shields.io/github/stars/hiyouga/EasyR1" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/OpenManus/OpenManus-RL" target="_blank" rel="noopener noreferrer">OpenManus-RL</a>: RL-платформа настройки агентов LLM для нескольких сред <img src="https://img.shields.io/github/stars/OpenManus/OpenManus-RL" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/agentica-project/rllm" target="_blank" rel="noopener noreferrer">rllm</a>: асинхронное RL-обучение с помощью <a href="https://github.com/agentica-project/verl-pipeline" target="_blank" rel="noopener noreferrer">verl-pipeline</a> <img src="https://img.shields.io/github/stars/agentica-project/rllm" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/PRIME-RL/PRIME" target="_blank" rel="noopener noreferrer">PRIME</a>: Процессное подкрепление через неявные награды <img src="https://img.shields.io/github/stars/PRIME-RL/PRIME" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/ZihanWang314/ragen" target="_blank" rel="noopener noreferrer">RAGEN</a>: универсальная рамка RL для обучения агентов рассуждения <img src="https://img.shields.io/github/stars/ZihanWang314/ragen" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/PeterGriffinJin/Search-R1" target="_blank" rel="noopener noreferrer">Search-R1</a>: RL с рассуждением и <strong>поиском (tool-call)</strong> для LLM <img src="https://img.shields.io/github/stars/PeterGriffinJin/Search-R1" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/pat-jj/DeepRetrieval" target="_blank" rel="noopener noreferrer">DeepRetrieval</a>: RL-обучение <strong>поискового агента</strong> с результатами поиска/извлечения <img src="https://img.shields.io/github/stars/pat-jj/DeepRetrieval" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/Agent-RL/ReSearch" target="_blank" rel="noopener noreferrer">ReSearch</a>: RL для обучения рассуждению с поиском для LLM <img src="https://img.shields.io/github/stars/Agent-RL/ReSearch" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/ganler/code-r1" target="_blank" rel="noopener noreferrer">Code-R1</a>: Воспроизведение R1 для <strong>кода</strong> с надёжными наградами <img src="https://img.shields.io/github/stars/ganler/code-r1" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/SkyworkAI/Skywork-OR1" target="_blank" rel="noopener noreferrer">Skywork-OR1</a>: серия Skywork open reasoner <img src="https://img.shields.io/github/stars/SkyworkAI/Skywork-OR1" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/GAIR-NLP/ToRL" target="_blank" rel="noopener noreferrer">ToRL</a>: Масштабируемый RL с интеграцией инструментов <img src="https://img.shields.io/github/stars/GAIR-NLP/ToRL" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/langfengQ/verl-agent" target="_blank" rel="noopener noreferrer">verl-agent</a>: Масштабируемая рамка обучения для <strong>LLM/VLM-агентов с длинным горизонтом</strong>, включая новый алгоритм <strong>GiGPO</strong> <img src="https://img.shields.io/github/stars/langfengQ/verl-agent" alt="GitHub Repo stars"></li>
<li><a href="https://arxiv.org/abs/2409.06957" target="_blank" rel="noopener noreferrer">PF-PPO</a>: Policy Filtration для PPO на основе надёжности сигналов награды для более эффективного и устойчивого RLHF.</li>
<li><a href="https://github.com/ritzz-ai/GUI-R1" target="_blank" rel="noopener noreferrer">GUI-R1</a>: <strong>GUI-R1</strong>: универсальная vision-language action модель для <strong>GUI-агентов</strong> <img src="https://img.shields.io/github/stars/ritzz-ai/GUI-R1" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/GAIR-NLP/DeepResearcher" target="_blank" rel="noopener noreferrer">DeepResearcher</a>: Масштабирование глубоких исследований с помощью RL в реальных средах <img src="https://img.shields.io/github/stars/GAIR-NLP/DeepResearcher" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/RAGEN-AI/VAGEN" target="_blank" rel="noopener noreferrer">VAGEN</a>: Обучение VLM-агентов с multi-turn RL <img src="https://img.shields.io/github/stars/RAGEN-AI/VAGEN" alt="GitHub Repo stars"></li>
<li><a href="https://retool-rl.github.io/" target="_blank" rel="noopener noreferrer">ReTool</a>: ReTool: RL для стратегического использования инструментов в LLM. Код будет опубликован...</li>
<li><a href="https://arxiv.org/abs/2505.02387" target="_blank" rel="noopener noreferrer">RM-R1</a>: RL-обучение моделей награды для рассуждений <img src="https://img.shields.io/github/stars/RM-R1-UIUC/RM-R1" alt="GitHub Repo stars"></li>
<li><a href="https://arxiv.org/abs/2505.03335" target="_blank" rel="noopener noreferrer">Absolute Zero Reasoner</a>: Framework самоигры для рассуждений без ручной разметки данных <img src="https://img.shields.io/github/stars/LeapLabTHU/Absolute-Zero-Reasoner" alt="GitHub Repo stars"></li>
<li><a href="https://arxiv.org/pdf/2504.14945" target="_blank" rel="noopener noreferrer">LUFFY</a>: Обучение рассуждению под off-policy-наставлением <img src="https://img.shields.io/github/stars/ElliottYan/LUFFY" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/TIGER-AI-Lab/verl-tool" target="_blank" rel="noopener noreferrer">verl-tool</a>: Унифицированная и легко расширяемая RL-рамка для обучения инструментальных агентов на базе verl <img src="https://img.shields.io/github/stars/TIGER-AI-Lab/verl-tool" alt="GitHub Repo stars"></li>
<li><a href="https://github.com/zwhe99/DeepMath" target="_blank" rel="noopener noreferrer">DeepMath</a>: DeepMath-103K датасет и серия моделей для математического рассуждения <img src="https://img.shields.io/github/stars/zwhe99/DeepMath" alt="GitHub Repo stars"></li></p><p></ul>и многие другие проекты перечислены в <a href="https://raw.githubusercontent.com/volcengine/verl/main/recipe/README.md" target="_blank" rel="noopener noreferrer">recipe</a>.
<h2>Руководство по вкладу</h2></p><p>Вклад от сообщества приветствуется! Пожалуйста, ознакомьтесь с нашей <a href="https://github.com/volcengine/verl/issues/710" target="_blank" rel="noopener noreferrer">дорожной картой</a> и <a href="https://github.com/volcengine/verl/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22good%20first%20issue%22" target="_blank" rel="noopener noreferrer">good first issues</a>, чтобы понять, где вы можете помочь.</p><h3>Линтинг и форматирование кода</h3></p><p>Для повышения качества кода мы используем pre-commit. Для инициализации pre-commit выполните:</p><pre><code class="language-bash">pip install pre-commit
pre-commit install</code></pre></p><p>Чтобы локально решить CI-ошибки, выполните:</p><pre><code class="language-bash">pre-commit run</code></pre></p><h3>Добавление CI-тестов</h3></p><p>По возможности добавляйте CI-тест(ы) для новой функции:</p><ul><li>Найдите наиболее подходящий workflow yml-файл, обычно соответствующий конфигу по умолчанию hydra (например, <code>ppo_trainer</code>, <code>ppo_megatron_trainer</code>, <code>sft_trainer</code> и т.д.).</li>
<li>Добавьте соответствующие паттерны путей в секцию <code>paths</code>, если их ещё нет.</li>
<li>Минимизируйте нагрузку тестовых скриптов (см. существующие примеры).</li></p><p></ul><h2>О <a href="https://team.doubao.com/" target="_blank" rel="noopener noreferrer">ByteDance Seed Team</a></h2></p><p>Основана в 2023 году, команда ByteDance Seed занимается созданием самых продвинутых базовых AI-моделей в индустрии. Команда стремится стать мировым лидером в исследованиях и внести значимый вклад в развитие науки и общества. Познакомьтесь с ByteDance Seed по ссылкам ниже 👇
<div>
  <a href="https://team.doubao.com/">
    <img src="https://img.shields.io/badge/Website-%231e37ff?style=for-the-badge&logo=bytedance&logoColor=white"></a>
  <a href="https://github.com/user-attachments/assets/469535a8-42f2-4797-acdf-4f7a1d4a0c3e">
    <img src="https://img.shields.io/badge/WeChat-07C160?style=for-the-badge&logo=wechat&logoColor=white"></a>
 <a href="https://www.xiaohongshu.com/user/profile/668e7e15000000000303157d?xsec_token=ABl2-aqekpytY6A8TuxjrwnZskU-6BsMRE_ufQQaSAvjc%3D&xsec_source=pc_search">
    <img src="https://img.shields.io/badge/Xiaohongshu-%23FF2442?style=for-the-badge&logo=xiaohongshu&logoColor=white"></a>
  <a href="https://www.zhihu.com/org/dou-bao-da-mo-xing-tuan-dui/">
    <img src="https://img.shields.io/badge/zhihu-%230084FF?style=for-the-badge&logo=zhihu&logoColor=white"></a></p><p></div>
<hr></p><p>Мы ИЩЕМ новых коллег! Если вам интересны стажировки/работа в RL для агентов, присылайте <a href="mailto:haibin.lin@bytedance.com" target="_blank" rel="noopener noreferrer">email</a>.

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-07

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/volcengine/verl/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>