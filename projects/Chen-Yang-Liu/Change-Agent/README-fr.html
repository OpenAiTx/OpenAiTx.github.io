<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Change-Agent - [IEEE TGRS 2024 &#128293;] Change-Agent : Vers une interpr&#233;tation et une analyse interactives et compl&#232;tes des changements en t&#233;l&#233;d&#233;tection</title>
    <meta name="description" content="[IEEE TGRS 2024 &#128293;] Change-Agent : Vers une interpr&#233;tation et une analyse interactives et compl&#232;tes des changements en t&#233;l&#233;d&#233;tection">
    <meta name="keywords" content="Change-Agent, French, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "Change-Agent",
  "description": "[IEEE TGRS 2024 🔥] Change-Agent : Vers une interprétation et une analyse interactives et complètes des changements en télédétection",
  "author": {
    "@type": "Person",
    "name": "Chen-Yang-Liu"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 139
  },
  "url": "https://OpenAiTx.github.io/projects/Chen-Yang-Liu/Change-Agent/README-fr.html",
  "sameAs": "https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/Chen-Yang-Liu/Change-Agent" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    Change-Agent
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 139 stars</span>
                <span class="language">French</span>
                <span>by Chen-Yang-Liu</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align="center">
    
<h1><a href="https://ieeexplore.ieee.org/document/10591792">Change-Agent : Vers une interprétation et une analyse interactives et complètes des changements en télédétection</a></h1></p><p><strong><a href="https://chen-yang-liu.github.io/" target="_blank" rel="noopener noreferrer">Chenyang Liu</a>, <a href="https://kyanchen.github.io" target="_blank" rel="noopener noreferrer">Keyan Chen</a>, <a href="https://scholar.google.com/citations?user=c7uR6NUAAAAJ" target="_blank" rel="noopener noreferrer">Haotian Zhang</a>, <a href="https://scholar.google.com/citations?user=KhMtmBsAAAAJ" target="_blank" rel="noopener noreferrer">Zipeng Qi</a>, <a href="https://scholar.google.com.hk/citations?hl=en&user=DzwoyZsAAAAJ" target="_blank" rel="noopener noreferrer">Zhengxia Zou</a>, et <a href="https://scholar.google.com.hk/citations?hl=en&user=kNhFWQIAAAAJ" target="_blank" rel="noopener noreferrer">Zhenwei Shi*✉</a></strong></p><p><div align="center">
  <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/Change_Agent.png" width="400"/>
</div>
</div></p><h2>Mettez-nous une :star: si ce dépôt vous intéresse</h2></p><p>Implémentation officielle PyTorch de l’article : "<strong>Change-Agent : Vers une interprétation et une analyse interactives et complètes des changements en télédétection</strong>" dans <a href="https://ieeexplore.ieee.org/document/10591792" target="_blank" rel="noopener noreferrer">[IEEE</a>]  <strong><em>(Accepté par IEEE TGRS 2024)</strong></em></p><h2>🥳Nouvelles</h2></p><ul><li>2024-06 : Le code est <strong>disponible</strong>.</li>
<li>2024-03 : L’article est <strong>disponible</strong>.</li>
<li>🔥 Notre enquête "<strong>Modèles vision-langage temporels en télédétection : une enquête complète" : <a href="https://arxiv.org/abs/2412.02573" target="_blank" rel="noopener noreferrer">Arxiv</a> || <a href="https://github.com/Chen-Yang-Liu/Awesome-RS-Temporal-VLM" target="_blank" rel="noopener noreferrer">Github</a></strong> 🔥 </li></p><p></ul><h2>Table des matières</h2>
<ul><li><a href="#LEVIR-MCI-dataset" target="_blank" rel="noopener noreferrer">Jeu de données LEVIR-MCI</a></li>
<li><a href="#Training-of-the-multi-level-change-interpretation-model" target="_blank" rel="noopener noreferrer">Entraînement du modèle MCI</a></li>
<li><a href="#Construction-of-Change-Agent" target="_blank" rel="noopener noreferrer">Construction de Change-Agent</a></li>
<li><a href="#Citation" target="_blank" rel="noopener noreferrer">Citation</a></li></p><p></ul><h2>Jeu de données LEVIR-MCI </h2>
<ul><li>Téléchargez le jeu de données LEVIR_MCI : <a href="https://huggingface.co/datasets/lcybuaa/LEVIR-MCI/tree/main" target="_blank" rel="noopener noreferrer">LEVIR-MCI</a> (<strong>Disponible maintenant !</strong>).</li>
<li>Ce jeu de données est une extension de notre précédent <a href="https://github.com/Chen-Yang-Liu/RSICC" target="_blank" rel="noopener noreferrer">jeu LEVIR-CC</a>. Il contient des images bi-temporelles ainsi que des masques de détection de changements divers et des phrases descriptives. Il fournit une base de données essentielle pour explorer l’apprentissage multitâche pour la détection et la description des changements.</li>
    </ul><br>
    <div align="center">
      <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/dataset.png" width="800"/>
    </div>
    <br>
<h2>Entraînement du modèle d’interprétation multi-niveaux des changements</h2>
Vue d’ensemble du modèle MCI :
<br>
    <div align="center">
      <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/MCI_model.png" width="800"/>
    </div>
<br></p><h3>Préparation</h3>
    
<ul><li><strong>Installation de l'environnement</strong> :</li>
    </ul><details open>
    
    <strong>Étape 1</strong> : Créez un environnement virtuel nommé <code>Multi_change_env</code> et activez-le.
    <pre><code class="language-python">    conda create -n Multi_change_env python=3.9
    conda activate Multi_change_env
    ``<code>
    
    <strong>Étape 2</strong> : Téléchargez ou clonez le dépôt.
    </code>`<code>python
    git clone https://github.com/Chen-Yang-Liu/Change-Agent.git
    cd ./Change-Agent/Multi_change
    </code>`<code>
    
    <strong>Étape 3</strong> : Installer les dépendances.
    </code>`<code>python
    pip install -r requirements.txt
    </code>`<code>
    </details></p><ul><li><strong>Télécharger le jeu de données</strong> :</li>
  </ul><details open>
      
  Lien : <a href="https://huggingface.co/datasets/lcybuaa/LEVIR-MCI/tree/main" target="_blank" rel="noopener noreferrer">LEVIR-MCI</a>. La structure des données de LEVIR-MCI est organisée comme suit :</p><p>    </code>`<code>
    ├─/DATA_PATH_ROOT/Levir-MCI-dataset/
            ├─LevirCCcaptions.json
            ├─images
                 ├─train
                 │  ├─A
                 │  ├─B
                 │  ├─label
                 ├─val
                 │  ├─A
                 │  ├─B
                 │  ├─label
                 ├─test
                 │  ├─A
                 │  ├─B
                 │  ├─label
    </code>`<code>
    où le dossier </code><code>A</code><code> contient les images pré-phase, le dossier </code><code>B</code><code> contient les images post-phase, et le dossier </code><code>label</code><code> contient les masques de détection de changement.
    </details></p><ul><li><strong>Extraire les fichiers texte pour les descriptions de chaque paire d’images dans LEVIR-MCI</strong> :</li></p><p>    </ul></code>`<code>
    python preprocess_data.py
    </code>`<code>
    Après cela, vous pouvez trouver certains fichiers générés dans </code>./data/LEVIR_MCI/<code>. </p><h3>Entraînement</h3>
Assurez-vous d'avoir effectué la préparation des données ci-dessus. Ensuite, lancez l'entraînement comme suit :</code></pre>python
python train.py --train_goal 2 --data_folder /DATA_PATH_ROOT/Levir-MCI-dataset/images --savepath ./models_ckpt/
<pre><code class="language-">
<h3>Évaluer</code></pre>python</h3>
python test.py --data_folder /DATA_PATH_ROOT/Levir-MCI-dataset/images --checkpoint {checkpoint_PATH}
<pre><code class="language-">Nous recommandons d'entraîner le modèle 5 fois pour obtenir un score moyen.</p><h3>Inférence</h3>
Lancez l'inférence pour commencer comme suit :</code></pre>python
python predict.py --imgA_path {imgA_path} --imgB_path {imgA_path} --mask_save_path ./CDmask.png
<pre><code class="language-">Vous pouvez modifier </code><code>--checkpoint</code><code> de </code><code>Change_Perception.define_args()</code><code> dans </code><code>predict.py</code><code>. Ensuite, vous pouvez utiliser votre propre modèle, bien sûr, vous pouvez également télécharger notre modèle pré-entraîné </code><code>MCI_model.pth</code><code> ici : <a href="https://huggingface.co/lcybuaa/Change-Agent/tree/main" target="_blank" rel="noopener noreferrer">[Hugging face</a>]. Après cela, placez-le dans </code>./models_ckpt/<code>.</p><h2>Construction de Change-Agent</h2>
<br>
<div align="center">
      <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/overview_agent.png" width="800"/>
</div></p><ul><li><strong>Installation de l'Agent</strong> :</li>
    </ul></code>`<code>python
    cd ./Change-Agent/lagent-main
    pip install -e .[all]
    </code>`<code>
<ul><li><strong>Exécuter l'Agent</strong> :</li></p><p>    </ul>se placer dans le dossier </code><code>Multi_change</code><code> :
    </code>`<code>python
    cd ./Change-Agent/Multi_change
    </code>`<code>
    (1) Exécuter la démo de l'Agent CLI :
    </code>`<code>bash
    # You need to install streamlit first
    # pip install streamlit
    python try_chat.py
    </code>`<code>
        
    (2) Exécuter la démonstration Web de l'Agent :
    </code>`<code>bash
    # You need to install streamlit first
    # pip install streamlit
    streamlit run react_web_demo.py
    </code>`<code>
    <br>
    <div align="center">
          <img src="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/resource/web.png"/>
    </div></p><h2>Citation</h2>
Si vous trouvez cet article utile dans vos recherches, veuillez envisager de le citer :</code></pre>
@ARTICLE{Liu_Change_Agent,
  author={Liu, Chenyang and Chen, Keyan and Zhang, Haotian and Qi, Zipeng and Zou, Zhengxia and Shi, Zhenwei},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Change-Agent: Toward Interactive Comprehensive Remote Sensing Change Interpretation and Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  keywords={Remote sensing;Feature extraction;Semantics;Transformers;Roads;Earth;Task analysis;Interactive Change-Agent;change captioning;change detection;multi-task learning;large language model},
  doi={10.1109/TGRS.2024.3425815}}</p><p></code>``</p><h2>Remerciements</h2>
Merci aux dépôts suivants :</p><p><a href="https://github.com/Chen-Yang-Liu/RSICC" target="_blank" rel="noopener noreferrer">RSICCformer</a>; <a href="https://github.com/ShizhenChang/Chg2Cap" target="_blank" rel="noopener noreferrer">Chg2Cap</a>; <a href="https://github.com/InternLM/lagent" target="_blank" rel="noopener noreferrer">lagent</a></p><h2>Licence</h2>
Ce dépôt est distribué sous la <a href="https://github.com/Chen-Yang-Liu/Change-Agent/blob/main/LICENSE.txt" target="_blank" rel="noopener noreferrer">Licence MIT</a>. Le code peut être utilisé uniquement à des fins académiques.</p><h2>Contactez-nous</h2>
Si vous avez d'autres questions❓, veuillez nous contacter rapidement 👬</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-08-19

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Chen-Yang-Liu/Change-Agent/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>