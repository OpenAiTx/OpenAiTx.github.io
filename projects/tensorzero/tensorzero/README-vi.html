<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>tensorzero - Read tensorzero documentation in Vietnamese. This project has 5476 stars on GitHub.</title>
    <meta name="description" content="Read tensorzero documentation in Vietnamese. This project has 5476 stars on GitHub.">
    <meta name="keywords" content="tensorzero, Vietnamese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "tensorzero",
  "description": "Read tensorzero documentation in Vietnamese. This project has 5476 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "tensorzero"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 5476
  },
  "url": "https://OpenAiTx.github.io/projects/tensorzero/tensorzero/README-vi.html",
  "sameAs": "https://raw.githubusercontent.com/tensorzero/tensorzero/main/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/tensorzero/tensorzero" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    tensorzero
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 5476 stars</span>
                <span class="language">Vietnamese</span>
                <span>by tensorzero</span>
            </div>
        </div>
        
        <div class="content">
            <p><img src="https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9" width=128 height=128></p><h1>TensorZero</h1></p><p><strong>TensorZero tạo ra một vòng lặp phản hồi để tối ưu hóa các ứng dụng LLM — biến dữ liệu thực tế thành các mô hình thông minh hơn, nhanh hơn, và rẻ hơn.</strong></p><ul><li>Tích hợp cổng mô hình của chúng tôi</li>
<li>Gửi các chỉ số hoặc phản hồi</li>
<li>Tối ưu hóa prompt, mô hình, và chiến lược suy diễn</li>
<li>Theo dõi LLMs của bạn cải thiện theo thời gian</li></p><p></ul>TensorZero cung cấp <strong>vòng quay dữ liệu & học tập cho LLMs</strong> bằng cách hợp nhất:</p><ul><li>[x] <strong>Suy diễn:</strong> một API cho tất cả LLM, với độ trễ P99 <1ms</li>
<li>[x] <strong>Quan sát:</strong> suy diễn & phản hồi → cơ sở dữ liệu của bạn</li>
<li>[x] <strong>Tối ưu hóa:</strong> từ prompt đến fine-tuning và RL</li>
<li>[x] <strong>Đánh giá:</strong> so sánh prompt, mô hình, chiến lược suy diễn</li>
<li>[x] <strong>Thử nghiệm:</strong> tích hợp A/B testing, định tuyến, fallback</li></p><p></ul>---</p><p><p align="center">
  <b><a href="https://www.tensorzero.com/" target="_blank">Website</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs" target="_blank">Docs</a></b>
  ·
  <b><a href="https://www.x.com/tensorzero" target="_blank">Twitter</a></b>
  ·
  <b><a href="https://www.tensorzero.com/slack" target="_blank">Slack</a></b>
  ·
  <b><a href="https://www.tensorzero.com/discord" target="_blank">Discord</a></b>
  <br>
  <br>
  <b><a href="https://www.tensorzero.com/docs/quickstart" target="_blank">Quick Start (5min)</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/tutorial" target="_blank">Comprehensive Tutorial</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank">Deployment Guide</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/api-reference" target="_blank">API Reference</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank">Configuration Reference</a></b>
</p></p><hr></p><p><table>
  <tr>
    <td width="30%" valign="top"><b>TensorZero là gì?</b></td>
    <td width="70%" valign="top">TensorZero là một framework mã nguồn mở để xây dựng các ứng dụng LLM đạt chuẩn sản xuất. Nó hợp nhất một cổng LLM, quan sát, tối ưu hóa, đánh giá và thử nghiệm.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>TensorZero khác gì so với các framework LLM khác?</b></td>
    <td width="70%" valign="top">
      <ul><li>TensorZero cho phép bạn tối ưu hóa các ứng dụng LLM phức tạp dựa trên các chỉ số thực tế và phản hồi của con người.<br></li>
      <li>TensorZero đáp ứng nhu cầu của các ứng dụng LLM quy mô công nghiệp: độ trễ thấp, thông lượng cao, an toàn kiểu dữ liệu, tự triển khai, GitOps, tùy biến, v.v.<br></li>
      <li>TensorZero hợp nhất toàn bộ stack LLMOps, tạo ra lợi ích cộng hưởng. Ví dụ, đánh giá LLM có thể dùng để fine-tune mô hình cùng với các AI judge.</li>
    </ul></td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Tôi có thể dùng TensorZero với ___ không?</b></td>
    <td width="70%" valign="top">Có. Mọi ngôn ngữ lập trình chính đều được hỗ trợ. Bạn có thể sử dụng TensorZero với client Python, bất kỳ SDK OpenAI nào, hoặc API HTTP của chúng tôi.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>TensorZero đã sẵn sàng cho sản xuất chưa?</b></td>
    <td width="70%" valign="top">Có. Đây là một case study: <b><a href="https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms">Tự động hóa Code Changelogs tại một ngân hàng lớn với LLMs</a></b></td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>TensorZero có giá bao nhiêu?</b></td>
    <td width="70%" valign="top">Miễn phí. TensorZero hoàn toàn tự triển khai và mã nguồn mở. Không có tính năng trả phí.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Ai đang phát triển TensorZero?</b></td>
    <td width="70%" valign="top">Đội ngũ kỹ thuật của chúng tôi gồm một cựu maintainer Rust compiler, các nhà nghiên cứu machine learning (Stanford, CMU, Oxford, Columbia) với hàng nghìn trích dẫn, và giám đốc sản phẩm của một startup decacorn. Chúng tôi được hậu thuẫn bởi các nhà đầu tư của các dự án mã nguồn mở hàng đầu (ví dụ ClickHouse, CockroachDB) và phòng lab AI (ví dụ OpenAI, Anthropic).</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Làm sao để bắt đầu với TensorZero?</b></td>
    <td width="70%" valign="top">Bạn có thể áp dụng TensorZero từng bước. <b><a href="https://www.tensorzero.com/docs/quickstart">Quick Start</a></b> của chúng tôi sẽ hướng dẫn từ một wrapper OpenAI cơ bản đến một ứng dụng LLM sản xuất với quan sát và fine-tuning chỉ trong 5 phút.</td>
  </tr>
</table></p><hr></p><h2>Tính năng</h2></p><h3>🌐 Cổng LLM</h3></p><blockquote><strong>Tích hợp với TensorZero một lần, truy cập mọi nhà cung cấp LLM lớn.</strong></blockquote></p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Nhà Cung Cấp Mô Hình</b></td>
    <td width="50%" align="center" valign="middle"><b>Tính Năng</b></td>
  </tr>
  <tr>
    <td width="50%" align="left" valign="top">
      <p>
        TensorZero Gateway hỗ trợ gốc cho:
      </p>
      <ul>
        <ul><li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/anthropic">Anthropic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock">AWS Bedrock</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker">AWS SageMaker</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/azure">Azure OpenAI Service</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/deepseek">DeepSeek</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/fireworks">Fireworks</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic">GCP Vertex AI Anthropic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini">GCP Vertex AI Gemini</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini">Google AI Studio (Gemini API)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic">Hyperbolic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/mistral">Mistral</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai">OpenAI</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/together">Together</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/vllm">vLLM</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/xai">xAI</a></b></li>
      </ul></ul>
        <em>
          Cần nhà cung cấp khác?
          Nhà cung cấp của bạn rất có thể được hỗ trợ vì TensorZero tích hợp với <b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible">mọi API tương thích OpenAI (vd: Ollama)</a></b>.
          </em>
      </p>
    </td>
    <td width="50%" align="left" valign="top">
      <p>
        TensorZero Gateway hỗ trợ các tính năng nâng cao như:
      </p>
      <ul>
        <ul><li><b><a href="https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks">Retries & Fallbacks</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations">Tối ưu hóa thời gian suy diễn</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/prompt-templates-schemas">Prompt Templates & Schemas</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/tutorial#experimentation">Thử nghiệm (A/B Testing)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/configuration-reference">Cấu hình dưới dạng mã (GitOps)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/batch-inference">Batch Inference</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/multimodal-inference">Suy diễn đa phương thức (VLMs)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-caching">Bộ nhớ đệm suy diễn</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/metrics-feedback">Chỉ số & Phản hồi</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/episodes">Quy trình LLM nhiều bước (Episodes)</a></b></li>
        <li><em>& còn nhiều hơn nữa...</em></li>
      </ul></ul>
        TensorZero Gateway được viết bằng Rust 🦀 với mục tiêu <b>hiệu năng</b> (&lt;1ms p99 latency overhead @ 10k QPS).
        Xem <b><a href="https://www.tensorzero.com/docs/gateway/benchmarks">Benchmarks</a></b>.<br>
      </p>
      <p>
        Bạn có thể chạy suy diễn bằng <b>client TensorZero</b> (khuyến nghị), <b>client OpenAI</b>, hoặc <b>API HTTP</b>.
      </p>
    </td>
  </tr>
</table></p><p><br></p><p><details open>
<summary><b>Cách dùng: Python &mdash; Client TensorZero (Khuyến nghị)</b></summary></p><p>Bạn có thể truy cập bất cứ nhà cung cấp nào bằng client Python của TensorZero.</p><ul><li><code>pip install tensorzero</code></li>
<li>Tuỳ chọn: Thiết lập cấu hình TensorZero.</li>
<li>Chạy suy diễn:</li></p><p></ul><pre><code class="language-python">from tensorzero import TensorZeroGateway  # hoặc AsyncTensorZeroGateway</p><p>
with TensorZeroGateway.build_embedded(clickhouse_url="...", config_file="...") as client:
    response = client.inference(
        model_name="openai::gpt-4o-mini",
        # Dễ dàng thử các nhà cung cấp khác: "anthropic::claude-3-7-sonnet-20250219"
        input={
            "messages": [
                {
                    "role": "user",
                    "content": "Viết một bài thơ haiku về trí tuệ nhân tạo.",
                }
            ]
        },
    )</code></pre></p><p>Xem <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">Quick Start</a></strong> để biết thêm chi tiết.</p><p></details></p><p><details>
<summary><b>Cách dùng: Python &mdash; Client OpenAI</b></summary></p><p>Bạn có thể truy cập bất cứ nhà cung cấp nào bằng client Python của OpenAI với TensorZero.</p><ul><li><code>pip install tensorzero</code></li>
<li>Tuỳ chọn: Thiết lập cấu hình TensorZero.</li>
<li>Chạy suy diễn:</li></p><p></ul><pre><code class="language-python">from openai import OpenAI  # hoặc AsyncOpenAI
from tensorzero import patch_openai_client</p><p>client = OpenAI()
patch_openai_client(
    client,
    clickhouse_url="http://chuser:chpassword@localhost:8123/tensorzero",
    config_file="config/tensorzero.toml",
    async_setup=False,
)</p><p>response = client.chat.completions.create(
    model="tensorzero::model_name::openai::gpt-4o-mini",
    # Thử các nhà cung cấp khác một cách dễ dàng: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
    messages=[
        {
            "role": "user",
            "content": "Viết một bài haiku về trí tuệ nhân tạo.",
        }
    ],
)</code></pre></p><p>Xem <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">Bắt đầu nhanh</a></strong> để biết thêm thông tin.</p><p></details></p><p><details>
<summary><b>Sử dụng: JavaScript / TypeScript (Node) &mdash; OpenAI Client</b></summary></p><p>Bạn có thể truy cập bất kỳ nhà cung cấp nào bằng OpenAI Node client với TensorZero.</p><ul><li>Triển khai <code>tensorzero/gateway</code> bằng Docker.</li>
   </ul><strong><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank" rel="noopener noreferrer">Hướng dẫn chi tiết →</a></strong>
<ul><li>Thiết lập cấu hình TensorZero.</li>
<li>Thực hiện suy luận:</li></p><p></ul><pre><code class="language-ts">import OpenAI from "openai";</p><p>const client = new OpenAI({
  baseURL: "http://localhost:3000/openai/v1",
});</p><p>const response = await client.chat.completions.create({
  model: "tensorzero::model_name::openai::gpt-4o-mini",
  // Thử các nhà cung cấp khác một cách dễ dàng: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
  messages: [
    {
      role: "user",
      content: "Viết một bài haiku về trí tuệ nhân tạo.",
    },
  ],
});</code></pre></p><p>Xem <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">Bắt đầu nhanh</a></strong> để biết thêm thông tin.</p><p></details></p><p><details>
<summary><b>Sử dụng: Ngôn ngữ & Nền tảng khác &mdash; HTTP API</b></summary></p><p>TensorZero hỗ trợ hầu như mọi ngôn ngữ lập trình hoặc nền tảng thông qua HTTP API của nó.</p><ul><li>Triển khai <code>tensorzero/gateway</code> bằng Docker.</li>
   </ul><strong><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank" rel="noopener noreferrer">Hướng dẫn chi tiết →</a></strong>
<ul><li>Tuỳ chọn: Thiết lập cấu hình TensorZero.</li>
<li>Thực hiện suy luận:</li></p><p></ul><pre><code class="language-bash">curl -X POST "http://localhost:3000/inference" \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "openai::gpt-4o-mini",
    "input": {
      "messages": [
        {
          "role": "user",
          "content": "Viết một bài haiku về trí tuệ nhân tạo."
        }
      ]
    }
  }'</code></pre></p><p>Xem <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">Bắt đầu nhanh</a></strong> để biết thêm thông tin.</p><p></details></p><p><br></p><h3>📈 Tối ưu hóa LLM</h3></p><blockquote><strong>Gửi các chỉ số sản xuất và phản hồi của con người để dễ dàng tối ưu hóa prompt, mô hình và chiến lược suy luận của bạn &mdash; sử dụng giao diện người dùng hoặc lập trình.</strong></blockquote></p><p>#### Tối ưu hóa mô hình</p><p>Tối ưu hóa các mô hình mã nguồn đóng và mã nguồn mở bằng fine-tuning có giám sát (SFT) và fine-tuning theo sở thích (DPO).</p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Fine-tuning có giám sát &mdash; UI</b></td>
    <td width="50%" align="center" valign="middle"><b>Fine-tuning theo sở thích (DPO) &mdash; Jupyter Notebook</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/cf7acf66-732b-43b3-af2a-5eba1ce40f6f"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/a67a0634-04a7-42b0-b934-9130cb7cdf51"></td>
  </tr>
</table></p><p>#### Tối ưu hóa trong thời gian suy luận</p><p>Tăng hiệu suất bằng cách cập nhật động prompt của bạn với các ví dụ liên quan, kết hợp phản hồi từ nhiều lần suy luận, và nhiều hơn nữa.</p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling">Best-of-N Sampling</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#mixture-of-n-sampling">Mixture-of-N Sampling</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/c0edfa4c-713c-4996-9964-50c0d26e6970"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/75b5bf05-4c1f-43c4-b158-d69d1b8d05be"></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl">Dynamic In-Context Learning (DICL)</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#chain-of-thought-cot">Chain-of-Thought (CoT)</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/d8489e92-ce93-46ac-9aab-289ce19bb67d"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/ea13d73c-76a4-4e0c-a35b-0c648f898311" height="320"></td>
  </tr>
</table></p><p>_Sẽ sớm có thêm..._</p><p><br></p><p>#### Tối ưu hóa Prompt</p><p>Tối ưu hóa prompt của bạn bằng lập trình với các kỹ thuật tối ưu hóa dựa trên nghiên cứu.</p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling">MIPROv2</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy">Tích hợp DSPy</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/d81a7c37-382f-4c46-840f-e6c2593301db" alt="MIPROv2 diagram"></td>
    <td width="50%" align="center" valign="middle">
      TensorZero đi kèm với nhiều công thức tối ưu hóa, nhưng bạn cũng có thể dễ dàng tạo công thức riêng.
      Ví dụ này minh họa cách tối ưu hóa một hàm TensorZero bằng một công cụ bất kỳ — ở đây là DSPy, thư viện nổi tiếng cho tự động hoá prompt engineering.
    </td>
  </tr>
</table></p><p>_Sẽ sớm có thêm..._</p><p><br></p><h3>🔍 Quan sát LLM</h3></p><blockquote><strong>Phóng to để debug từng API call riêng lẻ, hoặc thu nhỏ để giám sát các chỉ số trên toàn bộ mô hình và prompt theo thời gian &mdash; tất cả bằng giao diện người dùng mã nguồn mở của TensorZero.</strong></blockquote></p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Quan sát » Suy luận</b></td>
    <td width="50%" align="center" valign="middle"><b>Quan sát » Hàm</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/2cc3cc9a-f33f-4e94-b8de-07522326f80a"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/00ae6605-8fa0-4efd-8238-ae8ea589860f"></td>
  </tr>
</table></p><p><br></p><h3>📊 Đánh giá LLM</h3></p><blockquote><strong>So sánh prompt, mô hình và chiến lược suy luận bằng TensorZero Evaluations &mdash; với hỗ trợ cho heuristic và LLM judge.</strong></blockquote></p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Đánh giá » UI</b></td>
    <td width="50%" align="center" valign="middle"><b>Đánh giá » CLI</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699"></td>
    <td width="50%" align="left" valign="middle">
<pre><code class="language-bash">docker compose run --rm evaluations \
  --evaluation-name extract_data \
  --dataset-name hard_test_cases \
  --variant-name gpt_4o \
  --concurrency 5</code></pre>
<pre><code class="language-bash">Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4
Number of datapoints: 100
██████████████████████████████████████ 100/100
exact_match: 0.83 ± 0.03
semantic_match: 0.98 ± 0.01  
item_count: 7.15 ± 0.39</code></pre>
    </td>
  </tr>
</table></p><h2>Demo</h2></p><blockquote><strong>Xem LLM cải thiện khả năng trích xuất dữ liệu theo thời gian thực với TensorZero!</strong></blockquote>
>
<blockquote><strong><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl" target="_blank" rel="noopener noreferrer">Dynamic in-context learning (DICL)</a></strong> là một tối ưu hóa mạnh mẽ trong thời gian suy luận, có sẵn ngay khi sử dụng TensorZero.</blockquote>
<blockquote>Nó nâng cao hiệu suất của LLM bằng cách tự động bổ sung các ví dụ lịch sử liên quan vào prompt, mà không cần tinh chỉnh mô hình.</blockquote></p><p>https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb</p><h2>Kỹ thuật LLM với TensorZero</h2></p><p><br>
<p align="center" >
  <a href="https://www.tensorzero.com/docs">
    <picture>
      <source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6">
      <source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/e8bc699b-6378-4c2a-9cc1-6d189025e270">
      <img alt="TensorZero Flywheel" src="https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6" width=720>
    </picture>
  </a>
</p>
<br></p><ul><li><strong><a href="https://www.tensorzero.com/docs/gateway/" target="_blank" rel="noopener noreferrer">TensorZero Gateway</a></strong> là một cổng mô hình hiệu suất cao được viết bằng Rust 🦀, cung cấp giao diện API thống nhất cho tất cả các nhà cung cấp LLM lớn, cho phép tích hợp và chuyển đổi liền mạch giữa các nền tảng.</li>
<li>Nó xử lý suy luận dựa trên schema có cấu trúc với độ trễ P99 &lt;1ms (xem <strong><a href="https://www.tensorzero.com/docs/gateway/benchmarks" target="_blank" rel="noopener noreferrer">Benchmarks</a></strong>) cùng tính năng quan sát, thử nghiệm và <strong><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations" target="_blank" rel="noopener noreferrer">tối ưu hóa trong thời gian suy luận</a></strong> được tích hợp sẵn.</li>
<li>Nó cũng thu thập các chỉ số và phản hồi từ các suy luận này, với hỗ trợ hàng đầu cho các hệ thống LLM nhiều bước.</li>
<li>Mọi thứ đều được lưu trữ trong kho dữ liệu ClickHouse do bạn kiểm soát, cho phép phân tích thời gian thực, mở rộng và thân thiện với nhà phát triển.</li>
<li>Theo thời gian, <strong><a href="https://www.tensorzero.com/docs/recipes" target="_blank" rel="noopener noreferrer">TensorZero Recipes</a></strong> tận dụng tập dữ liệu có cấu trúc này để tối ưu hóa prompt và mô hình của bạn: chạy các recipe dựng sẵn cho các workflow phổ biến như fine-tuning, hoặc tự tạo recipe của riêng bạn với sự linh hoạt hoàn toàn trên bất kỳ ngôn ngữ và nền tảng nào.</li>
<li>Cuối cùng, các tính năng thử nghiệm và orchestration GitOps của gateway cho phép bạn lặp lại và triển khai tự tin, dù chỉ với một LLM hay hàng nghìn LLM.</li></p><p></ul>Mục tiêu của chúng tôi là giúp kỹ sư xây dựng, quản lý và tối ưu hóa thế hệ ứng dụng LLM tiếp theo: các hệ thống học hỏi từ kinh nghiệm thực tế.  
Đọc thêm về <strong><a href="https://www.tensorzero.com/docs/vision-roadmap/" target="_blank" rel="noopener noreferrer">Tầm nhìn & Lộ trình phát triển</a></strong> của chúng tôi.</p><h2>Bắt đầu</h2></p><p><strong>Bắt đầu xây dựng ngay hôm nay.</strong>  
<strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">Hướng dẫn Nhanh</a></strong> cho thấy việc thiết lập ứng dụng LLM với TensorZero dễ dàng như thế nào.  
Nếu bạn muốn tìm hiểu sâu hơn, <strong><a href="https://www.tensorzero.com/docs/gateway/tutorial" target="_blank" rel="noopener noreferrer">Tutorial</a></strong> sẽ hướng dẫn bạn xây dựng chatbot đơn giản, trợ lý email, hệ thống RAG thời tiết và pipeline trích xuất dữ liệu có cấu trúc.</p><p><strong>Có câu hỏi?</strong>  
Hỏi chúng tôi trên <strong><a href="https://www.tensorzero.com/slack" target="_blank" rel="noopener noreferrer">Slack</a></strong> hoặc <strong><a href="https://www.tensorzero.com/discord" target="_blank" rel="noopener noreferrer">Discord</a></strong>.</p><p><strong>Đang sử dụng TensorZero tại nơi làm việc?</strong>  
Gửi email cho chúng tôi tại <strong><a href="mailto:hello@tensorzero.com" target="_blank" rel="noopener noreferrer">hello@tensorzero.com</a></strong> để thiết lập kênh Slack hoặc Teams với nhóm của bạn (miễn phí).</p><p><strong>Làm việc cùng chúng tôi.</strong>  
Chúng tôi đang <strong><a href="https://www.tensorzero.com/jobs" target="_blank" rel="noopener noreferrer">tuyển dụng tại NYC</a></strong>.  
Chúng tôi cũng hoan nghênh <strong><a href="https://github.com/tensorzero/tensorzero/blob/main/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">đóng góp mã nguồn mở</a></strong>!</p><h2>Ví dụ</h2></p><p>Chúng tôi đang thực hiện một loạt <strong>ví dụ hoàn chỉnh có thể chạy được</strong> minh họa cho vòng lặp dữ liệu & học tập của TensorZero.</p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/data-extraction-ner" target="_blank" rel="noopener noreferrer">Tối ưu hóa Trích xuất Dữ liệu (NER) với TensorZero</a></strong></blockquote>
>
<blockquote>Ví dụ này trình bày cách sử dụng TensorZero để tối ưu hóa pipeline trích xuất dữ liệu.</blockquote>
<blockquote>Chúng tôi trình diễn các kỹ thuật như fine-tuning và dynamic in-context learning (DICL).</blockquote>
<blockquote>Cuối cùng, mô hình GPT-4o Mini đã được tối ưu hóa vượt qua GPT-4o trong tác vụ này — với chi phí và độ trễ chỉ bằng một phần nhỏ — sử dụng lượng dữ liệu huấn luyện rất nhỏ.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/rag-retrieval-augmented-generation/simple-agentic-rag/" target="_blank" rel="noopener noreferrer">Agentic RAG — Trả lời Câu hỏi Đa Bước với LLM</a></strong></blockquote>
>
<blockquote>Ví dụ này trình bày cách xây dựng agent truy xuất đa bước bằng TensorZero.</blockquote>
<blockquote>Agent sẽ lặp lại việc tìm kiếm trên Wikipedia để thu thập thông tin và quyết định khi nào đã có đủ ngữ cảnh để trả lời câu hỏi phức tạp.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences" target="_blank" rel="noopener noreferrer">Sáng tác Haiku để Làm Hài Lòng Ban Giám Khảo với Sở Thích Ẩn</a></strong></blockquote>
>
<blockquote>Ví dụ này fine-tune GPT-4o Mini để tạo ra các bài haiku phù hợp với sở thích riêng biệt.</blockquote>
<blockquote>Bạn sẽ thấy "vòng lặp dữ liệu trong hộp" của TensorZero hoạt động: biến thể tốt hơn tạo ra dữ liệu tốt hơn, và dữ liệu tốt hơn lại sinh ra biến thể tốt hơn.</blockquote>
<blockquote>Bạn sẽ thấy sự tiến bộ khi fine-tune LLM nhiều lần.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles/" target="_blank" rel="noopener noreferrer">Cải thiện Kỹ Năng Chơi Cờ của LLM với Best-of-N Sampling</a></strong></blockquote>
>
<blockquote>Ví dụ này minh họa cách best-of-N sampling có thể nâng cao đáng kể khả năng chơi cờ của LLM bằng cách chọn ra nước đi triển vọng nhất từ nhiều tùy chọn được sinh ra.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy" target="_blank" rel="noopener noreferrer">Cải thiện Lý luận Toán học với Recipe Tùy chỉnh cho Kỹ thuật Prompt Tự động (DSPy)</a></strong></blockquote>
>
<blockquote>TensorZero cung cấp nhiều recipe tối ưu hóa dựng sẵn cho các workflow kỹ thuật LLM phổ biến.</blockquote>
<blockquote>Nhưng bạn cũng có thể dễ dàng tạo recipe và workflow của riêng mình!</blockquote>
<blockquote>Ví dụ này trình bày cách tối ưu hóa một hàm TensorZero bằng công cụ bất kỳ — ở đây là DSPy.</blockquote></p><p>_& còn nhiều ví dụ khác đang được phát triển!_

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/tensorzero/tensorzero/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>