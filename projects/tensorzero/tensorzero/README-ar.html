<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>tensorzero - Read tensorzero documentation in Arabic. This project has 5476 stars on GitHub.</title>
    <meta name="description" content="Read tensorzero documentation in Arabic. This project has 5476 stars on GitHub.">
    <meta name="keywords" content="tensorzero, Arabic, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "tensorzero",
  "description": "Read tensorzero documentation in Arabic. This project has 5476 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "tensorzero"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 5476
  },
  "url": "https://OpenAiTx.github.io/projects/tensorzero/tensorzero/README-ar.html",
  "sameAs": "https://raw.githubusercontent.com/tensorzero/tensorzero/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/tensorzero/tensorzero" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    tensorzero
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 5476 stars</span>
                <span class="language">Arabic</span>
                <span>by tensorzero</span>
            </div>
        </div>
        
        <div class="content">
            <p><img src="https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9" width=128 height=128></p><h1>TensorZero</h1></p><p><strong>تنشئ TensorZero حلقة تغذية راجعة لتحسين تطبيقات النماذج اللغوية الكبيرة (LLM) — تحويل بيانات الإنتاج إلى نماذج أكثر ذكاءً وسرعة وأقل تكلفة.</strong></p><ul><li>دمج بوابة النموذج الخاصة بنا</li>
<li>إرسال المقاييس أو التعليقات</li>
<li>تحسين التعليمات، النماذج، واستراتيجيات الاستدلال</li>
<li>راقب تحسن نماذج LLM الخاصة بك مع الوقت</li></p><p></ul>توفر <strong>حلقة بيانات وتعلم للنماذج اللغوية الكبيرة (LLMs)</strong> من خلال توحيد:</p><ul><li>[x] <strong>الاستدلال:</strong> واجهة برمجية واحدة لجميع نماذج LLM، مع تأخير أقل من 1 مللي ثانية (P99)</li>
<li>[x] <strong>الرصد:</strong> الاستدلال والتعليقات → قاعدة بياناتك</li>
<li>[x] <strong>التحسين:</strong> من التعليمات إلى الضبط الدقيق والتعلم المعزز (RL)</li>
<li>[x] <strong>التقييمات:</strong> مقارنة التعليمات، النماذج، واستراتيجيات الاستدلال</li>
<li>[x] <strong>التجريب:</strong> اختبارات A/B مدمجة، التوجيه، آليات الاسترجاع</li></p><p></ul>---</p><p><p align="center">
  <b><a href="https://www.tensorzero.com/" target="_blank">الموقع الإلكتروني</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs" target="_blank">التوثيق</a></b>
  ·
  <b><a href="https://www.x.com/tensorzero" target="_blank">تويتر</a></b>
  ·
  <b><a href="https://www.tensorzero.com/slack" target="_blank">سلاك</a></b>
  ·
  <b><a href="https://www.tensorzero.com/discord" target="_blank">ديسكورد</a></b>
  <br>
  <br>
  <b><a href="https://www.tensorzero.com/docs/quickstart" target="_blank">البدء السريع (5 دقائق)</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/tutorial" target="_blank">دليل شامل</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank">دليل النشر</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/api-reference" target="_blank">مرجع واجهة برمجة التطبيقات</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank">مرجع الإعدادات</a></b>
</p></p><hr></p><p><table>
  <tr>
    <td width="30%" valign="top"><b>ما هو TensorZero؟</b></td>
    <td width="70%" valign="top">TensorZero هو إطار عمل مفتوح المصدر لبناء تطبيقات LLM على مستوى الإنتاج. يوحد بوابة LLM، الرصد، التحسين، التقييمات، والتجريب.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>كيف يختلف TensorZero عن أطر عمل LLM الأخرى؟</b></td>
    <td width="70%" valign="top">
      <ul><li>يتيح لك TensorZero تحسين تطبيقات LLM المعقدة بناءً على مقاييس الإنتاج والتغذية الراجعة البشرية.<br></li>
      <li>يدعم TensorZero احتياجات تطبيقات LLM على المستوى الصناعي: زمن استجابة منخفض، إنتاجية عالية، أمان الأنواع، استضافة ذاتية، GitOps، قابلية التخصيص، وغيرها.<br></li>
      <li>يوحد TensorZero مجموعة عمليات LLMOps بالكامل، مما يخلق فوائد تراكمية. على سبيل المثال، يمكن استخدام تقييمات LLM لضبط النماذج بمساعدة حكام الذكاء الاصطناعي.</li>
    </ul></td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>هل يمكنني استخدام TensorZero مع ___؟</b></td>
    <td width="70%" valign="top">نعم. يتم دعم كل لغات البرمجة الرئيسية. يمكنك استخدام TensorZero مع عميل Python الخاص بنا، أو أي حزمة SDK متوافقة مع OpenAI، أو عبر واجهة HTTP API.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>هل TensorZero جاهز للإنتاج؟</b></td>
    <td width="70%" valign="top">نعم. إليك دراسة حالة: <b><a href="https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms">أتمتة سجلات تغييرات الشيفرة في بنك كبير باستخدام LLMs</a></b></td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>كم يكلف TensorZero؟</b></td>
    <td width="70%" valign="top">لا شيء. TensorZero مستضاف ذاتيًا ومفتوح المصدر بنسبة 100%. لا توجد ميزات مدفوعة.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>من يطور TensorZero؟</b></td>
    <td width="70%" valign="top">يضم فريقنا التقني مشرفًا سابقًا على مترجم Rust، وباحثين في التعلم الآلي (ستانفورد، كارنيغي ميلون، أكسفورد، كولومبيا) مع آلاف الاقتباسات، ومسؤول المنتجات الرئيسي لشركة ناشئة بقيمة عشرة مليارات دولار. نحن مدعومون من نفس المستثمرين في مشاريع مفتوحة المصدر رائدة (مثل ClickHouse، CockroachDB) ومختبرات الذكاء الاصطناعي (مثل OpenAI، Anthropic).</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>كيف أبدأ؟</b></td>
    <td width="70%" valign="top">يمكنك اعتماد TensorZero تدريجيًا. دليل <b><a href="https://www.tensorzero.com/docs/quickstart">البدء السريع</a></b> يأخذك من غلاف OpenAI بسيط إلى تطبيق LLM جاهز للإنتاج مع الرصد والضبط الدقيق في 5 دقائق فقط.</td>
  </tr>
</table></p><hr></p><h2>الميزات</h2></p><h3>🌐 بوابة LLM</h3></p><blockquote><strong>ادمج مع TensorZero مرة واحدة وادخل إلى كل مزودي LLM الرئيسيين.</strong></blockquote></p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>مزودو النماذج</b></td>
    <td width="50%" align="center" valign="middle"><b>الميزات</b></td>
  </tr>
  <tr>
    <td width="50%" align="left" valign="top">
      <p>
        تدعم بوابة TensorZero بشكل أصلي:
      </p>
      <ul>
        <ul><li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/anthropic">Anthropic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock">AWS Bedrock</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker">AWS SageMaker</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/azure">Azure OpenAI Service</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/deepseek">DeepSeek</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/fireworks">Fireworks</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic">GCP Vertex AI Anthropic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini">GCP Vertex AI Gemini</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini">Google AI Studio (Gemini API)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic">Hyperbolic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/mistral">Mistral</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai">OpenAI</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/together">Together</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/vllm">vLLM</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/xai">xAI</a></b></li>
      </ul></ul>
        <em>
          تحتاج إلى شيء آخر؟
          على الأرجح مزودك مدعوم لأن TensorZero يتكامل مع <b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible">أي واجهة برمجة تطبيقات متوافقة مع OpenAI (مثل Ollama)</a></b>.
          </em>
      </p>
    </td>
    <td width="50%" align="left" valign="top">
      <p>
        تدعم بوابة TensorZero ميزات متقدمة مثل:
      </p>
      <ul>
        <ul><li><b><a href="https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks">إعادة المحاولة وآليات الاسترجاع</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations">تحسينات زمن الاستدلال</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/prompt-templates-schemas">قوالب التعليمات والمخططات</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/tutorial#experimentation">التجريب (اختبار A/B)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/configuration-reference">الإعداد ككود (GitOps)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/batch-inference">الاستدلال الدفعي</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/multimodal-inference">الاستدلال متعدد الأنماط (VLMs)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-caching">تخزين الاستدلال المؤقت</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/metrics-feedback">المقاييس والتعليقات</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/episodes">مهام LLM متعددة الخطوات (الحلقات)</a></b></li>
        <li><em>والمزيد...</em></li>
      </ul></ul>
        تم كتابة بوابة TensorZero بلغة Rust 🦀 مع التركيز على <b>الأداء</b> (تأخير أقل من 1 مللي ثانية P99 عند 10 آلاف طلب في الثانية).
        راجع <b><a href="https://www.tensorzero.com/docs/gateway/benchmarks">معايير الأداء</a></b>.<br>
      </p>
      <p>
        يمكنك تشغيل الاستدلال باستخدام <b>عميل TensorZero</b> (موصى به)، أو <b>عميل OpenAI</b>، أو <b>واجهة HTTP API</b>.
      </p>
    </td>
  </tr>
</table></p><p><br></p><p><details open>
<summary><b>الاستخدام: بايثون &mdash; عميل TensorZero (موصى به)</b></summary></p><p>يمكنك الوصول إلى أي مزود باستخدام عميل TensorZero لبايثون.</p><ul><li><code>pip install tensorzero</code></li>
<li>اختياري: إعداد تكوين TensorZero.</li>
<li>تنفيذ الاستدلال:</li></p><p></ul><pre><code class="language-python">from tensorzero import TensorZeroGateway  # أو AsyncTensorZeroGateway</p><p>
with TensorZeroGateway.build_embedded(clickhouse_url="...", config_file="...") as client:
    response = client.inference(
        model_name="openai::gpt-4o-mini",
        # جرب مزودين آخرين بسهولة: "anthropic::claude-3-7-sonnet-20250219"
        input={
            "messages": [
                {
                    "role": "user",
                    "content": "اكتب هايكو عن الذكاء الاصطناعي.",
                }
            ]
        },
    )</code></pre></p><p>راجع <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">البدء السريع</a></strong> للمزيد من المعلومات.</p><p></details></p><p><details>
<summary><b>الاستخدام: بايثون &mdash; عميل OpenAI</b></summary></p><p>يمكنك الوصول إلى أي مزود باستخدام عميل OpenAI لبايثون مع TensorZero.</p><ul><li><code>pip install tensorzero</code></li>
<li>اختياري: إعداد تكوين TensorZero.</li>
<li>تنفيذ الاستدلال:</li></p><p></ul><pre><code class="language-python">from openai import OpenAI  # أو AsyncOpenAI
from tensorzero import patch_openai_client</p><p>client = OpenAI()</code></pre>python
patch_openai_client(
    client,
    clickhouse_url="http://chuser:chpassword@localhost:8123/tensorzero",
    config_file="config/tensorzero.toml",
    async_setup=False,
)</p><p>response = client.chat.completions.create(
    model="tensorzero::model_name::openai::gpt-4o-mini",
    # جرّب مزودين آخرين بسهولة: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
    messages=[
        {
            "role": "user",
            "content": "اكتب هايكو عن الذكاء الاصطناعي.",
        }
    ],
)
<pre><code class="language-">
راجع <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">البدء السريع</a></strong> لمزيد من المعلومات.</p><p></details></p><p><details>
<summary><b>الاستخدام: JavaScript / TypeScript (Node) &mdash; عميل OpenAI</b></summary></p><p>يمكنك الوصول إلى أي مزود باستخدام عميل OpenAI Node مع TensorZero.</p><ul><li>قم بنشر <code>tensorzero/gateway</code> باستخدام Docker.</li>
   </ul><strong><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank" rel="noopener noreferrer">تعليمات مفصلة →</a></strong>
<ul><li>قم بإعداد إعدادات TensorZero.</li>
<li>شغّل الاستدلال:</li>
</ul></code></pre>ts
import OpenAI from "openai";</p><p>const client = new OpenAI({
  baseURL: "http://localhost:3000/openai/v1",
});</p><p>const response = await client.chat.completions.create({
  model: "tensorzero::model_name::openai::gpt-4o-mini",
  // جرّب مزودين آخرين بسهولة: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
  messages: [
    {
      role: "user",
      content: "اكتب هايكو عن الذكاء الاصطناعي.",
    },
  ],
});
<pre><code class="language-">
راجع <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">البدء السريع</a></strong> لمزيد من المعلومات.</p><p></details></p><p><details>
<summary><b>الاستخدام: لغات ومنصات أخرى &mdash; HTTP API</b></summary></p><p>يدعم TensorZero فعلياً أي لغة برمجة أو منصة عبر HTTP API الخاص به.</p><ul><li>قم بنشر <code>tensorzero/gateway</code> باستخدام Docker.</li>
   </ul><strong><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank" rel="noopener noreferrer">تعليمات مفصلة →</a></strong>
<ul><li>اختياري: قم بإعداد إعدادات TensorZero.</li>
<li>شغّل الاستدلال:</li>
</ul></code></pre>bash
curl -X POST "http://localhost:3000/inference" \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "openai::gpt-4o-mini",
    "input": {
      "messages": [
        {
          "role": "user",
          "content": "اكتب هايكو عن الذكاء الاصطناعي."
        }
      ]
    }
  }'
<pre><code class="language-">
راجع <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">البدء السريع</a></strong> لمزيد من المعلومات.</p><p></details></p><p><br></p><h3>📈 تحسين النماذج اللغوية الكبيرة (LLM)</h3></p><blockquote><strong>أرسل مقاييس الإنتاج والتقييم البشري لتحسين مطالباتك ونماذجك واستراتيجيات الاستدلال بسهولة &mdash; باستخدام الواجهة الرسومية أو برمجياً.</strong></blockquote></p><p>#### تحسين النماذج</p><p>قم بتحسين النماذج مغلقة المصدر ومفتوحة المصدر باستخدام التدريب تحت الإشراف (SFT) والتدريب المفضل (DPO).</p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>التدريب تحت الإشراف &mdash; واجهة المستخدم</b></td>
    <td width="50%" align="center" valign="middle"><b>التدريب المفضل (DPO) &mdash; Jupyter Notebook</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/cf7acf66-732b-43b3-af2a-5eba1ce40f6f"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/a67a0634-04a7-42b0-b934-9130cb7cdf51"></td>
  </tr>
</table></p><p>#### تحسين وقت الاستدلال</p><p>عزّز الأداء عبر تحديث مطالباتك ديناميكياً بأمثلة ذات صلة، أو دمج الاستجابات من استدلالات متعددة، والمزيد.</p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling">أفضل اختيار من N (Best-of-N Sampling)</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#mixture-of-n-sampling">مزيج من N (Mixture-of-N Sampling)</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/c0edfa4c-713c-4996-9964-50c0d26e6970"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/75b5bf05-4c1f-43c4-b158-d69d1b8d05be"></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl">التعلم الديناميكي في السياق (DICL)</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#chain-of-thought-cot">سلسلة الأفكار (CoT)</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/d8489e92-ce93-46ac-9aab-289ce19bb67d"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/ea13d73c-76a4-4e0c-a35b-0c648f898311" height="320"></td>
  </tr>
</table></p><p>_المزيد قادم قريباً..._</p><p><br></p><p>#### تحسين المطالبات</p><p>حسّن مطالباتك برمجياً باستخدام تقنيات بحثية متقدمة.</p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling">MIPROv2</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy">تكامل DSPy</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/d81a7c37-382f-4c46-840f-e6c2593301db" alt="MIPROv2 diagram"></td>
    <td width="50%" align="center" valign="middle">
      يأتي TensorZero مع العديد من وصفات التحسين، كما يمكنك بسهولة إنشاء وصفاتك الخاصة.
      يوضّح هذا المثال كيفية تحسين دالة في TensorZero باستخدام أداة خارجية — هنا، DSPy، مكتبة مشهورة لهندسة المطالبات الآلية.
    </td>
  </tr>
</table></p><p>_المزيد قادم قريباً..._</p><p><br></p><h3>🔍 مراقبة النماذج اللغوية الكبيرة (LLM Observability)</h3></p><blockquote><strong>تعمّق لتصحيح نداءات API الفردية، أو راقب المقاييس عبر النماذج والمطالبات مع مرور الوقت &mdash; كل ذلك باستخدام واجهة TensorZero مفتوحة المصدر.</strong></blockquote></p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>المراقبة » الاستدلال</b></td>
    <td width="50%" align="center" valign="middle"><b>المراقبة » الدالة</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/2cc3cc9a-f33f-4e94-b8de-07522326f80a"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/00ae6605-8fa0-4efd-8238-ae8ea589860f"></td>
  </tr>
</table></p><p><br></p><h3>📊 تقييمات النماذج اللغوية الكبيرة</h3></p><blockquote><strong>قارن المطالبات والنماذج واستراتيجيات الاستدلال باستخدام تقييمات TensorZero &mdash; مع دعم للمعايير والحكام من النماذج اللغوية الكبيرة.</strong></blockquote></p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>التقييم » واجهة المستخدم</b></td>
    <td width="50%" align="center" valign="middle"><b>التقييم » سطر الأوامر (CLI)</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699"></td>
    <td width="50%" align="left" valign="middle">
<pre><code class="language-bash">docker compose run --rm evaluations \
  --evaluation-name extract_data \
  --dataset-name hard_test_cases \
  --variant-name gpt_4o \
  --concurrency 5</code></pre>
<pre><code class="language-bash">Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4
Number of datapoints: 100
██████████████████████████████████████ 100/100
exact_match: 0.83 ± 0.03</code></pre>
semantic_match: 0.98 ± 0.01
item_count: 7.15 ± 0.39</code></pre>
    </td>
  </tr>
</table></p><h2>العرض التوضيحي</h2></p><blockquote><strong>شاهد نماذج اللغة الكبيرة (LLMs) تتحسن في استخراج البيانات في الوقت الفعلي مع TensorZero!</strong></blockquote>
>
<blockquote><strong><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl" target="_blank" rel="noopener noreferrer">التعلم الديناميكي داخل السياق (DICL)</a></strong> هو تحسين قوي لأداء الاستدلال متوفر مباشرة في TensorZero.</blockquote>
<blockquote>يعزز أداء نماذج اللغة الكبيرة من خلال دمج أمثلة تاريخية ذات صلة تلقائيًا في الموجه، دون الحاجة إلى إعادة ضبط النموذج (fine-tuning).</blockquote></p><p>https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb</p><h2>هندسة النماذج اللغوية مع TensorZero</h2></p><p><br>
<p align="center" >
  <a href="https://www.tensorzero.com/docs">
    <picture>
      <source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6">
      <source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/e8bc699b-6378-4c2a-9cc1-6d189025e270">
      <img alt="TensorZero Flywheel" src="https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6" width=720>
    </picture>
  </a>
</p>
<br></p><ul><li><strong><a href="https://www.tensorzero.com/docs/gateway/" target="_blank" rel="noopener noreferrer">بوابة TensorZero</a></strong> هي بوابة نماذج عالية الأداء مكتوبة بلغة Rust 🦀 وتوفر واجهة برمجة تطبيقات موحدة لجميع مزودي نماذج اللغة الكبيرة الرئيسيين، مما يسمح بتكامل سلس بين المنصات المختلفة ودعم التبديل التلقائي عند الحاجة.</li>
<li>تتعامل مع الاستدلال القائم على المخطط المهيكل مع زمن تأخير أقل من 1 مللي ثانية في المئين 99 (انظر <strong><a href="https://www.tensorzero.com/docs/gateway/benchmarks" target="_blank" rel="noopener noreferrer">الاختبارات المعيارية</a></strong>) وتوفر المراقبة المدمجة والتجريب و<strong><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations" target="_blank" rel="noopener noreferrer">تحسينات وقت الاستدلال</a></strong>.</li>
<li>تجمع أيضًا مقاييس وردود فعل مرتبطة بهذه الاستدلالات، مع دعم من الدرجة الأولى لأنظمة النماذج اللغوية متعددة الخطوات.</li>
<li>يتم تخزين كل شيء في مستودع بيانات ClickHouse تتحكم فيه أنت، لتحليلات فورية وقابلة للتطوير وصديقة للمطورين.</li>
<li>مع مرور الوقت، <strong><a href="https://www.tensorzero.com/docs/recipes" target="_blank" rel="noopener noreferrer">وصفات TensorZero</a></strong> تستفيد من مجموعة البيانات المهيكلة هذه لتحسين الموجهات والنماذج الخاصة بك: شغّل وصفات جاهزة لسير العمل الشائع مثل إعادة ضبط النموذج، أو أنشئ وصفاتك الخاصة بمرونة تامة باستخدام أي لغة وأي منصة.</li>
<li>أخيرًا، تتيح ميزات التجريب في البوابة وأتمتة GitOps لك التكرار والنشر بثقة، سواء كان لديك نموذج واحد أو آلاف النماذج.</li></p><p></ul>هدفنا هو مساعدة المهندسين على بناء وإدارة وتحسين الجيل القادم من تطبيقات النماذج اللغوية الكبيرة: أنظمة تتعلم من الخبرة الواقعية.
اقرأ المزيد حول <strong><a href="https://www.tensorzero.com/docs/vision-roadmap/" target="_blank" rel="noopener noreferrer">رؤيتنا وخارطة الطريق</a></strong>.</p><h2>ابدأ الآن</h2></p><p><strong>ابدأ بالبناء اليوم.</strong>
يوضح <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">دليل البدء السريع</a></strong> مدى سهولة إعداد تطبيق يعتمد على نموذج لغوي باستخدام TensorZero.
إذا كنت ترغب في التعمق أكثر، <strong><a href="https://www.tensorzero.com/docs/gateway/tutorial" target="_blank" rel="noopener noreferrer">الدليل التعليمي</a></strong> يعلمك كيفية بناء روبوت دردشة بسيط، ومساعد للبريد الإلكتروني، ونظام استرجاع معلومات الطقس (RAG)، وخط أنابيب لاستخراج البيانات المهيكلة.</p><p><strong>هل لديك أسئلة؟</strong>
تواصل معنا عبر <strong><a href="https://www.tensorzero.com/slack" target="_blank" rel="noopener noreferrer">Slack</a></strong> أو <strong><a href="https://www.tensorzero.com/discord" target="_blank" rel="noopener noreferrer">Discord</a></strong>.</p><p><strong>هل تستخدم TensorZero في العمل؟</strong>
راسلنا عبر البريد الإلكتروني على <strong><a href="mailto:hello@tensorzero.com" target="_blank" rel="noopener noreferrer">hello@tensorzero.com</a></strong> لإنشاء قناة Slack أو Teams مع فريقك (مجاني).</p><p><strong>انضم إلينا.</strong>
نحن <strong><a href="https://www.tensorzero.com/jobs" target="_blank" rel="noopener noreferrer">نوظف في نيويورك</a></strong>.
ونرحب أيضًا <strong><a href="https://github.com/tensorzero/tensorzero/blob/main/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">بالمساهمات مفتوحة المصدر</a></strong>!</p><h2>أمثلة</h2></p><p>نعمل على سلسلة من <strong>الأمثلة الكاملة القابلة للتنفيذ</strong> التي توضح دورة البيانات والتعلم في TensorZero.</p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/data-extraction-ner" target="_blank" rel="noopener noreferrer">تحسين استخراج البيانات (NER) باستخدام TensorZero</a></strong></blockquote>
>
<blockquote>يوضح هذا المثال كيفية استخدام TensorZero لتحسين خط أنابيب استخراج البيانات.</blockquote>
<blockquote>نستعرض تقنيات مثل إعادة ضبط النموذج والتعلم الديناميكي داخل السياق (DICL).</blockquote>
<blockquote>في النهاية، يتفوق نموذج GPT-4o Mini المحسّن على GPT-4o في هذه المهمة — بجزء بسيط من التكلفة والزمن — باستخدام كمية قليلة من بيانات التدريب.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/rag-retrieval-augmented-generation/simple-agentic-rag/" target="_blank" rel="noopener noreferrer">عامل RAG — الإجابة متعددة الخطوات على الأسئلة باستخدام النماذج اللغوية الكبيرة</a></strong></blockquote>
>
<blockquote>يوضح هذا المثال كيفية بناء عامل استرجاع متعدد الخطوات باستخدام TensorZero.</blockquote>
<blockquote>يبحث العامل بشكل تكراري في ويكيبيديا لجمع المعلومات، ويقرر متى يكون لديه سياق كافٍ للإجابة عن سؤال معقد.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences" target="_blank" rel="noopener noreferrer">كتابة الهايكو لإرضاء قاضٍ بتفضيلات مخفية</a></strong></blockquote>
>
<blockquote>في هذا المثال نقوم بضبط نموذج GPT-4o Mini لإنتاج قصائد هايكو مخصصة لذوق معين.</blockquote>
<blockquote>سترى دورة بيانات TensorZero الفريدة قيد التنفيذ: تحسين المتغيرات يؤدي إلى بيانات أفضل، والبيانات الأفضل تؤدي إلى متغيرات أفضل.</blockquote>
<blockquote>سترى التقدم من خلال إعادة ضبط النموذج عدة مرات.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles/" target="_blank" rel="noopener noreferrer">تحسين قدرة النماذج على لعب الشطرنج باستخدام أخذ عينات أفضل-N</a></strong></blockquote>
>
<blockquote>يوضح هذا المثال كيف يمكن أن تعزز تقنية أخذ عينات أفضل-N بشكل كبير من قدرات النماذج على لعب الشطرنج عن طريق اختيار التحركات الأكثر وعدًا من بين عدة خيارات مولدة.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy" target="_blank" rel="noopener noreferrer">تحسين الاستدلال الرياضي مع وصفة مخصصة لهندسة الموجهات الآلية (DSPy)</a></strong></blockquote>
>
<blockquote>يوفر TensorZero عددًا من وصفات التحسين الجاهزة التي تغطي سير العمل الشائع في هندسة النماذج.</blockquote>
<blockquote>لكن يمكنك أيضًا بسهولة إنشاء وصفاتك وسير العمل الخاصة!</blockquote>
<blockquote>يوضح هذا المثال كيفية تحسين وظيفة TensorZero باستخدام أي أداة — هنا، DSPy.</blockquote></p><p>_والمزيد في الطريق!_

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/tensorzero/tensorzero/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>