<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>tensorzero - Read tensorzero documentation in Korean. This project has 5476 stars on GitHub.</title>
    <meta name="description" content="Read tensorzero documentation in Korean. This project has 5476 stars on GitHub.">
    <meta name="keywords" content="tensorzero, Korean, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "tensorzero",
  "description": "Read tensorzero documentation in Korean. This project has 5476 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "tensorzero"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 5476
  },
  "url": "https://OpenAiTx.github.io/projects/tensorzero/tensorzero/README-ko.html",
  "sameAs": "https://raw.githubusercontent.com/tensorzero/tensorzero/main/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/tensorzero/tensorzero" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    tensorzero
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 5476 stars</span>
                <span class="language">Korean</span>
                <span>by tensorzero</span>
            </div>
        </div>
        
        <div class="content">
            <p><img src="https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9" width=128 height=128></p><h1>TensorZero</h1></p><p><strong>TensorZero는 LLM 애플리케이션 최적화를 위한 피드백 루프를 생성하여, 프로덕션 데이터를 더 똑똑하고 빠르며 저렴한 모델로 전환합니다.</strong></p><ul><li>모델 게이트웨이 통합</li>
<li>메트릭 또는 피드백 전송</li>
<li>프롬프트, 모델, 추론 전략 최적화</li>
<li>시간이 지날수록 LLM의 성능 향상 확인</li></p><p></ul>TensorZero는 다음을 통합하여 <strong>LLM을 위한 데이터 & 러닝 플라이휠</strong>을 제공합니다.</p><ul><li>[x] <strong>추론:</strong> 모든 LLM을 위한 하나의 API, P99 오버헤드 <1ms</li>
<li>[x] <strong>관찰성:</strong> 추론 & 피드백 → 당신의 데이터베이스로</li>
<li>[x] <strong>최적화:</strong> 프롬프트부터 파인튜닝, RL까지</li>
<li>[x] <strong>평가:</strong> 프롬프트, 모델, 추론 전략 비교</li>
<li>[x] <strong>실험:</strong> 내장된 A/B 테스트, 라우팅, 폴백</li></p><p></ul>---</p><p><p align="center">
  <b><a href="https://www.tensorzero.com/" target="_blank">웹사이트</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs" target="_blank">문서</a></b>
  ·
  <b><a href="https://www.x.com/tensorzero" target="_blank">트위터</a></b>
  ·
  <b><a href="https://www.tensorzero.com/slack" target="_blank">슬랙</a></b>
  ·
  <b><a href="https://www.tensorzero.com/discord" target="_blank">디스코드</a></b>
  <br>
  <br>
  <b><a href="https://www.tensorzero.com/docs/quickstart" target="_blank">빠른 시작 (5분)</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/tutorial" target="_blank">종합 튜토리얼</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank">배포 가이드</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/api-reference" target="_blank">API 레퍼런스</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank">설정 레퍼런스</a></b>
</p></p><hr></p><p><table>
  <tr>
    <td width="30%" valign="top"><b>TensorZero란?</b></td>
    <td width="70%" valign="top">TensorZero는 프로덕션급 LLM 애플리케이션 구축을 위한 오픈소스 프레임워크입니다. LLM 게이트웨이, 관찰성, 최적화, 평가, 실험을 통합합니다.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>TensorZero는 다른 LLM 프레임워크와 무엇이 다른가요?</b></td>
    <td width="70%" valign="top">
      <ul><li>TensorZero는 프로덕션 메트릭 및 인간 피드백 기반으로 복잡한 LLM 애플리케이션을 최적화할 수 있게 합니다.<br></li>
      <li>TensorZero는 산업 규모의 LLM 애플리케이션 요구사항(저지연, 고처리량, 타입 안전, 셀프 호스팅, GitOps, 커스터마이즈 등)을 지원합니다.<br></li>
      <li>TensorZero는 전체 LLMOps 스택을 통합하여 복합적인 이점을 제공합니다. 예를 들어, LLM 평가는 AI 심사관과 함께 모델 파인튜닝에 활용될 수 있습니다.</li>
    </ul></td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>TensorZero를 ___와 함께 사용할 수 있나요?</b></td>
    <td width="70%" valign="top">네, 모든 주요 프로그래밍 언어를 지원합니다. TensorZero는 Python 클라이언트, OpenAI SDK, HTTP API와 함께 사용할 수 있습니다.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>TensorZero는 프로덕션에 바로 쓸 수 있나요?</b></td>
    <td width="70%" valign="top">네, 다음은 사례 연구입니다: <b><a href="https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms">대형 은행의 코드 변경 로그 자동화 사례</a></b></td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>TensorZero는 비용이 얼마나 드나요?</b></td>
    <td width="70%" valign="top">무료입니다. TensorZero는 100% 셀프 호스팅 및 오픈소스입니다. 유료 기능이 없습니다.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>TensorZero는 누가 개발하나요?</b></td>
    <td width="70%" valign="top">기술팀은 전직 Rust 컴파일러 유지관리자, 수천 건의 인용 논문을 보유한 머신러닝 연구자(Stanford, CMU, Oxford, Columbia), 데카콘 스타트업의 CPO로 구성되어 있습니다. ClickHouse, CockroachDB 등 오픈소스 및 OpenAI, Anthropic 등 AI 연구소와 같은 투자자들의 지원을 받고 있습니다.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>시작하려면 어떻게 해야 하나요?</b></td>
    <td width="70%" valign="top">TensorZero는 점진적으로 도입할 수 있습니다. <b><a href="https://www.tensorzero.com/docs/quickstart">빠른 시작</a></b>에서는 OpenAI 래퍼에서 관찰성과 파인튜닝을 갖춘 프로덕션 준비 LLM 애플리케이션까지 5분 만에 안내합니다.</td>
  </tr>
</table></p><hr></p><h2>기능</h2></p><h3>🌐 LLM 게이트웨이</h3></p><blockquote><strong>TensorZero와 한 번만 통합하면 모든 주요 LLM 제공업체에 접근할 수 있습니다.</strong></blockquote></p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>모델 제공업체</b></td>
    <td width="50%" align="center" valign="middle"><b>기능</b></td>
  </tr>
  <tr>
    <td width="50%" align="left" valign="top">
      <p>
        TensorZero Gateway가 기본 지원하는 모델:
      </p>
      <ul>
        <ul><li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/anthropic">Anthropic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock">AWS Bedrock</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker">AWS SageMaker</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/azure">Azure OpenAI Service</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/deepseek">DeepSeek</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/fireworks">Fireworks</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic">GCP Vertex AI Anthropic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini">GCP Vertex AI Gemini</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini">Google AI Studio (Gemini API)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic">Hyperbolic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/mistral">Mistral</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai">OpenAI</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/together">Together</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/vllm">vLLM</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/xai">xAI</a></b></li>
      </ul></ul>
        <em>
          다른 제공업체가 필요하신가요?<br>
          TensorZero는 <b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible">OpenAI 호환 API (예: Ollama)</a></b>와 통합하므로 대부분의 제공업체를 지원합니다.
        </em>
      </p>
    </td>
    <td width="50%" align="left" valign="top">
      <p>
        TensorZero Gateway는 다음과 같은 고급 기능을 지원합니다:
      </p>
      <ul>
        <ul><li><b><a href="https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks">재시도 & 폴백</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations">추론 시점 최적화</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/prompt-templates-schemas">프롬프트 템플릿 & 스키마</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/tutorial#experimentation">실험 (A/B 테스트)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/configuration-reference">코드로서의 설정 (GitOps)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/batch-inference">배치 추론</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/multimodal-inference">멀티모달 추론 (VLMs)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-caching">추론 캐싱</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/metrics-feedback">메트릭 & 피드백</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/episodes">다단계 LLM 워크플로우 (에피소드)</a></b></li>
        <li><em>및 다양한 기능...</em></li>
      </ul></ul>
        TensorZero Gateway는 <b>성능</b>을 염두에 두고 Rust 🦀로 작성되었습니다 (10k QPS 기준 p99 지연 <1ms).
        <b><a href="https://www.tensorzero.com/docs/gateway/benchmarks">벤치마크</a></b> 참조.<br>
      </p>
      <p>
        <b>TensorZero 클라이언트</b>(권장), <b>OpenAI 클라이언트</b>, <b>HTTP API</b>를 사용해 추론을 실행할 수 있습니다.
      </p>
    </td>
  </tr>
</table></p><p><br></p><p><details open>
<summary><b>사용법: Python &mdash; TensorZero 클라이언트 (권장)</b></summary></p><p>TensorZero Python 클라이언트를 사용하여 모든 제공업체에 접근할 수 있습니다.</p><ul><li><code>pip install tensorzero</code></li>
<li>선택 사항: TensorZero 설정 구성</li>
<li>추론 실행:</li></p><p></ul><pre><code class="language-python">from tensorzero import TensorZeroGateway  # 또는 AsyncTensorZeroGateway</p><p>
with TensorZeroGateway.build_embedded(clickhouse_url="...", config_file="...") as client:
    response = client.inference(
        model_name="openai::gpt-4o-mini",
        # 다른 제공업체도 쉽게 사용 가능: "anthropic::claude-3-7-sonnet-20250219"
        input={
            "messages": [
                {
                    "role": "user",
                    "content": "Write a haiku about artificial intelligence.",
                }
            ]
        },
    )</code></pre></p><p>더 자세한 정보는 <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">빠른 시작</a></strong> 참고.</p><p></details></p><p><details>
<summary><b>사용법: Python &mdash; OpenAI 클라이언트</b></summary></p><p>TensorZero와 함께 OpenAI Python 클라이언트를 사용하여 모든 제공업체에 접근할 수 있습니다.</p><ul><li><code>pip install tensorzero</code></li>
<li>선택 사항: TensorZero 설정 구성</li>
<li>추론 실행:</li></p><p></ul><pre><code class="language-python">from openai import OpenAI  # 또는 AsyncOpenAI
from tensorzero import patch_openai_client</p><p>client = OpenAI()</code></pre>
<pre><code class="language-python">patch_openai_client(
    client,
    clickhouse_url="http://chuser:chpassword@localhost:8123/tensorzero",
    config_file="config/tensorzero.toml",
    async_setup=False,
)</p><p>response = client.chat.completions.create(
    model="tensorzero::model_name::openai::gpt-4o-mini",
    # 다른 프로바이더도 쉽게 시도하세요: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
    messages=[
        {
            "role": "user",
            "content": "인공지능에 관한 하이쿠를 작성하세요.",
        }
    ],
)</code></pre></p><p>자세한 내용은 <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">빠른 시작 가이드</a></strong>를 참고하세요.</p><p></details></p><p><details>
<summary><b>사용법: JavaScript / TypeScript (Node) &mdash; OpenAI 클라이언트</b></summary></p><p>TensorZero를 사용하면 OpenAI Node 클라이언트로 모든 프로바이더에 접근할 수 있습니다.</p><ul><li>Docker를 사용하여 <code>tensorzero/gateway</code>를 배포합니다.</li>
   </ul><strong><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank" rel="noopener noreferrer">자세한 배포 안내 →</a></strong>
<ul><li>TensorZero 설정을 구성합니다.</li>
<li>추론을 실행합니다:</li></p><p></ul><pre><code class="language-ts">import OpenAI from "openai";</p><p>const client = new OpenAI({
  baseURL: "http://localhost:3000/openai/v1",
});</p><p>const response = await client.chat.completions.create({
  model: "tensorzero::model_name::openai::gpt-4o-mini",
  // 다른 프로바이더도 쉽게 시도하세요: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
  messages: [
    {
      role: "user",
      content: "인공지능에 관한 하이쿠를 작성하세요.",
    },
  ],
});</code></pre></p><p>자세한 내용은 <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">빠른 시작 가이드</a></strong>를 참고하세요.</p><p></details></p><p><details>
<summary><b>사용법: 기타 언어 및 플랫폼 &mdash; HTTP API</b></summary></p><p>TensorZero는 HTTP API를 통해 거의 모든 프로그래밍 언어나 플랫폼을 지원합니다.</p><ul><li>Docker를 사용하여 <code>tensorzero/gateway</code>를 배포합니다.</li>
   </ul><strong><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank" rel="noopener noreferrer">자세한 배포 안내 →</a></strong>
<ul><li>선택 사항: TensorZero 설정을 구성합니다.</li>
<li>추론을 실행합니다:</li></p><p></ul><pre><code class="language-bash">curl -X POST "http://localhost:3000/inference" \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "openai::gpt-4o-mini",
    "input": {
      "messages": [
        {
          "role": "user",
          "content": "인공지능에 관한 하이쿠를 작성하세요."
        }
      ]
    }
  }'</code></pre></p><p>자세한 내용은 <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">빠른 시작 가이드</a></strong>를 참고하세요.</p><p></details></p><p><br></p><h3>📈 LLM 최적화</h3></p><blockquote><strong>프로덕션 메트릭 및 사용자 피드백을 전송하여 프롬프트, 모델, 추론 전략을 쉽게 최적화할 수 있습니다 — UI 또는 프로그래밍 방식으로 지원됩니다.</strong></blockquote></p><p>#### 모델 최적화</p><p>감독 학습(SFT) 및 선호 학습(DPO)을 통해 클로즈드소스 및 오픈소스 모델을 최적화하세요.</p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>감독 미세조정 &mdash; UI</b></td>
    <td width="50%" align="center" valign="middle"><b>선호 미세조정 (DPO) &mdash; 주피터 노트북</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/cf7acf66-732b-43b3-af2a-5eba1ce40f6f"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/a67a0634-04a7-42b0-b934-9130cb7cdf51"></td>
  </tr>
</table></p><p>#### 추론 시점 최적화</p><p>관련 예시로 프롬프트를 동적으로 갱신하거나, 여러 번의 추론 결과를 결합하는 등으로 성능을 향상할 수 있습니다.</p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling">Best-of-N 샘플링</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#mixture-of-n-sampling">Mixture-of-N 샘플링</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/c0edfa4c-713c-4996-9964-50c0d26e6970"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/75b5bf05-4c1f-43c4-b158-d69d1b8d05be"></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl">동적 인컨텍스트 학습 (DICL)</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#chain-of-thought-cot">Chain-of-Thought (CoT)</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/d8489e92-ce93-46ac-9aab-289ce19bb67d"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/ea13d73c-76a4-4e0c-a35b-0c648f898311" height="320"></td>
  </tr>
</table></p><p>_추가 기능이 곧 제공될 예정입니다..._</p><p><br></p><p>#### 프롬프트 최적화</p><p>연구 기반 최적화 기법을 사용하여 프로그래밍 방식으로 프롬프트를 최적화하세요.</p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling">MIPROv2</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy">DSPy 통합</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/d81a7c37-382f-4c46-840f-e6c2593301db" alt="MIPROv2 diagram"></td>
    <td width="50%" align="center" valign="middle">
      TensorZero는 여러 최적화 레시피를 기본 제공하며, 직접 새로운 레시피를 쉽게 만들 수도 있습니다.
      이 예시는 임의의 도구 — 여기서는 자동 프롬프트 엔지니어링을 위한 인기 라이브러리 DSPy — 를 사용해 TensorZero 함수를 최적화하는 방법을 보여줍니다.
    </td>
  </tr>
</table></p><p>_추가 기능이 곧 제공될 예정입니다..._</p><p><br></p><h3>🔍 LLM 가시성(Observability)</h3></p><blockquote><strong>API 호출 단위로 디버깅하거나, 장기간에 걸쳐 모델 및 프롬프트 메트릭을 모니터링하세요 — 오픈소스 TensorZero UI에서 모두 지원됩니다.</strong></blockquote></p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>가시성 » 추론</b></td>
    <td width="50%" align="center" valign="middle"><b>가시성 » 함수</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/2cc3cc9a-f33f-4e94-b8de-07522326f80a"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/00ae6605-8fa0-4efd-8238-ae8ea589860f"></td>
  </tr>
</table></p><p><br></p><h3>📊 LLM 평가</h3></p><blockquote><strong>TensorZero 평가 기능을 활용하여 프롬프트, 모델, 추론 전략을 비교하세요 — 휴리스틱 및 LLM 판정 지원.</strong></blockquote></p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>평가 » UI</b></td>
    <td width="50%" align="center" valign="middle"><b>평가 » CLI</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699"></td>
    <td width="50%" align="left" valign="middle">
<pre><code class="language-bash">docker compose run --rm evaluations \
  --evaluation-name extract_data \
  --dataset-name hard_test_cases \
  --variant-name gpt_4o \
  --concurrency 5</code></pre>
<pre><code class="language-bash">Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4
Number of datapoints: 100
██████████████████████████████████████ 100/100
exact_match: 0.83 ± 0.03
```
semantic_match: 0.98 ± 0.01  
item_count: 7.15 ± 0.39</code></pre>
    </td>
  </tr>
</table></p><h2>데모</h2></p><blockquote><strong>TensorZero와 함께 LLM이 실시간으로 데이터 추출 능력을 향상시키는 모습을 확인해보세요!</strong></blockquote>
>
<blockquote><strong><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl" target="_blank" rel="noopener noreferrer">동적 인컨텍스트 학습(DICL)</a></strong>은 TensorZero에서 기본적으로 제공되는 강력한 추론 최적화 기능입니다.</blockquote>
<blockquote>이 기능은 모델 파인튜닝 없이도 관련된 과거 예시를 자동으로 프롬프트에 반영하여 LLM의 성능을 향상시킵니다.</blockquote></p><p>https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb</p><h2>TensorZero를 활용한 LLM 엔지니어링</h2></p><p><br>
<p align="center" >
  <a href="https://www.tensorzero.com/docs">
    <picture>
      <source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6">
      <source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/e8bc699b-6378-4c2a-9cc1-6d189025e270">
      <img alt="TensorZero Flywheel" src="https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6" width=720>
    </picture>
  </a>
</p>
<br></p><ul><li><strong><a href="https://www.tensorzero.com/docs/gateway/" target="_blank" rel="noopener noreferrer">TensorZero Gateway</a></strong>는 Rust 🦀로 작성된 고성능 모델 게이트웨이로, 모든 주요 LLM 제공업체에 대한 통합 API 인터페이스를 제공하여 플랫폼 간 통합 및 폴백을 원활하게 지원합니다.</li>
<li>구조화된 스키마 기반 추론을 <1ms P99 지연 시간 오버헤드(자세한 내용은 <strong><a href="https://www.tensorzero.com/docs/gateway/benchmarks" target="_blank" rel="noopener noreferrer">Benchmarks</a></strong> 참조)로 처리하며, 내장된 관측 기능, 실험 기능, <strong><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations" target="_blank" rel="noopener noreferrer">추론 최적화</a></strong>를 제공합니다.</li>
<li>이러한 추론과 관련된 다운스트림 메트릭 및 피드백도 수집하며, 다단계 LLM 시스템을 1급 시민으로 지원합니다.</li>
<li>모든 데이터는 실시간, 확장 가능하며 개발자 친화적인 분석을 위해 여러분이 직접 제어할 수 있는 ClickHouse 데이터 웨어하우스에 저장됩니다.</li>
<li>시간이 지남에 따라 <strong><a href="https://www.tensorzero.com/docs/recipes" target="_blank" rel="noopener noreferrer">TensorZero Recipes</a></strong>가 이 구조화된 데이터셋을 활용하여 프롬프트와 모델을 최적화합니다. 파인튜닝 등 일반적인 워크플로우를 위한 사전 구축된 레시피를 실행하거나, 원하는 언어와 플랫폼으로 나만의 레시피를 자유롭게 만들 수 있습니다.</li>
<li>마지막으로, 게이트웨이의 실험 기능과 GitOps 오케스트레이션을 활용해 단일 LLM부터 수천 개의 LLM까지 자신 있게 반복·배포할 수 있습니다.</li></p><p></ul>저희의 목표는 엔지니어가 실세계 경험을 통해 학습하는 차세대 LLM 애플리케이션(시스템)을 구축, 관리, 최적화할 수 있도록 돕는 것입니다.  
<strong><a href="https://www.tensorzero.com/docs/vision-roadmap/" target="_blank" rel="noopener noreferrer">비전 및 로드맵</a></strong>에서 자세한 내용을 확인하세요.</p><h2>시작하기</h2></p><p><strong>지금 바로 빌드를 시작하세요.</strong>  
<strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">Quick Start</a></strong>에서는 TensorZero로 LLM 애플리케이션을 손쉽게 구축하는 방법을 안내합니다.  
더 깊이 배우고 싶다면 <strong><a href="https://www.tensorzero.com/docs/gateway/tutorial" target="_blank" rel="noopener noreferrer">Tutorial</a></strong>에서 간단한 챗봇, 이메일 코파일럿, 날씨 RAG 시스템, 구조화 데이터 추출 파이프라인 구축법을 배울 수 있습니다.</p><p><strong>궁금한 점이 있으신가요?</strong>  
<strong><a href="https://www.tensorzero.com/slack" target="_blank" rel="noopener noreferrer">Slack</a></strong> 또는 <strong><a href="https://www.tensorzero.com/discord" target="_blank" rel="noopener noreferrer">Discord</a></strong>에서 문의해 주세요.</p><p><strong>업무에서 TensorZero를 사용 중이신가요?</strong>  
<strong><a href="mailto:hello@tensorzero.com" target="_blank" rel="noopener noreferrer">hello@tensorzero.com</a></strong>로 이메일을 보내주시면, 여러분 팀과 함께할 전용 Slack 또는 Teams 채널을 무료로 마련해 드립니다.</p><p><strong>함께 일하고 싶으신가요?</strong>  
저희는 <strong><a href="https://www.tensorzero.com/jobs" target="_blank" rel="noopener noreferrer">NYC에서 채용 중</a></strong>입니다.  
또한 <strong><a href="https://github.com/tensorzero/tensorzero/blob/main/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">오픈소스 기여</a></strong>도 환영합니다!</p><h2>예시</h2></p><p>TensorZero의 데이터 & 러닝 플라이휠을 보여주는 <strong>완전 실행 가능한 예제</strong> 시리즈를 준비 중입니다.</p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/data-extraction-ner" target="_blank" rel="noopener noreferrer">TensorZero를 활용한 데이터 추출(NER) 최적화</a></strong></blockquote>
>
<blockquote>이 예제에서는 TensorZero로 데이터 추출 파이프라인을 최적화하는 방법을 보여줍니다.</blockquote>
<blockquote>파인튜닝과 동적 인컨텍스트 학습(DICL) 등 다양한 기법을 시연합니다.</blockquote>
<blockquote>결과적으로, 소량의 학습 데이터만으로 최적화된 GPT-4o Mini 모델이 비용과 지연 시간을 획기적으로 줄이면서도 동일 작업에서 GPT-4o보다 우수한 성능을 보입니다.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/rag-retrieval-augmented-generation/simple-agentic-rag/" target="_blank" rel="noopener noreferrer">에이전틱 RAG — LLM을 활용한 다중 단계 질의응답</a></strong></blockquote>
>
<blockquote>이 예제는 TensorZero를 이용해 다중 단계 검색 에이전트를 구축하는 방법을 보여줍니다.</blockquote>
<blockquote>에이전트는 위키피디아를 반복적으로 탐색해 정보를 수집하고, 충분한 맥락이 쌓였다고 판단되면 복잡한 질문에 답변을 제공합니다.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences" target="_blank" rel="noopener noreferrer">숨겨진 선호를 가진 심사위원을 만족시키는 하이쿠 생성하기</a></strong></blockquote>
>
<blockquote>이 예제는 GPT-4o Mini를 파인튜닝해 특정 취향에 맞는 하이쿠를 생성하도록 만듭니다.</blockquote>
<blockquote>TensorZero의 "상자 안 데이터 플라이휠"을 직접 경험할 수 있습니다: 더 나은 변종이 더 좋은 데이터를 만들고, 더 좋은 데이터가 더 나은 변종으로 이어집니다.</blockquote>
<blockquote>LLM을 여러 번 파인튜닝하는 과정을 통해 발전하는 모습을 볼 수 있습니다.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles/" target="_blank" rel="noopener noreferrer">Best-of-N 샘플링으로 LLM 체스 실력 향상시키기</a></strong></blockquote>
>
<blockquote>이 예제는 여러 번 생성된 옵션 중 가장 유망한 수를 선택하는 Best-of-N 샘플링 기법이 LLM의 체스 실력을 어떻게 크게 향상시킬 수 있는지 보여줍니다.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy" target="_blank" rel="noopener noreferrer">자동 프롬프트 엔지니어링(DSPy)을 위한 커스텀 레시피로 수학적 추론 향상</a></strong></blockquote>
>
<blockquote>TensorZero는 다양한 LLM 엔지니어링 워크플로우를 위한 사전 구축된 최적화 레시피를 제공합니다.</blockquote>
<blockquote>물론, 여러분만의 레시피와 워크플로우도 쉽게 만들 수 있습니다!</blockquote>
<blockquote>이 예제에서는 임의의 도구(DSPy)를 활용해 TensorZero 함수를 최적화하는 방법을 보여줍니다.</blockquote></p><p>_그리고 더 많은 예제가 곧 추가될 예정입니다!_

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/tensorzero/tensorzero/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>