<!DOCTYPE html>
<html lang="nl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>tensorzero - Read tensorzero documentation in Dutch. This project has 5476 stars on GitHub.</title>
    <meta name="description" content="Read tensorzero documentation in Dutch. This project has 5476 stars on GitHub.">
    <meta name="keywords" content="tensorzero, Dutch, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "tensorzero",
  "description": "Read tensorzero documentation in Dutch. This project has 5476 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "tensorzero"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 5476
  },
  "url": "https://OpenAiTx.github.io/projects/tensorzero/tensorzero/README-nl.html",
  "sameAs": "https://raw.githubusercontent.com/tensorzero/tensorzero/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/tensorzero/tensorzero" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    tensorzero
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 5476 stars</span>
                <span class="language">Dutch</span>
                <span>by tensorzero</span>
            </div>
        </div>
        
        <div class="content">
            <p><img src="https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9" width=128 height=128></p><h1>TensorZero</h1></p><p><strong>TensorZero creëert een feedbackloop voor het optimaliseren van LLM-toepassingen — productiegegevens worden omgezet in slimmere, snellere en goedkopere modellen.</strong></p><ul><li>Integreer onze modelgateway</li>
<li>Stuur metrics of feedback</li>
<li>Optimaliseer prompts, modellen en inferentiestrategieën</li>
<li>Zie je LLM’s in de loop van de tijd verbeteren</li></p><p></ul>Het biedt een <strong>data & learning flywheel voor LLM’s</strong> door het verenigen van:</p><ul><li>[x] <strong>Inferentie:</strong> één API voor alle LLM’s, met <1ms P99 overhead</li>
<li>[x] <strong>Observeerbaarheid:</strong> inferentie & feedback → jouw database</li>
<li>[x] <strong>Optimalisatie:</strong> van prompts tot fine-tuning en RL</li>
<li>[x] <strong>Evaluaties:</strong> vergelijk prompts, modellen, inferentiestrategieën</li>
<li>[x] <strong>Experimentatie:</strong> ingebouwde A/B-testen, routering, fallbacks</li></p><p></ul>---</p><p><p align="center">
  <b><a href="https://www.tensorzero.com/" target="_blank">Website</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs" target="_blank">Documentatie</a></b>
  ·
  <b><a href="https://www.x.com/tensorzero" target="_blank">Twitter</a></b>
  ·
  <b><a href="https://www.tensorzero.com/slack" target="_blank">Slack</a></b>
  ·
  <b><a href="https://www.tensorzero.com/discord" target="_blank">Discord</a></b>
  <br>
  <br>
  <b><a href="https://www.tensorzero.com/docs/quickstart" target="_blank">Snelle Start (5min)</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/tutorial" target="_blank">Uitgebreide Tutorial</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank">Deployment Gids</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/api-reference" target="_blank">API Referentie</a></b>
  ·
  <b><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank">Configuratie Referentie</a></b>
</p></p><hr></p><p><table>
  <tr>
    <td width="30%" valign="top"><b>Wat is TensorZero?</b></td>
    <td width="70%" valign="top">TensorZero is een open-source framework voor het bouwen van productieklare LLM-toepassingen. Het verenigt een LLM-gateway, observeerbaarheid, optimalisatie, evaluaties en experimentatie.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Hoe verschilt TensorZero van andere LLM-frameworks?</b></td>
    <td width="70%" valign="top">
      <ul><li>TensorZero stelt je in staat complexe LLM-toepassingen te optimaliseren op basis van productiemetrics en menselijke feedback.<br></li>
      <li>TensorZero ondersteunt de behoeften van industriële LLM-toepassingen: lage latency, hoge doorvoer, typeveiligheid, self-hosted, GitOps, aanpasbaarheid, enz.<br></li>
      <li>TensorZero verenigt de volledige LLMOps-stack, waardoor samenspelende voordelen ontstaan. Bijvoorbeeld, LLM-evaluaties kunnen worden gebruikt voor fine-tuning van modellen samen met AI-juryleden.</li>
    </ul></td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Kan ik TensorZero gebruiken met ___?</b></td>
    <td width="70%" valign="top">Ja. Elke grote programmeertaal wordt ondersteund. Je kunt TensorZero gebruiken met onze Python-client, elke OpenAI SDK, of onze HTTP API.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Is TensorZero geschikt voor productie?</b></td>
    <td width="70%" valign="top">Ja. Hier is een case study: <b><a href="https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms">Automatiseren van code changelogs bij een grote bank met LLMs</a></b></td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Wat kost TensorZero?</b></td>
    <td width="70%" valign="top">Niets. TensorZero is 100% self-hosted en open-source. Er zijn geen betaalde functies.</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Wie ontwikkelt TensorZero?</b></td>
    <td width="70%" valign="top">Ons technische team bestaat uit een voormalig Rust compiler maintainer, machine learning onderzoekers (Stanford, CMU, Oxford, Columbia) met duizenden citaties, en de chief product officer van een decacorn startup. We worden gesteund door dezelfde investeerders als toonaangevende open-source projecten (zoals ClickHouse, CockroachDB) en AI-labs (zoals OpenAI, Anthropic).</td>
  </tr>
  <tr>
    <td width="30%" valign="top"><b>Hoe begin ik met TensorZero?</b></td>
    <td width="70%" valign="top">Je kunt TensorZero geleidelijk adopteren. Onze <b><a href="https://www.tensorzero.com/docs/quickstart">Snelle Start</a></b> gaat van een eenvoudige OpenAI-wrapper naar een productieklare LLM-toepassing met observeerbaarheid en fine-tuning in slechts 5 minuten.</td>
  </tr>
</table></p><hr></p><h2>Functies</h2></p><h3>🌐 LLM Gateway</h3></p><blockquote><strong>Integreer één keer met TensorZero en krijg toegang tot elke grote LLM-provider.</strong></blockquote></p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Modelproviders</b></td>
    <td width="50%" align="center" valign="middle"><b>Functies</b></td>
  </tr>
  <tr>
    <td width="50%" align="left" valign="top">
      <p>
        De TensorZero Gateway ondersteunt standaard:
      </p>
      <ul>
        <ul><li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/anthropic">Anthropic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock">AWS Bedrock</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker">AWS SageMaker</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/azure">Azure OpenAI Service</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/deepseek">DeepSeek</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/fireworks">Fireworks</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic">GCP Vertex AI Anthropic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini">GCP Vertex AI Gemini</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini">Google AI Studio (Gemini API)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic">Hyperbolic</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/mistral">Mistral</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai">OpenAI</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/together">Together</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/vllm">vLLM</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/xai">xAI</a></b></li>
      </ul></ul>
        <em>
          Iets anders nodig?
          Jouw provider wordt waarschijnlijk ondersteund, want TensorZero integreert met <b><a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible">elke OpenAI-compatibele API (bijvoorbeeld Ollama)</a></b>.
          </em>
      </p>
    </td>
    <td width="50%" align="left" valign="top">
      <p>
        De TensorZero Gateway ondersteunt geavanceerde functies zoals:
      </p>
      <ul>
        <ul><li><b><a href="https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks">Retries & Fallbacks</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations">Inference-Time Optimalisaties</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/prompt-templates-schemas">Prompt Templates & Schema's</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/tutorial#experimentation">Experimentatie (A/B Testen)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/configuration-reference">Configuratie-als-Code (GitOps)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/batch-inference">Batch Inferentie</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/multimodal-inference">Multimodale Inferentie (VLM's)</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-caching">Inferentie Caching</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/metrics-feedback">Metrics & Feedback</a></b></li>
        <li><b><a href="https://www.tensorzero.com/docs/gateway/guides/episodes">Multi-Step LLM Workflows (Episodes)</a></b></li>
        <li><em>& veel meer...</em></li>
      </ul></ul>
        De TensorZero Gateway is geschreven in Rust 🦀 met het oog op <b>performance</b> (&lt;1ms p99 latency overhead @ 10k QPS).
        Zie <b><a href="https://www.tensorzero.com/docs/gateway/benchmarks">Benchmarks</a></b>.<br>
      </p>
      <p>
        Je kunt inferentie uitvoeren via de <b>TensorZero client</b> (aanbevolen), de <b>OpenAI client</b> of de <b>HTTP API</b>.
      </p>
    </td>
  </tr>
</table></p><p><br></p><p><details open>
<summary><b>Gebruik: Python &mdash; TensorZero Client (Aanbevolen)</b></summary></p><p>Je hebt toegang tot elke provider via de TensorZero Python-client.</p><ul><li><code>pip install tensorzero</code></li>
<li>Optioneel: Stel de TensorZero-configuratie in.</li>
<li>Voer inferentie uit:</li></p><p></ul><pre><code class="language-python">from tensorzero import TensorZeroGateway  # of AsyncTensorZeroGateway</p><p>
with TensorZeroGateway.build_embedded(clickhouse_url="...", config_file="...") as client:
    response = client.inference(
        model_name="openai::gpt-4o-mini",
        # Probeer eenvoudig andere providers: "anthropic::claude-3-7-sonnet-20250219"
        input={
            "messages": [
                {
                    "role": "user",
                    "content": "Schrijf een haiku over kunstmatige intelligentie.",
                }
            ]
        },
    )</code></pre></p><p>Zie <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">Snelle Start</a></strong> voor meer informatie.</p><p></details></p><p><details>
<summary><b>Gebruik: Python &mdash; OpenAI Client</b></summary></p><p>Je hebt toegang tot elke provider via de OpenAI Python-client met TensorZero.</p><ul><li><code>pip install tensorzero</code></li>
<li>Optioneel: Stel de TensorZero-configuratie in.</li>
<li>Voer inferentie uit:</li></p><p></ul><pre><code class="language-python">from openai import OpenAI  # of AsyncOpenAI
from tensorzero import patch_openai_client</p><p>client = OpenAI()
patch_openai_client(
    client,
    clickhouse_url="http://chuser:chpassword@localhost:8123/tensorzero",
    config_file="config/tensorzero.toml",
    async_setup=False,
)</p><p>response = client.chat.completions.create(
    model="tensorzero::model_name::openai::gpt-4o-mini",
    # Probeer eenvoudig andere providers: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
    messages=[
        {
            "role": "user",
            "content": "Schrijf een haiku over kunstmatige intelligentie.",
        }
    ],
)</code></pre></p><p>Zie <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">Snelstart</a></strong> voor meer informatie.</p><p></details></p><p><details>
<summary><b>Gebruik: JavaScript / TypeScript (Node) &mdash; OpenAI Client</b></summary></p><p>Je kunt elke provider benaderen met de OpenAI Node client via TensorZero.</p><ul><li>Deploy <code>tensorzero/gateway</code> met Docker.</li>
   </ul><strong><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank" rel="noopener noreferrer">Gedetailleerde instructies →</a></strong>
<ul><li>Stel de TensorZero-configuratie in.</li>
<li>Voer inference uit:</li></p><p></ul><pre><code class="language-ts">import OpenAI from "openai";</p><p>const client = new OpenAI({
  baseURL: "http://localhost:3000/openai/v1",
});</p><p>const response = await client.chat.completions.create({
  model: "tensorzero::model_name::openai::gpt-4o-mini",
  // Probeer eenvoudig andere providers: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
  messages: [
    {
      role: "user",
      content: "Schrijf een haiku over kunstmatige intelligentie.",
    },
  ],
});</code></pre></p><p>Zie <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">Snelstart</a></strong> voor meer informatie.</p><p></details></p><p><details>
<summary><b>Gebruik: Andere Talen & Platformen &mdash; HTTP API</b></summary></p><p>TensorZero ondersteunt vrijwel elke programmeertaal of platform via de HTTP API.</p><ul><li>Deploy <code>tensorzero/gateway</code> met Docker.</li>
   </ul><strong><a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank" rel="noopener noreferrer">Gedetailleerde instructies →</a></strong>
<ul><li>Optioneel: Stel de TensorZero-configuratie in.</li>
<li>Voer inference uit:</li></p><p></ul><pre><code class="language-bash">curl -X POST "http://localhost:3000/inference" \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "openai::gpt-4o-mini",
    "input": {
      "messages": [
        {
          "role": "user",
          "content": "Schrijf een haiku over kunstmatige intelligentie."
        }
      ]
    }
  }'</code></pre></p><p>Zie <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">Snelstart</a></strong> voor meer informatie.</p><p></details></p><p><br></p><h3>📈 LLM-optimalisatie</h3></p><blockquote><strong>Stuur productiemetingen en menselijke feedback om eenvoudig je prompts, modellen en inferentiestrategieën te optimaliseren &mdash; via de UI of programmeerbaar.</strong></blockquote></p><p>#### Modeloptimalisatie</p><p>Optimaliseer gesloten en open-source modellen met behulp van supervised fine-tuning (SFT) en preference fine-tuning (DPO).</p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Supervised Fine-tuning &mdash; UI</b></td>
    <td width="50%" align="center" valign="middle"><b>Preference Fine-tuning (DPO) &mdash; Jupyter Notebook</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/cf7acf66-732b-43b3-af2a-5eba1ce40f6f"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/a67a0634-04a7-42b0-b934-9130cb7cdf51"></td>
  </tr>
</table></p><p>#### Inference-tijd Optimalisatie</p><p>Verhoog de prestaties door je prompts dynamisch te updaten met relevante voorbeelden, reacties van meerdere inferenties te combineren, en meer.</p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling">Best-of-N Sampling</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#mixture-of-n-sampling">Mixture-of-N Sampling</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/c0edfa4c-713c-4996-9964-50c0d26e6970"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/75b5bf05-4c1f-43c4-b158-d69d1b8d05be"></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl">Dynamic In-Context Learning (DICL)</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#chain-of-thought-cot">Chain-of-Thought (CoT)</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/d8489e92-ce93-46ac-9aab-289ce19bb67d"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/ea13d73c-76a4-4e0c-a35b-0c648f898311" height="320"></td>
  </tr>
</table></p><p>_Meer binnenkort..._</p><p><br></p><p>#### Promptoptimalisatie</p><p>Optimaliseer je prompts programmeerbaar met onderzoeksgedreven optimalisatietechnieken.</p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling">MIPROv2</a></b></td>
    <td width="50%" align="center" valign="middle"><b><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy">DSPy-integratie</a></b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/d81a7c37-382f-4c46-840f-e6c2593301db" alt="MIPROv2 diagram"></td>
    <td width="50%" align="center" valign="middle">
      TensorZero wordt geleverd met verschillende optimalisatierecepten, maar je kunt ook eenvoudig je eigen maken.
      Dit voorbeeld toont hoe je een TensorZero-functie optimaliseert met een willekeurig hulpmiddel — hier DSPy, een populaire bibliotheek voor geautomatiseerde prompt engineering.
    </td>
  </tr>
</table></p><p>_Meer binnenkort..._</p><p><br></p><h3>🔍 LLM Observability</h3></p><blockquote><strong>Zoom in om individuele API-calls te debuggen, of zoom uit om metrieken over modellen en prompts in de tijd te monitoren &mdash; allemaal met de open-source TensorZero UI.</strong></blockquote></p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Observability » Inference</b></td>
    <td width="50%" align="center" valign="middle"><b>Observability » Functie</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/2cc3cc9a-f33f-4e94-b8de-07522326f80a"></td>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/00ae6605-8fa0-4efd-8238-ae8ea589860f"></td>
  </tr>
</table></p><p><br></p><h3>📊 LLM Evaluaties</h3></p><blockquote><strong>Vergelijk prompts, modellen en inferentiestrategieën met TensorZero Evaluaties &mdash; met ondersteuning voor heuristieken en LLM-jury’s.</strong></blockquote></p><p><table>
  <tr></tr> <!-- flip highlight order -->
  <tr>
    <td width="50%" align="center" valign="middle"><b>Evaluatie » UI</b></td>
    <td width="50%" align="center" valign="middle"><b>Evaluatie » CLI</b></td>
  </tr>
  <tr>
    <td width="50%" align="center" valign="middle"><img src="https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699"></td>
    <td width="50%" align="left" valign="middle">
<pre><code class="language-bash">docker compose run --rm evaluations \
  --evaluation-name extract_data \
  --dataset-name hard_test_cases \
  --variant-name gpt_4o \
  --concurrency 5</code></pre>
<pre><code class="language-bash">Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4
Aantal datapunten: 100
██████████████████████████████████████ 100/100
exact_match: 0.83 ± 0.03
semantic_match: 0,98 ± 0,01  
item_count: 7,15 ± 0,39</code></pre>
    </td>
  </tr>
</table></p><h2>Demo</h2></p><blockquote><strong>Bekijk hoe LLM's in realtime beter worden in data-extractie met TensorZero!</strong></blockquote>
>
<blockquote><strong><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl" target="_blank" rel="noopener noreferrer">Dynamisch in-context leren (DICL)</a></strong> is een krachtige optimalisatie tijdens inferentie, standaard beschikbaar met TensorZero.</blockquote>
<blockquote>Het verbetert de LLM-prestaties door automatisch relevante historische voorbeelden aan de prompt toe te voegen, zonder dat model-finetuning nodig is.</blockquote></p><p>https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb</p><h2>LLM Engineering met TensorZero</h2></p><p><br>
<p align="center" >
  <a href="https://www.tensorzero.com/docs">
    <picture>
      <source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6">
      <source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/e8bc699b-6378-4c2a-9cc1-6d189025e270">
      <img alt="TensorZero Flywheel" src="https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6" width=720>
    </picture>
  </a>
</p>
<br></p><ul><li>De <strong><a href="https://www.tensorzero.com/docs/gateway/" target="_blank" rel="noopener noreferrer">TensorZero Gateway</a></strong> is een high-performance modelgateway geschreven in Rust 🦀 die een uniforme API-interface biedt voor alle grote LLM-aanbieders, waardoor naadloze cross-platform integratie en fallbacks mogelijk zijn.</li>
<li>Het handelt gestructureerde schema-gebaseerde inferentie af met &lt;1ms P99 latency overhead (zie <strong><a href="https://www.tensorzero.com/docs/gateway/benchmarks" target="_blank" rel="noopener noreferrer">Benchmarks</a></strong>) en ingebouwde observability, experimentatie, en <strong><a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations" target="_blank" rel="noopener noreferrer">optimalisaties tijdens inferentie</a></strong>.</li>
<li>Het verzamelt ook downstream-metrics en feedback die gekoppeld zijn aan deze inferenties, met eersteklas ondersteuning voor multi-step LLM-systemen.</li>
<li>Alles wordt opgeslagen in een ClickHouse datawarehouse dat je zelf beheert, voor realtime, schaalbare en ontwikkelaarsvriendelijke analytics.</li>
<li>Na verloop van tijd gebruiken <strong><a href="https://www.tensorzero.com/docs/recipes" target="_blank" rel="noopener noreferrer">TensorZero Recipes</a></strong> deze gestructureerde dataset om je prompts en modellen te optimaliseren: voer kant-en-klare recepten uit voor veelvoorkomende workflows zoals fine-tuning, of maak je eigen recepten met volledige flexibiliteit in elke taal en elk platform.</li>
<li>Tot slot maken de experimenteerfuncties van de gateway en GitOps-orchestratie het mogelijk om met vertrouwen te itereren en uit te rollen, of het nu om één LLM of duizenden LLM's gaat.</li></p><p></ul>Ons doel is om engineers te helpen bij het bouwen, beheren en optimaliseren van de volgende generatie LLM-toepassingen: systemen die leren van echte ervaringen.
Lees meer over onze <strong><a href="https://www.tensorzero.com/docs/vision-roadmap/" target="_blank" rel="noopener noreferrer">Visie & Roadmap</a></strong>.</p><h2>Aan de slag</h2></p><p><strong>Begin vandaag nog met bouwen.</strong>  
De <strong><a href="https://www.tensorzero.com/docs/quickstart" target="_blank" rel="noopener noreferrer">Quick Start</a></strong> laat zien hoe eenvoudig het is om een LLM-toepassing op te zetten met TensorZero.  
Wil je dieper duiken? De <strong><a href="https://www.tensorzero.com/docs/gateway/tutorial" target="_blank" rel="noopener noreferrer">Tutorial</a></strong> leert je hoe je een eenvoudige chatbot, een e-mail copilot, een weer-RAG-systeem en een pipeline voor gestructureerde data-extractie bouwt.</p><p><strong>Vragen?</strong>  
Stel ze op <strong><a href="https://www.tensorzero.com/slack" target="_blank" rel="noopener noreferrer">Slack</a></strong> of <strong><a href="https://www.tensorzero.com/discord" target="_blank" rel="noopener noreferrer">Discord</a></strong>.</p><p><strong>Gebruik je TensorZero op het werk?</strong>  
Mail ons op <strong><a href="mailto:hello@tensorzero.com" target="_blank" rel="noopener noreferrer">hello@tensorzero.com</a></strong> om gratis een Slack- of Teams-kanaal met je team op te zetten.</p><p><strong>Werk met ons samen.</strong>  
We zijn <strong><a href="https://www.tensorzero.com/jobs" target="_blank" rel="noopener noreferrer">op zoek naar mensen in NYC</a></strong>.  
We verwelkomen ook graag <strong><a href="https://github.com/tensorzero/tensorzero/blob/main/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">open-source bijdragen</a></strong>!</p><h2>Voorbeelden</h2></p><p>We werken aan een reeks <strong>volledige uitvoerbare voorbeelden</strong> die TensorZero's data- & leerflywheel illustreren.</p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/data-extraction-ner" target="_blank" rel="noopener noreferrer">Data-extractie optimaliseren (NER) met TensorZero</a></strong></blockquote>
>
<blockquote>Dit voorbeeld laat zien hoe je TensorZero gebruikt om een data-extractiepijplijn te optimaliseren.</blockquote>
<blockquote>We demonstreren technieken zoals fine-tuning en dynamisch in-context leren (DICL).</blockquote>
<blockquote>Uiteindelijk presteert een geoptimaliseerd GPT-4o Mini-model beter dan GPT-4o op deze taak &mdash; tegen een fractie van de kosten en latency &mdash; met een kleine hoeveelheid trainingsdata.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/rag-retrieval-augmented-generation/simple-agentic-rag/" target="_blank" rel="noopener noreferrer">Agentic RAG — Multi-Hop Vraagbeantwoording met LLM's</a></strong></blockquote>
>
<blockquote>Dit voorbeeld laat zien hoe je een multi-hop retrieval agent bouwt met TensorZero.</blockquote>
<blockquote>De agent zoekt iteratief op Wikipedia om informatie te verzamelen, en beslist wanneer er genoeg context is om een complexe vraag te beantwoorden.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences" target="_blank" rel="noopener noreferrer">Haiku's schrijven om een rechter met verborgen voorkeuren tevreden te stellen</a></strong></blockquote>
>
<blockquote>In dit voorbeeld wordt GPT-4o Mini fijn afgestemd om haiku's te genereren die zijn afgestemd op een specifieke smaak.</blockquote>
<blockquote>Je ziet TensorZero's "data flywheel in a box" in actie: betere varianten leiden tot betere data, en betere data leiden tot betere varianten.</blockquote>
<blockquote>Je ziet vooruitgang door de LLM meerdere keren te fine-tunen.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles/" target="_blank" rel="noopener noreferrer">LLM Schaakkwaliteit verbeteren met Best-of-N Sampling</a></strong></blockquote>
>
<blockquote>Dit voorbeeld laat zien hoe best-of-N sampling de schaakkwaliteiten van een LLM aanzienlijk kan verbeteren door de meest veelbelovende zetten uit meerdere gegenereerde opties te selecteren.</blockquote></p><blockquote><strong><a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy" target="_blank" rel="noopener noreferrer">Wiskundig redeneren verbeteren met een Custom Recipe voor geautomatiseerde prompt engineering (DSPy)</a></strong></blockquote>
>
<blockquote>TensorZero biedt een aantal kant-en-klare optimalisatierecepten voor veelvoorkomende LLM engineering workflows.</blockquote>
<blockquote>Maar je kunt ook eenvoudig je eigen recepten en workflows maken!</blockquote>
<blockquote>Dit voorbeeld toont hoe je een TensorZero-functie optimaliseert met een willekeurige tool — hier, DSPy.</blockquote></p><p>_& nog veel meer in de maak!_

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/tensorzero/tensorzero/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>