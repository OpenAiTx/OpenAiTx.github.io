<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AutoDefense - AutoDefense : D&#233;fense Multi-Agent LLM contre les attaques de jailbreak</title>
    <meta name="description" content="AutoDefense : D&#233;fense Multi-Agent LLM contre les attaques de jailbreak">
    <meta name="keywords" content="AutoDefense, French, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "AutoDefense",
  "description": "AutoDefense : Défense Multi-Agent LLM contre les attaques de jailbreak",
  "author": {
    "@type": "Person",
    "name": "XHMY"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 65
  },
  "url": "https://OpenAiTx.github.io/projects/XHMY/AutoDefense/README-fr.html",
  "sameAs": "https://raw.githubusercontent.com/XHMY/AutoDefense/main/README.md",
  "datePublished": "2026-02-04",
  "dateModified": "2026-02-04"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/XHMY/AutoDefense" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    AutoDefense
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 65 stars</span>
                <span class="language">French</span>
                <span>by XHMY</span>
            </div>
        </div>
        
        <div class="content">
            <h1>AutoDefense : Défense Multi-Agent LLM contre les attaques de jailbreak</h1></p><p><a href="https://microsoft.github.io/autogen/0.2/blog/2024/03/11/AutoDefense/Defending%20LLMs%20Against%20Jailbreak%20Attacks%20with%20AutoDefense/" target="_blank" rel="noopener noreferrer"><strong>Blog</strong></a></p><h2>Installation</h2></p><pre><code class="language-bash">pip install vllm autogen pandas retry openai</code></pre></p><h2>Préparer le Service d'Inférence en Utilisant <a href="https://docs.vllm.ai/" target="_blank" rel="noopener noreferrer">vLLM</a></h2></p><p>vLLM fournit un serveur API compatible OpenAI avec une inférence efficace et un équilibrage de charge intégré sur plusieurs GPU.</p><h3>Démarrer le Serveur vLLM</h3></p><p>Démarrez le serveur vLLM avec le modèle de votre choix. Pour les configurations multi-GPU, utilisez <code>--data-parallel-size</code> pour activer l'équilibrage automatique de la charge :</p><p><strong>GPU Unique :</strong>
<pre><code class="language-bash">vllm serve Qwen/Qwen3-1.7B --port 8000</code></pre></p><p><strong>Plusieurs GPU (par exemple, 2 GPU avec parallélisme de données) :</strong>
<pre><code class="language-bash">vllm serve Qwen/Qwen3-1.7B --port 8000 --data-parallel-size 2</code></pre>
<strong>Avec le parallélisme tensoriel pour les modèles plus grands :</strong></p><pre><code class="language-bash">vllm serve <your-large-model> --port 8000 --tensor-parallel-size 4</code></pre></p><p><strong>Parallélisme tensoriel et parallélisme de données combinés (8 GPU, TP 2 voies × DP 4 voies) :</strong>
<pre><code class="language-bash">vllm serve <your-large-model> --port 8000 --tensor-parallel-size 2 --data-parallel-size 4</code></pre></p><p>Pour plus de détails sur le déploiement en parallèle des données avec équilibrage de charge interne, voir la <a href="https://docs.vllm.ai/en/latest/serving/data_parallel_deployment/" target="_blank" rel="noopener noreferrer">documentation vLLM</a>.</p><h3>Vérifier le serveur</h3></p><p>Vous pouvez vérifier que le serveur fonctionne en consultant le point de terminaison des modèles :</p><pre><code class="language-bash">curl http://localhost:8000/v1/models</code></pre></p><h2>Génération de réponses</h2></p><p>Les réponses sont générées par le modèle cible servi par vLLM (par défaut : <code>Qwen/Qwen3-1.7B</code>). Assurez-vous que votre serveur vLLM est en fonctionnement avant d'exécuter la commande suivante.</p><h3>Invites d'attaque (nuisibles)</h3></p><pre><code class="language-bash">python attack/attack.py --model Qwen/Qwen3-1.7B --host 127.0.0.1 --port 8000</code></pre></p><p>Cette commande générera des réponses en utilisant un modèle d’invite d’attaque (par défaut : <code>--template v1</code>) chargé depuis <code>data/prompt/attack_prompt_template.json</code>.  
Pour exécuter plusieurs répétitions, lancez le script plusieurs fois en variant <code>--output-suffix</code> et/ou <code>--cache-seed</code>.  </p><h3>Invites sûres (Bénignes)  </h3></p><p>Pour générer des réponses pour des invites sûres/bénignes (utilisées pour l’évaluation des faux positifs) :</p><pre><code class="language-bash">python attack/attack.py \
    --model Qwen/Qwen3-1.7B \
    --template placeholder \
    --prompts data/prompt/safe_prompts.json \
    --output-prefix safe</code></pre></p><p>Le modèle <code>placeholder</code> transmet les invites sans aucune mise en cadre d'attaque, tandis que <code>v1</code> enveloppe les invites avec des instructions de contournement.</p><h2>Exécuter des expériences de défense</h2></p><p>La commande suivante exécute les expériences de défense avec 1 agent, 2 agents et 3 agents. Le paramètre <code>--chat-file</code> doit pointer vers les sorties nuisibles générées par <code>attack/attack.py</code> (par défaut sauvegardées sous <code>data/harmful_output/<model_dir>/</code>, par exemple <code>data/harmful_output/Qwen-Qwen3-1.7B/attack-dan_0.json</code>).</p><pre><code class="language-bash">export AUTOGEN_USE_DOCKER=0</p><p>python defense/run_defense_exp.py \
  --model Qwen/Qwen3-1.7B \
  --chat-file data/harmful_output/Qwen-Qwen3-1.7B/attack-dan_0.json</code></pre></p><h3>Arguments en ligne de commande</h3></p><p>| Argument | Description | Par défaut |
|----------|-------------|------------|
| <code>--model</code> | Modèle cible servi par vLLM | <code>Qwen/Qwen3-1.7B</code> |
| <code>--chat-file</code> | Chemin vers le fichier de chat avec sorties nuisibles | Requis |
| <code>--port</code> | Port où le serveur vLLM fonctionne | <code>8000</code> |
| <code>--host</code> | Nom d'hôte du serveur vLLM | <code>127.0.0.1</code> |
| <code>--output-dir</code> | Répertoire de sortie | <code>data/defense_output/<model_dir></code> |
| <code>--output-suffix</code> | Suffixe pour le répertoire de sortie | <code>""</code> |
| <code>--strategies</code> | Stratégies de défense à exécuter | <code>ex-2 ex-3 ex-cot</code> |
| <code>--workers</code> | Nombre de travailleurs parallèles | <code>128</code> |
| <code>--frequency_penalty</code> | Pénalité de fréquence pour la génération | <code>0.0</code> |
| <code>--presence_penalty</code> | Pénalité de présence pour la génération | <code>0.0</code> |
| <code>--temperature</code> | Température pour la génération | <code>0.7</code> |</p><p>Après avoir terminé l'expérience de défense, la sortie apparaîtra dans <code>data/defense_output/<model_dir>/</code> (par exemple <code>data/defense_output/Qwen-Qwen3-1.7B/</code>).</p><h2>Évaluation GPT (l’article utilise GPT-4)</h2></p><p>Évaluation de la défense contre les sorties nuisibles :</p><pre><code class="language-bash">python evaluator/gpt4_evaluator.py \
--defense_output_dir data/defense_output/Qwen-Qwen3-1.7B \
--ori_prompt_file_name prompt_dan.json</code></pre></p><p>Après avoir terminé l’évaluation, le résultat apparaîtra dans <code>data/defense_output/Qwen-Qwen3-1.7B/asr.csv</code>.  
Il y aura également une valeur <code>score</code> apparaissant pour chaque sortie de défense dans le fichier <code>json</code> de sortie.  
<code>evaluator/gpt4_evaluator.py</code> utilise un modèle GPT comme évaluateur (l’article original utilise GPT-4).  
Configurez vos identifiants OpenAI via des variables d’environnement (ou des options CLI), et vous pouvez remplacer l’évaluateur par un modèle GPT plus récent (par exemple, GPT-5) via <code>--model</code>.  </p><pre><code class="language-bash">export OPENAI_API_KEY=...
<h1>optional (only if you use an OpenAI-compatible endpoint):</h1>
<h1>export OPENAI_BASE_URL=...</h1></p><p>python evaluator/gpt4_evaluator.py \
  --defense_output_dir data/defense_output/Qwen-Qwen3-1.7B \
  --ori_prompt_file_name prompt_dan.json \
  --model gpt-4-1106-preview</code></pre></p><p>L’évaluation basée sur GPT peut être coûteuse ; nous activons la mise en cache pour éviter les évaluations répétées.</p><p>Pour une évaluation sûre des réponses, il existe une méthode efficace sans utiliser GPT-4. Si vous savez que toutes les invites de votre ensemble de données sont des invites utilisateur régulières et ne doivent pas être rejetées, vous pouvez utiliser la commande suivante pour évaluer le taux de faux positifs (FPR) de la sortie de la défense.</p><pre><code class="language-bash">python evaluator/evaluate_safe.py</code></pre></p><p>Cela trouvera tous les dossiers de sortie dans <code>data/defense_output</code> contenant le mot-clé <code>-safe</code> et évaluera le taux de faux positifs (FPR).  
Le FPR sera enregistré dans le fichier <code>data/defense_output/defense_fp.csv</code>.</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-02-04

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/XHMY/AutoDefense/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-02-04 
    </div>
    
</body>
</html>