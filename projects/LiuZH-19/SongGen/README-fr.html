<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SongGen - [ICML 2025] SongGen : Un transformeur auto-r&#233;gressif &#224; &#233;tape unique pour la g&#233;n&#233;ration de chansons &#224; partir de texte</title>
    <meta name="description" content="[ICML 2025] SongGen : Un transformeur auto-r&#233;gressif &#224; &#233;tape unique pour la g&#233;n&#233;ration de chansons &#224; partir de texte">
    <meta name="keywords" content="SongGen, French, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "SongGen",
  "description": "[ICML 2025] SongGen : Un transformeur auto-régressif à étape unique pour la génération de chansons à partir de texte",
  "author": {
    "@type": "Person",
    "name": "LiuZH-19"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 251
  },
  "url": "https://OpenAiTx.github.io/projects/LiuZH-19/SongGen/README-fr.html",
  "sameAs": "https://raw.githubusercontent.com/LiuZH-19/SongGen/master/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/LiuZH-19/SongGen" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    SongGen
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 251 stars</span>
                <span class="language">French</span>
                <span>by LiuZH-19</span>
            </div>
        </div>
        
        <div class="content">
            <h1>SongGen : Un transformeur auto-régressif à étape unique pour la génération de chansons à partir de texte</h1></p><p>🚀🚀🚀 Implémentation officielle de <strong>SongGen : Un transformeur auto-régressif à étape unique pour la génération de chansons à partir de texte</strong>
<p align="center" style="font-size: 1 em; margin-top: -1em">
<a href="https://scholar.google.com/citations?user=iELd-Q0AAAAJ">Zihan Liu</a>,  
<a href="https://mark12ding.github.io/">Shuangrui Ding</a>,  
<a href="https://github.com/rookiexiong7/">Zhixiong Zhang</a>, 
<a href="https://lightdxy.github.io/">Xiaoyi Dong</a>,  
<a href="https://panzhang0212.github.io/">Pan Zhang</a>,
<a href="https://yuhangzang.github.io/">Yuhang Zang</a>,  
<a href="https://scholar.google.com/citations?user=sJkqsqkAAAAJ">Yuhang Cao</a>, </br>  
<a href="http://dahua.site/">Dahua Lin</a>,  
<a href="https://myownskyw7.github.io/">Jiaqi Wang</a> 
</p></p><p><p align="center" style="font-size: 5 em; margin-top: 0.5em">
<a href="https://arxiv.org/abs/2502.13128"><img src="https://img.shields.io/badge/arXiv-<color>"></a>
<a href="https://github.com/LiuZH-19/SongGen"><img src="https://img.shields.io/badge/Code-red"></a>
<a href="https://liuzh-19.github.io/SongGen/"><img src="https://img.shields.io/badge/Demo-20d67c"></a>
<a href="https://huggingface.co/collections/LiuZH-19/songgen-a-single-stage-auto-regressive-transformer-for-text-6867ec21169d808034f6d252">
    <img src="https://img.shields.io/badge/HF-Collection-yellow"></a>
</p></p><h2>📜 Actualités</h2>
🚀 [2025/7/4] Nous avons publié le code d'entraînement avec un <a href="https://raw.githubusercontent.com/LiuZH-19/SongGen/master/./training/README.md" target="_blank" rel="noopener noreferrer">guide détaillé</a>.</p><p>🚀 [2025/6/30] Le jeu de test MusicCaps est désormais disponible sur <a href="https://huggingface.co/datasets/LiuZH-19/MusicCaps_Test_Song" target="_blank" rel="noopener noreferrer">Huggingface🤗</a> pour l’évaluation texte-à-chanson.</p><p>🚀 [2025/6/27] Nous avons publié le checkpoint de SongGen Interleaving (A-V) sur <a href="https://huggingface.co/LiuZH-19/SongGen_interleaving_A_V" target="_blank" rel="noopener noreferrer">Huggingface🤗</a>.</p><p>🎉 [2025/5/1] SongGen est accepté à ICML 2025 !</p><p>🚀 [2025/3/18] Nous avons publié le checkpoint de SongGen Mixed_Pro sur <a href="https://huggingface.co/LiuZH-19/SongGen_mixed_pro" target="_blank" rel="noopener noreferrer">Huggingface🤗</a>.</p><p>🚀 [2025/2/19] Le <a href="https://arxiv.org/abs/2502.13128" target="_blank" rel="noopener noreferrer">papier</a> et la <a href="https://liuzh-19.github.io/SongGen/" target="_blank" rel="noopener noreferrer">page de démonstration</a> sont publiés !</p><h2>💡 Points forts</h2>
<ul><li>🔥Nous présentons SongGen, un transformeur auto-régressif <strong>à étape unique</strong> pour la génération <strong>texte-à-chanson</strong>, offrant un contrôle polyvalent via les paroles, un texte descriptif, et une voix de référence optionnelle.</li>
<li>🔥SongGen supporte à la fois les modes <strong>mixte</strong> et <strong>double-piste</strong> pour répondre à des besoins divers. Nos expériences fournissent des <strong>insights précieux</strong> pour optimiser les deux modes.</li>
<li>🔥En publiant les <strong>poids du modèle</strong>, le <strong>code</strong>, les <strong>données annotées</strong> et le <strong>pipeline de prétraitement</strong>, nous visons à établir une base simple mais efficace pour les futures recherches en génération de chansons.</li>
</ul><!-- <img align="center" src="https://raw.githubusercontent.com/LiuZH-19/SongGen/master/assets/imgs/motivation1.jpg" style="  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 50%;" /> --></p><h2>👨‍💻 À faire</h2>
<ul><li>[ ] Publier les données annotées et le pipeline de prétraitement</li>
<li>[x] Publier le jeu de test Musiccaps</li>
<li>[x] Publier le code d’entraînement SongGen</li>
<li>[x] Publier le checkpoint SongGen (Interleaving A-V)</li>
<li>[x] Publier le checkpoint SongGen Mixed_pro</li>
<li>[x] Publier le code d’inférence SongGen</li>
<li>[x] Démo SongGen</li></p><p></ul><h2>🛠️ Utilisation</h2></p><h3>1. Installer l’environnement et les dépendances</h3>
<pre><code class="language-bash">git clone https://github.com/LiuZH-19/SongGen.git
cd SongGen
<h1>We recommend using conda to create a new environment.</h1>
conda create -n songgen_env python=3.9.18 
conda activate songgen_env
<h1>Install CUDA >= 11.8 and PyTorch, e.g.,</h1>
pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu118
pip install flash-attn==2.6.1 --no-build-isolation</code></pre>
Pour utiliser SongGen uniquement en mode inférence, installez-le en utilisant :
<pre><code class="language-bash">pip install -e .</code></pre>
<h3>2. Télécharger le xcodec</h3></p><p>Téléchargez le point de contrôle X-Codec depuis <a href="https://raw.githubusercontent.com/LiuZH-19/SongGen/master/
https://huggingface.co/ZhenYe234/xcodec/blob/main/xcodec_hubert_general_audio_v2.pth" target="_blank" rel="noopener noreferrer">🤗</a> et placez-le dans le répertoire suivant : SongGen/songgen/xcodec_wrapper/xcodec_infer/ckpts/general_more</p><pre><code class="language-">xcodec_infer
    ├── ckpts
    │   └── general_more
    │       ├── config_hubert_general.yaml
    │       └── xcodec_hubert_general_audio_v2.pth
</code></pre></p><h3>3. Exécuter l'inférence</h3></p><p>#### (1). Mode Pro Mixte</p><pre><code class="language-python">import torch
import os
from songgen import (
    VoiceBpeTokenizer,
    SongGenMixedForConditionalGeneration,
    SongGenProcessor
)
import soundfile as sf</p><p>ckpt_path = "LiuZH-19/SongGen_mixed_pro" # Path to the pretrained model
device = "cuda:0" if torch.cuda.is_available() else "cpu"
model = SongGenMixedForConditionalGeneration.from_pretrained(
    ckpt_path,
    attn_implementation='sdpa').to(device)
processor = SongGenProcessor(ckpt_path, device)</p><h1>Define input text and lyrics</h1>
lyrics = "..." # The lyrics text
text = "..." # The music description text
ref_voice_path = 'path/to/your/reference_audio.wav' # Path to reference audio, optional
separate= True # Whether to separate the vocal track from the reference voice audio</p><p>model_inputs = processor(text=text, lyrics=lyrics, ref_voice_path=ref_voice_path, separate=separate) 
generation = model.generate(<em></em>model_inputs,
                do_sample=True,
            )
audio_arr = generation.cpu().numpy().squeeze()
sf.write("songgen_out.wav", audio_arr, model.config.sampling_rate)</code></pre></p><p>#### (2). Interleaving A-V  (Dual-track mode)
<pre><code class="language-python">import torch
import os
from songgen import (
    VoiceBpeTokenizer,
    SongGenDualTrackForConditionalGeneration,
    SongGenProcessor
)
import soundfile as sf</p><p>ckpt_path = "LiuZH-19/SongGen_interleaving_A_V" # Path to the pretrained model
device = "cuda:0" if torch.cuda.is_available() else "cpu"
model = SongGenDualTrackForConditionalGeneration.from_pretrained(
    ckpt_path,
    attn_implementation='sdpa').to(device)
processor = SongGenProcessor(ckpt_path, device)</p><h1>Define input text and lyrics</h1>
lyrics = "..." # The lyrics text
text = "..." # The music description text
ref_voice_path = 'path/to/your/reference_audio.wav' # Path to reference audio, optional
separate= True # Whether to separate the vocal track from the reference voice audio</p><p>model_inputs = processor(text=text, lyrics=lyrics, ref_voice_path=ref_voice_path, separate=True) 
generation = model.generate(<em></em>model_inputs,
                do_sample=True,
            )</p><p>acc_array = generation[0].cpu().numpy()
vocal_array = generation[1].cpu().numpy()
min_len =min(vocal_array.shape[0], acc_array.shape[0])
acc_array = acc_array[:min_len]
vocal_array = vocal_array[:min_len]
audio_arr = vocal_array + acc_array
sf.write("songgen_out.wav", audio_arr, model.config.sampling_rate)</code></pre></p><h3>4. Entraînement</h3></p><p>Le <a href="./training" target="_blank" rel="noopener noreferrer">dossier d'entraînement</a> contient toutes les informations pour entraîner ou affiner votre propre modèle SongGen. Consultez le <a href="https://raw.githubusercontent.com/LiuZH-19/SongGen/master/./training/README.md" target="_blank" rel="noopener noreferrer">guide d'entraînement</a> pour des instructions étape par étape.</p><h2>❤️ Remerciements</h2>
Cette bibliothèque s'appuie sur plusieurs géants open-source, auxquels nous souhaitons adresser nos plus chaleureux remerciements pour avoir fourni ces outils !</p><p>Remerciements particuliers à :</p><ul><li><a href="https://github.com/huggingface/parler-tts" target="_blank" rel="noopener noreferrer">Parler-tts</a> : La base de code sur laquelle nous nous sommes appuyés. </li>
<li><a href="https://github.com/zhenye234/xcodec" target="_blank" rel="noopener noreferrer">X-Codec</a> : Le codec audio utilisé dans notre recherche.</li>
<li><a href="https://github.com/seungheondoh/lp-music-caps" target="_blank" rel="noopener noreferrer">lp-music-caps</a> : Un projet visant à générer des légendes pour la musique. </li></p><p></ul>Nous apprécions profondément tout le soutien reçu au cours de cette aventure.</p><h2>☎️ Limites et travaux futurs</h2></p><p>Il s'agit d'un <strong>travail de recherche</strong> axé sur la génération de <strong>texte en chanson</strong>. En raison des limites du jeu de données actuel, notre modèle est actuellement limité à la génération de chansons en anglais d'une durée maximale de 30 secondes.
Cependant, malgré un entraînement sur seulement <strong>2k heures</strong> de données avec un modèle de <strong>1,3 milliard</strong> de paramètres, notre approche a démontré une forte efficacité et un potentiel prometteur pour générer des chansons cohérentes et expressives. Nous croyons que l'augmentation des données et de la taille du modèle améliorera davantage l'alignement des paroles et la musicalité.
Cela dit, l'agrandissement du jeu de données est long et difficile. Nous accueillons volontiers collaborations et discussions pour explorer de nouvelles façons d'améliorer le modèle et d'étendre ses capacités.
Pour toute question ou collaboration potentielle, n'hésitez pas à contacter : Zihan Liu (liuzihan@pjlab.org.cn) et Jiaqi Wang (wangjiaqi@pjlab.org.cn).</p><h2>✒️ Citation</h2>
Si vous trouvez notre travail utile pour votre recherche, merci de considérer mettre une étoile ⭐ et une citation 📝
<pre><code class="language-bibtex">@misc{liu2025songgen,
      title={SongGen: A Single Stage Auto-regressive Transformer for Text-to-Song Generation}, 
      author={Zihan Liu and Shuangrui Ding and Zhixiong Zhang and Xiaoyi Dong and Pan Zhang and Yuhang Zang and Yuhang Cao and Dahua Lin and Jiaqi Wang},
      year={2025},
      eprint={2502.13128},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2502.13128}, 
}
</code></pre></p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-08-07

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/LiuZH-19/SongGen/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>