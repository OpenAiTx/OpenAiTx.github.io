<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ThinkSound - [NeurIPS 2025] Triển khai PyTorch của [ThinkSound], một khung thống nhất để tạo &#226;m thanh từ bất kỳ dạng dữ liệu n&#224;o, được dẫn dắt bởi phương ph&#225;p suy luận Chain-of-Thought (CoT).</title>
    <meta name="description" content="[NeurIPS 2025] Triển khai PyTorch của [ThinkSound], một khung thống nhất để tạo &#226;m thanh từ bất kỳ dạng dữ liệu n&#224;o, được dẫn dắt bởi phương ph&#225;p suy luận Chain-of-Thought (CoT).">
    <meta name="keywords" content="ThinkSound, Vietnamese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ThinkSound",
  "description": "[NeurIPS 2025] Triển khai PyTorch của [ThinkSound], một khung thống nhất để tạo âm thanh từ bất kỳ dạng dữ liệu nào, được dẫn dắt bởi phương pháp suy luận Chain-of-Thought (CoT).",
  "author": {
    "@type": "Person",
    "name": "FunAudioLLM"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 1043
  },
  "url": "https://OpenAiTx.github.io/projects/FunAudioLLM/ThinkSound/README-vi.html",
  "sameAs": "https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/README.md",
  "datePublished": "2025-10-04",
  "dateModified": "2025-10-04"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/FunAudioLLM/ThinkSound" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    ThinkSound
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 1043 stars</span>
                <span class="language">Vietnamese</span>
                <span>by FunAudioLLM</span>
            </div>
        </div>
        
        <div class="content">
            <p><h1 align="center">ThinkSound</h1></p><p><p align="center">
  🌐
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=en">English</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-CN">简体中文</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=zh-TW">繁體中文</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=es">Español</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=fr">Français</a> |
  <a href="https://openaitx.github.io/view.html?user=FunAudioLLM&project=ThinkSound&lang=ja">日本語</a>
  
</p>
<p align="center">
  <img src="https://img.shields.io/badge/NeurIPS 2025-Main Conference-blue.svg" alt="NeurIPS 2025"/>
<p align="center">
  <a href="https://arxiv.org/pdf/2506.21448">
    <img src="https://img.shields.io/badge/arXiv-2506.21448-b31b1b.svg" alt="arXiv"/>
  </a>
  &nbsp;
  <a href="https://thinksound-project.github.io/">
    <img src="https://img.shields.io/badge/Online%20Demo-🌐-blue" alt="Online Demo"/>
  </a>
  &nbsp;
  <a href="https://huggingface.co/spaces/FunAudioLLM/ThinkSound">
    <img src="https://img.shields.io/badge/HuggingFace-Spaces-orange?logo=huggingface" alt="Hugging Face"/>
  </a>
  &nbsp;
  <a href="https://modelscope.cn/studios/iic/ThinkSound">
    <img src="https://img.shields.io/badge/ModelScope-在线体验-green" alt="ModelScope"/>
  </a>
</p></p><p><p align="center">
  Nếu bạn thấy dự án này hữu ích,<br>
  hãy tặng một sao ⭐ trên GitHub để ủng hộ!
</p></p><hr></p><p><strong>ThinkSound</strong> là một khung tạo Any2Audio thống nhất với phương pháp ghép luồng được hướng dẫn bởi lý luận Chuỗi-Suy-Nghĩ (CoT).</p><p>Triển khai PyTorch cho tạo và chỉnh sửa âm thanh đa phương thức: tạo hoặc chỉnh sửa âm thanh từ video, văn bản và âm thanh, được hỗ trợ bởi suy luận từng bước từ các Mô hình Ngôn ngữ Lớn Đa phương thức (MLLMs).</p><p><img src="https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig1_teaser.png" alt="Teaser">
<hr></p><h2>📰 Tin tức</h2>
<ul><li><strong>2025.09.19</strong> &nbsp; 🎉 ThinkSound đã được chấp nhận tại <strong>Hội nghị chính NeurIPS 2025</strong>!</li>
<li><strong>2025.09.01</strong> &nbsp; 🔥 Bộ dữ liệu AudioCoT của chúng tôi hiện đã mã nguồn mở và có sẵn trên <a href="https://huggingface.co/datasets/liuhuadai/AudioCoT" target="_blank" rel="noopener noreferrer">Hugging Face</a>!</li>
<li><strong>2025.07.17</strong> &nbsp; 🧠 Đã kích hoạt finetuning: mã huấn luyện và tinh chỉnh hiện đã công khai, kèm hướng dẫn sử dụng rõ ràng để bạn tùy chỉnh và mở rộng ThinkSound với dữ liệu của riêng mình.</li>
<li><strong>2025.07.15</strong> &nbsp; 📦 Cài đặt và sử dụng đơn giản: phụ thuộc đã có trên PyPI để thiết lập đa nền tảng dễ dàng; script Windows <code>.bat</code> tự động tạo môi trường và chạy script.</li>
<li><strong>2025.07.08</strong> &nbsp;  🔧 Cập nhật lớn: mô hình nhẹ hơn và tối ưu hóa bộ nhớ cùng GPU, hiện hỗ trợ tạo âm thanh hiệu suất cao với quy mô lớn!</li>
<li><strong>2025.07.01</strong> &nbsp; 🔥Demo trực tuyến trên <a href="https://huggingface.co/spaces/FunAudioLLM/ThinkSound" target="_blank" rel="noopener noreferrer">Hugging Face Spaces</a> và <a href="https://modelscope.cn/studios/iic/ThinkSound" target="_blank" rel="noopener noreferrer">ModelScope</a> cho trải nghiệm tương tác!</li>
<li><strong>2025.07.01</strong> &nbsp; 🔥Đã phát hành script suy luận và giao diện web;</li>
<li><strong>2025.06</strong> &nbsp; 🔥<a href="https://arxiv.org/pdf/2506.21448" target="_blank" rel="noopener noreferrer">Bài báo ThinkSound</a> đã phát hành trên arXiv!</li>
<li><strong>2025.06</strong> &nbsp; 🔥<a href="http://thinksound-project.github.io/" target="_blank" rel="noopener noreferrer">Demo trực tuyến</a> đã hoạt động - hãy thử ngay!</li></p><p></ul>---</p><h2>🚀 Tính năng</h2></p><ul><li><strong>Any2Audio</strong>: Tạo âm thanh từ bất kỳ phương thức nào — video, văn bản, âm thanh hoặc kết hợp của chúng.</li>
<li><strong>Video-to-Audio SOTA</strong>: Đạt kết quả hàng đầu trên nhiều bộ đánh giá V2A.</li>
<li><strong>Suy luận dựa trên CoT</strong>: Suy luận chuỗi tư duy cho tạo âm thanh có tính thành phần và kiểm soát qua MLLMs.</li>
<li><strong>Chỉnh sửa tập trung vào đối tượng tương tác</strong>: Tinh chỉnh hoặc chỉnh sửa sự kiện âm thanh cụ thể bằng cách nhấp vào đối tượng hình ảnh hoặc sử dụng hướng dẫn văn bản.</li>
<li><strong>Khung hợp nhất</strong>: Một mô hình nền tảng duy nhất hỗ trợ tạo, chỉnh sửa và quy trình tương tác.</li></p><p></ul>---</p><h2>✨ Tổng quan phương pháp</h2></p><p>ThinkSound phân tách quá trình tạo và chỉnh sửa âm thanh thành ba giai đoạn tương tác, tất cả đều được hướng dẫn bởi suy luận Chuỗi Tư Duy (CoT) dựa trên MLLM:</p><ul><li><strong>Tạo Foley:</strong> Tạo nền âm thanh cơ bản, phù hợp ngữ nghĩa và thời gian từ video.</li>
<li><strong>Tinh chỉnh tập trung vào đối tượng:</strong> Tinh chỉnh hoặc thêm âm thanh cho đối tượng do người dùng chỉ định thông qua nhấp chuột hoặc vùng trên video.</li>
<li><strong>Chỉnh sửa âm thanh mục tiêu:</strong> Chỉnh sửa âm thanh đã tạo bằng hướng dẫn ngôn ngữ tự nhiên cấp cao.</li></p><p></ul><img src="https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig3_model.png" alt="ThinkSound Overview">
<!-- Một bộ dữ liệu chú thích CoT quy mô lớn (<strong>AudioCoT</strong>) được sử dụng để huấn luyện cả module suy luận và mô hình âm thanh nền tảng hợp nhất.
<img src="https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/assets/figs/fig2_dataset.png" alt="AudioCoT Pipeline"> --></p><hr></p><h2>⚡ Bắt đầu nhanh</h2></p><p><strong>Chuẩn bị môi trường:</strong>
<pre><code class="language-bash">git clone https://github.com/liuhuadai/ThinkSound.git
cd ThinkSound
conda create -n thinksound python=3.10
conda activate thinksound
pip install thinksound
conda install -y -c conda-forge 'ffmpeg<7'
<h1>Download pretrained weights https://huggingface.co/liuhuadai/ThinkSound to Directory ckpts/</h1>
<h1>model weights can be also downloaded from https://www.modelscope.cn/models/iic/ThinkSound</h1>
git lfs install
git clone https://huggingface.co/liuhuadai/ThinkSound ckpts
<h1>To improve inference and training speed, you may optionally install a FlashAttention backend compatible with your system and PyTorch version.</code></pre></h1>
<blockquote>✅ <strong>Mẹo cho Windows:</strong>  </blockquote>
<blockquote>Người dùng Windows chỉ cần chạy <code>setup_windows.bat</code> (hoặc nhấp đúp vào nó) để tự động tạo môi trường conda, cài đặt tất cả các phụ thuộc (bao gồm cả FFmpeg), và tải về mô hình đã huấn luyện — không cần thiết lập thủ công.  </blockquote>
<blockquote>Hãy đảm bảo rằng <code>conda</code> và <code>git</code> đã được cài đặt và có trong PATH hệ thống của bạn trước khi chạy script.</blockquote></p><h3>▶️ Chạy Demo</h3></p><p>#### <strong>Linux/macOS</strong></p><pre><code class="language-bash">chmod +x scripts/demo.sh
./scripts/demo.sh <path-to-your-demo-video> <title> <CoT description> [use-half]</code></pre>
#### <strong>Windows</strong></p><p>Bạn có thể sử dụng tập lệnh <code>.bat</code> được cung cấp thay thế:</p><pre><code class="language-bash">.\scripts\demo.bat <path-to-your-demo-video> <title> <CoT description> [use-half]</code></pre>
<strong>Lưu ý:</strong></p><ul><li><code><path-to-your-demo-video></code>: Đường dẫn đến một video duy nhất</li>
<li><code>[use-half]</code> (tùy chọn): Thêm use-half vào cuối để bật chức năng trích xuất đặc tả với độ chính xác nửa.</li></p><p></ul>---</p><h3>📦 Suy luận theo lô</h3></p><p>#### <strong>Linux/macOS</strong></p><pre><code class="language-bash">chmod +x scripts/eval_batch.sh
./scripts/eval_batch.sh <video_path> <csv_path> <save_path (optional)> [use-half]</code></pre>
#### <strong>Windows</strong></p><p>Sử dụng script <code>.bat</code> tương đương:</p><pre><code class="language-bash">.\scripts\eval_batch.bat <video_path> <csv_path> <save_path (optional)> [use-half]</code></pre>
<strong>Lưu ý:</strong></p><ul><li><code><video_path></code>: Đường dẫn đến thư mục gốc chứa tất cả các video .mp4 cần xử lý (tất cả video phải có cùng độ dài).</li>
<li><code><csv_path></code>: Một tệp CSV chứa các lệnh văn bản cho mỗi video (xem <code>demo_test.csv</code> để biết định dạng).</li>
<li><code><save_path></code> (tùy chọn): Nơi lưu trữ tệp âm thanh được tạo ra. Mặc định là <code>results/features</code>.</li>
<li><code>[use-half]</code> (tùy chọn): Thêm use-half ở cuối để bật tính năng trích xuất đặc trưng với độ chính xác nửa.</li></p><p></ul>---</p><h3>Sử Dụng Giao Diện Web</h3></p><p>Để trải nghiệm tương tác, hãy khởi chạy giao diện web Gradio:</p><pre><code class="language-bash">python app.py</code></pre></p><h2>🏋️ Huấn Luyện Mô Hình</h2></p><p>Xem <a href="https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/docs/Training.md" target="_blank" rel="noopener noreferrer"><code>Training.md</code></a></p><hr></p><h2>📝 VIỆC CẦN LÀM & Kế Hoạch Tương Lai</h2>
<ul><li>- [ ] Phát hành mô hình nền tảng mạnh mẽ hơn, bao phủ nhiều lĩnh vực để cung cấp trải nghiệm tạo foley hấp dẫn và sống động hơn</li>
<li>- [ ] Thêm hỗ trợ cho các dạng dữ liệu và tác vụ hạ nguồn bổ sung</li>
<li>- [ ] Phát hành các mô hình ở các quy mô khác nhau</li>
<li>- [x] Mã nguồn mở bộ dữ liệu AudioCoT và quy trình tự động</li>
<li>- [x] Phát hành các script huấn luyện cho các mô hình ThinkSound</li>
<li>- [x] README hướng dẫn nhanh cho người mới dùng Windows</li>
</ul>---</p><h2>📄 Giấy Phép</h2></p><p>Dự án này được phát hành theo Giấy phép Apache 2.0.</p><blockquote><strong>Lưu ý:</strong></blockquote>
<blockquote>Mã nguồn, mô hình và bộ dữ liệu <strong>chỉ dành cho mục đích nghiên cứu và giáo dục</strong>.</blockquote>
<blockquote><strong>Không được phép sử dụng cho mục đích thương mại.</strong></blockquote>
<blockquote>Để xin giấy phép thương mại, vui lòng liên hệ tác giả.</blockquote></p><p><strong>📦 Thành Phần Bên Thứ Ba</strong></p><ul><li><strong>Stable Audio Open VAE</strong> (bởi Stability AI):</li>
  </ul>Kho lưu trữ này bao gồm một VAE đã tinh chỉnh từ <a href="https://huggingface.co/stabilityai/stable-audio-open-1.0/" target="_blank" rel="noopener noreferrer">Stable Audio Open</a>, được cấp phép theo <a href="https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/./third_party/LICENSE_StabilityAI.md" target="_blank" rel="noopener noreferrer">Stability AI Community License</a>.
  <strong>Việc sử dụng thương mại và phân phối lại cần có sự cho phép trước của Stability AI.</strong></p><ul><li>📘 <strong>Tất cả mã nguồn và mô hình còn lại</strong> được phát hành theo Giấy phép Apache 2.0.</li></p><p></ul>---</p><h2>Lời cảm ơn</h2></p><p>Xin cảm ơn đến:</p><ul><li><strong>stable-audio-tools</strong> (bởi Stability AI):</li>
</ul>Đã cung cấp một khung dễ sử dụng cho việc sinh âm thanh, cũng như module VAE và trọng số.
<ul><li><strong>MMAudio</strong>:</li>
  </ul>Đã triển khai backbone MM-DiT trong lĩnh vực âm thanh.</p><hr></p><h2>📖 Trích dẫn</h2></p><p>Nếu bạn thấy ThinkSound hữu ích trong nghiên cứu hoặc công việc của mình, vui lòng trích dẫn bài báo của chúng tôi:</p><pre><code class="language-bibtex">@misc{liu2025thinksoundchainofthoughtreasoningmultimodal,
      title={ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing}, 
      author={Huadai Liu and Jialei Wang and Kaicheng Luo and Wen Wang and Qian Chen and Zhou Zhao and Wei Xue},
      year={2025},
      eprint={2506.21448},
      archivePrefix={arXiv},
      primaryClass={eess.AS},
      url={https://arxiv.org/abs/2506.21448}, 
}</code></pre></p><hr></p><h2>📬 Contact</h2></p><p>
✨ Feel free to <a href="https://github.com/liuhuadai/ThinkSound/issues" target="_blank" rel="noopener noreferrer">open an issue</a> or contact us via email (<a href="https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/mailto:liuhuadai@zju.edu.cn" target="_blank" rel="noopener noreferrer">liuhuadai@zju.edu.cn</a>) if you have any questions or suggestions!</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-10-04

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/FunAudioLLM/ThinkSound/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-10-04 
    </div>
    
</body>
</html>