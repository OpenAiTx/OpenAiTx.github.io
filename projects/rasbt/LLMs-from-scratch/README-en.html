<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLMs-from-scratch - Implement a ChatGPT-like LLM in PyTorch from scratch, step by step</title>
    <meta name="description" content="Implement a ChatGPT-like LLM in PyTorch from scratch, step by step">
    <meta name="keywords" content="LLMs-from-scratch, English, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "LLMs-from-scratch",
  "description": "Implement a ChatGPT-like LLM in PyTorch from scratch, step by step",
  "author": {
    "@type": "Person",
    "name": "rasbt"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 74489
  },
  "url": "https://OpenAiTx.github.io/projects/rasbt/LLMs-from-scratch/README-en.html",
  "sameAs": "https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/README.md",
  "datePublished": "2025-10-05",
  "dateModified": "2025-10-05"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/rasbt/LLMs-from-scratch" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    LLMs-from-scratch
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 74489 stars</span>
                <span class="language">English</span>
                <span>by rasbt</span>
            </div>
        </div>
        
        <div class="content">
            <h1>Build a Large Language Model (From Scratch)</h1></p><p>This repository contains the code for developing, pretraining, and finetuning a GPT-like LLM and is the official code repository for the book <a href="https://amzn.to/4fqvn0D" target="_blank" rel="noopener noreferrer">Build a Large Language Model (From Scratch)</a>.</p><p><br>
<br></p><p><a href="https://amzn.to/4fqvn0D"><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/cover.jpg?123" width="250px"></a></p><p><br></p><p>In <a href="http://mng.bz/orYv" target="_blank" rel="noopener noreferrer"><em>Build a Large Language Model (From Scratch)</em></a>, you'll learn and understand how large language models (LLMs) work from the inside out by coding them from the ground up, step by step. In this book, I'll guide you through creating your own LLM, explaining each stage with clear text, diagrams, and examples.</p><p>The method described in this book for training and developing your own small-but-functional model for educational purposes mirrors the approach used in creating large-scale foundational models such as those behind ChatGPT. In addition, this book includes code for loading the weights of larger pretrained models for finetuning.</p><ul><li>Link to the official <a href="https://github.com/rasbt/LLMs-from-scratch" target="_blank" rel="noopener noreferrer">source code repository</a></li>
<li><a href="http://mng.bz/orYv" target="_blank" rel="noopener noreferrer">Link to the book at Manning (the publisher's website)</a></li>
<li><a href="https://www.amazon.com/gp/product/1633437167" target="_blank" rel="noopener noreferrer">Link to the book page on Amazon.com</a></li>
<li>ISBN 9781633437166</li></p><p></ul><a href="http://mng.bz/orYv#reviews"><img src="https://sebastianraschka.com//images/LLMs-from-scratch-images/other/reviews.png" width="220px"></a></p><p>
<br>
<br></p><p>To download a copy of this repository, click on the <a href="https://github.com/rasbt/LLMs-from-scratch/archive/refs/heads/main.zip" target="_blank" rel="noopener noreferrer">Download ZIP</a> button or execute the following command in your terminal:</p><pre><code class="language-bash">git clone --depth 1 https://github.com/rasbt/LLMs-from-scratch.git</code></pre></p><p><br></p><p>(If you downloaded the code bundle from the Manning website, please consider visiting the official code repository on GitHub at <a href="https://github.com/rasbt/LLMs-from-scratch" target="_blank" rel="noopener noreferrer">https://github.com/rasbt/LLMs-from-scratch</a> for the latest updates.)</p><p><br>
<br></p><h1>Table of Contents</h1></p><p>Please note that this <code>README.md</code> file is a Markdown (<code>.md</code>) file. If you have downloaded this code bundle from the Manning website and are viewing it on your local computer, I recommend using a Markdown editor or previewer for proper viewing. If you haven't installed a Markdown editor yet, <a href="https://ghostwriter.kde.org" target="_blank" rel="noopener noreferrer">Ghostwriter</a> is a good free option.</p><p>You can alternatively view this and other files on GitHub at <a href="https://github.com/rasbt/LLMs-from-scratch" target="_blank" rel="noopener noreferrer">https://github.com/rasbt/LLMs-from-scratch</a> in your browser, which renders Markdown automatically.</p><p><br>
<br></p><blockquote><strong>Tip:</strong></blockquote>
<blockquote>If you're seeking guidance on installing Python and Python packages and setting up your code environment, I suggest reading the <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup/README.md" target="_blank" rel="noopener noreferrer">README.md</a> file located in the <a href="setup" target="_blank" rel="noopener noreferrer">setup</a> directory.</blockquote></p><p><br>
<br></p><p><a href="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml" target="_blank" rel="noopener noreferrer"><img src="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml/badge.svg" alt="Code tests Linux"></a>
<a href="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml" target="_blank" rel="noopener noreferrer"><img src="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml/badge.svg" alt="Code tests Windows"></a>
<a href="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml" target="_blank" rel="noopener noreferrer"><img src="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml/badge.svg" alt="Code tests macOS"></a></p><p>
<br></p><p>| Chapter Title                                              | Main Code (for Quick Access)                                                                                                    | All Code + Supplementary      |
|------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------|-------------------------------|
| <a href="setup" target="_blank" rel="noopener noreferrer">Setup recommendations</a>                             | -                                                                                                                               | -                             |
| Ch 1: Understanding Large Language Models                  | No code                                                                                                                         | -                             |
| Ch 2: Working with Text Data                               | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/ch02.ipynb" target="_blank" rel="noopener noreferrer">ch02.ipynb</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/dataloader.ipynb" target="_blank" rel="noopener noreferrer">dataloader.ipynb</a> (summary)<br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">exercise-solutions.ipynb</a>               | <a href="./ch02" target="_blank" rel="noopener noreferrer">./ch02</a>            |
| Ch 3: Coding Attention Mechanisms                          | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/01_main-chapter-code/ch03.ipynb" target="_blank" rel="noopener noreferrer">ch03.ipynb</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/01_main-chapter-code/multihead-attention.ipynb" target="_blank" rel="noopener noreferrer">multihead-attention.ipynb</a> (summary) <br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">exercise-solutions.ipynb</a>| <a href="./ch03" target="_blank" rel="noopener noreferrer">./ch03</a>             |
| Ch 4: Implementing a GPT Model from Scratch                | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/01_main-chapter-code/ch04.ipynb" target="_blank" rel="noopener noreferrer">ch04.ipynb</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/01_main-chapter-code/gpt.py" target="_blank" rel="noopener noreferrer">gpt.py</a> (summary)<br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">exercise-solutions.ipynb</a> | <a href="./ch04" target="_blank" rel="noopener noreferrer">./ch04</a>           |
| Ch 5: Pretraining on Unlabeled Data                        | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/ch05.ipynb" target="_blank" rel="noopener noreferrer">ch05.ipynb</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_train.py" target="_blank" rel="noopener noreferrer">gpt_train.py</a> (summary) <br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_generate.py" target="_blank" rel="noopener noreferrer">gpt_generate.py</a> (summary) <br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">exercise-solutions.ipynb</a> | <a href="./ch05" target="_blank" rel="noopener noreferrer">./ch05</a>              |
| Ch 6: Finetuning for Text Classification                   | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/01_main-chapter-code/ch06.ipynb" target="_blank" rel="noopener noreferrer">ch06.ipynb</a>  <br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/01_main-chapter-code/gpt_class_finetune.py" target="_blank" rel="noopener noreferrer">gpt_class_finetune.py</a>  <br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">exercise-solutions.ipynb</a> | <a href="./ch06" target="_blank" rel="noopener noreferrer">./ch06</a>              |
| Ch 7: Finetuning to Follow Instructions                    | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/ch07.ipynb" target="_blank" rel="noopener noreferrer">ch07.ipynb</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/gpt_instruction_finetuning.py" target="_blank" rel="noopener noreferrer">gpt_instruction_finetuning.py</a> (summary)<br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/ollama_evaluate.py" target="_blank" rel="noopener noreferrer">ollama_evaluate.py</a> (summary)<br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">exercise-solutions.ipynb</a> | <a href="./ch07" target="_blank" rel="noopener noreferrer">./ch07</a>  |
| Appendix A: Introduction to PyTorch                        | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/code-part1.ipynb" target="_blank" rel="noopener noreferrer">code-part1.ipynb</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/code-part2.ipynb" target="_blank" rel="noopener noreferrer">code-part2.ipynb</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/DDP-script.py" target="_blank" rel="noopener noreferrer">DDP-script.py</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">exercise-solutions.ipynb</a> | <a href="./appendix-A" target="_blank" rel="noopener noreferrer">./appendix-A</a> |
| Appendix B: References and Further Reading                 | No code                                                                                                                         | -                             |
| Appendix C: Exercise Solutions                             | No code                                                                                                                         | -                             |
| Appendix D: Adding Bells and Whistles to the Training Loop | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-D/01_main-chapter-code/appendix-D.ipynb" target="_blank" rel="noopener noreferrer">appendix-D.ipynb</a>                                                          | <a href="./appendix-D" target="_blank" rel="noopener noreferrer">./appendix-D</a>  |
| Appendix E: Parameter-efficient Finetuning with LoRA       | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-E/01_main-chapter-code/appendix-E.ipynb" target="_blank" rel="noopener noreferrer">appendix-E.ipynb</a>                                                          | <a href="./appendix-E" target="_blank" rel="noopener noreferrer">./appendix-E</a> |</p><p><br>
&nbsp;</p><p>The mental model below summarizes the contents covered in this book.</p><p><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/mental-model.jpg" width="650px"></p><p>
<br>
&nbsp;</p><h2>Prerequisites</h2></p><p>The most important prerequisite is a strong foundation in Python programming.
With this knowledge, you will be well prepared to explore the fascinating world of LLMs
and understand the concepts and code examples presented in this book.</p><p>If you have some experience with deep neural networks, you may find certain concepts more familiar, as LLMs are built upon these architectures.</p><p>This book uses PyTorch to implement the code from scratch without using any external LLM libraries. While proficiency in PyTorch is not a prerequisite, familiarity with PyTorch basics is certainly useful. If you are new to PyTorch, Appendix A provides a concise introduction to PyTorch. Alternatively, you may find my book, <a href="https://sebastianraschka.com/teaching/pytorch-1h/" target="_blank" rel="noopener noreferrer">PyTorch in One Hour: From Tensors to Training Neural Networks on Multiple GPUs</a>, helpful for learning about the essentials.</p><p><br>
&nbsp;</p><h2>Hardware Requirements</h2></p><p>The code in the main chapters of this book is designed to run on conventional laptops within a reasonable timeframe and does not require specialized hardware. This approach ensures that a wide audience can engage with the material. Additionally, the code automatically utilizes GPUs if they are available. (Please see the <a href="https://github.com/rasbt/LLMs-from-scratch/blob/main/setup/README.md" target="_blank" rel="noopener noreferrer">setup</a> doc for additional recommendations.)</p><p>
&nbsp;
<h2>Video Course</h2></p><p><a href="https://www.manning.com/livevideo/master-and-build-large-language-models" target="_blank" rel="noopener noreferrer">A 17-hour and 15-minute companion video course</a> where I code through each chapter of the book. The course is organized into chapters and sections that mirror the book's structure so that it can be used as a standalone alternative to the book or complementary code-along resource.</p><p><a href="https://www.manning.com/livevideo/master-and-build-large-language-models"><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/video-screenshot.webp?123" width="350px"></a></p><p>
&nbsp;</p><h2>Companion Book / Sequel</h2></p><p><a href="https://mng.bz/lZ5B" target="_blank" rel="noopener noreferrer"><em>Build A Reasoning Model (From Scratch)</em></a>, while a standalone book, can be considered as a sequel to <em>Build A Large Language Model (From Scratch)</em>.</p><p>It starts with a pretrained model and implements different reasoning approaches, including inference-time scaling, reinforcement learning, and distillation, to improve the model's reasoning capabilities. </p><p>Similar to <em>Build A Large Language Model (From Scratch)</em>, <a href="https://mng.bz/lZ5B" target="_blank" rel="noopener noreferrer"><em>Build A Reasoning Model (From Scratch)</em></a> takes a hands-on approach implementing these methods from scratch.</p><p><a href="https://mng.bz/lZ5B"><img src="https://sebastianraschka.com/images/reasoning-from-scratch-images/cover.webp?123" width="120px"></a></p><ul><li>Amazon link (TBD)</li>
<li><a href="https://mng.bz/lZ5B" target="_blank" rel="noopener noreferrer">Manning link</a></li>
<li><a href="https://github.com/rasbt/reasoning-from-scratch" target="_blank" rel="noopener noreferrer">GitHub repository</a></li></p><p></ul><br></p><p>&nbsp;
<h2>Exercises</h2></p><p>Each chapter of the book includes several exercises. The solutions are summarized in Appendix C, and the corresponding code notebooks are available in the main chapter folders of this repository (for example,  <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/./ch02/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">./ch02/01_main-chapter-code/exercise-solutions.ipynb</a>.</p><p>In addition to the code exercises, you can download a free 170-page PDF titled  <a href="https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch" target="_blank" rel="noopener noreferrer">Test Yourself On Build a Large Language Model (From Scratch)</a> from the Manning website. It contains approximately 30 quiz questions and solutions per chapter to help you test your understanding.</p><p><a href="https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch"><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/test-yourself-cover.jpg?123" width="150px"></a></p><p>&nbsp;
<h2>Bonus Material</h2></p><p>Several folders contain optional materials as a bonus for interested readers:</p><ul><li><strong>Setup</strong></li>
  <li><a href="setup/01_optional-python-setup-preferences" target="_blank" rel="noopener noreferrer">Python Setup Tips</a></li>
  <li><a href="setup/02_installing-python-libraries" target="_blank" rel="noopener noreferrer">Installing Python Packages and Libraries Used In This Book</a></li>
  <li><a href="setup/03_optional-docker-environment" target="_blank" rel="noopener noreferrer">Docker Environment Setup Guide</a></li>
<li><strong>Chapter 2: Working with text data</strong></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/05_bpe-from-scratch/bpe-from-scratch.ipynb" target="_blank" rel="noopener noreferrer">Byte Pair Encoding (BPE) Tokenizer From Scratch</a></li>
  <li><a href="ch02/02_bonus_bytepair-encoder" target="_blank" rel="noopener noreferrer">Comparing Various Byte Pair Encoding (BPE) Implementations</a></li>
  <li><a href="ch02/03_bonus_embedding-vs-matmul" target="_blank" rel="noopener noreferrer">Understanding the Difference Between Embedding Layers and Linear Layers</a></li>
  <li><a href="ch02/04_bonus_dataloader-intuition" target="_blank" rel="noopener noreferrer">Dataloader Intuition with Simple Numbers</a></li>
<li><strong>Chapter 3: Coding attention mechanisms</strong></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/02_bonus_efficient-multihead-attention/mha-implementations.ipynb" target="_blank" rel="noopener noreferrer">Comparing Efficient Multi-Head Attention Implementations</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/03_understanding-buffers/understanding-buffers.ipynb" target="_blank" rel="noopener noreferrer">Understanding PyTorch Buffers</a></li>
<li><strong>Chapter 4: Implementing a GPT model from scratch</strong></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/02_performance-analysis/flops-analysis.ipynb" target="_blank" rel="noopener noreferrer">FLOPS Analysis</a></li>
  <li><a href="ch04/03_kv-cache" target="_blank" rel="noopener noreferrer">KV Cache</a></li>
<li><strong>Chapter 5: Pretraining on unlabeled data:</strong></li>
  <li><a href="ch05/02_alternative_weight_loading/" target="_blank" rel="noopener noreferrer">Alternative Weight Loading Methods</a></li>
  <li><a href="ch05/03_bonus_pretraining_on_gutenberg" target="_blank" rel="noopener noreferrer">Pretraining GPT on the Project Gutenberg Dataset</a></li>
  <li><a href="ch05/04_learning_rate_schedulers" target="_blank" rel="noopener noreferrer">Adding Bells and Whistles to the Training Loop</a></li>
  <li><a href="ch05/05_bonus_hparam_tuning" target="_blank" rel="noopener noreferrer">Optimizing Hyperparameters for Pretraining</a></li>
  <li><a href="ch05/06_user_interface" target="_blank" rel="noopener noreferrer">Building a User Interface to Interact With the Pretrained LLM</a></li>
  <li><a href="ch05/07_gpt_to_llama" target="_blank" rel="noopener noreferrer">Converting GPT to Llama</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/07_gpt_to_llama/standalone-llama32.ipynb" target="_blank" rel="noopener noreferrer">Llama 3.2 From Scratch</a></li>
  <li><a href="ch05/11_qwen3/" target="_blank" rel="noopener noreferrer">Qwen3 Dense and Mixture-of-Experts (MoE) From Scratch</a></li>
  <li><a href="ch05/12_gemma3/" target="_blank" rel="noopener noreferrer">Gemma 3 From Scratch</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/08_memory_efficient_weight_loading/memory-efficient-state-dict.ipynb" target="_blank" rel="noopener noreferrer">Memory-efficient Model Weight Loading</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/09_extending-tokenizers/extend-tiktoken.ipynb" target="_blank" rel="noopener noreferrer">Extending the Tiktoken BPE Tokenizer with New Tokens</a></li>
  <li><a href="ch05/10_llm-training-speed" target="_blank" rel="noopener noreferrer">PyTorch Performance Tips for Faster LLM Training</a></li>
<li><strong>Chapter 6: Finetuning for classification</strong></li>
  <li><a href="ch06/02_bonus_additional-experiments" target="_blank" rel="noopener noreferrer">Additional experiments finetuning different layers and using larger models</a></li>
  <li><a href="ch06/03_bonus_imdb-classification" target="_blank" rel="noopener noreferrer">Finetuning different models on 50k IMDb movie review dataset</a></li>
  <li><a href="ch06/04_user_interface" target="_blank" rel="noopener noreferrer">Building a User Interface to Interact With the GPT-based Spam Classifier</a></li>
<li><strong>Chapter 7: Finetuning to follow instructions</strong></li>
  <li><a href="ch07/02_dataset-utilities" target="_blank" rel="noopener noreferrer">Dataset Utilities for Finding Near Duplicates and Creating Passive Voice Entries</a></li>
  <li><a href="ch07/03_model-evaluation" target="_blank" rel="noopener noreferrer">Evaluating Instruction Responses Using the OpenAI API and Ollama</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/05_dataset-generation/llama3-ollama.ipynb" target="_blank" rel="noopener noreferrer">Generating a Dataset for Instruction Finetuning</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/05_dataset-generation/reflection-gpt4.ipynb" target="_blank" rel="noopener noreferrer">Improving a Dataset for Instruction Finetuning</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/04_preference-tuning-with-dpo/create-preference-data-ollama.ipynb" target="_blank" rel="noopener noreferrer">Generating a Preference Dataset with Llama 3.1 70B and Ollama</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb" target="_blank" rel="noopener noreferrer">Direct Preference Optimization (DPO) for LLM Alignment</a></li>
  <li><a href="ch07/06_user_interface" target="_blank" rel="noopener noreferrer">Building a User Interface to Interact With the Instruction Finetuned GPT Model</a></li></p><p></ul><br>
&nbsp;</p><h2>Questions, Feedback, and Contributing to This Repository</h2></p><p>
I welcome all sorts of feedback, best shared via the <a href="https://livebook.manning.com/forum?product=raschka&page=1" target="_blank" rel="noopener noreferrer">Manning Forum</a> or <a href="https://github.com/rasbt/LLMs-from-scratch/discussions" target="_blank" rel="noopener noreferrer">GitHub Discussions</a>. Likewise, if you have any questions or just want to bounce ideas off others, please don't hesitate to post these in the forum as well.</p><p>Please note that since this repository contains the code corresponding to a print book, I currently cannot accept contributions that would extend the contents of the main chapter code, as it would introduce deviations from the physical book. Keeping it consistent helps ensure a smooth experience for everyone.</p><p>
&nbsp;
<h2>Citation</h2></p><p>If you find this book or code useful for your research, please consider citing it.</p><p>Chicago-style citation:</p><blockquote>Raschka, Sebastian. <em>Build A Large Language Model (From Scratch)</em>. Manning, 2024. ISBN: 978-1633437166.</blockquote></p><p>BibTeX entry:</p><pre><code class="language-">@book{build-llms-from-scratch-book,
  author       = {Sebastian Raschka},
  title        = {Build A Large Language Model (From Scratch)},
  publisher    = {Manning},
  year         = {2024},
  isbn         = {978-1633437166},
  url          = {https://www.manning.com/books/build-a-large-language-model-from-scratch},
  github       = {https://github.com/rasbt/LLMs-from-scratch}
}</code></pre></p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-10-05

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-10-05 
    </div>
    
</body>
</html>