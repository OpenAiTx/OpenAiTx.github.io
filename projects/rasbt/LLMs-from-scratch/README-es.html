<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLMs-from-scratch - Implementa un LLM tipo ChatGPT en PyTorch desde cero, paso a paso.</title>
    <meta name="description" content="Implementa un LLM tipo ChatGPT en PyTorch desde cero, paso a paso.">
    <meta name="keywords" content="LLMs-from-scratch, Spanish, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "LLMs-from-scratch",
  "description": "Implementa un LLM tipo ChatGPT en PyTorch desde cero, paso a paso.",
  "author": {
    "@type": "Person",
    "name": "rasbt"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 74489
  },
  "url": "https://OpenAiTx.github.io/projects/rasbt/LLMs-from-scratch/README-es.html",
  "sameAs": "https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/README.md",
  "datePublished": "2025-10-05",
  "dateModified": "2025-10-05"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/rasbt/LLMs-from-scratch" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    LLMs-from-scratch
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 74489 stars</span>
                <span class="language">Spanish</span>
                <span>by rasbt</span>
            </div>
        </div>
        
        <div class="content">
            <h1>Construir un Modelo de Lenguaje Grande (Desde Cero)</h1></p><p>Este repositorio contiene el código para desarrollar, preentrenar y ajustar un LLM tipo GPT y es el repositorio oficial de código para el libro <a href="https://amzn.to/4fqvn0D" target="_blank" rel="noopener noreferrer">Construir un Modelo de Lenguaje Grande (Desde Cero)</a>.</p><p><br>
<br></p><p><a href="https://amzn.to/4fqvn0D"><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/cover.jpg?123" width="250px"></a></p><p><br></p><p>En <a href="http://mng.bz/orYv" target="_blank" rel="noopener noreferrer"><em>Construir un Modelo de Lenguaje Grande (Desde Cero)</em></a>, aprenderás y comprenderás cómo funcionan los modelos de lenguaje grandes (LLMs) desde adentro hacia afuera codificándolos desde cero, paso a paso. En este libro, te guiaré a través de la creación de tu propio LLM, explicando cada etapa con texto claro, diagramas y ejemplos.</p><p>El método descrito en este libro para entrenar y desarrollar tu propio modelo pequeño pero funcional con fines educativos refleja el enfoque utilizado en la creación de modelos fundamentales a gran escala como los que están detrás de ChatGPT. Además, este libro incluye código para cargar los pesos de modelos preentrenados más grandes para ajustar finamente.</p><ul><li>Enlace al <a href="https://github.com/rasbt/LLMs-from-scratch" target="_blank" rel="noopener noreferrer">repositorio oficial de código fuente</a></li>
<li><a href="http://mng.bz/orYv" target="_blank" rel="noopener noreferrer">Enlace al libro en Manning (sitio web del editor)</a></li>
<li><a href="https://www.amazon.com/gp/product/1633437167" target="_blank" rel="noopener noreferrer">Enlace a la página del libro en Amazon.com</a></li>
<li>ISBN 9781633437166</li></p><p></ul><a href="http://mng.bz/orYv#reviews"><img src="https://sebastianraschka.com//images/LLMs-from-scratch-images/other/reviews.png" width="220px"></a></p><p>
<br>
<br></p><p>Para descargar una copia de este repositorio, haz clic en el botón <a href="https://github.com/rasbt/LLMs-from-scratch/archive/refs/heads/main.zip" target="_blank" rel="noopener noreferrer">Download ZIP</a> o ejecuta el siguiente comando en tu terminal:</p><pre><code class="language-bash">git clone --depth 1 https://github.com/rasbt/LLMs-from-scratch.git</code></pre></p><p><br></p><p>(If you downloaded the code bundle from the Manning website, please consider visiting the official code repository on GitHub at <a href="https://github.com/rasbt/LLMs-from-scratch" target="_blank" rel="noopener noreferrer">https://github.com/rasbt/LLMs-from-scratch</a> for the latest updates.)</p><p><br>
<br></p><h1>Table of Contents</h1></p><p>Please note that this <code>README.md</code> file is a Markdown (<code>.md</code>) file. If you have downloaded this code bundle from the Manning website and are viewing it on your local computer, I recommend using a Markdown editor or previewer for proper viewing. If you haven't installed a Markdown editor yet, <a href="https://ghostwriter.kde.org" target="_blank" rel="noopener noreferrer">Ghostwriter</a> is a good free option.</p><p>You can alternatively view this and other files on GitHub at <a href="https://github.com/rasbt/LLMs-from-scratch" target="_blank" rel="noopener noreferrer">https://github.com/rasbt/LLMs-from-scratch</a> in your browser, which renders Markdown automatically.</p><p><br>
<br></p><blockquote><strong>Tip:</strong></blockquote>
<blockquote>If you're seeking guidance on installing Python and Python packages and setting up your code environment, I suggest reading the <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/setup/README.md" target="_blank" rel="noopener noreferrer">README.md</a> file located in the <a href="setup" target="_blank" rel="noopener noreferrer">setup</a> directory.</blockquote></p><p><br>
<br></p><p><a href="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml" target="_blank" rel="noopener noreferrer"><img src="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-linux-uv.yml/badge.svg" alt="Code tests Linux"></a>
<a href="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml" target="_blank" rel="noopener noreferrer"><img src="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-windows-uv-pip.yml/badge.svg" alt="Code tests Windows"></a>
<a href="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml" target="_blank" rel="noopener noreferrer"><img src="https://github.com/rasbt/LLMs-from-scratch/actions/workflows/basic-tests-macos-uv.yml/badge.svg" alt="Code tests macOS"></a></p><p>
<br></p><p>| Chapter Title                                              | Main Code (for Quick Access)                                                                                                    | All Code + Supplementary      |
|------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------|-------------------------------|
| <a href="setup" target="_blank" rel="noopener noreferrer">Setup recommendations</a>                             | -                                                                                                                               | -                             |
| Ch 1: Understanding Large Language Models                  | No code                                                                                                                         | -                             |
| Ch 2: Working with Text Data                               | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/ch02.ipynb" target="_blank" rel="noopener noreferrer">ch02.ipynb</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/dataloader.ipynb" target="_blank" rel="noopener noreferrer">dataloader.ipynb</a> (summary)<br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">exercise-solutions.ipynb</a>               | <a href="./ch02" target="_blank" rel="noopener noreferrer">./ch02</a>            |
| Ch 3: Coding Attention Mechanisms                          | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/01_main-chapter-code/ch03.ipynb" target="_blank" rel="noopener noreferrer">ch03.ipynb</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/01_main-chapter-code/multihead-attention.ipynb" target="_blank" rel="noopener noreferrer">multihead-attention.ipynb</a> (summary) <br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">exercise-solutions.ipynb</a>| <a href="./ch03" target="_blank" rel="noopener noreferrer">./ch03</a>             |
| Cap 4: Implementando un Modelo GPT desde Cero               | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/01_main-chapter-code/ch04.ipynb" target="_blank" rel="noopener noreferrer">ch04.ipynb</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/01_main-chapter-code/gpt.py" target="_blank" rel="noopener noreferrer">gpt.py</a> (resumen)<br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">exercise-solutions.ipynb</a> | <a href="./ch04" target="_blank" rel="noopener noreferrer">./ch04</a>           |
| Cap 5: Preentrenamiento con Datos Sin Etiquetas            | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/ch05.ipynb" target="_blank" rel="noopener noreferrer">ch05.ipynb</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_train.py" target="_blank" rel="noopener noreferrer">gpt_train.py</a> (resumen) <br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_generate.py" target="_blank" rel="noopener noreferrer">gpt_generate.py</a> (resumen) <br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">exercise-solutions.ipynb</a> | <a href="./ch05" target="_blank" rel="noopener noreferrer">./ch05</a>              |
| Cap 6: Ajuste fino para Clasificación de Texto             | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/01_main-chapter-code/ch06.ipynb" target="_blank" rel="noopener noreferrer">ch06.ipynb</a>  <br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/01_main-chapter-code/gpt_class_finetune.py" target="_blank" rel="noopener noreferrer">gpt_class_finetune.py</a>  <br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch06/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">exercise-solutions.ipynb</a> | <a href="./ch06" target="_blank" rel="noopener noreferrer">./ch06</a>              |
| Cap 7: Ajuste fino para Seguir Instrucciones                | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/ch07.ipynb" target="_blank" rel="noopener noreferrer">ch07.ipynb</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/gpt_instruction_finetuning.py" target="_blank" rel="noopener noreferrer">gpt_instruction_finetuning.py</a> (resumen)<br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/ollama_evaluate.py" target="_blank" rel="noopener noreferrer">ollama_evaluate.py</a> (resumen)<br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">exercise-solutions.ipynb</a> | <a href="./ch07" target="_blank" rel="noopener noreferrer">./ch07</a>  |
| Apéndice A: Introducción a PyTorch                          | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/code-part1.ipynb" target="_blank" rel="noopener noreferrer">code-part1.ipynb</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/code-part2.ipynb" target="_blank" rel="noopener noreferrer">code-part2.ipynb</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/DDP-script.py" target="_blank" rel="noopener noreferrer">DDP-script.py</a><br/>- <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-A/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">exercise-solutions.ipynb</a> | <a href="./appendix-A" target="_blank" rel="noopener noreferrer">./appendix-A</a> |
| Apéndice B: Referencias y Lecturas Adicionales              | Sin código                                                                                                                      | -                             |
| Apéndice C: Soluciones a los Ejercicios                      | Sin código                                                                                                                      | -                             |
| Apéndice D: Añadiendo Extras al Bucle de Entrenamiento      | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-D/01_main-chapter-code/appendix-D.ipynb" target="_blank" rel="noopener noreferrer">appendix-D.ipynb</a>                                                          | <a href="./appendix-D" target="_blank" rel="noopener noreferrer">./appendix-D</a>  |
| Apéndice E: Ajuste fino eficiente en parámetros con LoRA    | - <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/appendix-E/01_main-chapter-code/appendix-E.ipynb" target="_blank" rel="noopener noreferrer">appendix-E.ipynb</a>                                                          | <a href="./appendix-E" target="_blank" rel="noopener noreferrer">./appendix-E</a> |</p><p><br>
&nbsp;</p><p>El modelo mental a continuación resume los contenidos tratados en este libro.</p><p><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/mental-model.jpg" width="650px"></p><p>
<br>
&nbsp;</p><h2>Prerrequisitos</h2></p><p>El prerrequisito más importante es una sólida base en programación en Python.
Con este conocimiento, estarás bien preparado para explorar el fascinante mundo de los LLMs
y entender los conceptos y ejemplos de código presentados en este libro.</p><p>Si tienes algo de experiencia con redes neuronales profundas, puede que algunos conceptos te resulten más familiares, ya que los LLMs están basados en estas arquitecturas.</p><p>Este libro usa PyTorch para implementar el código desde cero sin usar librerías externas de LLMs. Aunque no es necesario ser experto en PyTorch, sí es útil estar familiarizado con sus conceptos básicos. Si eres nuevo en PyTorch, el Apéndice A ofrece una introducción concisa a PyTorch. Alternativamente, puede que mi libro, <a href="https://sebastianraschka.com/teaching/pytorch-1h/" target="_blank" rel="noopener noreferrer">PyTorch en Una Hora: De Tensores a Entrenar Redes Neuronales en Múltiples GPUs</a>, te sea útil para aprender lo esencial.</p><p><br>
&nbsp;</p><h2>Requisitos de Hardware</h2></p><p>El código en los capítulos principales de este libro está diseñado para ejecutarse en laptops convencionales en un tiempo razonable y no requiere hardware especializado. Este enfoque asegura que una amplia audiencia pueda interactuar con el material. Además, el código utiliza automáticamente GPUs si están disponibles. (Por favor, consulta la documentación de <a href="https://github.com/rasbt/LLMs-from-scratch/blob/main/setup/README.md" target="_blank" rel="noopener noreferrer">configuración</a> para recomendaciones adicionales.)</p><p>
&nbsp;
<h2>Curso en Video</h2></p><p><a href="https://www.manning.com/livevideo/master-and-build-large-language-models" target="_blank" rel="noopener noreferrer">Un curso en video de 17 horas y 15 minutos</a> donde programo junto a cada capítulo del libro. El curso está organizado en capítulos y secciones que reflejan la estructura del libro para que pueda usarse como una alternativa independiente al libro o como un recurso complementario para seguir el código.</p><p><a href="https://www.manning.com/livevideo/master-and-build-large-language-models"><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/video-screenshot.webp?123" width="350px"></a></p><p>
&nbsp;</p><h2>Libro Complementario / Secuela</h2></p><p><a href="https://mng.bz/lZ5B" target="_blank" rel="noopener noreferrer"><em>Construye un Modelo de Razonamiento (Desde Cero)</em></a>, aunque es un libro independiente, puede considerarse como una secuela de <em>Construye un Gran Modelo de Lenguaje (Desde Cero)</em>.</p><p>Comienza con un modelo preentrenado e implementa diferentes enfoques de razonamiento, incluyendo escalado en tiempo de inferencia, aprendizaje por refuerzo y destilación, para mejorar las capacidades de razonamiento del modelo.</p><p>Similar a <em>Construye un Gran Modelo de Lenguaje (Desde Cero)</em>, <a href="https://mng.bz/lZ5B" target="_blank" rel="noopener noreferrer"><em>Construye un Modelo de Razonamiento (Desde Cero)</em></a> adopta un enfoque práctico implementando estos métodos desde cero.</p><p><a href="https://mng.bz/lZ5B"><img src="https://sebastianraschka.com/images/reasoning-from-scratch-images/cover.webp?123" width="120px"></a></p><ul><li>Enlace de Amazon (por confirmar)</li>
<li><a href="https://mng.bz/lZ5B" target="_blank" rel="noopener noreferrer">Enlace de Manning</a></li>
<li><a href="https://github.com/rasbt/reasoning-from-scratch" target="_blank" rel="noopener noreferrer">Repositorio de GitHub</a></li></p><p></ul><br></p><p>&nbsp;
<h2>Ejercicios</h2></p><p>Cada capítulo del libro incluye varios ejercicios. Las soluciones se resumen en el Apéndice C, y los cuadernos de código correspondientes están disponibles en las carpetas principales de cada capítulo de este repositorio (por ejemplo, <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/./ch02/01_main-chapter-code/exercise-solutions.ipynb" target="_blank" rel="noopener noreferrer">./ch02/01_main-chapter-code/exercise-solutions.ipynb</a>).</p><p>Además de los ejercicios de código, puedes descargar un PDF gratuito de 170 páginas titulado <a href="https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch" target="_blank" rel="noopener noreferrer">Ponte a Prueba con Construye un Gran Modelo de Lenguaje (Desde Cero)</a> desde el sitio web de Manning. Contiene aproximadamente 30 preguntas tipo cuestionario y soluciones por capítulo para ayudarte a evaluar tu comprensión.</p><p><a href="https://www.manning.com/books/test-yourself-on-build-a-large-language-model-from-scratch"><img src="https://sebastianraschka.com/images/LLMs-from-scratch-images/test-yourself-cover.jpg?123" width="150px"></a></p><p>&nbsp;
<h2>Material adicional</h2></p><p>Varias carpetas contienen materiales opcionales como bono para los lectores interesados:</p><ul><li><strong>Configuración</strong></li>
  <li><a href="setup/01_optional-python-setup-preferences" target="_blank" rel="noopener noreferrer">Consejos para configurar Python</a></li>
  <li><a href="setup/02_installing-python-libraries" target="_blank" rel="noopener noreferrer">Instalación de paquetes y bibliotecas de Python usados en este libro</a></li>
  <li><a href="setup/03_optional-docker-environment" target="_blank" rel="noopener noreferrer">Guía para configurar el entorno Docker</a></li>
<li><strong>Capítulo 2: Trabajando con datos de texto</strong></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/05_bpe-from-scratch/bpe-from-scratch.ipynb" target="_blank" rel="noopener noreferrer">Tokenizador Byte Pair Encoding (BPE) desde cero</a></li>
  <li><a href="ch02/02_bonus_bytepair-encoder" target="_blank" rel="noopener noreferrer">Comparación de varias implementaciones de Byte Pair Encoding (BPE)</a></li>
  <li><a href="ch02/03_bonus_embedding-vs-matmul" target="_blank" rel="noopener noreferrer">Entendiendo la diferencia entre capas de embedding y capas lineales</a></li>
  <li><a href="ch02/04_bonus_dataloader-intuition" target="_blank" rel="noopener noreferrer">Intuición sobre Dataloader con números simples</a></li>
<li><strong>Capítulo 3: Codificando mecanismos de atención</strong></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/02_bonus_efficient-multihead-attention/mha-implementations.ipynb" target="_blank" rel="noopener noreferrer">Comparación de implementaciones eficientes de atención multi-cabeza</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch03/03_understanding-buffers/understanding-buffers.ipynb" target="_blank" rel="noopener noreferrer">Entendiendo los buffers de PyTorch</a></li>
<li><strong>Capítulo 4: Implementando un modelo GPT desde cero</strong></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch04/02_performance-analysis/flops-analysis.ipynb" target="_blank" rel="noopener noreferrer">Análisis de FLOPS</a></li>
  <li><a href="ch04/03_kv-cache" target="_blank" rel="noopener noreferrer">Cache KV</a></li>
<li><strong>Capítulo 5: Preentrenamiento con datos no etiquetados:</strong></li>
  <li><a href="ch05/02_alternative_weight_loading/" target="_blank" rel="noopener noreferrer">Métodos alternativos para cargar pesos</a></li>
  <li><a href="ch05/03_bonus_pretraining_on_gutenberg" target="_blank" rel="noopener noreferrer">Preentrenando GPT con el conjunto de datos Project Gutenberg</a></li>
  <li><a href="ch05/04_learning_rate_schedulers" target="_blank" rel="noopener noreferrer">Añadiendo mejoras al ciclo de entrenamiento</a></li>
  <li><a href="ch05/05_bonus_hparam_tuning" target="_blank" rel="noopener noreferrer">Optimizando hiperparámetros para el preentrenamiento</a></li>
  <li><a href="ch05/06_user_interface" target="_blank" rel="noopener noreferrer">Construyendo una interfaz de usuario para interactuar con el LLM preentrenado</a></li>
  <li><a href="ch05/07_gpt_to_llama" target="_blank" rel="noopener noreferrer">Convirtiendo GPT a Llama</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/07_gpt_to_llama/standalone-llama32.ipynb" target="_blank" rel="noopener noreferrer">Llama 3.2 desde cero</a></li>
  <li><a href="ch05/11_qwen3/" target="_blank" rel="noopener noreferrer">Qwen3 Dense y Mixture-of-Experts (MoE) desde cero</a></li>
  <li><a href="ch05/12_gemma3/" target="_blank" rel="noopener noreferrer">Gemma 3 desde cero</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/08_memory_efficient_weight_loading/memory-efficient-state-dict.ipynb" target="_blank" rel="noopener noreferrer">Carga eficiente en memoria de pesos de modelos</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/09_extending-tokenizers/extend-tiktoken.ipynb" target="_blank" rel="noopener noreferrer">Extendiendo el tokenizador BPE Tiktoken con nuevos tokens</a></li>
  <li><a href="ch05/10_llm-training-speed" target="_blank" rel="noopener noreferrer">Consejos de rendimiento en PyTorch para entrenar LLMs más rápido</a></li>
<li><strong>Capítulo 6: Ajuste fino para clasificación</strong></li>
  <li><a href="ch06/02_bonus_additional-experiments" target="_blank" rel="noopener noreferrer">Experimentos adicionales ajustando diferentes capas y usando modelos más grandes</a></li>
  <li><a href="ch06/03_bonus_imdb-classification" target="_blank" rel="noopener noreferrer">Ajuste fino de diferentes modelos con el conjunto de datos de 50k reseñas de películas IMDb</a></li>
  <li><a href="ch06/04_user_interface" target="_blank" rel="noopener noreferrer">Construyendo una interfaz de usuario para interactuar con el clasificador de spam basado en GPT</a></li>
<li><strong>Capítulo 7: Ajuste fino para seguir instrucciones</strong></li>
  <li><a href="ch07/02_dataset-utilities" target="_blank" rel="noopener noreferrer">Utilidades de conjuntos de datos para encontrar duplicados cercanos y crear entradas en voz pasiva</a></li>
  <li><a href="ch07/03_model-evaluation" target="_blank" rel="noopener noreferrer">Evaluando respuestas a instrucciones usando la API de OpenAI y Ollama</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/05_dataset-generation/llama3-ollama.ipynb" target="_blank" rel="noopener noreferrer">Generando un conjunto de datos para ajuste fino de instrucciones</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/05_dataset-generation/reflection-gpt4.ipynb" target="_blank" rel="noopener noreferrer">Mejorando un Conjunto de Datos para Ajuste Fino por Instrucción</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/04_preference-tuning-with-dpo/create-preference-data-ollama.ipynb" target="_blank" rel="noopener noreferrer">Generación de un Conjunto de Datos de Preferencias con Llama 3.1 70B y Ollama</a></li>
  <li><a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/04_preference-tuning-with-dpo/dpo-from-scratch.ipynb" target="_blank" rel="noopener noreferrer">Optimización Directa de Preferencias (DPO) para Alineación de LLM</a></li>
  <li><a href="ch07/06_user_interface" target="_blank" rel="noopener noreferrer">Construyendo una Interfaz de Usuario para Interactuar con el Modelo GPT Ajustado por Instrucción</a></li></p><p></ul><br>
&nbsp;</p><h2>Preguntas, Comentarios y Contribuciones a Este Repositorio</h2></p><p>
Agradezco todo tipo de comentarios, que es mejor compartir a través del <a href="https://livebook.manning.com/forum?product=raschka&page=1" target="_blank" rel="noopener noreferrer">Foro de Manning</a> o <a href="https://github.com/rasbt/LLMs-from-scratch/discussions" target="_blank" rel="noopener noreferrer">GitHub Discussions</a>. Asimismo, si tienes alguna pregunta o simplemente quieres intercambiar ideas con otros, no dudes en publicarlas también en el foro.</p><p>Ten en cuenta que, dado que este repositorio contiene el código correspondiente a un libro impreso, actualmente no puedo aceptar contribuciones que extiendan el contenido del código principal de los capítulos, ya que introducirían desviaciones respecto al libro físico. Mantener la consistencia ayuda a garantizar una experiencia fluida para todos.</p><p>
&nbsp;
<h2>Citación</h2></p><p>Si encuentras este libro o código útil para tu investigación, por favor considera citarlo.</p><p>Citación estilo Chicago:</p><blockquote>Raschka, Sebastian. <em>Build A Large Language Model (From Scratch)</em>. Manning, 2024. ISBN: 978-1633437166.</blockquote></p><p>Entrada BibTeX:</p><pre><code class="language-">@book{build-llms-from-scratch-book,
  author       = {Sebastian Raschka},
  title        = {Build A Large Language Model (From Scratch)},
  publisher    = {Manning},
  year         = {2024},
  isbn         = {978-1633437166},
  url          = {https://www.manning.com/books/build-a-large-language-model-from-scratch},
  github       = {https://github.com/rasbt/LLMs-from-scratch}
}</code></pre></p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-10-05

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-10-05 
    </div>
    
</body>
</html>