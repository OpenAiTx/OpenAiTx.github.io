<!DOCTYPE html>
<html lang="hi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - आधुनिक पक्षपात को कम करने के लिए केवल निश्चित समय अवधियों के डेटा पर प्रशिक्षित एक LLM</title>
    <meta name="description" content="आधुनिक पक्षपात को कम करने के लिए केवल निश्चित समय अवधियों के डेटा पर प्रशिक्षित एक LLM">
    <meta name="keywords" content="TimeCapsuleLLM, Hindi, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "आधुनिक पक्षपात को कम करने के लिए केवल निश्चित समय अवधियों के डेटा पर प्रशिक्षित एक LLM",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 349
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-hi.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 349 stars</span>
                <span class="language">Hindi</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 भाषा</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">अंग्रेज़ी</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">सरलीकृत चीनी</a>
        | <a href="#" title="Coming soon">पारंपरिक चीनी (जल्द आ रहा है)</a> |
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">जापानी</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">कोरियाई</a>
        | <a href="#" title="Coming soon">हिन्दी (जल्द आ रहा है)</a> |
        | <a href="#" title="Coming soon">थाई (जल्द आ रहा है)</a> |
        | <a href="#" title="Coming soon">फ्रेंच (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">जर्मन (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">स्पेनिश (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">इटालियन (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">रूसी (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">पुर्तगाली (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">डच (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">पोलिश (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">अरबी (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">फारसी (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">तुर्की (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">वियतनामी (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">इंडोनेशियाई (जल्द आ रहा है)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>टाइमकैप्सूल LLM</h1></p><p><em>एक भाषा मॉडल जो <strong>शुरू से</strong> विशेष स्थानों और समय अवधियों के डेटा पर प्रशिक्षित किया गया है ताकि आधुनिक पक्षपात को कम किया जा सके और उस युग की आवाज़, शब्दावली और दृष्टिकोण का अनुकरण किया जा सके।</em></p><p>कल्पना कीजिए कि अगर एक एआई मॉडल केवल ऐतिहासिक बनने का दिखावा नहीं करता, बल्कि वास्तव में ऐतिहासिक होता।</p><p>v0 और v0.5 <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">Andrej Karpathy के nanoGPT</a> पर बनाए गए हैं। मुख्य प्रशिक्षण स्क्रिप्ट और मॉडल संरचना उन्हीं का कार्य है।</p><p>v1 <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Microsoft के Phi 1.5</a> पर निर्मित</p><h2> मॉडल व्यवहार एवं सीमाएँ</h2></p><h3><strong>v0</strong>  </h3></p><p>प्रारंभिक प्रॉम्प्ट्स में मॉडल 1800 के दशक की भाषा और व्यवहार में उत्तर देता है। 
उदाहरण: प्रॉम्प्ट: "Who art Henry?" और उत्तर था "I know that man, I have did not a black, the storm." </p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="TimeLockLLM Sample Output"></p><ul><li>आधुनिक अवधारणाओं का कोई उल्लेख नहीं  </li>
<li>अधिकांशतः युग-संगत शब्दावली  </li>
<li>वाक्य अधिकतर असंगत (लगभग ~187MB प्रशिक्षण डेटा के लिए अपेक्षित)</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>v0 की तुलना में महत्वपूर्ण सुधार।  
<ul><li>विक्टोरियन लेखन शैली, उचित विराम चिन्ह, अधिकतर व्याकरणिक वाक्य  </li>
<li>अब भी उच्च तथ्यात्मक भ्रम की दर  </li>
<li>OCR शोर (“Digitized by Google”) अब भी आउटपुट में उपस्थित</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="TimeLockLLM Sample Output"></p><h3><strong>v1</strong></h3></p><p>पहला मॉडल जो वास्तविक ऐतिहासिक घटना को डेटासेट के वास्तविक व्यक्ति से जोड़ता है।</p><p>उदाहरण: प्रॉम्प्ट: "It was the year of our Lord 1834" </p><p>आउटपुट: "It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity" </p><p>पहले मुझे लगा कि उसी वर्ष में कोई विरोध संयोगवश हुआ होगा, लेकिन यह देखें: <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3>यह क्यों महत्वपूर्ण है:</h3></p><p>यह मेरी मॉडलों के द्वारा किसी वर्ष को वास्तविक ऐतिहासिक घटना और उस घटना से जुड़े वास्तविक व्यक्ति (Lord Palmerston) से जोड़ने का पहला उदाहरण है। पहले के मॉडल (v0 और v0.5) 19वीं सदी की लेखन शैली की नकल कर सकते थे, लेकिन हमेशा घटनाओं, लोगों और तथ्यों का भ्रम पैदा करते थे। यह दर्शाता है कि मॉडल डेटासेट से चीजें याद रखना शुरू कर रहा है</p><h2>आगामी योजनाएँ </h2>
<ul><li>लंदन में 1800-1875 के बीच प्रकाशित लगभग 1,75,000 ग्रंथ Internet Archive पर उपलब्ध हैं</li>
<li>मैं कार्पस को बढ़ाने और बेहतर तर्क क्षमताओं के लिए इसे और साफ करने की योजना बना रहा हूँ</li>
<li>अधिक ऐतिहासिक मॉडलों के लिए विभिन्न क्षेत्रों और समय काल में विस्तार</li></p><p></ul><h2>उपयोग कैसे करें</h2></p><p>यह परियोजना मुख्य रूप से ऐतिहासिक डेटा को संकलित करने, प्रशिक्षण के लिए तैयार करने और एक टोकनाइज़र बनाने पर केंद्रित है। मैं पूरी LLM प्रशिक्षण प्रक्रिया को शामिल नहीं कर रहा हूँ, उसके लिए Andrej Karpathy के nanoGPT को देखें।</p><h3>चरण 1: ऐतिहासिक ग्रंथों को एकत्रित और तैयार करें</h3></p><ul><li>सार्वजनिक डोमेन की पुस्तकों, दस्तावेज़ों आदि की .txt फाइलें अपने चुने हुए समय काल (जैसे, लंदन 1800-1850) से एकत्रित करें</li>
<li>इन्हें अपने चुने हुए समय/स्थान की सीमा के भीतर रखें</li>
<li>टेक्स्ट फाइलों को एक स्क्रिप्ट से या मैन्युअल रूप से साफ करें, जैसे Project Gutenberg के हेडर/फुटर, आधुनिक टिप्पणियाँ या OCR त्रुटियाँ हटाएँ।</li></p><p></ul><h3>चरण 2: कस्टम टोकनाइज़र बनाएं</h3></p><ul><li>साफ किए गए डेटा पर train_tokenizer.py या train_tokenizer_hf.py चलाएँ।</li>
<li>इससे आपको vocab.json और merges.txt मिलेंगे</li>
<li>ये फाइलें आपके मॉडल के लिए शब्दावली और मर्ज नियमों को परिभाषित करती हैं</li></p><p></ul><h3>चरण 3: अपना मॉडल प्रशिक्षित करें</h3></p><ul><li>प्रशिक्षण प्रक्रिया के लिए <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT by Andrej Karpathy</a> या आपके चुने हुए आर्किटेक्चर की डॉक्यूमेंटेशन देखें।</li></p><p></ul><h1>सामान्य प्रश्न</h1></p><h2>चयनित कालिक प्रशिक्षण (Selective Temporal Training) क्या है?</h2></p><p>चयनित कालिक प्रशिक्षण (Selective Temporal Training - STT) मशीन लर्निंग की एक विधि है जिसमें सभी प्रशिक्षण डेटा को विशेष रूप से एक ऐतिहासिक समय अवधि के भीतर संकलित किया जाता है। इसका उद्देश्य उस युग की भाषा और ज्ञान को बिना आधुनिक अवधारणाओं के प्रभाव के मॉडल करना है। उदाहरण के लिए, वर्तमान में मेरे पास जो मॉडल (v0.5) है वह विशेष रूप से 1800-1875 के डेटा पर प्रशिक्षित है, यह फाइन ट्यून नहीं है बल्कि शुरू से ही प्रशिक्षित है जिससे उसके आउटपुट में उस समय की भाषाई शैली और ऐतिहासिक संदर्भ झलकता है।</p><h2>सिर्फ फाइन-ट्यूनिंग या LoRA क्यों नहीं इस्तेमाल करें?</h2></p><p>इस परियोजना के लिए मैं ऐसा भाषा मॉडल बनाना चाहता हूँ जिसमें आधुनिक पक्षपात न हो। अगर मैं GPT-2 जैसे किसी मॉडल को फाइन-ट्यून करता हूँ, तो वह पहले से प्रशिक्षित है और उसकी जानकारी हटाई नहीं जा सकती। अगर मैं शुरू से प्रशिक्षण करता हूँ तो भाषा मॉडल पुराने जैसा दिखावा नहीं करेगा, वह सच में पुराना होगा। इस परियोजना का लक्ष्य है ऐसा मॉडल बनाना जो केवल 1800 और 1875 के बीच लंदन में प्रकाशित पुस्तकों के ज्ञान से ही तर्क कर सके।</p><h2>आपने प्रशिक्षण के लिए किस प्रकार के डेटा का उपयोग किया?</h2></p><p>मैं 1800–1875 लंदन की पुस्तकें, कानूनी दस्तावेज़, समाचारपत्र और अन्य लेखन का उपयोग कर रहा हूँ। जो सूची मैंने लिंक की है (v0) उसमें लगभग 200 दस्तावेज़ हैं लेकिन पहले प्रशिक्षण के लिए मैंने सिर्फ 50 फाइलें, लगभग ~187 MB इस्तेमाल कीं। आप दस्तावेज़ों की सूची यहाँ देख सकते हैं:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>डेटासेट आकार:
v0: ~187MB
v0.5: ~435MB 
v1: ~6.25GB </p><h2>मॉडल कितने बड़े हैं ?</h2></p><p>V0: 16M पैरामीटर्स</p><p>V0.5 123M पैरामीटर्स</p><p>V1: 700M पैरामीटर्स</p><h1>प्रशिक्षण विशिष्टताएँ ?</h1></p><h1>V0/V0.5</h1>
GPU: Geforce rtx 4060
CPU: i5-13400F 
रैम: 16GB DDR5.</p><h1>V1</h1>
GPU: A100 किराए पर लिया गया</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-08-19

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>