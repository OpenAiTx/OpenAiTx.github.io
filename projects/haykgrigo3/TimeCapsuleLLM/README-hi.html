<!DOCTYPE html>
<html lang="hi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - आधुनिक पक्षपात को कम करने के लिए केवल निश्चित समय अवधियों के डेटा पर प्रशिक्षित एक LLM</title>
    <meta name="description" content="आधुनिक पक्षपात को कम करने के लिए केवल निश्चित समय अवधियों के डेटा पर प्रशिक्षित एक LLM">
    <meta name="keywords" content="TimeCapsuleLLM, Hindi, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "आधुनिक पक्षपात को कम करने के लिए केवल निश्चित समय अवधियों के डेटा पर प्रशिक्षित एक LLM",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 545
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-hi.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2025-09-30",
  "dateModified": "2025-09-30"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 545 stars</span>
                <span class="language">Hindi</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 भाषा</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">अंग्रेज़ी</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">सरलीकृत चीनी</a>
        | <a href="#" title="Coming soon">पारंपरिक चीनी (जल्द आ रहा है)</a> |
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">जापानी</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">कोरियाई</a>
        | <a href="#" title="Coming soon">हिन्दी (जल्द आ रहा है)</a> |
        | <a href="#" title="Coming soon">थाई (जल्द आ रहा है)</a> |
        | <a href="#" title="Coming soon">फ्रेंच (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">जर्मन (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">स्पेनिश (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">इटालियन (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">रूसी (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">पुर्तगाली (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">डच (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">पोलिश (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">अरबी (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">फारसी (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">तुर्की (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">वियतनामी (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">इंडोनेशियाई (जल्द आ रहा है)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>टाइमकैप्सूल LLM</h1></p><p><em>एक भाषा मॉडल जो <strong>शुरू से</strong> विशेष स्थानों और समय अवधियों के डेटा पर प्रशिक्षित किया गया है ताकि आधुनिक पक्षपात को कम किया जा सके और उस युग की आवाज़, शब्दावली और दृष्टिकोण का अनुकरण किया जा सके।</em></p><p>कल्पना कीजिए कि अगर एक एआई मॉडल केवल ऐतिहासिक बनने का दिखावा नहीं करता, बल्कि वास्तव में ऐतिहासिक होता।</p><p>v0 और v0.5 <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">Andrej Karpathy के nanoGPT</a> पर बनाए गए हैं। मुख्य प्रशिक्षण स्क्रिप्ट और मॉडल संरचना उन्हीं का कार्य है।</p><p>v1 <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Microsoft के Phi 1.5</a> पर आधारित है</p><p><a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">Hugging Face लिंक</a></p><h2> मॉडल व्यवहार और सीमाएँ</h2></p><h3><strong>v0</strong>  </h3></p><p>शुरुआती प्रॉम्प्ट्स में मॉडल 1800 के दशक की भाषा और व्यवहार में प्रतिक्रिया देता है। 
उदाहरण: प्रॉम्प्ट: "Who art Henry?" और उत्तर: "I know that man, I have did not a black, the storm."</p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="TimeLockLLM नमूना आउटपुट"></p><ul><li>आधुनिक अवधारणाओं का कोई उल्लेख नहीं  </li>
<li>अधिकांश शब्दावली युग-संगत है  </li>
<li>वाक्य अक्सर असंगठित होते हैं (~187MB प्रशिक्षण डेटा के लिए अपेक्षित)</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>v0 की तुलना में महत्वपूर्ण सुधार।
<ul><li>विक्टोरियन लेखन शैली, उचित विराम चिह्न, अधिकांश वाक्य व्याकरणिक  </li>
<li>तथ्यात्मक कल्पना दर अभी भी अधिक  </li>
<li>OCR शोर (“Digitized by Google”) अभी भी आउटपुट में मौजूद</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="TimeLockLLM नमूना आउटपुट"></p><h3><strong>v1</strong></h3></p><p>पहला मॉडल जो डेटासेट से वास्तविक ऐतिहासिक घटना और उससे जुड़े व्यक्ति को याद और जोड़ सका।</p><p>उदाहरण: प्रॉम्प्ट: "It was the year of our Lord 1834"</p><p>आउटपुट: "It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity" </p><p>पहले मुझे लगा कि उसी वर्ष कोई विरोध प्रदर्शन संयोगवश हुआ होगा, लेकिन यह देखिए: <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3>यह क्यों महत्वपूर्ण है:</h3></p><p>यह मेरे मॉडल्स का पहला उदाहरण है जहाँ किसी वर्ष को एक वास्तविक ऐतिहासिक घटना और उस घटना से जुड़े वास्तविक व्यक्ति (Lord Palmerston) से जोड़ा गया। पहले के मॉडल्स (v0 और v0.5) 19वीं सदी की लेखन शैली की नकल कर सकते थे लेकिन घटनाओं, लोगों और तथ्यों को हमेशा कल्पना करते थे। इससे पता चलता है कि मॉडल अब डेटासेट से चीजें याद रखना शुरू कर रहा है।</p><h2>आगामी योजनाएँ</h2></p><ul><li>इंटरनेट आर्काइव पर 1800-1875 के बीच लंदन में प्रकाशित लगभग 175,000 ग्रंथ उपलब्ध हैं</li>
<li>मैं इस कॉर्पस को विस्तार देने और इसे बेहतर तर्क क्षमताओं के लिए और अधिक साफ करने की योजना बना रहा हूँ</li>
<li>अधिक ऐतिहासिक मॉडल के लिए विभिन्न क्षेत्रों और समय अवधियों में विस्तार</li></p><p></ul><h2>उपयोग कैसे करें</h2></p><p>यह प्रोजेक्ट मुख्य रूप से ऐतिहासिक डेटा को संकलित करने, प्रशिक्षण के लिए तैयार करने और एक टोकनाइज़र बनाने पर केंद्रित है। मैं पूरी LLM प्रशिक्षण प्रक्रिया को कवर नहीं करने जा रहा हूँ, उसके लिए Andrej Karpathy की nanoGPT देखें।</p><h3>चरण 1: ऐतिहासिक ग्रंथ एकत्रित करें और तैयार करें</h3></p><ul><li>सार्वजनिक डोमेन की पुस्तकों, दस्तावेजों आदि की .txt फाइलें चुने गए समय अवधि से एकत्र करें (जैसे, लंदन 1800-1850)</li>
<li>इन्हें अपनी चुनी हुई समय/स्थान सीमा के भीतर रखें</li>
<li>टेक्स्ट फाइलों को एक स्क्रिप्ट से साफ करें या प्रोजेक्ट गुटेनबर्ग के हेडर/फूटर, आधुनिक एनोटेशन या OCR त्रुटियों को मैन्युअली हटाएँ</li></p><p></ul><h3>चरण 2: कस्टम टोकनाइज़र बनाएं</h3></p><ul><li>train_tokenizer.py या train_tokenizer_hf.py को साफ किए गए डेटा पर चलाएँ।</li>
<li>इससे आपको vocab.json और merges.txt मिलेंगे</li>
<li>ये फाइलें आपके मॉडल के लिए शब्दावली और मर्ज नियम परिभाषित करती हैं</li></p><p></ul><h3>चरण 3: अपना मॉडल ट्रेन करें</h3></p><ul><li>प्रशिक्षण प्रक्रिया के लिए <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">Andrej Karpathy की nanoGPT</a> या अपनी चुनी हुई आर्किटेक्चर के दस्तावेज़ देखें</li></p><p></ul><h1>सामान्य प्रश्न</h1></p><h2>चयनात्मक कालिक प्रशिक्षण (Selective Temporal Training) क्या है?</h2></p><p>चयनात्मक कालिक प्रशिक्षण (STT) एक मशीन लर्निंग पद्धति है जिसमें सभी प्रशिक्षण डेटा विशेष रूप से एक निश्चित ऐतिहासिक समय अवधि के भीतर चुना जाता है। इसका उद्देश्य उस युग की भाषा और ज्ञान को आधुनिक अवधारणाओं के प्रभाव के बिना मॉडल करना है। उदाहरण के लिए, वर्तमान मॉडल (v0.5) केवल 1800-1875 के डेटा पर प्रशिक्षित है, यह फाइन ट्यून नहीं किया गया है बल्कि शुरू से ही प्रशिक्षित है जिससे आउटपुट उस समय अवधि की भाषाई शैली और ऐतिहासिक संदर्भ को दर्शाता है।</p><h2>बस फाइन-ट्यूनिंग या LoRA क्यों नहीं उपयोग करें?</h2></p><p>इस परियोजना के लिए मैं ऐसा भाषा मॉडल बनाना चाहता हूँ जो आधुनिक पूर्वाग्रह से मुक्त हो। अगर मैं GPT-2 जैसा कुछ फाइन-ट्यून करता हूँ, तो वह पहले से ही प्री-ट्रेंड है और वह जानकारी नहीं हटेगी। यदि मैं शुरू से ट्रेन करता हूँ तो भाषा मॉडल पुराना होने का नाटक नहीं करेगा, वह वास्तव में वैसा ही होगा। इस परियोजना का उद्देश्य अभी ऐसा कुछ बनाना है जो केवल 1800 और 1875 के बीच लंदन में प्रकाशित किताबों के ज्ञान का उपयोग करके तर्क कर सके।</p><h2>प्रशिक्षण के लिए आपने किस प्रकार का डेटा इस्तेमाल किया?</h2></p><p>
मैं 1800–1875 लंदन की किताबें, कानूनी दस्तावेज़, समाचार पत्र और अन्य लेखन का उपयोग कर रहा हूँ। मैंने जो सूची लिंक की है (v0 के लिए) उसमें लगभग 200 दस्तावेज़ हैं, लेकिन पहली ट्रेनिंग के लिए मैंने सिर्फ 50 फाइलें ~187 एमबी के बारे में इस्तेमाल की थीं। आप दस्तावेजों की सूची देख सकते हैं:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>डेटासेट आकार:
v0: ~187MB
v0.5: ~435MB 
v1: ~6.25GB </p><h2>मॉडल कितने बड़े हैं?</h2></p><p>V0: 16M पैरामीटर</p><p>V0.5 123M पैरामीटर</p><p>V1: 700M पैरामीटर</p><h1>प्रशिक्षण विशिष्टताएँ ?</h1></p><h1>V0/V0.5</h1>
GPU: Geforce rtx 4060
CPU: i5-13400F 
Ram: 16GB DDR5.</p><h1>V1</h1>
GPU: A100 किराए पर लिया गया</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-09-30

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-30 
    </div>
    
</body>
</html>