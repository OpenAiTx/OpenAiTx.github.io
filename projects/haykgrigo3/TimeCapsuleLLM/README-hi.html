<!DOCTYPE html>
<html lang="hi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - आधुनिक पक्षपात को कम करने के लिए केवल कुछ निश्चित समय अवधियों के डेटा पर प्रशिक्षित एक LLM</title>
    <meta name="description" content="आधुनिक पक्षपात को कम करने के लिए केवल कुछ निश्चित समय अवधियों के डेटा पर प्रशिक्षित एक LLM">
    <meta name="keywords" content="TimeCapsuleLLM, Hindi, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "आधुनिक पक्षपात को कम करने के लिए केवल कुछ निश्चित समय अवधियों के डेटा पर प्रशिक्षित एक LLM",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 275
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-hi.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2025-08-07",
  "dateModified": "2025-08-07"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 275 stars</span>
                <span class="language">Hindi</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align="right">
  <details>
    <summary >🌐 भाषा</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">अंग्रेज़ी</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="#" title="Coming soon">繁體中文 (जल्द आ रहा है)</a> |
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">한국어</a>
        | <a href="#" title="Coming soon">हिन्दी (जल्द आ रहा है)</a> |
        | <a href="#" title="Coming soon">ไทย (जल्द आ रहा है)</a> |
        | <a href="#" title="Coming soon">Français (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">Deutsch (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">Español (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">Italiano (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">Русский (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">Português (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">Nederlands (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">Polski (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">العربية (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">فارسی (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">Türkçe (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">Tiếng Việt (जल्द आ रहा है)</a>
        | <a href="#" title="Coming soon">Bahasa Indonesia (जल्द आ रहा है)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>टाइमकैप्सूल LLM</h1>
एक LLM जिसे केवल कुछ विशेष समय अवधियों के डेटा पर प्रशिक्षित किया गया है ताकि आधुनिक पक्षपात कम हो सके।</p><p>कल्पना कीजिए यदि एक एआई मॉडल केवल ऐतिहासिक होने का दिखावा न करे बल्कि वास्तव में हो।</p><p><a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">Andrej Karpathy द्वारा nanoGPT</a> पर आधारित। मुख्य प्रशिक्षण स्क्रिप्ट्स और मॉडल आर्किटेक्चर उन्हीं का कार्य है।</p><h1>परियोजना के लक्ष्य</h1></p><p>टाइमकैप्सूल LLM एक प्रयोगात्मक परियोजना है जिसे केवल कुछ निश्चित समय अवधियों में लिखे गए पाठों पर प्रशिक्षित किया जाएगा। इसका उद्देश्य विशिष्ट ऐतिहासिक युगों की विश्वदृष्टि और भाषा का अनुकरण करना है।</p><h1>केवल फाइन ट्यूनिंग क्यों पर्याप्त नहीं है</h1></p><p>यदि आप केवल एक पूर्व-प्रशिक्षित मॉडल को फाइन ट्यून करते हैं, तो भी आपका LLM आधुनिक अवधारणाओं को जानता रहेगा। बेशक शून्य आधुनिक पक्षपात प्राप्त करना कठिन है लेकिन मैं इसके जितना करीब हो सकता हूं, होना चाहता हूं। कोई आधुनिक पक्षपात न होने के लिए मॉडल को शुरू से प्रशिक्षित करना आवश्यक है।</p><h1>अपेक्षित परिणाम</h1></p><p>आशा है कि जब यह मॉडल तैयार हो जाएगा, तो इसे आधुनिक अवधारणाओं का ज्ञान नहीं होगा और यह केवल उसी पर विचार कर सकेगा जो इसे सिखाया गया है। इसे आधुनिक शब्दावली/अवधारणाएं नहीं पहचाननी चाहिए और मैं आशा करता हूँ कि यह आधुनिक ज्ञान का काल्पनिक निर्माण न करे।</p><h1>प्रगति अपडेट</h1></p><h2>9 जुलाई, 2025</h2></p><p>मैंने अपनी समय अवधि 1800-1850 और क्षेत्र: लंदन निर्धारित कर लिया है</p><p>मैंने ग्रंथों, पुस्तकों, दस्तावेजों की एक सूची एकत्र की है</p><p>अब तक मेरे पास 50 txt फाइलें हैं और जल्द ही NanoGPT पर प्रशिक्षण शुरू करूंगा</p><p>जैसे ही प्रगति होगी, मैं इसमें अपडेट करता रहूंगा</p><h2>13 जुलाई, 2025</h2></p><p>मैंने nanoGPT को 187MB ऐतिहासिक पाठ डेटा के साथ प्रशिक्षित किया।</p><h2>15 जुलाई, 2025</h2></p><p>मैंने दूसरे प्रशिक्षण रन के लिए ग्रंथ डाउनलोड करना शुरू कर दिया है। मैं सब कुछ Internet Archive से ले रहा हूँ और मैंने समयावधि 1800-1875 तक बढ़ा दी है। विविध प्रकार के ग्रंथ प्राप्त करने के लिए, आप Internet Archive पर विषय और खोज फ़िल्टर का उपयोग कर सकते हैं जैसे प्रकाशन स्थान, समयावधि और विषय।</p><p><img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/searchfilter.jpg" alt="Search Filters"></p><h2>16 जुलाई, 2025</h2></p><p>मैंने Internet Archive से लगभग 500 txt फाइलें डाउनलोड कीं और उन्हें साफ करने के बाद (सिर्फ व्हाइटस्पेस, गुटेनबर्ग हैडर आदि हटाकर) मेरे पास लगभग 500MB डेटा बचा है। यह एक छोटा सा डेटासेट है लेकिन पिछली बार मैंने 187MB से प्रशिक्षण लिया था, तो प्रशिक्षण के बाद आउटपुट में कुछ न कुछ उल्लेखनीय अंतर होना चाहिए। मुझे उम्मीद है कि यह मॉडल कम से कम अधिक सुसंगत वाक्य उत्पन्न कर सकेगा जो कुछ हद तक अर्थपूर्ण हों। बेशक यह कोई गारंटी नहीं है क्योंकि यह अभी भी एक बहुत ही छोटा डेटासेट है, लेकिन यह पिछली बार से अधिक है।</p><p>यह मेरे अपने हार्डवेयर पर संभव होना चाहिए, यह अच्छा भी है क्योंकि मैं किसी बड़े डेटासेट पर जाने से पहले कुछ सुधार देख सकूं, जिसमें मुझे GPU किराए पर लेना पड़ेगा। लेकिन चिंता न करें मैं जल्द ही GPU किराए पर लेने की योजना बना रहा हूं, लेकिन इससे पहले मैं चाहूंगा कि मेरा डेटासेट जितना हो सके उतना संकलित और साफ हो। मेरी एक समस्या सफाई है, इन txt फाइलों में बहुत सारा बेमतलब का कंटेंट मिला होता है। मैंने सफाई के लिए जो स्क्रिप्ट्स इस्तेमाल की हैं वे काम करती हैं लेकिन 100% प्रभावी नहीं हैं।</p><p>मैं आज ही इस डेटासेट को प्रशिक्षित करूंगा और इसमें लगभग 4-5 घंटे लगने चाहिए। जब यह हो जाएगा और मैं इसका परीक्षण करूंगा, तो अपडेट दूंगा। मेरे प्रोजेक्ट को देखने के लिए सभी का धन्यवाद, मुझे कुछ लोगों ने OCR संसाधनों के लिंक भी दिए हैं, इसके लिए भी धन्यवाद! मुझे उम्मीद है कि और लोग इसे आजमाएं और अपने-अपने डेटासेट के साथ प्रयोग करें।</p><h3>प्रशिक्षण अपडेट</h3></p><p>मैंने 435MB (108 मिलियन टोकन) कॉर्पस पर प्रशिक्षण शुरू किया, यह अभी काफी अच्छा चल रहा है। पहले 2800 इटरेशन में ट्रेन लॉस 10.9 से घटकर 4.9 हो गया। मुझे उम्मीद है कि पूरा होने में लगभग 8 या 9 घंटे लगेंगे। पूरा होने के बाद मैं एक और अपडेट पोस्ट करूंगा।</p><h2>17 जुलाई, 2025</h2></p><p>दूसरे मॉडल का प्रशिक्षण पूरा हो गया है, मेरे 4060 ने लगभग 8 घंटे 40 मिनट (3,900 इटरेशन/घंटा) में 33,000 इटरेशन (5 ईपोक्स) पूरे किए। अंतिम ट्रेन लॉस 3.73 था। आउटपुट आश्चर्यजनक रूप से अच्छे थे, अब यह सच में 19वीं सदी की शैली के सुसंगत वाक्य उत्पन्न करता है।</p><h2>28 जुलाई, 2025</h2></p><p>मैंने v0.5 को Hugging Face पर अपलोड कर दिया है, <a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">यहां देखें</a> अगर आप चाहें। अब आप मेरा रिपॉजिटरी डाउनलोड कर सकते हैं और इसे लोकली चला सकते हैं। दुर्भाग्यवश nanoGPT HuggingFace के साथ सीधे काम नहीं करता, इसलिए आपको मॉडल डाउनलोड करके लोकली चलाना होगा।</p><p>साथ ही, मैं अपने अगले प्रशिक्षण रन के लिए डेटा संकलित करना शुरू करूंगा, मुझे लगता है कि तर्क क्षमता हासिल करने के लिए शायद 5-10 गुना अधिक डेटा चाहिए होगा।</p><h2>2 अगस्त, 2025</h2></p><p>मैं जल्द ही Version 1 पर काम शुरू करने जा रहा हूं। मुझे nanoGPT की आर्किटेक्चर से कुछ अधिक आधुनिक पर स्विच करना होगा। मेरे दिमाग में कई ओपन-सोर्स LLM आर्किटेक्चर हैं, जैसे: OpenLLaMA v3, Phi-2 और Qwen 1.5B। और V1 के लिए, मुझे और बड़ा व विविध डेटासेट सावधानी से संकलित करना होगा। मुझे कम से कम 5GB साफ प्रशिक्षण डेटा की आवश्यकता होगी।</p><h1>V0 मॉडल व्यवहार और सीमाएँ</h1></p><p>प्रारंभिक प्रॉम्प्ट्स में मॉडल 1800 के दशक की भाषा और व्यवहार में प्रतिक्रिया देता है। उदाहरण के लिए, मैंने इसे "Who art Henry?" पूछा और इसने उत्तर दिया "I know that man, I have did not a black, the storm." और हाँ, उस वाक्य का कोई अर्थ नहीं है लेकिन LLM समझ रहा है कि मैं किसी व्यक्ति के बारे में पूछ रहा हूँ।</p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="TimeLockLLM Sample Output"></p><p>यहाँ आधुनिक अवधारणाओं का कोई उल्लेख नहीं है, आउटपुट में अधिकांश शब्द और वाक्यांश 1800 के दशक के हैं।</p><p>इसे अभी भी बहुत काम की जरूरत है, 187MB डेटा से ट्रेनिंग करने से आपको जटिल तर्क वाली टेक्स्ट उत्पन्न करने वाला मॉडल नहीं मिलेगा।</p><p>अभी यह ऐसे वाक्य बनाता है जिनमें पूरी वाक्य संरचना नहीं होती और कुल मिलाकर कोई अर्थ नहीं बनता, लेकिन यह इस ट्रेनिंग साइज के लिए सामान्य है।</p><h1>V0.5 मॉडल व्यवहार और सीमाएँ</h1></p><p>यह पिछले मॉडल की तुलना में अच्छा सुधार है। लेखन शैली और शब्दावली विक्टोरियन है और लगभग हर वाक्य व्याकरणिक रूप से सही है और उचित विराम चिह्नों के साथ है। और फिर, यह शुरू से ट्रेन किया गया है इसलिए यह 1800 के दशक के विषयों तक ही सीमित रहता है।</p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="TimeLockLLM Sample Output"></p><p>यहाँ बहुत सारी तथ्यों की कल्पनाएँ हैं। अधिकांश (लगभग 100%) विवरण (तिथियाँ, घटनाएँ, ऐतिहासिक व्यक्ति) काल्पनिक हैं। इसके अलावा वाक्य आपस में जुड़ते नहीं हैं, कभी-कभी शायद 2 वाक्य जुड़े हुए लग सकते हैं लेकिन उससे आगे नहीं। एक और समस्या है कि कभी-कभी “Digitized by Google” फुटर आ जाता है, तो अगली बार मुझे ट्रेनिंग से पहले टेक्स्ट को अच्छे से साफ़ करना होगा। कुल मिलाकर मैं परिणामों से बहुत खुश हूँ, यह LLM के स्तर पर नहीं है लेकिन निश्चित रूप से एक वाक्य जनरेटर है।</p><p>मैं बहुत कुछ सीख रहा हूँ और आने वाले हफ्तों में पता करूंगा कि मुझे क्या बेहतर करना है। मैं जल्द ही फाइलें अपलोड करूंगा!</p><h1>आगामी योजनाएँ</h1></p><p>(पूरा हुआ) मैं वर्शन 0.5 पर काम शुरू करने जा रहा हूँ, 50 किताबों की जगह मैं आदर्श रूप से 500-600 किताबों से ट्रेन करूंगा। अभी मैं nanoGPT का उपयोग करके 1800-1850 की किताबें ट्रेन कर रहा हूँ, और खासकर लंदन से। इसमें कुछ चुनौतियाँ हैं जैसे यह सुनिश्चित करना कि जो किताबें मुझे मिलें वे अपडेटेड या आधुनिक व्याख्याओं वाली न हों बल्कि मेरी चुनी हुई समय सीमा के भीतर प्रकाशित असंपादित किताबें हों।</p><p>मैं एक नया मॉडल (v1) एक बड़े कॉर्पस के साथ ट्रेन करना चाहता हूँ, शायद v0.5 के मुकाबले 5-10 गुना बड़ा। मेरा लक्ष्य है कि क्या केवल Selective Temporal Training से तर्क क्षमताएँ उत्पन्न हो सकती हैं, यह अधिक कठिन कार्य होगा और मैं पूरी तरह निश्चित नहीं हूँ कि यह ऐतिहासिक डेटा सीमाओं के कारण संभव है या नहीं। आने वाले हफ्तों में मैं 5-10GB का कॉर्पस तैयार करने की कोशिश करूंगा। मुझे विश्वास है कि यदि मुझे साफ, उच्च गुणवत्ता वाला डेटा मिल जाए और GPU किराए पर ले सकूं, तो प्रगति होगी।</p><h1>इस प्रोजेक्ट का उपयोग कैसे करें</h1></p><p>यह प्रोजेक्ट मुख्य रूप से ऐतिहासिक डेटा एकत्र करने, उसे ट्रेनिंग के लिए तैयार करने और टोकनाइज़र बनाने पर केंद्रित है। मैं यहाँ पूरी LLM ट्रेनिंग प्रक्रिया नहीं बताऊंगा, उसके लिए Andrej Karpathy का nanoGPT देखें।</p><h1>चरण 1: ऐतिहासिक ग्रंथ एकत्रित और तैयार करें</h1></p><p>अपने चुने हुए समय अवधि (जैसे, लंदन 1800-1850) के सार्वजनिक डोमेन की किताबें, दस्तावेज़ आदि की .txt फाइलें इकट्ठा करें।</p><p>यदि आवश्यकता हो तो आप download_texts_improved.py का उपयोग करके किताबें डाउनलोड कर सकते हैं।</p><p>टेक्स्ट फाइलों को स्क्रिप्ट या मैन्युअली साफ करें, जैसे प्रोजेक्ट गुटेनबर्ग के हेडर/फुटर, आधुनिक टिप्पणियाँ या OCR की गलतियाँ हटाएँ।</p><p>prepare_dataset.py ठीक से काम करना चाहिए।</p><h1>चरण 2: कस्टम टोकनाइज़र बनाएँ</h1></p><p>साफ की गई डेटा पर train_tokenizer.py या train_tokenizer_hf.py चलाएँ।
यह आपको vocab.json और merges.txt देगा।</p><p>ये फाइलें आपके मॉडल के लिए शब्दावली और मर्ज नियम परिभाषित करती हैं।</p><h1>चरण 3: अपना मॉडल ट्रेन करें (nanoGPT)</h1></p><p>ट्रेनिंग प्रक्रिया के लिए <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">Andrej Karpathy का nanoGPT</a> देखें।</p><p>अगर चाहें तो आप कोई और LLM ट्रेन कर सकते हैं, लेकिन मैंने nanoGPT का उपयोग किया।</p><h1>सामान्य प्रश्न</h1></p><h2>Selective Temporal Training क्या है?</h2></p><p>Selective Temporal Training (STT) एक मशीन लर्निंग पद्धति है जिसमें सभी ट्रेनिंग डेटा विशेष रूप से एक निश्चित ऐतिहासिक समयावधि के भीतर चुना जाता है। इसका उद्देश्य उस युग की भाषा और ज्ञान को बिना आधुनिक प्रभाव के मॉडल करना है। उदाहरण के लिए, मेरा वर्तमान मॉडल (v0.5) पूरी तरह 1800-1875 की डेटा पर ट्रेन है, यह फाइन ट्यून नहीं किया गया बल्कि शुरू से ट्रेन है, जिससे आउटपुट उस समय की भाषाशैली और ऐतिहासिक संदर्भ को दर्शाता है।</p><h2>फाइन-ट्यूनिंग या LoRA का उपयोग क्यों नहीं?</h2></p><p>इस प्रोजेक्ट के लिए मैं ऐसा भाषा मॉडल बनाना चाहता हूँ जिसमें आधुनिक पूर्वाग्रह न हो। अगर मैं GPT-2 जैसा कुछ फाइन-ट्यून करता हूँ, तो वह पहले से ही प्री-ट्रेंड है और वह जानकारी हटाई नहीं जा सकती। अगर मैं शुरू से ट्रेन करता हूँ तो भाषा मॉडल सिर्फ पुराना होने का दिखावा नहीं करेगा, वह सच में वही होगा। इस प्रोजेक्ट का लक्ष्य फिलहाल यही है कि यह केवल 1800 से 1850 के बीच लंदन में प्रकाशित किताबों के ज्ञान से ही तर्क कर सके।</p><h2>ट्रेनिंग के लिए आपने किस तरह का डेटा इस्तेमाल किया?</h2></p><p>मैं किताबें, कानूनी दस्तावेज़, अखबार, और अन्य लेखन 1800–1850 के लंदन से इस्तेमाल कर रहा हूँ। जो सूची मैंने लिंक की है उसमें लगभग 200 दस्तावेज़ हैं लेकिन पहली ट्रेनिंग के लिए मैंने सिर्फ 50 फाइलें (~187 MB) इस्तेमाल कीं। आप दस्तावेज़ों की सूची देख सकते हैं:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><h2>वर्शन 0 मॉडल कितना बड़ा है?</h2></p><p>यह मॉडल अभी बहुत छोटा है, मैं यह सिर्फ मज़े के लिए कर रहा हूँ और बिना आधुनिक स्रोतों के सख्त ट्रेनिंग नियम का पालन कर रहा हूँ। इसमें लगभग 16 मिलियन पैरामीटर हैं लेकिन मैं और पुराने ग्रंथ एकत्र करना शुरू करूंगा ताकि अगला मॉडल ट्रेन कर सकूं। जैसे-जैसे आगे बढ़ूंगा अपडेट दूंगा।</p><h2>ट्रेनिंग स्पेक्स?</h2></p><p>GPU: Geforce rtx 4060
CPU: i5-13400F
रैम: 16GB DDR5.</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-08-07

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-08-07 
    </div>
    
</body>
</html>