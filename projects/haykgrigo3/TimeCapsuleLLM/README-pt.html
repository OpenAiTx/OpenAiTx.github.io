<!DOCTYPE html>
<html lang="pt">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - Um LLM treinado apenas com dados de determinados per&#237;odos para reduzir o vi&#233;s moderno</title>
    <meta name="description" content="Um LLM treinado apenas com dados de determinados per&#237;odos para reduzir o vi&#233;s moderno">
    <meta name="keywords" content="TimeCapsuleLLM, Portuguese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "Um LLM treinado apenas com dados de determinados períodos para reduzir o viés moderno",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 830
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-pt.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2026-01-09",
  "dateModified": "2026-01-09"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 830 stars</span>
                <span class="language">Portuguese</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align="right">
  <details>
    <summary >🌐 Idioma</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-TW">繁體中文</a> 
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=as">हिन्दी</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=th">ไทย</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=es">Español</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ar">العربية</a>
        | <a href="#" title="Coming soon">فارسی (em breve)</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=vi">Tiếng Việt</a>
        | <a href="#" title="Coming soon">Bahasa Indonesia (em breve)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1></p><p><em>Um modelo de linguagem treinado <strong>do zero</strong> exclusivamente com dados de determinados locais e períodos históricos para reduzir o viés moderno e emular a voz, o vocabulário e a visão de mundo da época.</em></p><p>Imagine se um modelo de IA não apenas fingisse ser histórico, mas realmente fosse.</p><p>v0 e v0.5 construídos sobre <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT por Andrej Karpathy</a> Os scripts principais de treinamento e a arquitetura do modelo são de autoria dele. </p><p>v1 construído sobre <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Phi 1.5 da Microsoft</a></p><p><a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">Link Hugging Face</a></p><h2> Comportamento do Modelo & Limitações</h2></p><h3><strong>v0</strong>  </h3></p><p>Os primeiros prompts mostram o modelo respondendo com linguagem e comportamento do século XIX. 
Exemplo: Prompt: "Who art Henry?" e respondeu "I know that man, I have did not a black, the storm." </p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="Saída de Amostra TimeLockLLM"></p><ul><li>Nenhuma menção a conceitos modernos  </li>
<li>Vocabulário em sua maioria fiel à época  </li>
<li>Frases em sua maioria incoerentes (esperado para ~187MB de dados de treinamento)</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>Uma melhoria significativa em relação ao v0.  
<ul><li>Estilo de escrita vitoriano, pontuação adequada, frases em sua maioria gramaticais  </li>
<li>Ainda alta taxa de alucinação factual  </li>
<li>Ruído de OCR (“Digitized by Google”) ainda presente nas saídas</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="Saída de Amostra TimeLockLLM"></p><h3><strong>v1</strong></h3></p><p>Primeiro modelo a recordar e conectar um evento histórico real com uma figura real do conjunto de dados.</p><p>Exemplo: Prompt: "It was the year of our Lord 1834" </p><p>A saída: "It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity" </p><p>A princípio presumi que um protesto poderia ter ocorrido coincidentemente no mesmo ano, mas veja isto: <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3><strong>v2mini-eval1</strong></h3></p><p>Treinado usando uma amostra de 15GB do conjunto de dados de 90GB do v2.</p><p>Modelo treinado por apenas 10.000 etapas.</p><p>Houve um problema com a tokenização que faz com que a saída fique assim:</p><p>PROMPT:
Quem é Charles Dickens?</p><p>
W ho is Charles D ic ens ? D oes that work more of h ise x cell ent st ir ring , in his pl ays , int he G reat C omp any 's f arm ? What I have y et to qu ote from J ack P ick ett ? D oy oun ot know th att hey were as pe cies of g all oping , ors aw ing oft heir bre asts , or what w ast ob ed one about the t im ew hen J acks on was looking ont hew ind ow ? What ist hes uccess of an English man , and which h isson has not be end is cover ing t ome , where by to acc omp lish such a we ight ? D idy ou ever m ake ap ass age int othe old road way , ort o an anch or - b ree ze att he foot of our boat , which you m ust le ave us ? The fact is , that whe ther the wind would rise up from the pl ain on S atur day night orn o ont ide , ort ill then orth , or other wise , wes hall be com pelled t od esc ribe af orm idable bar rier , with t hes ame e ffect s ast he p resent . In th iss itu ation , at le ast , itis not to omuch t os ay that we have le ft that room . I bel ieve there are three c op ies int he " F ive H undred - fold ," to bere fer red to , ast he first n umber of our read ers wh ow is ht
Corrigido:</p><p>"Quem é Charles Dickens? Isso funciona mais da sua excelente comoção, em suas peças, na fazenda da Grande Companhia? O que ainda tenho a citar de Jack Pickett? Você não sabe que eles eram uma espécie de galope, ou serração de seus peitos, ou o que deveria ser feito na época em que Jackson olhava pela janela? Qual é o sucesso de um inglês, e o que seu filho ainda não descobriu para mim, pelo qual realizar tal peso? Você já fez uma passagem para a velha estrada, ou para uma brisa de âncora ao pé do nosso barco, que você deve nos deixar? O fato é que, se o vento se levantaria da planície no sábado à noite ou ao meio-dia, ou até o norte, ou de outra forma, seremos obrigados a descrever uma barreira formidável, com os mesmos efeitos do presente. Nesta situação, pelo menos, não é exagero dizer que deixamos aquele quarto. Acredito que há três cópias no 'Quinhentas vezes', para serem referidas, como o primeiro número de nossos leitores que desejam t[o]..."</p><h3><strong>v2mini-eval2</strong></h3></p><p>Treinado usando a mesma amostra de 15GB usada para treinar o eval1.
O modelo foi novamente treinado por apenas 10K passos.</p><p>PROMPT:Charles Darwin</p><p>Charles DarwinECCEMACY. Senhor, — O seguinte caso é interessante para mim: — Estive em Londres por uma quinzena e fui muito afetado por um ataque de reumatismo. O primeiro ataque de reumatismo foi uma semana antes de eu vê-lo, e o segundo quando o vi, e o terceiro quando o vi, e o terceiro no mesmo tempo. O segundo ataque de gota, no entanto, não foi acompanhado por sintomas febris, mas foi acompanhado por um aumento no fluxo de urina, e por uma descarga mais copiosa de urina. O terceiro ataque foi uma hora depois que o vi, e foi sucedido por um retorno de um paroxismo de gota, e um retorno mais rápido da gota. O quarto ataque também foi acompanhado por uma febre, mas nem sempre foi acompanhado por sintomas febris. O terceiro ataque de gota foi uma quinzena depois que você esteve doente, e o quarto foi seguido por um paroxismo de gota. O quarto ataque foi uma quinzena depois que você foi atacado, e foi acompanhado por uma sensação</p><h2> Conjuntos de Dados</h2></p><h3><strong>v2</strong></h3></p><ul><li>90GB de textos londrinos de 1800-1875</li>
<li>136.344 documentos</li>
<li>Os 90GB completos ainda não estão disponíveis pois não foram tokenizados, mas você pode encontrar uma amostra de 15GB aqui: https://huggingface.co/datasets/haykgrigorian/TimeCapsuleLLM-London-1800-1875-v2-15GB</li></p><p> </ul>### Estatísticas de Viés 
  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/pronoun_bias.png" alt="Viés de pronome"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/geographic_bias.png" alt="Viés geográfico"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/temporal_bias.png" alt="Viés temporal"></p><p>Consulte o <a href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/v2_bias_report.json" target="_blank" rel="noopener noreferrer">relatório de viés v2</a> para mais informações.</p><h2>Como Usar</h2></p><p>Este projeto foca principalmente na curadoria de dados históricos, preparação para treinamento e construção de um tokenizador. Não vou abordar o processo completo de treinamento de LLM, para isso consulte o nanoGPT de Andrej Karpathy.</p><h3>Passo 1: Reunir e Preparar Textos Históricos </h3></p><ul><li>Colete arquivos .txt de livros de domínio público, documentos, etc do período escolhido (ex: Londres 1800-1850)</li></p><p><li>Mantenha-os dentro do intervalo de tempo/local escolhido  </li>
<li>Limpe os arquivos de texto usando um script ou remova manualmente cabeçalhos/rodapés do Project Gutenberg, anotações modernas ou coisas como erros de OCR.</li></p><p></ul><h3>Passo 2: Construa um Tokenizador Personalizado</h3></p><ul><li>Execute train_tokenizer.py ou train_tokenizer_hf.py nos dados limpos.</li>
<li>Isso irá gerar vocab.json e merges.txt</li>
<li>Esses arquivos definem o vocabulário e as regras de mesclagem para seu modelo</li></p><p></ul><h3>Passo 3: Treine Seu Modelo</h3></p><ul><li>Consulte <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT de Andrej Karpathy</a> para o processo de treinamento ou a documentação da arquitetura escolhida.</li></p><p></ul><h1>FAQ</h1></p><h2>O que é Treinamento Temporal Seletivo?</h2></p><p>O Treinamento Temporal Seletivo (STT) é uma metodologia de aprendizado de máquina onde todos os dados de treinamento são especificamente selecionados para se enquadrar em um determinado período histórico. É feito para modelar a linguagem e o conhecimento daquela época sem influência de conceitos modernos. Por exemplo, o modelo que possuo agora (v0.5) foi treinado exclusivamente com dados de 1800-1875, não foi ajustado, mas treinado do zero, resultando em uma saída que reflete o estilo linguístico e contexto histórico daquele período.</p><h2>Por que não apenas usar fine-tuning ou LoRA?</h2></p><p>Para este projeto, estou tentando criar um modelo de linguagem livre de vieses modernos. Se eu ajustar algo como o GPT-2, ele já está pré-treinado e essa informação não será removida. Se eu treinar do zero, o modelo de linguagem não vai fingir ser antigo, ele simplesmente será. O objetivo deste projeto agora é criar algo que possa raciocinar exclusivamente usando conhecimento de livros de Londres publicados entre 1800 e 1875.</p><h2>Que tipo de dados você usou para o treinamento?</h2></p><p>Estou usando livros, documentos legais, jornais e outros escritos de Londres entre 1800–1875. A lista que eu linkei (para v0) tem cerca de 200, mas para o primeiro treinamento usei apenas 50 arquivos de aproximadamente 187 MB. Você pode ver uma lista dos documentos:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>Tamanhos dos datasets:
<ul><li>v0: ~187MB</li>
<li>v0.5: ~435MB </li>
<li>v1: ~6,25GB </li>
<li>v2mini-eval1: 15GB</li></p><p></ul><h2>Qual o tamanho dos modelos?</h2></p><p>v0: 16M Parâmetros</p><p>v0.5 123M Parâmetros</p><p>v1: 700M Parameters</p><p>v2mini-eval1: 300M Parameters</p><h1>Training Specs ? </h1></p><h1>v0/v0.5</h1>
GPU: Geforce rtx 4060
CPU: i5-13400F 
Ram: 16GB DDR5.</p><h1>v1</h1>
GPU: A100 SXM rented</p><h1>v2mini-eval1</h1></p><p>GPU: A100 SXM rented</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-01-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-01-09 
    </div>
    
</body>
</html>