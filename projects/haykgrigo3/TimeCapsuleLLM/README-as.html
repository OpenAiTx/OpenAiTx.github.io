<!DOCTYPE html>
<html lang="as">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - আধুনিক পক্ষপাত কমাবলৈ নিৰ্দিষ্ট সময়কালৰ তথ্যতহলতহে প্ৰশিক্ষিত LLM</title>
    <meta name="description" content="আধুনিক পক্ষপাত কমাবলৈ নিৰ্দিষ্ট সময়কালৰ তথ্যতহলতহে প্ৰশিক্ষিত LLM">
    <meta name="keywords" content="TimeCapsuleLLM, Assamese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "আধুনিক পক্ষপাত কমাবলৈ নিৰ্দিষ্ট সময়কালৰ তথ্যতহলতহে প্ৰশিক্ষিত LLM",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 830
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-as.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2026-01-09",
  "dateModified": "2026-01-09"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 830 stars</span>
                <span class="language">Assamese</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align="right">
  <details>
    <summary >🌐 ভাষা</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">ইংৰাজী</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">সৰল চীনা</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-TW">জটিল চীনা</a> 
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">জাপানী</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">কোৰিয়ান</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=as">হিন্দী</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=th">থাই</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=fr">ফ্ৰেঞ্চ</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=de">জাৰ্মান</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=es">স্পেনিছ</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=it">ইটালিয়ান</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ru">ৰাছিয়ান</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pt">পৰ্তুগীজ</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=nl">ডাচ</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pl">পোলিশ</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ar">আৰবী</a>
        | <a href="#" title="Coming soon">ফার্সী (শীঘ্ৰে আহিব)</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=tr">তুৰ্কী</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=vi">ভিয়েটনামীজ</a>
        | <a href="#" title="Coming soon">বাহাসা ইণ্ডোনেছিয়া (শীঘ্ৰে আহিব)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>টাইমক্যাপচুল এলএলএম</h1></p><p><em>এক ভাষা মডেল যি <strong>শূন্যৰ পৰা</strong> কেৱল নিৰ্দিষ্ট স্থান আৰু সময়ৰ তথ্যত প্ৰশিক্ষিত হৈছে, আধুনিক পক্ষপাত কমাবলৈ আৰু সেই যুগৰ ভাষা, শব্দভাণ্ডাৰ আৰু চিন্তাধাৰা অনুকৰণ কৰিবলৈ।</em></p><p>ভাবক, যদি এটা AI মডেল কেৱল ইতিহাসৰ দৰে অভিনয় নকৰে, বৰং সত্যই ইতিহাসৰ হৈছে।</p><p>v0 আৰু v0.5 <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT by Andrej Karpathy</a> ত নিৰ্মিত। মূল প্ৰশিক্ষণ স্ক্ৰিপ্ট আৰু মডেলৰ স্থাপত্য তেওঁৰ কাম। </p><p>v1 <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Microsoft ৰ Phi 1.5</a> ত নিৰ্মিত</p><p><a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">Hugging Face লিংক</a></p><h2> মডেলৰ আচৰণ & সীমাবদ্ধতা</h2></p><h3><strong>v0</strong>  </h3></p><p>প্ৰাথমিক প্ৰম্প্টসমূহত মডেলে 1800 দশকৰ ভাষা আৰু আচৰণত প্ৰতিক্ৰিয়া দেখুৱাইছিল।
উদাহৰণ: প্ৰম্প্ট: "Who art Henry?" আৰু উত্তৰ দিলে "I know that man, I have did not a black, the storm."</p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="TimeLockLLM নমুনা আউটপুট"></p><ul><li>আধুনিক পৰিকल्पনাৰ উল্লেখ নাই  </li>
<li>প্ৰায়কৈ যুগ-উপযুক্ত শব্দচয়ন  </li>
<li>বাক্যবোৰ প্ৰায় অসংলগ্ন (~187MB প্রশিক্ষণ ডাটা হিচাপে আশা কৰা)</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>v0-ৰ তুলনাত উল্লেখযোগ্য উন্নতি।
<ul><li>ভিক্টোৰিয়ান লিখন শৈলী, সঠিক বিরাম চিহ্ন, প্ৰায় শুদ্ধ বাক্য</li>
<li>তথ্যমূলক ভুলৰ হার এতিয়াও উচ্চ</li>
<li>OCR শব্দৰ বিভ্ৰান্তি (“Digitized by Google”) এতিয়াও আউটপুটত উপস্থিত</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="TimeLockLLM নমুনা আউটপুট"></p><h3><strong>v1</strong></h3></p><p>প্ৰথম মডেল যি বাস্তৱ ইতিহাসিক ঘটনা আৰু তথ্যভিত্তিক ব্যক্তিক dataset-ৰ সৈতে সংযোগ কৰিলে।</p><p>উদাহৰণ: প্ৰম্প্ট: "It was the year of our Lord 1834"</p><p>উৎপাদন: "It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity"</p><p>প্ৰথমতে ভাবিছিলো সেই বছৰত প্ৰতিবাদ কাকতিয়াকৈ হৈছিল; কিন্তু এইটো চাওক: <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3><strong>v2mini-eval1</strong></h3></p><p>v2-ৰ 90GB dataset-ৰ পৰা 15GB নমুনা ব্যৱহাৰ কৰি প্রশিক্ষণ কৰা।</p><p>মডেল কেৱল ১০,০০০ ষ্টেপলৈকে প্ৰশিক্ষণ দিয়া হৈছে।</p><p>টোকেনাইজেশ্বনত এটা সমস্যা আছিল যাৰ বাবে আউটপুট এইদৰে দেখিবলৈ পোৱা গৈছে:</p><p>প্ৰম্পট:
চাৰ্লছ ডিকেন্স কোন?</p><p>
W ho is Charles D ic ens ? D oes that work more of h ise x cell ent st ir ring , in his pl ays , int he G reat C omp any 's f arm ? What I have y et to qu ote from J ack P ick ett ? D oy oun ot know th att hey were as pe cies of g all oping , ors aw ing oft heir bre asts , or what w ast ob ed one about the t im ew hen J acks on was looking ont hew ind ow ? What ist hes uccess of an English man , and which h isson has not be end is cover ing t ome , where by to acc omp lish such a we ight ? D idy ou ever m ake ap ass age int othe old road way , ort o an anch or - b ree ze att he foot of our boat , which you m ust le ave us ? The fact is , that whe ther the wind would rise up from the pl ain on S atur day night orn o ont ide , ort ill then orth , or other wise , wes hall be com pelled t od esc ribe af orm idable bar rier , with t hes ame e ffect s ast he p resent . In th iss itu ation , at le ast , itis not to omuch t os ay that we have le ft that room . I bel ieve there are three c op ies int he " F ive H undred - fold ," to bere fer red to , ast he first n umber of our read ers wh ow is ht
শুদ্ধিকৰণ:</p><p>"চাৰ্লছ ডিকেন্স কোন? তেওঁৰ উৎকৃষ্ট আৰু উদ্দীপক কৰ্মসমূহ, তেওঁৰ নাটকৰ ক্ষেত্ৰত, গ্ৰেট কোম্পানীৰ খেতিত, অধিক কাম কৰিছিল নেকি? মই এতিয়াও জেক পিকেটৰ পৰা উদ্ধৃত কৰিব লাগিছে নেকি? আপুনি নাজানে নেকি যে সেইসকল গালপিং, নাইবা ছাতীৰে চিৰা মৰা, নাইবা কি কৰিব লাগিব সেই সময়ত যেতিয়া জেকছনে খিৰিকিৰ পৰা চাই আছিল? এজন ইংৰাজৰ সফলতা কি, আৰু তেওঁৰ পুত্ৰে মোক এতিয়াও আৱিষ্কাৰ কৰা নাই, যাতে এনে এটা বিশাল কাম সম্পন্ন কৰিব পাৰি? আপুনি কেতিয়াবা পুৰণি পথেদি গৈছিলেনে, নাইবা আমাৰ নাওৰ তলত এংকৰ-ব্ৰিজত, য'ত আপুনি আমাক এৰি যাব লাগিব? কথাটো হৈছে, বতাহখন শনিবাৰে ৰাতিপুৱা নাইবা দুপৰীয়া, নাইবা উত্তৰৰ পৰা, নাইবা আন স্থানৰ পৰা আহিব নে, আমি এটা ভয়ংকৰ বাধা বৰ্ণনা কৰিবলৈ বাধ্য হ'ম, বৰ্তমানৰ দৰে একে প্ৰভাৱৰে। এই পৰিস্থিতিত, অন্ততঃ, ক'বলৈ বেছি নহয় যে আমি সেই কোঠাটো এৰি আহিছোঁ। মই বিশ্বাস কৰোঁ যে 'ফাইভ হানড্ৰেড-ফোল্ড'ত তিনি টা কপি আছে, উল্লেখ কৰিবৰ বাবে, আমাৰ পাঠকৰ প্ৰথম সংখ্যাত যিসকলে ইচ্ছা কৰে t[o]..."</p><h3><strong>v2mini-eval2</strong></h3></p><p>এভাল১-ৰ সৈতে একে ১৫GB নমুনা ব্যৱহাৰ কৰি প্ৰশিক্ষণ দিয়া হৈছে।
মডেলটো আকৌ কেৱল ১০,০০০ খোজলৈকে প্ৰশিক্ষিত হৈছে।</p><p>PROMPT: Charles Darwin</p><p>Charles DarwinECCEMACY. ছাৰ, — তলৰ ঘটনাটো মোৰ বাবে ৰসাল: — মই লণ্ডনত এটা সপ্তাহ আছিলোঁ, আৰু গাঁঠিৰ ব্যথাত ভয়ংকৰ ভুগিছিলোঁ। গাঁঠিৰ প্ৰথম আক্ৰমণটো আপুনি মোক দেখাৰ এটা সপ্তাহ আগতে হৈছিল, দ্বিতীয়টো আপুনি মোক দেখাত, আৰু তৃতীয়টো আকৌ একেটা সময়ত। গাউটৰ দ্বিতীয়টো আক্ৰমণ যদিও কোনো জ্বৰজনিত লক্ষণৰ সৈতে নহ'ল, কিন্তু পেছাবৰ পৰিমাণ বৃদ্ধি পালে, আৰু অধিক পৰিমাণে পেছাব নিগৰালে। তৃতীয়টো আক্ৰমণ আছিল আপুনি মোক দেখাৰ এটা ঘণ্টা পিছত, আৰু তাৰ পিছতে আকৌ গাউটৰ আক্ৰমণ ঘূৰি আহিল, আৰু গাউটৰ অধিক তীব্ৰ আক্ৰমণ। চতুৰ্থটো আক্ৰমণো জ্বৰ লৈ আহিছিল, কিন্তু সদায় জ্বৰজনিত লক্ষণ নাছিল। গাউটৰ তৃতীয়টো আক্ৰমণ হৈছিল আপুনি অসুস্থ হোৱা এটা সপ্তাহ পিছত, আৰু চতুৰ্থটো আক্ৰমণ আকৌ গাউটৰ আক্ৰমণৰ পিছত। চতুৰ্থটো আক্ৰমণ আছিল আপুনি আক্ৰমিত হোৱাৰ এটা সপ্তাহ পিছত, আৰু সৈতে এটা অনুভূতি আছিল।</p><h2> ডেটাসেটসমূহ</h2></p><h3><strong>v2</strong></h3></p><ul><li>১৮০০-১৮৭৫ লণ্ডনৰ পাঠ্যৰ ৯০GB</li>
<li>১,৩৬,৩৪৪ টা নথিপত্ৰ</li>
<li>সম্পূৰ্ণ ৯০GB এতিয়াও উপলব্ধ নহয় কাৰণ ই এতিয়াও টোকেনাইজ হোৱা নাই, কিন্তু আপুনি ১৫GB নমুনা ইয়াত পাব: https://huggingface.co/datasets/haykgrigorian/TimeCapsuleLLM-London-1800-1875-v2-15GB</li></p><p> </ul>### পক্ষপাতি তথ্য
  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/pronoun_bias.png" alt="সৰ্বনাম পক্ষপাতি"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/geographic_bias.png" alt="ভৌগোলিক পক্ষপাতি"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/temporal_bias.png" alt="কালগত পক্ষপাতি"></p><p>অধিক তথ্যৰ বাবে <a href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/v2_bias_report.json" target="_blank" rel="noopener noreferrer">v2 পক্ষপাতি প্ৰতিবেদন</a> চাওক।</p><h2>ব্যৱহাৰ কিদৰে কৰিব</h2></p><p>এই প্ৰকল্পটো মূলতঃ ঐতিহাসিক তথ্য সংগ্ৰহ, প্ৰস্তুতি আৰু টোকেনাইজাৰ নিৰ্মাণত কেন্দ্ৰিত। মই সম্পূৰ্ণ LLM প্ৰশিক্ষণ প্ৰক্ৰিয়া আলোচনা নকৰোঁ, তাৰ বাবে Andrej Karpathy-ৰ nanoGPT চাওক।</p><h3>ধাপ ১: ঐতিহাসিক পাঠ্য সংগ্ৰহ আৰু প্ৰস্তুত কৰক</h3></p><ul><li>নিজৰ পছন্দৰ সময়ছোৱাৰ (যেনে, লণ্ডন ১৮০০-১৮৫০) ৰাজহুৱা ডমেইনৰ কিতাপ, নথিপত্ৰ আদি .txt ফাইল সংগ্ৰহ কৰক</li></p><p><li>আপোনাৰ নিৰ্বাচিত সময়/স্থান উইণ্ডোৰ ভিতৰত তেওঁলোকক ৰাখক  </li>
<li>টেক্সট ফাইলসমূহ স্ক্ৰিপ্ট ব্যৱহাৰ কৰি বা Project Gutenberg, আধুনিক টীকা বা OCR ত্ৰুটিসমূহৰ দৰে হেডাৰ/ফুটাৰ ম্যানুৱেলভাৱে আঁতৰাই পৰিষ্কাৰ কৰক।</li></p><p></ul><h3>পদক্ষেপ ২: এটা কাষ্টম ট’কেনাইজাৰ নিৰ্মাণ কৰক</h3></p><ul><li>পৰিষ্কৃত ডেটাত train_tokenizer.py বা train_tokenizer_hf.py চলাওক।</li>
<li>এইটো আপোনাক vocab.json আৰু merges.txt দিব</li>
<li>এই ফাইলসমূহে আপোনাৰ মডেলৰ বাবে শব্দভাণ্ডাৰ আৰু মাৰ্জ নিয়ম সংজ্ঞায়িত কৰে</li></p><p></ul><h3>পদক্ষেপ ৩: আপোনাৰ মডেলটো প্ৰশিক্ষণ কৰক </h3></p><ul><li>প্ৰশিক্ষণ প্ৰক্ৰিয়াৰ বাবে <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">Andrej Karpathy ৰ nanoGPT</a> অথবা আপোনাৰ পছন্দৰ স্থাপত্যৰ নথিপত্ৰ চাওক।</li></p><p></ul><h1>FAQ</h1></p><h2>Selective Temporal Training কি?</h2></p><p>Selective Temporal Training (STT) হৈছে এটা যন্ত্ৰ শিক্ষণ পদ্ধতি য’ত সকলো প্ৰশিক্ষণ তথ্য বিশেষভাৱে নিৰ্বাচিত, যাতে সেইটো এখন বিশেষ ঐতিহাসিক সময়চোৱাত পৰে। এইটো সেই যুগৰ ভাষা আৰু জ্ঞানক আধুনিক ধাৰণাৰ প্ৰভাৱৰ পৰা বাচি মডেল কৰিবলৈ কৰা হয়। উদাহৰণস্বৰূপে, মোৰ বৰ্তমান মডেল (v0.5) কেৱল ১৮০০-১৮৭৫ সময়চোৱাৰ তথ্যৰ ওপৰত প্ৰশিক্ষিত, ফাইন-টিউন কৰা নহয়, সম্পূৰ্ণভাৱে আৰম্ভণিৰ পৰা প্ৰশিক্ষিত, যাৰ ফলত সেই যুগৰ ভাষা শৈলী আৰু ঐতিহাসিক প্ৰসংগ প্ৰদর্শন কৰে।</p><h2>কেৱল fine-tuning বা LoRA ব্যৱহাৰ নকৰা কিয়?</h2></p><p>এই প্ৰকল্পত মই এজন ভাষা মডেল সৃষ্টি কৰিবলৈ চেষ্টা কৰিছো যি আধুনিক পক্ষপাতৰ পৰা মুক্ত। যদি মই GPT-2 যেনেকুৱা কিছুমান ফাইন-টিউন কৰোঁ, সেইটো ইতিমধ্যে প্ৰশিক্ষিত, আৰু সেই তথ্য আঁতৰাব নোৱাৰি। যদি মই আৰম্ভণিৰ পৰা প্ৰশিক্ষণ কৰোঁ, ভাষা মডেলে পুৰণি বুলি ভণিত নকৰে, সেয়া হব। বৰ্তমান এই প্ৰকল্পৰ লক্ষ্য হৈছে কেৱল ১৮০০-১৮৭৫ সময়চোৱাৰ লণ্ডনৰ পুথি-সমূহৰ জ্ঞান ব্যৱহাৰ কৰি যুক্তি কৰিব পৰা এটা মডেল সৃষ্টি কৰা।</p><h2>কোন ধৰণৰ তথ্য প্ৰশিক্ষণৰ বাবে ব্যৱহাৰ কৰা হৈছিল?</h2></p><p>মই ১৮০০-১৮৭৫ লণ্ডনৰ পুথি, আইনগত নথি, বাতৰি কাকত, আৰু অন্যান্য লিখনি ব্যৱহাৰ কৰিছো। মই সংযোগ দিয়া তালিকাত (v0 ৰ বাবে) প্ৰায় ২০০ আছে, কিন্তু প্ৰথম প্ৰশিক্ষণৰ বাবে মই কেৱল ৫০ টা ফাইল ~১৮৭ এম.বি. ব্যৱহাৰ কৰিছিলোঁ। নথিপত্ৰৰ তালিকা চাব পাৰে:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>Dataset আকাৰসমূহ:
<ul><li>v0: ~১৮৭MB</li>
<li>v0.5: ~৪৩৫MB </li>
<li>v1: ~৬.২৫GB </li>
<li>v2mini-eval1: ১৫GB</li></p><p></ul><h2>মডেলসমূহ কিমান ডাঙৰ ?</h2></p><p>v0: ১৬M পেৰামিটাৰ</p><p>v0.5 ১২৩M পেৰামিটাৰ</p><p>v1: 700M Parameters</p><p>v2mini-eval1: 300M Parameters</p><h1>Training Specs ? </h1></p><h1>v0/v0.5</h1>
GPU: Geforce rtx 4060
CPU: i5-13400F 
Ram: 16GB DDR5.</p><h1>v1</h1>
GPU: A100 SXM rented</p><h1>v2mini-eval1</h1></p><p>GPU: A100 SXM rented</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-01-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-01-09 
    </div>
    
</body>
</html>