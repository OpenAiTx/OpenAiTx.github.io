<!DOCTYPE html>
<html lang="as">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - আধুনিক পক্ষপাত কমাবলৈ নিৰ্দিষ্ট সময়ৰ তথ্যতহলতহে প্ৰশিক্ষিত এটা LLM</title>
    <meta name="description" content="আধুনিক পক্ষপাত কমাবলৈ নিৰ্দিষ্ট সময়ৰ তথ্যতহলতহে প্ৰশিক্ষিত এটা LLM">
    <meta name="keywords" content="TimeCapsuleLLM, Assamese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "আধুনিক পক্ষপাত কমাবলৈ নিৰ্দিষ্ট সময়ৰ তথ্যতহলতহে প্ৰশিক্ষিত এটা LLM",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 275
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-as.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2025-08-07",
  "dateModified": "2025-08-07"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 275 stars</span>
                <span class="language">Assamese</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 ভাষা</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">ইংৰাজী</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">সৰল চীনা</a>
        | <a href="#" title="Coming soon">পৰম্পৰাগত চীনা (চিগৈ আহিব)</a> |
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">জাপানী</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">কোৰিয়ান</a>
        | <a href="#" title="Coming soon">হিন্দী (চিগৈ আহিব)</a> |
        | <a href="#" title="Coming soon">থাই (চিগৈ আহিব)</a> |
        | <a href="#" title="Coming soon">ফ্ৰেঞ্চ (চিগৈ আহিব)</a>
        | <a href="#" title="Coming soon">জাৰ্মান (চিগৈ আহিব)</a>
        | <a href="#" title="Coming soon">স্পেনিছ (চিগৈ আহিব)</a>
        | <a href="#" title="Coming soon">ইটালিয়ান (চিগৈ আহিব)</a>
        | <a href="#" title="Coming soon">ৰাছিয়ান (চিগৈ আহিব)</a>
        | <a href="#" title="Coming soon">পৰ্তুগীজ (চিগৈ আহিব)</a>
        | <a href="#" title="Coming soon">ডাচ (চিগৈ আহিব)</a>
        | <a href="#" title="Coming soon">প'লিশ (চিগৈ আহিব)</a>
        | <a href="#" title="Coming soon">আৰবী (চিগৈ আহিব)</a>
        | <a href="#" title="Coming soon">ফাৰ্ছী (চিগৈ আহিব)</a>
        | <a href="#" title="Coming soon">তুৰ্কী (চিগৈ আহিব)</a>
        | <a href="#" title="Coming soon">ভিয়েটনামীজ (চিগৈ আহিব)</a>
        | <a href="#" title="Coming soon">ইণ্ডোনেচিয়ান (চিগৈ আহিব)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>টাইমকেপচুল এলএলএম</h1>
এলএলএম কেৱল নিৰ্দিষ্ট সময়ৰ পৰিসৰৰ তথ্যতকৈ প্ৰশিক্ষণ দিয়া হৈছে যাতে আধুনিক পক্ষপাত কম হয়।</p><p>ভাবক, যদি এখন AI মডেল কেৱল ইতিহাসিক সাজিছিল নহয়, সত্যই ইতিহাসিক আছিল।</p><p><a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">Andrej Karpathy-ৰ nanoGPT</a>ৰ ওপৰত নিৰ্মিত। মূল প্ৰশিক্ষণ স্ক্ৰিপ্ট আৰু মডেল আৰ্হি তেওঁৰ কাম। </p><h1>প্ৰকল্পৰ লক্ষ্যসমূহ </h1></p><p>টাইমকেপচুল এলএলএম এটা পৰীক্ষামূলক প্ৰকল্প যিটো কেৱল নিৰ্দিষ্ট সময়ৰ ভিতৰত লিখা পাঠ্যতকৈ প্ৰশিক্ষণ দিয়া হ'ব। লক্ষ্য হৈছে নিৰ্দিষ্ট ইতিহাসিক যুগৰ দৃষ্টিভংগী আৰু ভাষা অনুকৰণ কৰা।</p><h1>কিয় কেৱল ফাইন-টিউনিং যথেষ্ট নহয় </h1></p><p>আপুনি যদি কেৱল এটা প্ৰি-ট্ৰেইনড মডেল ফাইন-টিউন কৰে, আপোনাৰ এলএলএম-এ এতিয়াও আধুনিক ধাৰণা জানিব। নিশ্চয়েই, শূন্য আধুনিক পক্ষপাত লাভ কৰাটো কঠিন, কিন্তু মই ইয়াৰ ওচৰলৈ যাব বিচাৰো। একেবাৰে আধুনিক পক্ষপাত নথকা মডেল প্ৰস্তুত কৰিবলৈ আৰম্ভণিৰ পৰাই প্ৰশিক্ষণ দিয়াটো প্ৰয়োজন।</p><h1>আগ্ৰহ কৰা ফলাফলসমূহ </h1></p><p>আশা কৰোঁ, সম্পূৰ্ণ হ'লে, এই মডেলটোৱে আধুনিক ধাৰণা নাজানিব আৰু ইয়াক যি প্ৰশিক্ষণ দিয়া হৈছে তাৰ বাহিৰে যুক্তি কৰিব নোৱাৰিব। ইয়াৰ উচিত আধুনিক শব্দ/ধাৰণা চিনাক্ত নকৰা আৰু আশা কৰোঁ আধুনিক জ্ঞানৰ ভুল সৃষ্টি নকৰে।</p><h1>অগ্ৰগতিৰ আপডেটসমূহ</h1></p><h2>৯ জুলাই, ২০২৫</h2></p><p>মই মোৰ সময়ৰ পৰিসৰ ১৮০০-১৮৫০ আৰু অঞ্চল: লণ্ডন নিৰ্ধাৰণ কৰিছোঁ </p><p>মই পাঠ্য, কিতাপ, নথিপত্ৰৰ এটা তালিকা সংগ্ৰহ কৰিছোঁ </p><p>এতিয়ালৈকে মই ৫০টা txt ফাইল সংগ্ৰহ কৰিছোঁ আৰু শীঘ্ৰেই NanoGPT প্ৰশিক্ষণ আৰম্ভ কৰিম </p><p>অগ্ৰগতি থাকিলেহে ইয়াত আপডেট দিব</p><h2>১৩ জুলাই, ২০২৫</h2></p><p>১৮৭এমবি ইতিহাসিক পাঠ্য ডেটাত nanoGPT প্ৰশিক্ষণ দিছোঁ। </p><h2>১৫ জুলাই, ২০২৫</h2></p><p>মই দ্বিতীয়বাৰ প্ৰশিক্ষণৰ বাবে পাঠ্য ডাউনলোড কৰা আৰম্ভ কৰিছোঁ। সকলো Internet Archive-ৰ পৰা সংগ্ৰহ কৰিছোঁ আৰু সময়ৰ পৰিসৰ ১৮০০-১৮৭৫লৈ বৃদ্ধি কৰিছোঁ। বিভিন্ন পাঠ্য সংগ্ৰহ কৰিবলৈ Internet Archive-ত বিষয়বস্তু, প্ৰকাশস্থান, সময় আৰু বিষয়ৰ অনুসন্ধান ফিল্টাৰ ব্যৱহাৰ কৰিব পাৰি। </p><p><img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/searchfilter.jpg" alt="Search Filters"></p><h2>১৬ জুলাই, ২০২৫</h2></p><p>মই Internet Archive-ৰ পৰা প্ৰায় ৫০০টা txt ফাইল ডাউনলোড কৰিছোঁ আৰু সাফ কৰি (হোৱাইটস্পেইচ, গুটেনবাৰ্গ হেডাৰ আদিৰে মচি) প্ৰায় ৫০০এমবি ডেটা পাইছোঁ। সৰু ডেটাসেট, কিন্তু যোৱা বাৰ ১৮৭এমবি-ৰ পৰা প্ৰশিক্ষণ দিছিলোঁ, সেয়ে এইবাৰ আউটপুটত অলপ বেলেগতা আশা কৰিব পাৰি। আশা কৰিছোঁ, এই মডেলে অধিক সুসংগঠিত বাক্য উলিয়াব পাৰে। নিশ্চয় নহয়, কাৰণ এইটো এতিয়াও খুব সৰু ডেটাসেট, কিন্তু আগৰ তুলনাত বেছি। </p><p>এইটো মোৰ ব্যক্তিগত হাৰ্ডৱেৰতেই সম্ভৱ, ভালো কথাও, কাৰণ বৃহৎ ডেটাসেটলৈ যাওঁতে আগতে উন্নতি দেখা পাব পাৰোঁ। ডেটাসেট সৰ্বোচ্চ পৰিস্কাৰ আৰু মানসম্পন্ন হোৱাটো নিশ্চিত কৰিব খোজো। সমস্যাসমূহৰ ভিতৰত এটা হৈছে ফাইল ক্লিনিং, বহুত txt ফাইলত বুজি নোপোৱা কথা থাকে। ক্লিনিং স্ক্ৰিপ্টসমূহে কাম কৰে, কিন্তু ১০০% সফল নহয়। </p><p>মই আজি এই ডেটাসেটত প্ৰশিক্ষণ দিম, প্ৰায় ৪-৫ ঘণ্টা লাগিব। শেষ হ'লে আৰু পৰীক্ষা কৰিলে আপডেট দিম। মোৰ প্ৰকল্প চাবলৈ আহিছা সকললৈ ধন্যবাদ, কিছুমানে OCR সম্পৰ্কীয় লিংকো দিলে, ধন্যবাদ! আশা কৰোঁ, আৰু মানুহে নিজৰ ডেটাসেট লৈ চেষ্টা কৰে আৰু পৰীক্ষা কৰে। </p><h3>প্ৰশিক্ষণৰ আপডেট </h3></p><p>মই ৪৩৫এমবি (১০৮ মিলিয়ন টোকেন) ডেটাত প্ৰশিক্ষণ আৰম্ভ কৰিছোঁ, এতিয়া ভালেই চলি আছে। প্ৰথম ২৮০০ ইটাৰেশ্যনত train loss ১০.৯ৰ পৰা ৪.৯লৈ নামিছে। ৮-৯ ঘণ্টা লাগিব বুলি অনুমান কৰিছোঁ। শেষ হ'লে আৰু আপডেট দিম।</p><h2>১৭ জুলাই, ২০২৫</h2></p><p>দ্বিতীয় মডেলৰ প্ৰশিক্ষণ শেষ, মোৰ ৪০৬০ত প্ৰায় ৮ ঘণ্টা ৪০ মিনিট (৩,৯০০ ইটাৰ/ঘণ্টা) লাগিল ৩৩,০০০ ইটাৰ (৫ ইপক)। Final train loss আছিল ৩.৭৩। আউটপুট আচলতে ভাল, সঁচাকৈ ১৯শ শতিকাৰ ধৰণৰ বাক্য উলিয়াব পাৰে। </p><h2>২৮ জুলাই, ২০২৫ </h2></p><p>মই আগবাঢ়ি v0.5 Hugging Face-ত আপলোড কৰিছোঁ, <a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">চাওক</a> বিচাৰিলে। এতিয়া মোৰ ৰিপো ডাউনলোড কৰি স্থানীয়ত চলাব পাৰিব। দুঃখজনকভাৱে nanoGPT-এ HuggingFace-ত native কাম নকৰে, সেয়ে স্থানীয়ত ডাউনলোড কৰি চলাব লাগিব। </p><p>আৰু, মই পাছৰ প্ৰশিক্ষণৰ বাবে ডেটা সংগ্ৰহ আৰম্ভ কৰিম, বিশ্বাস কৰোঁ ৫-১০ গুণ বেছি ডেটা লাগিব যুক্তি-ক্ষমতা পাবলৈ। </p><h2>২ আগষ্ট, ২০২৫</h2></p><p>মই Version 1-ৰ কাম শীঘ্ৰে আৰম্ভ কৰিম। nanoGPT-ৰ আৰ্হিৰ পৰা অধিক আধুনিক আৰ্হিলৈ যাব লাগিব। কিছুমান মুক্ত উৎস LLM আৰ্হি বিবেচনা কৰিছোঁ: OpenLLaMA v3, Phi-2 আৰু Qwen 1.5B। আৰু V1-লৈ যাওঁতে, বহুত বৃহৎ আৰু বৈচিত্ৰ্যময় ডেটাসেট ভালদৰে নিৰ্বাচন কৰিব লাগিব। কমেও ৫জিবি পৰিস্কাৰ প্ৰশিক্ষণ ডেটা লাগিব।</p><h1>V0 মডেলৰ আচৰণ আৰু সীমাবদ্ধতা</h1></p><p>প্ৰাৰম্ভিক প্ৰম্প্টসমূহত মডেলটোৱে ১৮০০ দশকৰ ভাষা আৰু আচৰণত প্ৰতিক্ৰিয়া দেখুৱায়। উদাহৰণস্বৰূপ, মই "Who art Henry?" বুলি সুধিছিলোঁ আৰু ই উত্তৰ দিছিল "I know that man, I have did not a black, the storm." আৰু এই বাক্যটো বুজাব নোৱাৰিলেও, LLM-এ বুজিছে যে মই এজন ব্যক্তিৰ বিষয়ে সুধিছোঁ।</p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="TimeLockLLM Sample Output"></p><p>আধুনিক ধাৰণাৰ কোনো উল্লেখ নাই, আউটপুটবোৰত প্ৰায়কৈ ১৮০০ দশকৰ শব্দ আৰু বাক্য গঠন থাকে।</p><p>এতিয়াও ইয়াত বহু কাম বাকী, কেৱল ১৮৭MB তথ্যৰ পৰা প্ৰশিক্ষণ দিলে যুক্তিসম্পন্ন পাঠ্য উৎপন্ন কৰিব পৰা মডেল নহয়।</p><p>বতর্মান ই সম্পূৰ্ণ বাক্য গঠনৰ অভাৱত থকা বাক্য উৎপন্ন কৰে আৰু অধিকাংশ সময়ত বুজাব নোৱাৰে, কিন্তু এইটো এই প্ৰশিক্ষণ আকাৰৰ বাবে স্বাভাৱিক।</p><h1>V0.5 মডেলৰ আচৰণ আৰু সীমাবদ্ধতা</h1></p><p>এইটো আগৰ মডেলটোৰ তুলনাত যথেষ্ট উন্নতি। লেখাৰ শৈলী আৰু শব্দভাণ্ডাৰ ভিক্টোৰিয়ান আৰু প্ৰায় প্ৰতিটো বাক্য ব্যাকৰণিকভাৱে শুদ্ধ আৰু উপযুক্ত যতিচিহ্ন আছে। আৰু এইটোও আৰম্ভণিৰ পৰা প্ৰশিক্ষিত, সেয়ে ১৮০০ দশকৰ বিষয়বোৰতেই সীমাবদ্ধ।</p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="TimeLockLLM Sample Output"></p><p>অনেক তথ্যগত ভুল (হলুসিনেচন) আছে। অধিকাংশ (প্ৰায় ১০০%) তথ্য (তাৰিখ, ঘটনা, ঐতিহাসিক ব্যক্তি) মনগড়া। লগতে বাক্যসমূহৰ মাজত সংযোগ নাই, কেতিয়াবা দুটা বাক্য একেলগে থাকিব পাৰে, তাৰ বাহিৰে নহয়। আন এটা সমস্যা হৈছে কেতিয়াবা "Digitized by Google" ফুটাৰ দেখা যায়, সেয়ে অহা প্ৰশিক্ষণৰ সময়ত পাঠ্যবোৰ ভালদৰে পৰিষ্কাৰ কৰিব লাগিব। সামগ্ৰিকভাৱে মই ফলাফলে আনন্দিত, এইটো এতিয়াও LLM নহয়, কিন্তু বাক্য উৎপাদক হিচাপে যথেষ্ট।</p><p>মই বহু কথা শিকিছোঁ আৰু অহা সপ্তাহত কেনেকৈ উন্নতি কৰিব পাৰিম তাক চিন্তা কৰিম। মই শীঘ্ৰে ফাইলসমূহ আপলোড কৰিম!</p><h1>আগন্তুক পৰিকল্পনা</h1></p><p>(সম্পূৰ্ণ) মই এতিয়া সংস্কৰণ ০.৫-ৰ কাম আৰম্ভ কৰিম, ৫০খন বইৰ সলনি ৫০০-৬০০খন ব্যৱহাৰ কৰাৰ চিন্তা। বৰ্তমানে মই nanoGPT-ত ১৮০০-১৮৫০ সময়ৰ লণ্ডনৰ বইসমূহ ব্যৱহাৰ কৰি প্ৰশিক্ষণ দিছোঁ। মূল সমস্যাটো হৈছে পোৱা বইবোৰ আধুনিকীকৰণ নহয় আৰু বাছনি কৰা সময়ত প্ৰকাশিত অক্ষত বইহে বাছনি কৰা।</p><p>মই এখন নতুন মডেল (v1) বহু ডাঙৰ কর্পাছৰে প্ৰশিক্ষণ দিব বিচাৰিছোঁ, সম্ভৱত v0.5-তকৈ ৫-১০ গুণ ডাঙৰ। মোৰ লক্ষ্য হৈছে কেৱল Selective Temporal Training-এ যুক্তি কৌশল উদ্ভৱ হয় নে চাব, এইটো কঠিন হ’ব আৰু তথ্য সীমাবদ্ধতাৰ বাবে সম্ভৱ নোহোৱা হ’ব পাৰে। অহা সপ্তাহত মই ৫-১০GB ডাটা সংগ্ৰহ কৰিবলৈ চেষ্টা কৰিম। মই বিশ্বাস কৰোঁ যদি উচ্চমানৰ পৰিষ্কাৰ ডাটা পাই আৰু GPU ভাড়া কৰিব পাৰোঁ, আগবঢ়া দেখা যাব।</p><h1>এই প্ৰকল্প কেনেকৈ ব্যৱহাৰ কৰিব</h1></p><p>এই প্ৰকল্পটো মূলত ঐতিহাসিক ডাটা সংগ্ৰহ, প্ৰস্তুতি আৰু টোকেনাইজাৰ নিৰ্মাণত কেন্দ্ৰিত। মই সম্পূৰ্ণ LLM প্ৰশিক্ষণ প্ৰক্ৰিয়া উল্লেখ নকৰোঁ, তাৰ বাবে Andrej Karpathy-ৰ nanoGPT চাই চাব।</p><h1>Step 1: ঐতিহাসিক পাঠ্য সংগ্ৰহ আৰু প্ৰস্তুতি</h1></p><p>আপোনাৰ নিৰ্বাচিত সময়ছোৱাৰ (যেনে, লণ্ডন ১৮০০-১৮৫০) পাব্লিক ডোমেইনৰ বই, নথি আদিৰ .txt ফাইল সংগ্ৰহ কৰক।</p><p>আপুনি প্ৰয়োজনত download_texts_improved.py ব্যৱহাৰ কৰি বই ডাউনল’ড কৰিব পাৰে।</p><p>স্ক্ৰিপ্ট বা হাতেৰে পাঠ্য ফাইলসমূহৰ পৰা Project Gutenberg-ৰ হেডাৰ/ফুটাৰ, আধুনিক টিকা বা OCR ত্ৰুটি আঁতৰাই পৰিষ্কাৰ কৰক।</p><p>prepare_dataset.py ভালদৰে কাম কৰিব।</p><h1>Step 2: কাষ্টম টোকেনাইজাৰ নিৰ্মাণ</h1></p><p>পৰিষ্কৃত ডাটাত train_tokenizer.py বা train_tokenizer_hf.py চলাওক।
এইয়ে আপোনাক vocab.json আৰু merges.txt দিব</p><p>এই ফাইলসমূহে আপোনাৰ মডেলৰ শব্দভাণ্ডাৰ আৰু সংযোগ নিয়ম সংজ্ঞা দিয়ে</p><h1>Step 3: আপোনাৰ মডেল (nanoGPT) প্ৰশিক্ষণ কৰক</h1></p><p>প্ৰশিক্ষণ প্ৰক্ৰিয়াৰ বাবে <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">Andrej Karpathy-ৰ nanoGPT</a> চাওক।</p><p>আপুনি চাইলে বেলেগ LLM প্ৰশিক্ষণ কৰিব পাৰে, কিন্তু মই nanoGPT ব্যৱহাৰ কৰিছোঁ</p><h1>FAQ</h1></p><h2>Selective Temporal Training (STT) কি?</h2></p><p>Selective Temporal Training (STT) হৈছে এক মেচিন লাৰ্নিং পদ্ধতি য’ত সকলো প্ৰশিক্ষণ ডাটা নিৰ্দিষ্ট ঐতিহাসিক সময়ছোৱাৰ ভিতৰত পৰে। এইটো সেই সময়ৰ ভাষা আৰু জ্ঞান মডেল কৰিবলৈ, আধুনিক ধাৰণাৰ প্ৰভাৱ নোহোৱাকৈ কৰা হয়। উদাহৰণস্বৰূপ, মোৰ বৰ্তমানৰ মডেল (v0.5)-ত কেৱল ১৮০০-১৮৭৫ সময়ছোৱাৰ ডাটা ব্যৱহাৰ হৈছে, এইটো ফাইন-টিউন নহয়, আৰম্ভণিৰ পৰা প্ৰশিক্ষিত, ফলস্বৰূপ  সেই সময়ৰ ভাষা আৰু ঐতিহাসিক পৰিপ্ৰেক্ষিত ফুটাই তোলে।</p><h2>কেৱল fine-tuning বা LoRA-হে কিয় ব্যৱহাৰ নকৰে?</h2></p><p>এই প্ৰকল্পত মই আধুনিক পক্ষপাত মুক্ত ভাষা মডেল নিৰ্মাণ কৰিবলৈ চেষ্টা কৰিছোঁ। যদি মই GPT-2-ধৰণৰ কিবা fine-tune কৰোঁ, ই পূৰ্বেই প্ৰশিক্ষিত আৰু সেই তথ্য আঁতৰাব নোৱাৰি। আৰম্ভণিৰ পৰা প্ৰশিক্ষণ দিলে, ভাষা মডেলটোৱে পুৰণি বুলি ভান নকৰে, সেয়া নিজেই পুৰণি হয়। এই প্ৰকল্পৰ লক্ষ্য হৈছে কেৱল লণ্ডনৰ ১৮০০-১৮৫০ সময়ৰ বইৰ জ্ঞানেই ব্যৱহাৰ কৰি যুক্তি কৰিব পৰা এটি মডেল নিৰ্মাণ।</p><h2>প্ৰশিক্ষণৰ বাবে কিমান ধৰণৰ ডাটা ব্যৱহাৰ কৰা হৈছে?</h2></p><p>মই ১৮০০–১৮৫০ সময়ৰ লণ্ডনৰ বই, আইনী নথি, বাতৰি কাকত আৰু আন লেখা ব্যৱহাৰ কৰিছোঁ। মই যি তালিকা দিছোঁ তাত ২০০টা আছে, কিন্তু প্ৰথম প্ৰশিক্ষণত কেৱল ৫০টা ফাইল ~১৮৭MB ব্যৱহাৰ কৰিছোঁ। নথিসমূহৰ তালিকা চাব পাৰে:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><h2>Version 0 মডেল কিমান ডাঙৰ?</h2></p><p>এই মডেল বৰ্তমান খুবেই সৰু, মই মাত্ৰ আনন্দৰ বাবে আৰু আধুনিক উৎস নোহোৱা প্ৰশিক্ষণ নিয়ম মানি কৰিছোঁ। ইয়াত প্ৰায় ১৬ নিযুত পেৰামিটাৰ আছে, কিন্তু মই এতিয়া অধিক পুৰণি লেখা সংগ্ৰহ কৰি নতুন প্ৰশিক্ষণ আৰম্ভ কৰিম। আগবঢ়াৰ লগে লগে আপডেট দিম।</p><h2>প্ৰশিক্ষণ স্পেছিফিকেচন?</h2></p><p>GPU: Geforce rtx 4060
CPU: i5-13400F
Ram: 16GB DDR5.</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-08-07

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-08-07 
    </div>
    
</body>
</html>