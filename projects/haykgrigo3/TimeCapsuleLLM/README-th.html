<!DOCTYPE html>
<html lang="th">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - โมเดล LLM ที่ถูกฝึกด้วยข้อมูลจากช่วงเวลาที่กำหนดเท่านั้น เพื่อลดอคติสมัยใหม่</title>
    <meta name="description" content="โมเดล LLM ที่ถูกฝึกด้วยข้อมูลจากช่วงเวลาที่กำหนดเท่านั้น เพื่อลดอคติสมัยใหม่">
    <meta name="keywords" content="TimeCapsuleLLM, Thai, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "โมเดล LLM ที่ถูกฝึกด้วยข้อมูลจากช่วงเวลาที่กำหนดเท่านั้น เพื่อลดอคติสมัยใหม่",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 545
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-th.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2025-09-30",
  "dateModified": "2025-09-30"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 545 stars</span>
                <span class="language">Thai</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 ภาษา</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="#" title="Coming soon">繁體中文 (เร็ว ๆ นี้)</a> |
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">한국어</a>
        | <a href="#" title="Coming soon">हिन्दी (เร็ว ๆ นี้)</a> |
        | <a href="#" title="Coming soon">ไทย (เร็ว ๆ นี้)</a> |
        | <a href="#" title="Coming soon">Français (เร็ว ๆ นี้)</a>
        | <a href="#" title="Coming soon">Deutsch (เร็ว ๆ นี้)</a>
        | <a href="#" title="Coming soon">Español (เร็ว ๆ นี้)</a>
        | <a href="#" title="Coming soon">Italiano (เร็ว ๆ นี้)</a>
        | <a href="#" title="Coming soon">Русский (เร็ว ๆ นี้)</a>
        | <a href="#" title="Coming soon">Português (เร็ว ๆ นี้)</a>
        | <a href="#" title="Coming soon">Nederlands (เร็ว ๆ นี้)</a>
        | <a href="#" title="Coming soon">Polski (เร็ว ๆ นี้)</a>
        | <a href="#" title="Coming soon">العربية (เร็ว ๆ นี้)</a>
        | <a href="#" title="Coming soon">فارسی (เร็ว ๆ นี้)</a>
        | <a href="#" title="Coming soon">Türkçe (เร็ว ๆ นี้)</a>
        | <a href="#" title="Coming soon">Tiếng Việt (เร็ว ๆ นี้)</a>
        | <a href="#" title="Coming soon">Bahasa Indonesia (เร็ว ๆ นี้)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1></p><p><em>โมเดลภาษาที่ฝึก <strong>ตั้งแต่เริ่มต้น</strong> โดยใช้ข้อมูลเฉพาะจากสถานที่และช่วงเวลาเพื่อลดอคติแบบสมัยใหม่ และจำลองเสียง คำศัพท์ และมุมมองโลกของยุคนั้น</em></p><p>ลองจินตนาการว่า ถ้าโมเดล AI ไม่ได้แค่แกล้งทำเป็นประวัติศาสตร์ แต่เป็นจริง ๆ</p><p>v0 และ v0.5 สร้างขึ้นโดยใช้ <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT โดย Andrej Karpathy</a> สคริปต์การฝึกหลักและสถาปัตยกรรมโมเดลเป็นผลงานของเขา</p><p>v1 สร้างขึ้นบน <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Phi 1.5 โดย Microsoft</a></p><p><a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">ลิงก์ Hugging Face</a></p><h2> พฤติกรรมของโมเดล & ข้อจำกัด</h2></p><h3><strong>v0</strong>  </h3></p><p>ข้อความแรก ๆ แสดงให้เห็นว่าโมเดลตอบกลับด้วยภาษาและพฤติกรรมในยุค 1800 
ตัวอย่าง: คำถาม: "Who art Henry?" และมันตอบกลับว่า "I know that man, I have did not a black, the storm." </p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="ตัวอย่างผลลัพธ์ TimeLockLLM"></p><ul><li>ไม่มีการกล่าวถึงแนวคิดสมัยใหม่  </li>
<li>คำศัพท์ส่วนใหญ่ตรงกับยุคนั้น  </li>
<li>ประโยคส่วนใหญ่ไม่ปะติดปะต่อ (เป็นสิ่งที่คาดไว้สำหรับข้อมูลฝึก ~187MB)</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>ปรับปรุงอย่างเห็นได้ชัดจาก v0  
<ul><li>สไตล์การเขียนยุควิกตอเรีย การใช้เครื่องหมายวรรคตอนถูกต้อง ส่วนใหญ่เป็นประโยคที่ถูกหลักไวยากรณ์  </li>
<li>อัตราการจินตนาการข้อเท็จจริงยังสูง  </li>
<li>มีเสียงรบกวนจาก OCR (“Digitized by Google”) ปรากฏในผลลัพธ์</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="ตัวอย่างผลลัพธ์ TimeLockLLM"></p><h3><strong>v1</strong></h3></p><p>เป็นโมเดลแรกที่สามารถจดจำและเชื่อมโยงเหตุการณ์ทางประวัติศาสตร์จริงกับบุคคลจริงในชุดข้อมูลได้</p><p>ตัวอย่าง: คำถาม: "It was the year of our Lord 1834" </p><p>ผลลัพธ์: "It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity" </p><p>แรก ๆ ฉันคิดว่าอาจจะมีการประท้วงเกิดขึ้นในปีเดียวกันโดยบังเอิญ แต่ลองดูนี่สิ: <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3>เหตุผลที่เรื่องนี้สำคัญ:</h3></p><p>นี่เป็นตัวอย่างแรกที่โมเดลของฉันเชื่อมโยงปีเข้ากับทั้งเหตุการณ์ทางประวัติศาสตร์จริงและบุคคลจริงที่เกี่ยวข้องกับเหตุการณ์นั้น (Lord Palmerston) โมเดลก่อนหน้านี้ (v0 และ v0.5) สามารถเลียนแบบสไตล์การเขียนในศตวรรษที่ 19 ได้ แต่จะจินตนาการเหตุการณ์ บุคคล และข้อเท็จจริงเสมอ สิ่งนี้แสดงให้เห็นว่าโมเดลเริ่มจดจำสิ่งต่าง ๆ จากชุดข้อมูลแล้ว</p><h2>แผนงานในอนาคต</h2></p><ul><li>มีข้อความเกือบ 175,000 รายการที่เผยแพร่ในลอนดอนระหว่างปี 1800-1875 บน Internet Archive</li>
<li>ผมมีแผนที่จะขยายคลังข้อมูลและทำความสะอาดเพิ่มเติมเพื่อเพิ่มความสามารถในการให้เหตุผล</li>
<li>ขยายไปยังภูมิภาคและช่วงเวลาต่างๆ เพื่อสร้างโมเดลทางประวัติศาสตร์ที่หลากหลายมากขึ้น</li></p><p></ul><h2>วิธีการใช้งาน</h2></p><p>โครงการนี้เน้นการรวบรวมข้อมูลประวัติศาสตร์ เตรียมข้อมูลสำหรับการฝึกฝน และสร้างตัวแบ่งคำ ผมจะไม่ครอบคลุมกระบวนการฝึกฝน LLM ทั้งหมด สำหรับเรื่องนี้โปรดดู nanoGPT โดย Andrej Karpathy</p><h3>ขั้นตอนที่ 1: รวบรวมและเตรียมข้อความประวัติศาสตร์</h3></p><ul><li>รวบรวมไฟล์ .txt ของหนังสือ เอกสาร ฯลฯ ที่เป็นสาธารณสมบัติจากช่วงเวลาที่คุณเลือก (เช่น ลอนดอน 1800-1850)</li>
<li>เก็บข้อมูลไว้ในช่วงเวลา/สถานที่ที่คุณเลือก</li>
<li>ทำความสะอาดไฟล์ข้อความโดยใช้สคริปต์หรือเอาส่วนหัว/ท้ายออกด้วยมือจาก Project Gutenberg, หมายเหตุสมัยใหม่ หรือข้อผิดพลาด OCR ต่างๆ</li></p><p></ul><h3>ขั้นตอนที่ 2: สร้างตัวแบ่งคำแบบกำหนดเอง</h3></p><ul><li>รัน train_tokenizer.py หรือ train_tokenizer_hf.py กับข้อมูลที่ทำความสะอาดแล้ว</li>
<li>จะได้ไฟล์ vocab.json และ merges.txt</li>
<li>ไฟล์เหล่านี้กำหนดคำศัพท์และกฎการรวมสำหรับโมเดลของคุณ</li></p><p></ul><h3>ขั้นตอนที่ 3: ฝึกฝนโมเดลของคุณ</h3></p><ul><li>ดู <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT โดย Andrej Karpathy</a> สำหรับขั้นตอนการฝึกฝนหรือเอกสารของสถาปัตยกรรมที่คุณเลือก</li></p><p></ul><h1>คำถามที่พบบ่อย</h1></p><h2>Selective Temporal Training คืออะไร?</h2></p><p>Selective Temporal Training (STT) เป็นวิธีการเรียนรู้ของเครื่องที่มีการคัดกรองข้อมูลฝึกฝนให้ตรงกับช่วงเวลาทางประวัติศาสตร์ที่เฉพาะเจาะจง เพื่อสร้างแบบจำลองภาษาและความรู้ของยุคนั้นโดยปราศจากอิทธิพลจากแนวคิดสมัยใหม่ ตัวอย่างเช่น โมเดลปัจจุบันที่ผมมี (v0.5) ได้รับการฝึกฝนจากข้อมูลระหว่างปี 1800-1875 เท่านั้น ไม่ได้ปรับแต่งแต่ฝึกฝนจากศูนย์ ส่งผลให้ผลลัพธ์สะท้อนรูปแบบภาษาและบริบททางประวัติศาสตร์ของช่วงเวลานั้น</p><h2>ทำไมไม่ใช้การปรับแต่งหรือ LoRA?</h2></p><p>สำหรับโครงการนี้ผมต้องการสร้างโมเดลภาษาโดยปราศจากอคติสมัยใหม่ หากผมปรับแต่งโมเดลเช่น GPT-2 มันได้รับการฝึกฝนมาก่อนแล้วและข้อมูลนั้นจะไม่หายไป หากฝึกฝนจากศูนย์ โมเดลภาษาจะไม่แกล้งทำเป็นเก่าแต่มันจะเป็นเช่นนั้นจริงๆ เป้าหมายของโครงการนี้ในตอนนี้คือสร้างโมเดลที่สามารถให้เหตุผลโดยใช้ความรู้จากหนังสือลอนดอนที่ตีพิมพ์ระหว่างปี 1800 ถึง 1875 เท่านั้น</p><h2>ใช้ข้อมูลประเภทใดในการฝึกฝน?</h2></p><p>
ผมใช้หนังสือ เอกสารทางกฎหมาย หนังสือพิมพ์ และงานเขียนอื่น ๆ จากลอนดอนช่วงปี 1800–1875 รายการที่ผมแนบไว้ (สำหรับ v0) มีประมาณ 200 รายการ แต่สำหรับการเทรนครั้งแรกผมใช้เพียง 50 ไฟล์ ประมาณ ~187 MB คุณสามารถดูรายการเอกสารได้ที่:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>ขนาดของชุดข้อมูล:
v0: ~187MB
v0.5: ~435MB 
v1: ~6.25GB </p><h2>โมเดลมีขนาดเท่าไร ?</h2></p><p>V0: 16M พารามิเตอร์</p><p>V0.5 123M พารามิเตอร์</p><p>V1: 700M พารามิเตอร์</p><h1>สเปกการเทรน ?</h1></p><h1>V0/V0.5</h1>
GPU: Geforce rtx 4060
CPU: i5-13400F 
Ram: 16GB DDR5.</p><h1>V1</h1>
GPU: A100 เช่าใช้บริการ</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-09-30

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-30 
    </div>
    
</body>
</html>