<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - Một m&#244; h&#236;nh LLM được huấn luyện chỉ tr&#234;n dữ liệu từ c&#225;c giai đoạn thời gian nhất định nhằm giảm thi&#234;n vị hiện đại</title>
    <meta name="description" content="Một m&#244; h&#236;nh LLM được huấn luyện chỉ tr&#234;n dữ liệu từ c&#225;c giai đoạn thời gian nhất định nhằm giảm thi&#234;n vị hiện đại">
    <meta name="keywords" content="TimeCapsuleLLM, Vietnamese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "Một mô hình LLM được huấn luyện chỉ trên dữ liệu từ các giai đoạn thời gian nhất định nhằm giảm thiên vị hiện đại",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 830
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-vi.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2026-01-09",
  "dateModified": "2026-01-09"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 830 stars</span>
                <span class="language">Vietnamese</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align="right">
  <details>
    <summary >🌐 Ngôn ngữ</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-TW">繁體中文</a> 
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=as">हिन्दी</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=th">ไทย</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=es">Español</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ar">العربية</a>
        | <a href="#" title="Coming soon">فارسی (coming soon)</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=vi">Tiếng Việt</a>
        | <a href="#" title="Coming soon">Bahasa Indonesia (coming soon)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1></p><p><em>Một mô hình ngôn ngữ được huấn luyện <strong>từ đầu</strong> chỉ dựa trên dữ liệu từ những địa điểm và thời kỳ nhất định nhằm giảm thiên vị hiện đại và mô phỏng giọng điệu, từ vựng, cũng như thế giới quan của thời đại đó.</em></p><p>Hãy tưởng tượng nếu một mô hình AI không chỉ giả vờ là lịch sử mà thực sự là như vậy.</p><p>v0 và v0.5 được xây dựng dựa trên <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT của Andrej Karpathy</a> Các tập lệnh huấn luyện cốt lõi và kiến trúc mô hình là công trình của ông ấy. </p><p>v1 được xây dựng trên <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Phi 1.5 của Microsoft</a></p><p><a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">Liên kết Hugging Face</a></p><h2> Hành Vi & Hạn Chế của Mô Hình</h2></p><h3><strong>v0</strong>  </h3></p><p>Những prompt ban đầu cho thấy mô hình phản hồi với ngôn ngữ và cách hành xử của thế kỷ 19. 
Ví dụ: Prompt: "Who art Henry?" và nó trả lời "I know that man, I have did not a black, the storm." </p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="Kết quả mẫu của TimeLockLLM"></p><ul><li>Không đề cập đến các khái niệm hiện đại  </li>
<li>Chủ yếu sử dụng từ vựng đúng với thời kỳ  </li>
<li>Câu văn phần lớn không mạch lạc (điều này được mong đợi với dữ liệu huấn luyện ~187MB)</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>Cải tiến đáng kể so với v0.  
<ul><li>Phong cách viết thời Victoria, dấu câu đầy đủ, câu văn phần lớn đúng ngữ pháp  </li>
<li>Tỷ lệ ảo giác thông tin thực tế vẫn cao  </li>
<li>Nhiễu OCR (“Digitized by Google”) vẫn xuất hiện trong kết quả đầu ra</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="Kết quả mẫu của TimeLockLLM"></p><h3><strong>v1</strong></h3></p><p>Mô hình đầu tiên có thể nhớ và kết nối một sự kiện lịch sử thực với một nhân vật có thật trong bộ dữ liệu.</p><p>Ví dụ: Prompt: "It was the year of our Lord 1834" </p><p>Kết quả: "It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity" </p><p>Ban đầu tôi nghĩ rằng có thể một cuộc biểu tình đã diễn ra trùng hợp vào năm đó nhưng hãy xem điều này: <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3><strong>v2mini-eval1</strong></h3></p><p>Huấn luyện bằng mẫu 15GB từ bộ dữ liệu 90GB của v2.</p><p>Mô hình chỉ được huấn luyện đến 10.000 bước.</p><p>Đã có vấn đề với quá trình mã hóa token khiến kết quả đầu ra trông như sau:</p><p>LỆNH:
Charles Dickens là ai?</p><p>
W ho is Charles D ic ens ? D oes that work more of h ise x cell ent st ir ring , in his pl ays , int he G reat C omp any 's f arm ? What I have y et to qu ote from J ack P ick ett ? D oy oun ot know th att hey were as pe cies of g all oping , ors aw ing oft heir bre asts , or what w ast ob ed one about the t im ew hen J acks on was looking ont hew ind ow ? What ist hes uccess of an English man , and which h isson has not be end is cover ing t ome , where by to acc omp lish such a we ight ? D idy ou ever m ake ap ass age int othe old road way , ort o an anch or - b ree ze att he foot of our boat , which you m ust le ave us ? The fact is , that whe ther the wind would rise up from the pl ain on S atur day night orn o ont ide , ort ill then orth , or other wise , wes hall be com pelled t od esc ribe af orm idable bar rier , with t hes ame e ffect s ast he p resent . In th iss itu ation , at le ast , itis not to omuch t os ay that we have le ft that room . I bel ieve there are three c op ies int he " F ive H undred - fold ," to bere fer red to , ast he first n umber of our read ers wh ow is ht
Đã chỉnh sửa:</p><p>"Charles Dickens là ai? Liệu tác phẩm đó có phải là sự khuấy động xuất sắc hơn nữa của ông, trong các vở kịch của ông, tại nông trại của Công ty Lớn không? Tôi còn phải trích dẫn gì từ Jack Pickett? Bạn không biết rằng họ là một loài phi nước đại, hoặc cưa ngực họ, hoặc phải làm gì vào thời điểm Jackson đang nhìn qua cửa sổ? Thành công của một người Anh là gì, và điều mà con trai ông ta chưa phát hiện ra với tôi, qua đó thực hiện được một trọng lượng như vậy? Bạn đã bao giờ đi qua con đường cũ, hoặc tới một làn gió neo đậu ở chân thuyền của chúng tôi, nơi bạn phải rời chúng tôi chưa? Thực tế là, dù gió có nổi lên từ đồng bằng vào đêm thứ Bảy hay giữa trưa, hoặc đến từ phương bắc, hoặc khác đi, chúng tôi sẽ buộc phải mô tả một rào cản đáng gờm, với cùng những hiệu ứng như hiện tại. Trong tình huống này, ít nhất, không quá lời khi nói rằng chúng tôi đã rời khỏi căn phòng đó. Tôi tin rằng có ba bản sao trong 'Năm Trăm lần,' để tham khảo, như số đầu tiên của độc giả chúng tôi mong muốn t[o]..."</p><h3><strong>v2mini-eval2</strong></h3></p><p>Được huấn luyện sử dụng cùng mẫu 15GB đã dùng để huấn luyện eval1.
Mô hình lại được huấn luyện tới 10K bước mà thôi.</p><p>PROMPT:Charles Darwin</p><p>Charles DarwinECCEMACY. Thưa ngài, — Trường hợp sau đây khiến tôi quan tâm : — Tôi đã ở London hai tuần, và bị ảnh hưởng nhiều bởi một cơn thấp khớp. Cơn thấp khớp đầu tiên xảy ra một tuần trước khi tôi gặp ngài, và cơn thứ hai khi tôi gặp ngài, và cơn thứ ba khi tôi gặp ngài, và cơn thứ ba trong cùng thời gian đó. Tuy nhiên, cơn gút thứ hai không kèm theo triệu chứng sốt nào, mà lại kèm theo lượng nước tiểu tăng, và lượng nước tiểu bài tiết nhiều hơn. Cơn thứ ba xuất hiện một giờ sau khi tôi gặp ngài, và tiếp sau đó là một đợt tái phát gút, và một lần trở lại nhanh hơn của bệnh gút. Cơn thứ tư cũng kèm theo sốt, nhưng không phải lúc nào cũng có triệu chứng sốt. Cơn gút thứ ba là hai tuần sau khi ngài bị bệnh, và cơn thứ tư tiếp theo một đợt tái phát gút. Cơn thứ tư là hai tuần sau khi ngài bị tấn công, và kèm theo cảm giác</p><h2> Bộ dữ liệu</h2></p><h3><strong>v2</strong></h3></p><ul><li>90GB văn bản London giai đoạn 1800-1875</li>
<li>136.344 tài liệu</li>
<li>Toàn bộ 90GB hiện chưa có sẵn vì chưa được mã hóa, nhưng bạn có thể tìm một mẫu 15GB tại đây: https://huggingface.co/datasets/haykgrigorian/TimeCapsuleLLM-London-1800-1875-v2-15GB</li></p><p> </ul>### Thống kê thiên lệch 
  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/pronoun_bias.png" alt="Thiên lệch đại từ nhân xưng"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/geographic_bias.png" alt="Thiên lệch địa lý"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/temporal_bias.png" alt="Thiên lệch thời gian"></p><p>Xem <a href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/v2_bias_report.json" target="_blank" rel="noopener noreferrer">báo cáo thiên lệch v2</a> để biết thêm thông tin.</p><h2>Hướng dẫn sử dụng</h2></p><p>Dự án này tập trung chủ yếu vào việc thu thập dữ liệu lịch sử, chuẩn bị dữ liệu cho huấn luyện và xây dựng một bộ mã hóa từ vựng. Tôi sẽ không đề cập đến toàn bộ quy trình huấn luyện LLM, cho điều đó hãy tham khảo nanoGPT của Andrej Karpathy.</p><h3>Bước 1: Thu thập và chuẩn bị văn bản lịch sử </h3></p><ul><li>Thu thập các tệp .txt của sách, tài liệu miền công cộng, v.v. từ khoảng thời gian bạn chọn (ví dụ: London 1800-1850)</li></p><p>
<li>Giữ chúng trong khung thời gian/địa điểm bạn đã chọn  </li>
<li>Làm sạch các tệp văn bản bằng script hoặc thủ công loại bỏ tiêu đề/chân trang từ Project Gutenberg, chú thích hiện đại hoặc các lỗi như OCR.</li></p><p></ul><h3>Bước 2: Xây dựng Bộ phân tách Token tùy chỉnh</h3></p><ul><li>Chạy train_tokenizer.py hoặc train_tokenizer_hf.py trên dữ liệu đã được làm sạch.</li>
<li>Điều này sẽ tạo ra vocab.json và merges.txt</li>
<li>Các tệp này xác định từ vựng và quy tắc hợp nhất cho mô hình của bạn</li></p><p></ul><h3>Bước 3: Huấn luyện Mô hình của bạn </h3></p><ul><li>Tham khảo <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT của Andrej Karpathy</a> cho quy trình huấn luyện hoặc tài liệu kiến trúc bạn chọn.</li></p><p></ul><h1>Câu hỏi thường gặp</h1></p><h2>Đào tạo theo thời kỳ chọn lọc là gì?</h2></p><p>Đào tạo theo thời kỳ chọn lọc (Selective Temporal Training - STT) là một phương pháp học máy trong đó tất cả dữ liệu huấn luyện được chọn lọc để nằm trong một giai đoạn lịch sử cụ thể. Việc này được thực hiện để mô phỏng ngôn ngữ và tri thức của thời kỳ đó mà không bị ảnh hưởng bởi các khái niệm hiện đại. Ví dụ, mô hình hiện tại tôi có (v0.5) được huấn luyện độc quyền trên dữ liệu từ 1800-1875, không phải tinh chỉnh mà huấn luyện từ đầu nên cho ra kết quả phản ánh đúng phong cách ngôn ngữ và bối cảnh lịch sử của thời kỳ đó.</p><h2>Tại sao không chỉ dùng fine-tuning hoặc LoRA?</h2></p><p>Với dự án này tôi muốn tạo ra một mô hình ngôn ngữ không bị ảnh hưởng bởi thành kiến hiện đại. Nếu tôi fine-tune thứ gì đó như GPT-2, nó đã được huấn luyện trước và thông tin đó sẽ không mất đi. Nếu tôi huấn luyện từ đầu, mô hình ngôn ngữ sẽ không giả vờ là cổ điển, mà thực sự sẽ là như vậy. Mục tiêu hiện tại là tạo ra một mô hình có thể suy luận hoàn toàn dựa trên kiến thức từ các sách London xuất bản giai đoạn 1800 đến 1875.</p><h2>Bạn đã dùng loại dữ liệu nào để huấn luyện?</h2></p><p>Tôi sử dụng sách, tài liệu pháp lý, báo chí và các bài viết khác từ London giai đoạn 1800–1875. Danh sách tôi đã liên kết (cho v0) có khoảng 200 nhưng cho lần huấn luyện đầu tiên tôi chỉ dùng 50 tệp khoảng ~187 MB. Bạn có thể xem danh sách tài liệu tại:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>Kích thước bộ dữ liệu:
<ul><li>v0: ~187MB</li>
<li>v0.5: ~435MB </li>
<li>v1: ~6.25GB </li>
<li>v2mini-eval1: 15GB</li></p><p></ul><h2>Kích thước các mô hình là bao nhiêu?</h2></p><p>v0: 16 triệu tham số</p><p>v0.5: 123 triệu tham số</p><p>v1: 700M Parameters</p><p>v2mini-eval1: 300M Parameters</p><h1>Training Specs ? </h1></p><h1>v0/v0.5</h1>
GPU: Geforce rtx 4060
CPU: i5-13400F 
Ram: 16GB DDR5.</p><h1>v1</h1>
GPU: A100 SXM rented</p><h1>v2mini-eval1</h1></p><p>GPU: A100 SXM rented</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-01-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-01-09 
    </div>
    
</body>
</html>