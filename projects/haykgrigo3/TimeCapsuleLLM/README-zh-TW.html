<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - 一個僅使用特定時期資料訓練的大型語言模型，以減少現代偏見</title>
    <meta name="description" content="一個僅使用特定時期資料訓練的大型語言模型，以減少現代偏見">
    <meta name="keywords" content="TimeCapsuleLLM, Traditional Chinese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "一個僅使用特定時期資料訓練的大型語言模型，以減少現代偏見",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 349
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-zh-TW.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 349 stars</span>
                <span class="language">Traditional Chinese</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 語言</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">簡體中文</a>
        | <a href="#" title="Coming soon">繁體中文（即將推出）</a> |
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">韓國語</a>
        | <a href="#" title="Coming soon">हिन्दी（即將推出）</a> |
        | <a href="#" title="Coming soon">ไทย（即將推出）</a> |
        | <a href="#" title="Coming soon">Français（即將推出）</a>
        | <a href="#" title="Coming soon">Deutsch（即將推出）</a>
        | <a href="#" title="Coming soon">Español（即將推出）</a>
        | <a href="#" title="Coming soon">Italiano（即將推出）</a>
        | <a href="#" title="Coming soon">Русский（即將推出）</a>
        | <a href="#" title="Coming soon">Português（即將推出）</a>
        | <a href="#" title="Coming soon">Nederlands（即將推出）</a>
        | <a href="#" title="Coming soon">Polski（即將推出）</a>
        | <a href="#" title="Coming soon">العربية（即將推出）</a>
        | <a href="#" title="Coming soon">فارسی（即將推出）</a>
        | <a href="#" title="Coming soon">Türkçe（即將推出）</a>
        | <a href="#" title="Coming soon">Tiếng Việt（即將推出）</a>
        | <a href="#" title="Coming soon">Bahasa Indonesia（即將推出）</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1></p><p><em>一個語言模型，從零開始<strong>專門</strong>在特定地區和時期的資料上訓練，以減少現代偏見並模擬該時代的語音、詞彙和世界觀。</em></p><p>想像一下，如果一個 AI 模型不只是假裝是歷史的，而是真的如此。</p><p>v0 和 v0.5 基於 <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT by Andrej Karpathy</a> 核心訓練腳本及模型架構皆來自於他。</p><p>v1 建立於 <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">微軟 Phi 1.5</a></p><h2> 模型行為與限制</h2></p><h3><strong>v0</strong>  </h3></p><p>早期提示顯示模型以十九世紀語言及行為回應。
範例：提示：「Who art Henry?」模型回覆：「I know that man, I have did not a black, the storm.」</p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="TimeLockLLM 範例輸出"></p><ul><li>未提及現代概念  </li>
<li>主要使用當代詞彙  </li>
<li>句子大多不連貫（約 187MB 訓練資料，屬預期現象）</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>相較 v0 有顯著進步。  
<ul><li>維多利亞時期寫作風格，標點正確，句子語法大致正確  </li>
<li>事實虛構率仍高  </li>
<li>輸出仍有 OCR 雜訊（如「Digitized by Google」）</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="TimeLockLLM 範例輸出"></p><h3><strong>v1</strong></h3></p><p>首個能夠回憶並連結真實歷史事件及資料集中真實人物的模型。</p><p>範例：提示：「It was the year of our Lord 1834」 </p><p>模型輸出：「It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity」 </p><p>我原以為抗議活動可能只是巧合地發生於該年，但請看這張圖：<img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3>為何這很重要：</h3></p><p>這是我模型首次將年份與真實歷史事件及相關人物（Lord Palmerston）連結。早期模型（v0 及 v0.5）雖可模仿十九世紀寫作風格，但總是虛構事件、人物及事實。這顯示模型開始記住資料集中的內容。</p><h2>未來計畫 </h2>
<ul><li>在網際網路檔案館（Internet Archive）上，倫敦於1800-1875年間出版的文本近175,000份</li>
<li>我計劃擴展語料庫並進行更完善的清理，以提升推理能力</li>
<li>擴展至不同地區和時期，以建立更多歷史模型</li></p><p></ul><h2>如何使用</h2></p><p>本專案主要聚焦於蒐集歷史資料，準備訓練並建立分詞器。完整的LLM訓練流程將不在此涵蓋，詳細請參考Andrej Karpathy的nanoGPT。</p><h3>步驟1：蒐集並準備歷史文本</h3></p><ul><li>收集所選時期的公有領域書籍、文件等的.txt檔案（如：倫敦1800-1850）</li>
<li>保持在你選定的時間與地點範圍內</li>
<li>使用腳本清理文本檔案，或手動移除古騰堡計畫的頁首/頁尾、現代註釋或OCR錯誤等內容。</li></p><p></ul><h3>步驟2：建立自訂分詞器</h3></p><ul><li>在清理過的資料上執行train_tokenizer.py或train_tokenizer_hf.py</li>
<li>這會產生vocab.json和merges.txt</li>
<li>這些檔案定義了你的模型的詞彙及合併規則</li></p><p></ul><h3>步驟3：訓練你的模型</h3></p><ul><li>訓練流程請參考<a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">Andrej Karpathy的nanoGPT</a>或你選用架構的官方文件。</li></p><p></ul><h1>常見問答</h1></p><h2>什麼是選擇性時代訓練（Selective Temporal Training）？</h2></p><p>選擇性時代訓練（STT）是一種機器學習方法，所有訓練資料都特別挑選在特定歷史時期之內。這麼做是為了建模該時代的語言和知識，避免受現代概念影響。例如，我目前的模型（v0.5）完全以1800-1875年的資料訓練，並非微調，而是從零開始訓練，因此輸出能反映那個時期的語言風格和歷史語境。</p><h2>為什麼不直接用微調或LoRA？</h2></p><p>這個專案目標是打造不受現代偏見影響的語言模型。如果我微調如GPT-2，該模型已經預先訓練過，舊知識無法被完全替代。如果從零開始訓練，語言模型不會「假裝」古老，而是本身就具有那個時代的特質。現階段目標是建立一個能只用1800到1875年倫敦出版書籍的知識來推理的模型。</p><h2>你用什麼資料訓練的？</h2></p><p>我使用1800–1875年倫敦的書籍、法律文件、報紙與其他著作。我連結的清單（v0）約200份，但首次訓練只用50個檔案，約187 MB。你可以查閱文件清單：
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>資料集大小：
v0：約 187MB
v0.5：約 435MB
v1：約 6.25GB</p><h2>模型有多大？</h2></p><p>V0：16M 參數</p><p>V0.5：123M 參數</p><p>V1：700M 參數</p><h1>訓練規格？</h1></p><h1>V0/V0.5</h1>
GPU：Geforce RTX 4060
CPU：i5-13400F
記憶體：16GB DDR5。</p><h1>V1</h1>
GPU：租用的 A100</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-08-19

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>