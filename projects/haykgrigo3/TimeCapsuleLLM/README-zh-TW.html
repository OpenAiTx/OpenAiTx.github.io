<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - 一個僅使用特定時期資料訓練的 LLM，以減少現代偏見</title>
    <meta name="description" content="一個僅使用特定時期資料訓練的 LLM，以減少現代偏見">
    <meta name="keywords" content="TimeCapsuleLLM, Traditional Chinese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "一個僅使用特定時期資料訓練的 LLM，以減少現代偏見",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 267
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-zh-TW.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2025-07-29",
  "dateModified": "2025-07-29"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 267 stars</span>
                <span class="language">Traditional Chinese</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 語言</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="#" title="Coming soon">繁體中文 (即將推出)</a> |
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">한국어</a>
        | <a href="#" title="Coming soon">हिन्दी (即將推出)</a> |
        | <a href="#" title="Coming soon">ไทย (即將推出)</a> |
        | <a href="#" title="Coming soon">Français (即將推出)</a>
        | <a href="#" title="Coming soon">Deutsch (即將推出)</a>
        | <a href="#" title="Coming soon">Español (即將推出)</a>
        | <a href="#" title="Coming soon">Italiano (即將推出)</a>
        | <a href="#" title="Coming soon">Русский (即將推出)</a>
        | <a href="#" title="Coming soon">Português (即將推出)</a>
        | <a href="#" title="Coming soon">Nederlands (即將推出)</a>
        | <a href="#" title="Coming soon">Polski (即將推出)</a>
        | <a href="#" title="Coming soon">العربية (即將推出)</a>
        | <a href="#" title="Coming soon">فارسی (即將推出)</a>
        | <a href="#" title="Coming soon">Türkçe (即將推出)</a>
        | <a href="#" title="Coming soon">Tiếng Việt (即將推出)</a>
        | <a href="#" title="Coming soon">Bahasa Indonesia (即將推出)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1>
一個僅以特定時期資料訓練的 LLM，以降低現代偏見。</p><p>想像一下，如果 AI 模型不只是「假裝」是歷史性的，而是真正如此。</p><p>基於 <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">Andrej Karpathy 的 nanoGPT</a> 開發，核心訓練腳本與模型架構皆源自其作品。</p><h1>專案目標</h1></p><p>TimeCapsule LLM 是一個實驗性專案，僅以特定時期的文本進行訓練。目標是模擬特定歷史時代的世界觀與語言。</p><h1>為什麼微調還不夠</h1></p><p>如果你只是對預訓練模型進行微調，你的 LLM 仍然會知道現代的概念。當然要完全消除現代偏見非常困難，但我希望能盡可能接近這個目標。要做到完全沒有現代偏見，必須從零開始訓練模型。</p><h1>預期成果</h1></p><p>希望完成後，這個模型將不會知道現代概念，也無法推理超出訓練內容的知識。它不應該辨識現代詞彙／概念，也希望不會幻想出現代知識。</p><h1>進度更新</h1></p><h2>2025 年 7 月 9 日</h2></p><p>我將時間範圍設定為 1800-1850 年，地區為倫敦</p><p>已整理出一份文本、書籍、文件清單</p><p>目前已取得 50 份 txt 檔案，將很快開始訓練 NanoGPT</p><p>只要有進展會隨時更新</p><h2>2025 年 7 月 13 日</h2></p><p>已用 187MB 的歷史文本資料訓練 nanoGPT。</p><h2>2025 年 7 月 15 日</h2></p><p>我已開始下載第二次訓練所需的文本。全部都來自 Internet Archive，並將時間範圍擴大到 1800-1875 年。為了獲得多樣化文本，你可以使用 Internet Archive 的主題與搜尋篩選功能，按出版地點、時期及主題篩選。</p><p><img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/searchfilter.jpg" alt="搜尋篩選器"></p><h2>2025 年 7 月 16 日</h2></p><p>我從 Internet Archive 下載了約 500 個 txt 檔案，經過清理（只刪除空白、Gutenberg 標頭等）後，約有 500MB 資料。資料集很小，但上次只用 187MB 訓練，所以這次訓練後輸出應該會有明顯差異。我希望這次的模型至少能產生較通順且有意義的句子。當然這沒有保證，畢竟資料集還是很小，但總比上次多了。</p><p>這應該能在我自己的硬體上完成訓練，也好，因為希望在跳到更大資料集、需要租用 GPU 之前，先看到一些進步。但別擔心，我仍然計畫很快租用 GPU，只是在此之前要確保我的資料集夠精選、夠乾淨。其中一個問題就是清理，很多 txt 檔案裡有亂碼。用過的清理腳本雖然有效，但不是 100% 有效。</p><p>我今天會訓練這個資料集，預計需要 4-5 小時。完成並測試後會再更新。再次感謝所有關注我專案的人，甚至有人提供 OCR 資源連結，感謝！希望有更多人嘗試並實驗自己的資料集。</p><h2>2025 年 7 月 28 日</h2></p><p>我已將 v0.5 上傳至 Hugging Face，<a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">點此查看</a>。你現在可以下載我的 repo 並在本地運行。不幸的是 nanoGPT 無法直接與 HuggingFace 整合，所以必須下載模型到本地執行。</p><p>同時我會開始整理下一輪訓練所需的資料，我認為需要 5-10 倍的資料量才能讓模型有推理能力。</p><h3>訓練進度更新</h3></p><p>我已開始用 435MB（1.08 億詞元）的語料庫訓練，目前進展順利。訓練損失從 10.9 降到 4.9，僅 2800 次迭代。我預計總共要花 8~9 小時才能完成。等完成會再發布更新。</p><h2>2025 年 7 月 17 日 2:13AM</h2></p><p>第二個模型訓練完成，我的 4060 共花了約 8 小時 40 分鐘（每小時 3,900 次迭代），共 33,000 次迭代（5 輪）。最終訓練損失為 3.73。結果讓我驚訝，現在真的能產生通順的 19 世紀風格句子。</p><h1>V0 模型行為與限制</h1></p><p>早期提示顯示模型會用 1800 年代的語言與行為回應。例如，我以 "Who art Henry?" 提示，它回覆 "I know that man, I have did not a black, the storm."——雖然語句不通，但 LLM 已能辨識我在詢問某個人。</p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="TimeLockLLM 範例輸出"></p><p>沒有提及現代概念，輸出內容大多為十九世紀的詞彙與用語。</p><p>目前還需要大量改進，僅以187MB的資料進行訓練，無法產生具有複雜推理能力的模型。</p><p>現在產出的句子缺乏完整句子結構，整體也不合邏輯，但這對於這樣的訓練規模來說是正常的。</p><h1>V0.5 模型行為與限制</h1></p><p>這比上一個模型有明顯改進。寫作風格與詞彙屬於維多利亞時代，幾乎每個句子都文法正確且標點合宜。由於完全從零訓練，因此內容緊扣十九世紀主題。</p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="TimeLockLLM Sample Output"></p><p>存在大量事實性幻覺。大多數細節（日期、事件、歷史人物）幾乎都是虛構的。另外句子之間沒有真正的連貫性，頂多兩句會有關聯，超過就沒有了。另一個問題是偶爾會有“Digitized by Google”的頁腳出現，下次訓練時必須確實清理文本。總體來說我對結果很滿意，雖然離LLM還很遠，但確實可以生成句子。</p><p>我學到了很多，接下來幾週會開始思考該如何改進。我很快會上傳檔案！</p><h1>未來計畫</h1></p><p>（已完成）我將開始製作0.5版，這次不再只用50本書訓練，而是目標500-600本。目前我正使用來自1800-1850年、特別是倫敦的書籍來訓練nanoGPT。挑戰包括確保找到的書沒有被修改或有現代詮釋，而是要選擇在目標時期內出版且未經更動的原始書籍。</p><p>我希望訓練一個（v1）更大的模型，語料庫規模可能會是v0.5的5-10倍。我的目標是觀察是否僅靠選擇性時期訓練能產生推理能力，這會更具挑戰性，甚至不確定可不可行，畢竟歷史資料有限。接下來幾週我會盡量整理出5-10GB的語料庫。我相信若能取得乾淨高品質的資料並租用GPU，應該會有進展。</p><h1>如何使用本專案</h1></p><p>本專案主要聚焦於整理歷史資料、準備訓練用數據及建立分詞器。不會涵蓋完整的LLM訓練流程，相關細節請參考Andrej Karpathy的nanoGPT。</p><h1>步驟一：收集與準備歷史文本</h1></p><p>蒐集你所選時期的公有領域書籍、文件等.txt檔（如倫敦1800-1850）</p><p>如需自動下載書籍，可使用 download_texts_improved.py。</p><p>使用腳本或手動清理文本檔，去除Gutenberg專案的標頭/頁腳、現代註釋或OCR錯誤等內容。</p><p>prepare_dataset.py 應該可以正常運作。</p><h1>步驟二：建立自訂分詞器</h1></p><p>在清理過的資料上運行 train_tokenizer.py 或 train_tokenizer_hf.py。
這將生成 vocab.json 與 merges.txt</p><p>這些檔案定義了模型的詞彙與合併規則。</p><h1>步驟三：訓練你的模型（nanoGPT）</h1></p><p>請參考 <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">Andrej Karpathy 的 nanoGPT</a> 的訓練流程。</p><p>你也可以訓練其他LLM，但我這裡使用的是 nanoGPT。</p><h1>常見問答</h1></p><h2>什麼是 Selective Temporal Training ？</h2></p><p>Selective Temporal Training（STT，選擇性時期訓練）是一種機器學習方法，所有訓練資料都經過特別挑選，僅限於特定歷史時期。這樣做是為了建構該時代的語言和知識模型，不受現代概念影響。例如，目前的模型（v0.5）只用1800-1875年的資料訓練，非微調，而是從零開始訓練，因此輸出能反映當時的語言風格與歷史脈絡。</p><h2>為什麼不用微調或LoRA？</h2></p><p>這個專案希望打造一個不受現代偏見影響的語言模型。如果用GPT-2之類的模型做微調，它原本的訓練資料依然存在，無法去除。如果從零開始訓練，語言模型就不會“假裝”是舊的，而是真的只會用舊知識。目前的目標是做出一個能只用1800到1850年倫敦書籍知識進行推理的模型。</p><h2>你用什麼資料來訓練？</h2></p><p>我使用了1800-1850年倫敦的書籍、法律文件、報紙和其他著作。我連結的清單有約200本，但第一次訓練只用了約50個檔案，總計約187MB。你可以在這裡查看文件清單：
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><h2>0版模型有多大？</h2></p><p>這個模型目前非常小，純粹是娛樂性質並嚴格遵守不使用現代資料的原則。參數接近1600萬個。我會開始收集更多舊文本，進行新一輪模型訓練。進度會隨時更新。</p><h2>訓練規格？</h2></p><p>GPU：Geforce rtx 4060
CPU：i5-13400F
記憶體：16GB DDR5。</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-29

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-29 
    </div>
    
</body>
</html>