<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - 一個僅使用特定時期資料訓練的大型語言模型，以減少現代偏見</title>
    <meta name="description" content="一個僅使用特定時期資料訓練的大型語言模型，以減少現代偏見">
    <meta name="keywords" content="TimeCapsuleLLM, Traditional Chinese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "一個僅使用特定時期資料訓練的大型語言模型，以減少現代偏見",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 545
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-zh-TW.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2025-09-30",
  "dateModified": "2025-09-30"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 545 stars</span>
                <span class="language">Traditional Chinese</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 語言</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">簡體中文</a>
        | <a href="#" title="Coming soon">繁體中文（即將推出）</a> |
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">韓國語</a>
        | <a href="#" title="Coming soon">हिन्दी（即將推出）</a> |
        | <a href="#" title="Coming soon">ไทย（即將推出）</a> |
        | <a href="#" title="Coming soon">Français（即將推出）</a>
        | <a href="#" title="Coming soon">Deutsch（即將推出）</a>
        | <a href="#" title="Coming soon">Español（即將推出）</a>
        | <a href="#" title="Coming soon">Italiano（即將推出）</a>
        | <a href="#" title="Coming soon">Русский（即將推出）</a>
        | <a href="#" title="Coming soon">Português（即將推出）</a>
        | <a href="#" title="Coming soon">Nederlands（即將推出）</a>
        | <a href="#" title="Coming soon">Polski（即將推出）</a>
        | <a href="#" title="Coming soon">العربية（即將推出）</a>
        | <a href="#" title="Coming soon">فارسی（即將推出）</a>
        | <a href="#" title="Coming soon">Türkçe（即將推出）</a>
        | <a href="#" title="Coming soon">Tiếng Việt（即將推出）</a>
        | <a href="#" title="Coming soon">Bahasa Indonesia（即將推出）</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1></p><p><em>一個語言模型，從零開始<strong>專門</strong>在特定地區和時期的資料上訓練，以減少現代偏見並模擬該時代的語音、詞彙和世界觀。</em></p><p>想像一下，如果一個 AI 模型不只是假裝是歷史的，而是真的如此。</p><p>v0 和 v0.5 基於 <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT by Andrej Karpathy</a> 核心訓練腳本及模型架構皆來自於他。</p><p>v1 建立於 <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">微軟的 Phi 1.5</a></p><p><a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">Hugging Face 連結</a></p><h2> 模型行為與限制</h2></p><h3><strong>v0</strong>  </h3></p><p>早期提示讓模型以 1800 年代的語言和行為回應。
範例：提示："Who art Henry?"，它回覆 "I know that man, I have did not a black, the storm."</p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="TimeLockLLM 範例輸出"></p><ul><li>未提及現代概念  </li>
<li>大多使用符合時代的詞彙  </li>
<li>句子大多不通順（約 187MB 訓練資料時預期現象）</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>相較於 v0 有顯著提升。  
<ul><li>維多利亞時代寫作風格，標點正確，句子多數語法正確  </li>
<li>事實幻覺率仍高  </li>
<li>輸出中仍有 OCR 噪音（如 "Digitized by Google"）</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="TimeLockLLM 範例輸出"></p><h3><strong>v1</strong></h3></p><p>首個能回想並連結真實歷史事件與資料集真實人物的模型。</p><p>範例：提示："It was the year of our Lord 1834"</p><p>輸出："It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity"</p><p>起初我以為抗議活動可能只是巧合地發生在同一年，但請看這裡：<img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3>為何這很重要：</h3></p><p>這是我模型首次將年份與真實歷史事件及與該事件有關的真實人物（Palmerston 勳爵）相連結的例子。早期模型（v0 和 v0.5）雖能模仿十九世紀的寫作風格，但總是捏造事件、人物和事實。這顯示模型開始能記住資料集中的內容。</p><h2>未來計畫</h2></p><ul><li>在 Internet Archive 上，倫敦於1800-1875年間出版的文本有近175,000份</li>
<li>我計畫擴展語料庫並進一步清理，以提升推理能力</li>
<li>擴展到不同地區和時期，以建立更多的歷史模型</li></p><p></ul><h2>如何使用</h2></p><p>本專案主要聚焦於整理歷史資料、準備訓練資料並建立分詞器。不會涵蓋完整的 LLM 訓練流程，相關內容請參考 Andrej Karpathy 的 nanoGPT。</p><h3>步驟一：收集並準備歷史文本</h3></p><ul><li>收集你選定時期的公有領域書籍、文件等 .txt 檔（例如：倫敦 1800-1850）</li>
<li>請確保資料都在你選定的時間/地點範圍內</li>
<li>使用腳本清理文本檔，或手動移除如 Project Gutenberg 的標頭/頁尾、現代註解或 OCR 錯誤等雜訊。</li></p><p></ul><h3>步驟二：建立自訂分詞器</h3></p><ul><li>對清理過的資料執行 train_tokenizer.py 或 train_tokenizer_hf.py</li>
<li>這將產生 vocab.json 與 merges.txt</li>
<li>這些檔案定義了模型的詞彙表和合併規則</li></p><p></ul><h3>步驟三：訓練你的模型</h3></p><ul><li>有關訓練流程，請參考 <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">Andrej Karpathy 的 nanoGPT</a> 或你選用架構的官方文件。</li></p><p></ul><h1>常見問答</h1></p><h2>什麼是選擇性時期訓練（Selective Temporal Training）？</h2></p><p>選擇性時期訓練（STT）是一種機器學習方法，所有訓練資料都特別整理，僅限於某個歷史時期。這麼做是為了建模該時代的語言與知識，不受現代概念影響。例如，目前的模型（v0.5）只用1800-1875年的資料訓練，並非微調，而是從零開始訓練，因此輸出能反映該時期的語言風格與歷史背景。</p><h2>為什麼不直接用微調或 LoRA？</h2></p><p>本專案目標是建立一個不受現代偏見影響的語言模型。如果用 GPT-2 這類模型微調，原本的預訓練資訊無法完全消除。從零開始訓練的語言模型不會假裝是舊的，而是本身就是。現階段目標是建立一個僅能用1800-1875年倫敦出版書籍知識推理的模型。</p><h2>你用什麼資料來訓練？</h2></p><p>
我正在使用1800至1875年倫敦的書籍、法律文件、報紙以及其他著作。你可以查看我提供的清單（v0版本），裡面大約有200份文件，但在第一次訓練時我只用了50個檔案，約187MB。你可以在以下連結查看文件清單：
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>資料集大小：
v0：約187MB
v0.5：約435MB
v1：約6.25GB</p><h2>模型有多大？</h2></p><p>V0：1600萬參數</p><p>V0.5：1億2300萬參數</p><p>V1：7億參數</p><h1>訓練規格？</h1></p><h1>V0/V0.5</h1>
GPU：Geforce RTX 4060
CPU：i5-13400F
記憶體：16GB DDR5。</p><h1>V1</h1>
GPU：租用A100</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-09-30

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-30 
    </div>
    
</body>
</html>