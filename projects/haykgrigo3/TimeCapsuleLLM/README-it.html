<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - Un LLM addestrato solo su dati di determinati periodi storici per ridurre i bias moderni</title>
    <meta name="description" content="Un LLM addestrato solo su dati di determinati periodi storici per ridurre i bias moderni">
    <meta name="keywords" content="TimeCapsuleLLM, Italian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "Un LLM addestrato solo su dati di determinati periodi storici per ridurre i bias moderni",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 545
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-it.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2025-09-30",
  "dateModified": "2025-09-30"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 545 stars</span>
                <span class="language">Italian</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Lingua</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="#" title="In arrivo">繁體中文 (in arrivo)</a> |
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">한국어</a>
        | <a href="#" title="In arrivo">हिन्दी (in arrivo)</a> |
        | <a href="#" title="In arrivo">ไทย (in arrivo)</a> |
        | <a href="#" title="In arrivo">Français (in arrivo)</a>
        | <a href="#" title="In arrivo">Deutsch (in arrivo)</a>
        | <a href="#" title="In arrivo">Español (in arrivo)</a>
        | <a href="#" title="In arrivo">Italiano (in arrivo)</a>
        | <a href="#" title="In arrivo">Русский (in arrivo)</a>
        | <a href="#" title="In arrivo">Português (in arrivo)</a>
        | <a href="#" title="In arrivo">Nederlands (in arrivo)</a>
        | <a href="#" title="In arrivo">Polski (in arrivo)</a>
        | <a href="#" title="In arrivo">العربية (in arrivo)</a>
        | <a href="#" title="In arrivo">فارسی (in arrivo)</a>
        | <a href="#" title="In arrivo">Türkçe (in arrivo)</a>
        | <a href="#" title="In arrivo">Tiếng Việt (in arrivo)</a>
        | <a href="#" title="In arrivo">Bahasa Indonesia (in arrivo)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1></p><p><em>Un modello linguistico addestrato <strong>da zero</strong> esclusivamente su dati provenienti da specifici luoghi e periodi storici per ridurre il bias moderno e imitare la voce, il vocabolario e la visione del mondo dell’epoca.</em></p><p>Immagina se un modello AI non si limitasse a fingere di essere storico, ma lo fosse davvero.</p><p>v0 e v0.5 sono stati costruiti su <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT di Andrej Karpathy</a> Le principali script di addestramento e l’architettura del modello sono opera sua. </p><p>v1 costruito su <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Phi 1.5 di Microsoft</a></p><p><a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">Link Hugging Face</a></p><h2> Comportamento del Modello & Limitazioni</h2></p><h3><strong>v0</strong>  </h3></p><p>I primi prompt mostrano il modello rispondere con linguaggio e comportamento dell'Ottocento. 
Esempio: Prompt: "Who art Henry?" e ha risposto "I know that man, I have did not a black, the storm." </p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="Output di esempio TimeLockLLM"></p><ul><li>Nessun riferimento a concetti moderni  </li>
<li>Vocabolario quasi sempre accurato per l’epoca  </li>
<li>Frasi per lo più incoerenti (previsto per ~187MB di dati di addestramento)</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>Un miglioramento significativo rispetto a v0.  
<ul><li>Stile di scrittura vittoriano, punteggiatura corretta, frasi generalmente grammaticali  </li>
<li>Ancora alto tasso di allucinazione fattuale  </li>
<li>Rumore OCR (“Digitized by Google”) ancora presente negli output</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="Output di esempio TimeLockLLM"></p><h3><strong>v1</strong></h3></p><p>Primo modello in grado di richiamare e collegare un vero evento storico con una persona reale presente nel dataset.</p><p>Esempio: Prompt: "It was the year of our Lord 1834" </p><p>Output: "It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity" </p><p>All’inizio pensavo che una protesta potesse essere avvenuta casualmente nello stesso anno, ma guarda qui: <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3>Perché è importante:</h3></p><p>Questo è il primo esempio di uno dei miei modelli che collega un anno sia a un vero evento storico sia a una persona reale legata a quell’evento (Lord Palmerston). I modelli precedenti (v0 e v0.5) riuscivano a imitare lo stile di scrittura del XIX secolo ma inventavano sempre eventi, persone e fatti. Questo dimostra che il modello sta iniziando a ricordare elementi dal dataset.</p><h2>Piani Futuri</h2></p><ul><li>Ci sono quasi 175.000 testi pubblicati a Londra dal 1800 al 1875 disponibili su Internet Archive</li>
<li>Ho intenzione di espandere il corpus e pulirlo ulteriormente per migliorare le capacità di ragionamento</li>
<li>Espansione verso diverse regioni e periodi storici per modelli più storici</li></p><p></ul><h2>Come Utilizzare</h2></p><p>Questo progetto si concentra principalmente sulla raccolta di dati storici, sulla loro preparazione per l'addestramento e sulla costruzione di un tokenizer. Non tratterò il processo completo di addestramento LLM, per quello consultare nanoGPT di Andrej Karpathy.</p><h3>Passo 1: Raccogliere e Preparare i Testi Storici</h3></p><ul><li>Raccogli file .txt di libri di dominio pubblico, documenti, ecc. dal periodo scelto (ad esempio, Londra 1800-1850)</li>
<li>Mantienili all'interno della finestra temporale/luogo scelta</li>
<li>Pulisci i file di testo usando uno script o rimuovendo manualmente intestazioni/piedi di pagina da Project Gutenberg, annotazioni moderne o errori OCR.</li></p><p></ul><h3>Passo 2: Costruire un Tokenizer Personalizzato</h3></p><ul><li>Esegui train_tokenizer.py o train_tokenizer_hf.py sui dati puliti.</li>
<li>Questo ti fornirà vocab.json e merges.txt</li>
<li>Questi file definiscono il vocabolario e le regole di fusione per il tuo modello</li></p><p></ul><h3>Passo 3: Addestra il Tuo Modello</h3></p><ul><li>Consulta <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT di Andrej Karpathy</a> per il processo di addestramento o la documentazione dell'architettura scelta.</li></p><p></ul><h1>FAQ</h1></p><h2>Cos'è l'Addestramento Temporale Selettivo?</h2></p><p>L'Addestramento Temporale Selettivo (STT) è una metodologia di machine learning in cui tutti i dati di addestramento sono accuratamente selezionati per ricadere in uno specifico periodo storico. Viene fatto per modellare il linguaggio e la conoscenza di quell'epoca senza influenze da concetti moderni. Ad esempio, il modello attuale che ho ora (v0.5) è addestrato esclusivamente su dati dal 1800 al 1875, non è stato ottimizzato ma addestrato da zero, risultando in output che riflettono lo stile linguistico e il contesto storico di quel periodo.</p><h2>Perché non usare semplicemente fine-tuning o LoRA?</h2></p><p>Per questo progetto sto cercando di creare un modello linguistico non influenzato dai bias moderni. Se ottimizzo qualcosa come GPT-2, è già pre-addestrato e quell'informazione non sparirà. Se lo addestro da zero il modello linguistico non fingerà di essere antico, lo sarà realmente. L'obiettivo di questo progetto al momento è creare qualcosa che possa ragionare esclusivamente usando la conoscenza dei libri londinesi pubblicati tra il 1800 e il 1875.</p><h2>Che tipo di dati hai usato per l'addestramento?</h2></p><p>
Sto utilizzando libri, documenti legali, giornali e altri scritti della Londra tra il 1800 e il 1875. La lista che ho linkato (per v0) contiene circa 200 documenti, ma per il primo addestramento ho usato solo 50 file per circa ~187 MB. Puoi visualizzare un elenco dei documenti:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>Dimensioni dei dataset:
v0: ~187MB
v0.5: ~435MB 
v1: ~6.25GB </p><h2>Quanto sono grandi i modelli?</h2></p><p>V0: 16M Parametri</p><p>V0.5 123M Parametri</p><p>V1: 700M Parametri</p><h1>Specifiche di addestramento?</h1></p><h1>V0/V0.5</h1>
GPU: Geforce rtx 4060
CPU: i5-13400F 
Ram: 16GB DDR5.</p><h1>V1</h1>
GPU: A100 noleggiata</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-09-30

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-30 
    </div>
    
</body>
</html>