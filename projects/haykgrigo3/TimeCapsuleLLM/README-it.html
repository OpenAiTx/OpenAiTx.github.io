<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - Un LLM addestrato esclusivamente su dati di determinati periodi storici per ridurre i bias moderni</title>
    <meta name="description" content="Un LLM addestrato esclusivamente su dati di determinati periodi storici per ridurre i bias moderni">
    <meta name="keywords" content="TimeCapsuleLLM, Italian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "Un LLM addestrato esclusivamente su dati di determinati periodi storici per ridurre i bias moderni",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 349
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-it.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2025-08-19",
  "dateModified": "2025-08-19"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 349 stars</span>
                <span class="language">Italian</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Lingua</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="#" title="In arrivo">繁體中文 (in arrivo)</a> |
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">한국어</a>
        | <a href="#" title="In arrivo">हिन्दी (in arrivo)</a> |
        | <a href="#" title="In arrivo">ไทย (in arrivo)</a> |
        | <a href="#" title="In arrivo">Français (in arrivo)</a>
        | <a href="#" title="In arrivo">Deutsch (in arrivo)</a>
        | <a href="#" title="In arrivo">Español (in arrivo)</a>
        | <a href="#" title="In arrivo">Italiano (in arrivo)</a>
        | <a href="#" title="In arrivo">Русский (in arrivo)</a>
        | <a href="#" title="In arrivo">Português (in arrivo)</a>
        | <a href="#" title="In arrivo">Nederlands (in arrivo)</a>
        | <a href="#" title="In arrivo">Polski (in arrivo)</a>
        | <a href="#" title="In arrivo">العربية (in arrivo)</a>
        | <a href="#" title="In arrivo">فارسی (in arrivo)</a>
        | <a href="#" title="In arrivo">Türkçe (in arrivo)</a>
        | <a href="#" title="In arrivo">Tiếng Việt (in arrivo)</a>
        | <a href="#" title="In arrivo">Bahasa Indonesia (in arrivo)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1></p><p><em>Un modello linguistico addestrato <strong>da zero</strong> esclusivamente su dati provenienti da specifici luoghi e periodi storici per ridurre il bias moderno e imitare la voce, il vocabolario e la visione del mondo dell’epoca.</em></p><p>Immagina se un modello AI non si limitasse a fingere di essere storico, ma lo fosse davvero.</p><p>v0 e v0.5 sono stati costruiti su <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT di Andrej Karpathy</a> Le principali script di addestramento e l’architettura del modello sono opera sua. </p><p>v1 basato su <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Phi 1.5 di Microsoft</a></p><h2> Comportamento del Modello & Limitazioni</h2></p><h3><strong>v0</strong>  </h3></p><p>I primi prompt mostrano il modello rispondere con linguaggio e comportamento tipici dell'Ottocento.  
Esempio: Prompt: "Chi è Henry?" e ha risposto "Conosco quell'uomo, non ho fatto nero, la tempesta." </p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="Esempio Output TimeLockLLM"></p><ul><li>Nessun accenno a concetti moderni  </li>
<li>Vocabolario perlopiù accurato per l'epoca  </li>
<li>Frasi perlopiù incoerenti (previsto per ~187MB di dati di addestramento)</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>Un miglioramento significativo rispetto a v0.  
<ul><li>Stile di scrittura vittoriano, punteggiatura corretta, frasi perlopiù grammaticali  </li>
<li>Tasso ancora elevato di allucinazione fattuale  </li>
<li>Rumore OCR (“Digitalizzato da Google”) ancora presente negli output</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="Esempio Output TimeLockLLM"></p><h3><strong>v1</strong></h3></p><p>Primo modello a richiamare e collegare un vero evento storico con una figura reale del dataset.</p><p>Esempio: Prompt: "Era l'anno del Signore 1834" </p><p>Output: "Era l'anno del Signore 1834 e le strade di Londra erano piene di protesta e petizione. La causa, come molti ricordavano, non era vincolata al modo privato, ma era stata presa nello stesso giorno nel giorno di Lord Palmerston, il pubblico riceverà una breve dichiarazione delle difficoltà sotto le quali il giorno della legge ci ha raggiunto. È motivo di profondo rammarico che gli eventi attuali nella storia del mondo siano chiari, e di conseguenza saranno conosciuti. Non è vero che gli stessi uomini che per primi si stabilirono nel Vangelo a Gerusalemme dovrebbero avere un registro così esteso e interessante della prosperità e prosperità" </p><p>All'inizio pensavo che una protesta potesse essere avvenuta casualmente nello stesso anno, ma guarda qui: <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3>Perché è importante:</h3></p><p>Questo è il primo esempio di uno dei miei modelli che collega un anno sia a un vero evento storico sia a una persona reale legata a quell'evento (Lord Palmerston). I modelli precedenti (v0 e v0.5) potevano imitare gli stili di scrittura del XIX secolo ma avrebbero sempre inventato eventi, persone e fatti. Questo mostra che il modello sta iniziando a ricordare elementi dal dataset</p><h2>Piani Futuri</h2></p><ul><li>Ci sono quasi 175.000 testi pubblicati a Londra dal 1800 al 1875 su Internet Archive </li>
<li>Ho intenzione di espandere il corpus e pulirlo ulteriormente per migliorare le capacità di ragionamento</li>
<li>Espansione verso diverse regioni e periodi storici per modelli più storici</li></p><p>
</ul><h2>Come Usare</h2></p><p>Questo progetto si concentra principalmente sulla raccolta di dati storici, sulla loro preparazione per l’addestramento e sulla costruzione di un tokenizer. Non coprirò il processo completo di addestramento LLM, per quello si rimanda a nanoGPT di Andrej Karpathy.</p><h3>Passo 1: Raccogliere e Preparare Testi Storici</h3></p><ul><li>Raccogli file .txt di libri, documenti ecc. di dominio pubblico dal periodo scelto (es. Londra 1800-1850)</li>
<li>Mantienili all’interno della finestra temporale/luogo selezionata  </li>
<li>Pulisci i file di testo con uno script o manualmente rimuovendo intestazioni/piedipagina da Project Gutenberg, annotazioni moderne o errori OCR.</li></p><p></ul><h3>Passo 2: Costruire un Tokenizer Personalizzato</h3></p><ul><li>Esegui train_tokenizer.py o train_tokenizer_hf.py sui dati puliti.</li>
<li>Questo ti darà vocab.json e merges.txt</li>
<li>Questi file definiscono vocabolario e regole di unione per il tuo modello</li></p><p></ul><h3>Passo 3: Addestra il Tuo Modello</h3></p><ul><li>Consulta <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT di Andrej Karpathy</a> per il processo di addestramento o la documentazione dell’architettura scelta.</li></p><p></ul><h1>FAQ</h1></p><h2>Cos’è l’Addestramento Temporale Selettivo?</h2></p><p>L’Addestramento Temporale Selettivo (STT) è una metodologia di machine learning dove tutti i dati di addestramento sono selezionati specificamente per ricadere in un determinato periodo storico. Viene fatto per modellare la lingua e la conoscenza di quell’epoca senza influenze da concetti moderni. Ad esempio, il modello attuale che ho ora (v0.5) è addestrato esclusivamente su dati dal 1800 al 1875, non è ottimizzato ma addestrato da zero producendo output che riflette lo stile linguistico e il contesto storico di quell’epoca.</p><h2>Perché non usare semplicemente il fine-tuning o LoRA?</h2></p><p>Per questo progetto sto cercando di creare un modello linguistico non influenzato da bias moderni. Se faccio il fine-tuning di qualcosa come GPT-2, è già pre-addestrato e quell’informazione non andrà via. Se addestro da zero il modello linguistico non fingerà di essere antico, lo sarà e basta. L’obiettivo per questo progetto ora è creare qualcosa che possa ragionare esclusivamente usando la conoscenza dei libri londinesi pubblicati tra il 1800 e il 1875.</p><h2>Che tipo di dati hai usato per l’addestramento?</h2></p><p>Sto usando libri, documenti legali, giornali e altri scritti di Londra dal 1800 al 1875. La lista che ho collegato (per v0) ne ha circa 200, ma per il primo addestramento ho usato solo 50 file per circa ~187 MB. Puoi vedere una lista dei documenti:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>
Dimensioni dei dataset:
v0: ~187MB
v0.5: ~435MB 
v1: ~6,25GB </p><h2>Quanto sono grandi i modelli?</h2></p><p>V0: 16M Parametri</p><p>V0.5: 123M Parametri</p><p>V1: 700M Parametri</p><h1>Specifiche di addestramento?</h1></p><h1>V0/V0.5</h1>
GPU: Geforce rtx 4060
CPU: i5-13400F 
Ram: 16GB DDR5.</p><h1>V1</h1>
GPU: A100 noleggiata</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-08-19

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-08-19 
    </div>
    
</body>
</html>