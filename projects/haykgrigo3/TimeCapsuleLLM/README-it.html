<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - Un LLM addestrato esclusivamente su dati di determinati periodi storici per ridurre i bias moderni</title>
    <meta name="description" content="Un LLM addestrato esclusivamente su dati di determinati periodi storici per ridurre i bias moderni">
    <meta name="keywords" content="TimeCapsuleLLM, Italian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "Un LLM addestrato esclusivamente su dati di determinati periodi storici per ridurre i bias moderni",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 830
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-it.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2026-01-09",
  "dateModified": "2026-01-09"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 830 stars</span>
                <span class="language">Italian</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align="right">
  <details>
    <summary >🌐 Lingua</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-TW">繁體中文</a> 
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=as">हिन्दी</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=th">ไทย</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=es">Español</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ar">العربية</a>
        | <a href="#" title="Coming soon">فارسی (coming soon)</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=vi">Tiếng Việt</a>
        | <a href="#" title="Coming soon">Bahasa Indonesia (coming soon)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1></p><p><em>Un modello linguistico addestrato <strong>da zero</strong> esclusivamente su dati provenienti da determinati luoghi e periodi storici per ridurre il bias moderno ed emulare la voce, il vocabolario e la visione del mondo dell'epoca.</em></p><p>Immagina se un modello AI non fingesse soltanto di essere storico, ma lo fosse davvero.</p><p>v0 e v0.5 costruiti su <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT di Andrej Karpathy</a> Gli script principali di addestramento e l'architettura del modello sono opera sua. </p><p>v1 basato su <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Phi 1.5 di Microsoft</a></p><p><a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">Link Hugging Face</a></p><h2> Comportamento del modello e limitazioni</h2></p><h3><strong>v0</strong>  </h3></p><p>I primi prompt mostrano il modello che risponde con linguaggio e comportamento dell’800. 
Esempio: Prompt: "Who art Henry?" e ha risposto "I know that man, I have did not a black, the storm." </p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="Esempio Output TimeLockLLM"></p><ul><li>Nessun riferimento a concetti moderni  </li>
<li>Lessico per lo più accurato per l’epoca  </li>
<li>Le frasi sono per lo più incoerenti (previsto con ~187MB di dati di addestramento)</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>Un miglioramento significativo rispetto alla v0.  
<ul><li>Stile di scrittura vittoriano, punteggiatura corretta, frasi per lo più grammaticali  </li>
<li>Ancora alta presenza di allucinazioni fattuali  </li>
<li>Rumore OCR (“Digitized by Google”) ancora presente negli output</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="Esempio Output TimeLockLLM"></p><h3><strong>v1</strong></h3></p><p>Primo modello a ricordare e collegare un evento storico reale con una figura effettiva del dataset.</p><p>Esempio: Prompt: "It was the year of our Lord 1834" </p><p>L’output: "It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity" </p><p>All’inizio pensavo che una protesta potesse essere avvenuta casualmente nello stesso anno, ma guarda qui: <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3><strong>v2mini-eval1</strong></h3></p><p>Addestrato utilizzando un campione da 15GB del dataset v2 da 90GB.</p><p>Modello addestrato solo per 10.000 step.</p><p>C'è stato un problema con la tokenizzazione che causa un output simile a questo:</p><p>PROMPT:
Chi è Charles Dickens?</p><p>
W ho is Charles D ic ens ? D oes that work more of h ise x cell ent st ir ring , in his pl ays , int he G reat C omp any 's f arm ? What I have y et to qu ote from J ack P ick ett ? D oy oun ot know th att hey were as pe cies of g all oping , ors aw ing oft heir bre asts , or what w ast ob ed one about the t im ew hen J acks on was looking ont hew ind ow ? What ist hes uccess of an English man , and which h isson has not be end is cover ing t ome , where by to acc omp lish such a we ight ? D idy ou ever m ake ap ass age int othe old road way , ort o an anch or - b ree ze att he foot of our boat , which you m ust le ave us ? The fact is , that whe ther the wind would rise up from the pl ain on S atur day night orn o ont ide , ort ill then orth , or other wise , wes hall be com pelled t od esc ribe af orm idable bar rier , with t hes ame e ffect s ast he p resent . In th iss itu ation , at le ast , itis not to omuch t os ay that we have le ft that room . I bel ieve there are three c op ies int he " F ive H undred - fold ," to bere fer red to , ast he first n umber of our read ers wh ow is ht
Corretto:</p><p>"Chi è Charles Dickens? È forse quel lavoro uno dei suoi eccellenti e appassionanti, nelle sue opere teatrali, nella fattoria della Grande Compagnia? Cosa devo ancora citare da Jack Pickett? Non sai che erano una sorta di galoppata, o un segare dei loro petti, o cosa si doveva fare al tempo in cui Jackson stava guardando dalla finestra? Qual è il successo di un inglese, e che suo figlio non mi ha ancora rivelato, per poter compiere un tale peso? Hai mai fatto un passaggio sulla vecchia strada, o verso una brezza d’ancora ai piedi della nostra barca, che devi lasciarci? Il fatto è che, sia che il vento si alzi dalla pianura il sabato notte o a mezzogiorno, o fino al nord, o in altro modo, saremo costretti a descrivere una barriera formidabile, con gli stessi effetti dell’attuale. In questa situazione, almeno, non è troppo dire che abbiamo lasciato quella stanza. Credo che ci siano tre copie nel 'Cinque Cento volte,' a cui fare riferimento, come il primo numero dei nostri lettori che desiderano t[o]..."</p><h3><strong>v2mini-eval2</strong></h3></p><p>Addestrato utilizzando lo stesso campione da 15GB usato per l’addestramento di eval1.
Il modello è stato nuovamente addestrato solo fino a 10.000 step.</p><p>PROMPT: Charles Darwin</p><p>Charles DarwinECCEMACY. Signore, — Il seguente caso mi interessa: — Sono stato a Londra quindici giorni, e sono stato molto colpito da un attacco di reumatismo. Il primo attacco di reumatismo è stato una settimana prima che la vedessi, il secondo quando l’ho vista, e il terzo quando l’ho vista, e il terzo nello stesso periodo. Il secondo attacco di gotta, però, non era accompagnato da sintomi febbrili, ma da un aumento del flusso urinario, e da una minzione più abbondante. Il terzo attacco è stato un’ora dopo che l’ho vista, ed è stato seguito da un ritorno di un parossismo di gotta, e da un ritorno più rapido della gotta. Il quarto attacco è stato anch’esso accompagnato da febbre, ma non sempre da sintomi febbrili. Il terzo attacco di gotta è stato quindici giorni dopo che lei era stato male, e il quarto fu seguito da un parossismo di gotta. Il quarto attacco fu quindici giorni dopo che lei fu colpito, ed era accompagnato da una sensazione</p><h2> Datasets</h2></p><h3><strong>v2</strong></h3></p><ul><li>90GB di testi londinesi dal 1800 al 1875</li>
<li>136.344 documenti</li>
<li>L’intero set da 90GB non è ancora disponibile poiché non è stato tokenizzato, ma puoi trovare un campione da 15GB qui: https://huggingface.co/datasets/haykgrigorian/TimeCapsuleLLM-London-1800-1875-v2-15GB</li></p><p> </ul>### Statistiche Bias
  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/pronoun_bias.png" alt="Bias nei pronomi"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/geographic_bias.png" alt="Bias geografico"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/temporal_bias.png" alt="Bias temporale"></p><p>Consultare il <a href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/v2_bias_report.json" target="_blank" rel="noopener noreferrer">rapporto bias v2</a> per ulteriori informazioni.</p><h2>Come utilizzare</h2></p><p>Questo progetto si concentra principalmente sulla raccolta di dati storici, la loro preparazione per l’addestramento e la costruzione di un tokenizer. Non tratterò l’intero processo di training di un LLM; per questo fare riferimento a nanoGPT di Andrej Karpathy.</p><h3>Passo 1: Raccogli e prepara testi storici</h3></p><ul><li>Raccogli file .txt di libri, documenti, ecc. di pubblico dominio dal periodo storico scelto (ad esempio, Londra 1800-1850)</li></p><p>
<li>Mantienili all'interno della finestra di tempo/luogo scelta  </li>
<li>Pulisci i file di testo usando uno script o rimuovi manualmente intestazioni/piedipagina di Project Gutenberg, annotazioni moderne o errori OCR.</li></p><p></ul><h3>Passo 2: Costruisci un Tokenizer Personalizzato</h3></p><ul><li>Esegui train_tokenizer.py o train_tokenizer_hf.py sui dati puliti.</li>
<li>Questo ti fornirà vocab.json e merges.txt</li>
<li>Questi file definiscono il vocabolario e le regole di unione per il tuo modello</li></p><p></ul><h3>Passo 3: Allena il Tuo Modello</h3></p><ul><li>Fai riferimento a <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT di Andrej Karpathy</a> per il processo di training o alla documentazione dell’architettura scelta.</li></p><p></ul><h1>FAQ</h1></p><h2>Cos’è l’Addestramento Temporale Selettivo?</h2></p><p>L’Addestramento Temporale Selettivo (STS) è una metodologia di machine learning in cui tutti i dati di addestramento sono accuratamente selezionati per ricadere in uno specifico periodo storico. Viene fatto per modellare il linguaggio e la conoscenza di quell’epoca senza l’influenza di concetti moderni. Ad esempio, il modello attuale che ho ora (v0.5) è addestrato esclusivamente su dati dal 1800 al 1875, non è stato fine-tuned ma addestrato da zero, producendo output che riflettono lo stile linguistico e il contesto storico di quel periodo.</p><h2>Perché non usare semplicemente fine-tuning o LoRA?</h2></p><p>Per questo progetto voglio creare un modello linguistico libero dai bias moderni. Se faccio fine-tuning su qualcosa come GPT-2, è già pre-addestrato e quell’informazione non andrà via. Se alleno da zero il modello linguistico non fingerà di essere antico, lo sarà davvero. L’obiettivo attuale è creare qualcosa che possa ragionare esclusivamente usando conoscenza tratta da libri londinesi pubblicati tra il 1800 e il 1875.</p><h2>Che tipo di dati hai usato per l’addestramento?</h2></p><p>Sto usando libri, documenti legali, giornali e altri scritti della Londra del 1800–1875. La lista che ho linkato (per la v0) contiene circa 200 file ma per il primo addestramento ne ho usati solo 50 per un totale di circa 187 MB. Puoi vedere la lista dei documenti qui:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>Dimensioni dei dataset:
<ul><li>v0: ~187MB</li>
<li>v0.5: ~435MB </li>
<li>v1: ~6.25GB </li>
<li>v2mini-eval1: 15GB</li></p><p></ul><h2>Quanto sono grandi i modelli?</h2></p><p>v0: 16M Parametri</p><p>v0.5 123M Parametri</p><p>v1: 700M Parameters</p><p>v2mini-eval1: 300M Parameters</p><h1>Training Specs ? </h1></p><h1>v0/v0.5</h1>
GPU: Geforce rtx 4060
CPU: i5-13400F 
Ram: 16GB DDR5.</p><h1>v1</h1>
GPU: A100 SXM rented</p><h1>v2mini-eval1</h1></p><p>GPU: A100 SXM rented</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-01-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-01-09 
    </div>
    
</body>
</html>