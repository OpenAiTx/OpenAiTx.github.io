<!DOCTYPE html>
<html lang="pl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - LLM wytrenowany wyłącznie na danych z określonych okres&#243;w, aby zredukować wsp&#243;łczesne uprzedzenia</title>
    <meta name="description" content="LLM wytrenowany wyłącznie na danych z określonych okres&#243;w, aby zredukować wsp&#243;łczesne uprzedzenia">
    <meta name="keywords" content="TimeCapsuleLLM, Polish, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "LLM wytrenowany wyłącznie na danych z określonych okresów, aby zredukować współczesne uprzedzenia",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 830
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-pl.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2026-01-09",
  "dateModified": "2026-01-09"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 830 stars</span>
                <span class="language">Polish</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align="right">
  <details>
    <summary >🌐 Język</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-TW">繁體中文</a> 
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=as">हिन्दी</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=th">ไทย</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=es">Español</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ar">العربية</a>
        | <a href="#" title="Coming soon">فارسی (wkrótce)</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=vi">Tiếng Việt</a>
        | <a href="#" title="Coming soon">Bahasa Indonesia (wkrótce)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1></p><p><em>Model językowy wytrenowany <strong>od podstaw</strong> wyłącznie na danych z określonych miejsc i epok, aby ograniczyć współczesne uprzedzenia i odwzorować język, słownictwo oraz światopogląd danej ery.</em></p><p>Wyobraź sobie, że model AI nie tylko udaje historyczny, ale faktycznie nim jest.</p><p>Wersje v0 oraz v0.5 zbudowane na <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT autorstwa Andreja Karpathy'ego</a> Podstawowe skrypty treningowe i architektura modelu to jego dzieło. </p><p>v1 zbudowany na <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Phi 1.5 firmy Microsoft</a></p><p><a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">Link do Hugging Face</a></p><h2> Zachowanie modelu i ograniczenia</h2></p><h3><strong>v0</strong>  </h3></p><p>Wczesne zapytania pokazują, że model odpowiada językiem i zachowaniem z XIX wieku. 
Przykład: Zapytanie: "Who art Henry?" i odpowiedź: "I know that man, I have did not a black, the storm." </p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="Przykładowe wyjście TimeLockLLM"></p><ul><li>Brak wzmianki o współczesnych koncepcjach  </li>
<li>Głównie słownictwo zgodne z epoką  </li>
<li>Zdania przeważnie niespójne (oczekiwane przy ~187MB danych treningowych)</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>Znacząca poprawa względem v0.  
<ul><li>Wiktoriański styl pisania, poprawna interpunkcja, przeważnie gramatyczne zdania  </li>
<li>Nadal wysoki poziom halucynacji faktów  </li>
<li>Szumy OCR („Digitized by Google”) nadal obecne w odpowiedziach</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="Przykładowe wyjście TimeLockLLM"></p><h3><strong>v1</strong></h3></p><p>Pierwszy model, który przywołuje i łączy prawdziwe wydarzenie historyczne z rzeczywistą postacią z zestawu danych.</p><p>Przykład: Zapytanie: "It was the year of our Lord 1834" </p><p>Odpowiedź: "It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity" </p><p>Na początku założyłem, że protest mógł przypadkowo mieć miejsce w tym samym roku, ale zobaczcie to: <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3><strong>v2mini-eval1</strong></h3></p><p>Wytrenowany przy użyciu 15GB próbki z 90GB zestawu danych v2.
Model wytrenowany tylko do 10 000 kroków.</p><p>Wystąpił problem z tokenizacją, który powoduje, że wynik wygląda tak:</p><p>ZAPYTANIE:
Kim jest Charles Dickens?</p><p>
W ho is Charles D ic ens ? D oes that work more of h ise x cell ent st ir ring , in his pl ays , int he G reat C omp any 's f arm ? What I have y et to qu ote from J ack P ick ett ? D oy oun ot know th att hey were as pe cies of g all oping , ors aw ing oft heir bre asts , or what w ast ob ed one about the t im ew hen J acks on was looking ont hew ind ow ? What ist hes uccess of an English man , and which h isson has not be end is cover ing t ome , where by to acc omp lish such a we ight ? D idy ou ever m ake ap ass age int othe old road way , ort o an anch or - b ree ze att he foot of our boat , which you m ust le ave us ? The fact is , that whe ther the wind would rise up from the pl ain on S atur day night orn o ont ide , ort ill then orth , or other wise , wes hall be com pelled t od esc ribe af orm idable bar rier , with t hes ame e ffect s ast he p resent . In th iss itu ation , at le ast , itis not to omuch t os ay that we have le ft that room . I bel ieve there are three c op ies int he " F ive H undred - fold ," to bere fer red to , ast he first n umber of our read ers wh ow is ht</p><p>Poprawione:</p><p>„Kim jest Charles Dickens? Czy to dzieło bardziej jego doskonałego poruszania, w jego sztukach, na farmie Wielkiej Spółki? Co mam jeszcze zacytować od Jacka Picketta? Czy nie wiesz, że byli gatunkiem galopujących, albo piłujących swoje piersi, albo co należało zrobić w czasie, gdy Jackson patrzył przez okno? Czym jest sukces Anglika i co jego syn nie odkrył przede mną, aby osiągnąć taki ciężar? Czy kiedykolwiek przebyłeś starą drogę, albo do bryzy kotwicznej u stóp naszej łodzi, którą musisz nas opuścić? Faktem jest, że czy wiatr powstanie z równiny w sobotnią noc, czy w południe, czy aż do północy, czy inaczej, będziemy zmuszeni opisać potężną barierę, z tymi samymi skutkami co obecnie. W tej sytuacji, przynajmniej, nie jest przesadą powiedzieć, że opuściliśmy tamten pokój. Wierzę, że są trzy egzemplarze w „Pięćsetkrotnym”, do których można się odwołać, jako pierwszy numer naszych czytelników, którzy chcą t[o]...”</p><h3><strong>v2mini-eval2</strong></h3></p><p>Wytrenowany na tej samej próbce 15GB użytej do trenowania eval1.
Model ponownie wytrenowany tylko do 10K kroków.</p><p>PROMPT: Charles Darwin</p><p>Charles Darwin ECCEMACY. Proszę pana, — Następujący przypadek jest dla mnie interesujący: — Byłem w Londynie przez dwa tygodnie i bardzo dotknął mnie atak reumatyzmu. Pierwszy atak reumatyzmu nastąpił tydzień przed tym, jak się z panem zobaczyłem, drugi gdy się spotkaliśmy, trzeci gdy się zobaczyliśmy, i trzeci w tym samym czasie. Drugi atak dny nie był jednak związany z objawami gorączkowymi, lecz towarzyszył mu zwiększony przepływ moczu i obfitszy jego wypływ. Trzeci atak nastąpił godzinę po naszym spotkaniu i zakończył się powrotem napadu dny oraz szybszym nawrotem dny. Czwarty atak również był związany z gorączką, ale nie zawsze z objawami gorączkowymi. Trzeci atak dny był dwa tygodnie po tym, jak był pan chory, a czwarty nastąpił po napadzie dny. Czwarty atak nastąpił dwa tygodnie po tym, jak został pan zaatakowany, i towarzyszyło mu uczucie</p><h2> Zbiory danych</h2></p><h3><strong>v2</strong></h3></p><ul><li>90GB tekstów londyńskich z lat 1800-1875</li>
<li>136 344 dokumentów</li>
<li>Całe 90GB nie jest jeszcze dostępne, ponieważ nie zostało ztokenizowane, ale próbkę 15GB można znaleźć tutaj: https://huggingface.co/datasets/haykgrigorian/TimeCapsuleLLM-London-1800-1875-v2-15GB</li></p><p> </ul>### Statystyki uprzedzeń 
  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/pronoun_bias.png" alt="Uprzedzenie zaimkowe"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/geographic_bias.png" alt="Uprzedzenie geograficzne"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/temporal_bias.png" alt="Uprzedzenie czasowe"></p><p>Więcej informacji znajdziesz w <a href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/v2_bias_report.json" target="_blank" rel="noopener noreferrer">raporcie o uprzedzeniach v2</a>.</p><h2>Jak używać</h2></p><p>Ten projekt koncentruje się głównie na gromadzeniu danych historycznych, przygotowaniu ich do treningu i budowie tokenizera. Nie będę omawiać pełnego procesu treningu LLM, w tym celu odsyłam do nanoGPT autorstwa Andreja Karpathy.</p><h3>Krok 1: Zbierz i przygotuj historyczne teksty </h3></p><ul><li>Zbierz pliki .txt z książkami, dokumentami itp. będącymi w domenie publicznej z wybranego okresu (np. Londyn 1800-1850)</li>
<li>Trzymaj je w wybranym przez siebie oknie czasowym/miejscu  </li>
<li>Oczyść pliki tekstowe za pomocą skryptu lub ręcznie usuń nagłówki/stopki z Project Gutenberg, nowoczesne adnotacje lub błędy OCR.</li></p><p></ul><h3>Krok 2: Zbuduj własny tokenizator</h3></p><ul><li>Uruchom train_tokenizer.py lub train_tokenizer_hf.py na oczyszczonych danych.</li>
<li>To da ci pliki vocab.json i merges.txt</li>
<li>Te pliki definiują słownik oraz zasady łączenia dla twojego modelu</li></p><p></ul><h3>Krok 3: Wytrenuj swój model </h3></p><ul><li>Odnieś się do <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT Andreja Karpathy’ego</a> w celu procesu treningu lub dokumentacji wybranej architektury.</li></p><p></ul><h1>FAQ</h1></p><h2>Czym jest Selektywne Szkolenie Czasowe?</h2></p><p>Selektywne Szkolenie Czasowe (STT) to metodologia uczenia maszynowego, w której wszystkie dane treningowe są starannie wyselekcjonowane tak, by pochodziły z określonego okresu historycznego. Ma to na celu modelowanie języka i wiedzy tamtej epoki bez wpływu współczesnych koncepcji. Przykładowo, obecny model (v0.5) został wytrenowany wyłącznie na danych z lat 1800-1875, nie został dostrojony, lecz wytrenowany od zera, dzięki czemu jego wyniki odzwierciedlają styl językowy i kontekst historyczny tamtego czasu.</p><h2>Dlaczego nie użyć po prostu fine-tuningu lub LoRA?</h2></p><p>W tym projekcie próbuję stworzyć model językowy wolny od współczesnych uprzedzeń. Jeśli zrobię fine-tuning np. GPT-2, to już jest wstępnie wytrenowany i tej wiedzy nie da się usunąć. Jeśli wytrenuję od zera, model językowy nie będzie udawał starego – po prostu taki będzie. Celem projektu na teraz jest stworzenie czegoś, co potrafi rozumować wyłącznie na podstawie wiedzy z londyńskich książek wydanych między 1800 a 1875 rokiem.</p><h2>Na jakich danych trenowałeś model?</h2></p><p>Używam książek, dokumentów prawnych, gazet i innych tekstów z Londynu z lat 1800–1875. Lista, którą podlinkowałem (dla v0), zawiera około 200 pozycji, ale do pierwszego treningu użyłem tylko 50 plików o łącznej wielkości ~187 MB. Listę dokumentów możesz zobaczyć tutaj:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>Rozmiary zbiorów danych:
<ul><li>v0: ~187MB</li>
<li>v0.5: ~435MB </li>
<li>v1: ~6.25GB </li>
<li>v2mini-eval1: 15GB</li></p><p></ul><h2>Jak duże są modele?</h2></p><p>v0: 16M parametrów</p><p>v0.5 123M parametrów</p><p>v1: 700M Parameters</p><p>v2mini-eval1: 300M Parameters</p><h1>Training Specs ? </h1></p><h1>v0/v0.5</h1>
GPU: Geforce rtx 4060
CPU: i5-13400F 
Ram: 16GB DDR5.</p><h1>v1</h1>
GPU: A100 SXM rented</p><h1>v2mini-eval1</h1></p><p>GPU: A100 SXM rented</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-01-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-01-09 
    </div>
    
</body>
</html>