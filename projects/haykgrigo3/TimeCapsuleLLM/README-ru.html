<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - LLM, обученная только на данных из определённых временных периодов для снижения современного уклона</title>
    <meta name="description" content="LLM, обученная только на данных из определённых временных периодов для снижения современного уклона">
    <meta name="keywords" content="TimeCapsuleLLM, Russian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "LLM, обученная только на данных из определённых временных периодов для снижения современного уклона",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 830
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-ru.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2026-01-09",
  "dateModified": "2026-01-09"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 830 stars</span>
                <span class="language">Russian</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align="right">
  <details>
    <summary >🌐 Язык</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-TW">繁體中文</a> 
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=as">हिन्दी</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=th">ไทย</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=es">Español</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ar">العربية</a>
        | <a href="#" title="Скоро">فارسی (скоро)</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=vi">Tiếng Việt</a>
        | <a href="#" title="Скоро">Bahasa Indonesia (скоро)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1></p><p><em>Языковая модель, обученная <strong>с нуля</strong> исключительно на данных из определённых мест и исторических периодов для уменьшения современного влияния и имитации голоса, словаря и мировоззрения эпохи.</em></p><p>Представьте, если бы ИИ-модель не просто притворялась исторической, а действительно была таковой.</p><p>v0 и v0.5 построены на <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT от Andrej Karpathy</a>. Основные скрипты обучения и архитектура модели — его работа. </p><p>v1 создан на основе <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Phi 1.5 от Microsoft</a></p><p><a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">Ссылка на Hugging Face</a></p><h2> Поведение модели и ограничения</h2></p><h3><strong>v0</strong>  </h3></p><p>Ранние запросы показывают, что модель отвечает на языке и с поведением 1800-х годов. 
Пример: Запрос: "Who art Henry?" и ответ: "I know that man, I have did not a black, the storm." </p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="Пример вывода TimeLockLLM"></p><ul><li>Нет упоминания современных концепций  </li>
<li>В основном аутентичная для эпохи лексика  </li>
<li>Предложения в основном бессвязные (ожидаемо для ~187MB обучающих данных)</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>Значительное улучшение по сравнению с v0.  
<ul><li>Викторианский стиль письма, правильная пунктуация, в основном грамматичные предложения  </li>
<li>Всё ещё высокий уровень фактических галлюцинаций  </li>
<li>Шум от OCR (“Digitized by Google”) всё ещё присутствует в выводах</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="Пример вывода TimeLockLLM"></p><h3><strong>v1</strong></h3></p><p>Первая модель, которая воспроизводит и связывает реальное историческое событие с реальной фигурой из датасета.</p><p>Пример: Запрос: "It was the year of our Lord 1834" </p><p>Ответ: "It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity" </p><p>Сначала я предполагал, что протест мог случайно произойти в тот же год, но посмотрите на это: <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3><strong>v2mini-eval1</strong></h3></p><p>Обучена на 15ГБ сэмпле из 90ГБ датасета v2.</p><p>Модель обучена только на 10K шагов.</p><p>Возникла проблема с токенизацией, из-за которой вывод выглядит следующим образом:</p><p>ЗАПРОС:
Кто такой Чарльз Диккенс?</p><p>
W ho is Charles D ic ens ? D oes that work more of h ise x cell ent st ir ring , in his pl ays , int he G reat C omp any 's f arm ? What I have y et to qu ote from J ack P ick ett ? D oy oun ot know th att hey were as pe cies of g all oping , ors aw ing oft heir bre asts , or what w ast ob ed one about the t im ew hen J acks on was looking ont hew ind ow ? What ist hes uccess of an English man , and which h isson has not be end is cover ing t ome , where by to acc omp lish such a we ight ? D idy ou ever m ake ap ass age int othe old road way , ort o an anch or - b ree ze att he foot of our boat , which you m ust le ave us ? The fact is , that whe ther the wind would rise up from the pl ain on S atur day night orn o ont ide , ort ill then orth , or other wise , wes hall be com pelled t od esc ribe af orm idable bar rier , with t hes ame e ffect s ast he p resent . In th iss itu ation , at le ast , itis not to omuch t os ay that we have le ft that room . I bel ieve there are three c op ies int he " F ive H undred - fold ," to bere fer red to , ast he first n umber of our read ers wh ow is ht</p><p>Исправлено:</p><p>"Кто такой Чарльз Диккенс? Проявляется ли его выдающееся волнение больше в пьесах, на ферме Великой Компании? Что мне еще следует процитировать из Джека Пикетта? Разве вы не знаете, что они были своего рода всадниками, или пилили свои груди, или что следовало делать примерно в то время, когда Джексон смотрел в окно? Каков успех англичанина, и что его сын еще не открыл мне, чтобы выполнить такую тяжесть? Вы когда-нибудь проходили по старой дороге или к якорной пристани у подножия нашей лодки, которую вы должны покинуть? Дело в том, что независимо от того, поднимется ли ветер с равнины в субботу ночью или в полдень, или на север, или иначе, мы будем вынуждены описать грозное препятствие, с теми же последствиями, что и сейчас. В этой ситуации, по крайней мере, нельзя сказать, что мы остались в той комнате. Я полагаю, что есть три экземпляра в «Пятисоткратном», к которым можно обратиться, как к первому номеру наших читателей, желающих [о]..."</p><h3><strong>v2mini-eval2</strong></h3></p><p>Обучение проведено на том же 15ГБ выборке, что и для eval1.
Модель снова обучена только до 10К шагов.</p><p>ПРОМПТ:Charles Darwin</p><p>Charles DarwinECCEMACY. Сэр, — Следующий случай интересен для меня: — Я был в Лондоне две недели, и сильно страдал от приступа ревматизма. Первый приступ ревматизма был за неделю до встречи с вами, второй — когда я встретил вас, третий — когда я увидел вас, третий — в то же время. Второй приступ подагры, однако, не сопровождался лихорадочными симптомами, но сопровождался усиленным выделением мочи и более обильным выделением мочи. Третий приступ был через час после встречи с вами и сменился возвращением приступа подагры и более быстрым возвращением подагры. Четвертый приступ также сопровождался лихорадкой, но не всегда сопровождался лихорадочными симптомами. Третий приступ подагры был через две недели после вашего недомогания, а четвертый — после приступа подагры. Четвертый приступ был через две недели после вашего поражения, и сопровождался ощущением</p><h2> Наборы данных</h2></p><h3><strong>v2</strong></h3></p><ul><li>90ГБ текстов Лондона 1800-1875 гг.</li>
<li>136 344 документа</li>
<li>Полные 90ГБ пока недоступны, так как не токенизированы, но вы можете найти 15ГБ выборку здесь: https://huggingface.co/datasets/haykgrigorian/TimeCapsuleLLM-London-1800-1875-v2-15GB</li></p><p> </ul>### Статистика предвзятости 
  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/pronoun_bias.png" alt="Предвзятость по местоимениям"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/geographic_bias.png" alt="Географическая предвзятость"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/temporal_bias.png" alt="Временная предвзятость"></p><p>См. <a href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/v2_bias_report.json" target="_blank" rel="noopener noreferrer">отчет о предвзятости v2</a> для получения дополнительной информации.</p><h2>Как использовать</h2></p><p>Данный проект в основном посвящен сбору исторических данных, их подготовке для обучения и созданию токенизатора. Я не буду описывать полный процесс обучения LLM, для этого обратитесь к nanoGPT Андрея Карпати.</p><h3>Шаг 1: Сбор и подготовка исторических текстов </h3></p><ul><li>Соберите .txt-файлы книг, документов и др. из общественного достояния выбранного вами периода (например, Лондон 1800-1850) </li>
<li>Держите их в пределах выбранного вами временного/географического окна  </li>
<li>Очистите текстовые файлы с помощью скрипта или вручную удалите заголовки/подвалы из Project Gutenberg, современные аннотации или такие вещи, как ошибки OCR.</li></p><p></ul><h3>Шаг 2: Постройте собственный токенизатор</h3></p><ul><li>Запустите train_tokenizer.py или train_tokenizer_hf.py на очищенных данных.</li>
<li>Это даст вам vocab.json и merges.txt</li>
<li>Эти файлы определяют словарь и правила слияния для вашей модели</li></p><p></ul><h3>Шаг 3: Обучите свою модель</h3></p><ul><li>Обратитесь к <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT Андрея Карпаты</a> для процесса обучения или к документации выбранной вами архитектуры.</li></p><p></ul><h1>FAQ</h1></p><h2>Что такое Selective Temporal Training?</h2></p><p>Selective Temporal Training (STT) — это методика машинного обучения, когда все обучающие данные тщательно подбираются так, чтобы они соответствовали определенному историческому периоду. Это делается для моделирования языка и знаний той эпохи без влияния современных концепций. Например, текущая модель (v0.5) обучена только на данных 1800–1875 годов, она не дообучена, а обучена с нуля, что приводит к результатам, отражающим лингвистический стиль и исторический контекст того времени.</p><h2>Почему не использовать просто дообучение или LoRA?</h2></p><p>В этом проекте я пытаюсь создать языковую модель, не затуманенную современными предубеждениями. Если я дообучу что-то вроде GPT-2, она уже предварительно обучена и эта информация не исчезнет. Если обучать с нуля, языковая модель не будет притворяться старой, она просто будет такой. Цель проекта сейчас — создать что-то, что может рассуждать исключительно на основе знаний из лондонских книг, опубликованных между 1800 и 1875 годами.</p><h2>Какие данные вы использовали для обучения?</h2></p><p>Я использую книги, юридические документы, газеты и другие тексты Лондона 1800–1875 годов. В списке, который я дал (для v0), примерно 200 файлов, но для первого обучения я взял только 50 файлов, около ~187 МБ. Список документов можно посмотреть тут:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>Размеры датасетов:
<ul><li>v0: ~187МБ</li>
<li>v0.5: ~435МБ </li>
<li>v1: ~6.25ГБ </li>
<li>v2mini-eval1: 15ГБ</li></p><p></ul><h2>Насколько большие модели?</h2></p><p>v0: 16M параметров</p><p>v0.5: 123M параметров</p><p>v1: 700M Parameters</p><p>v2mini-eval1: 300M Parameters</p><h1>Training Specs ? </h1></p><h1>v0/v0.5</h1>
GPU: Geforce rtx 4060
CPU: i5-13400F 
Ram: 16GB DDR5.</p><h1>v1</h1>
GPU: A100 SXM rented</p><h1>v2mini-eval1</h1></p><p>GPU: A100 SXM rented</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-01-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-01-09 
    </div>
    
</body>
</html>