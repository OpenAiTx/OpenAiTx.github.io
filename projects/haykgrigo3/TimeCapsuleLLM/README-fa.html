<!DOCTYPE html>
<html lang="fa">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - یک مدل زبان بزرگ (LLM) که فقط با داده‌های مربوط به دوره‌های زمانی خاص آموزش دیده تا سوگیری‌های مدرن را کاهش دهد.</title>
    <meta name="description" content="یک مدل زبان بزرگ (LLM) که فقط با داده‌های مربوط به دوره‌های زمانی خاص آموزش دیده تا سوگیری‌های مدرن را کاهش دهد.">
    <meta name="keywords" content="TimeCapsuleLLM, Persian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "یک مدل زبان بزرگ (LLM) که فقط با داده‌های مربوط به دوره‌های زمانی خاص آموزش دیده تا سوگیری‌های مدرن را کاهش دهد.",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 830
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-fa.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2026-01-09",
  "dateModified": "2026-01-09"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 830 stars</span>
                <span class="language">Persian</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align="right">
  <details>
    <summary >🌐 زبان</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">انگلیسی</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-TW">繁體中文</a> 
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">ژاپنی</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">کره‌ای</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=as">هندی</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=th">تایلندی</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=fr">فرانسوی</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=de">آلمانی</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=es">اسپانیایی</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=it">ایتالیایی</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ru">روسی</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pt">پرتغالی</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=nl">هلندی</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pl">لهستانی</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ar">عربی</a>
        | <a href="#" title="Coming soon">فارسی (به زودی)</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=tr">ترکی</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=vi">ویتنامی</a>
        | <a href="#" title="Coming soon">اندونزیایی (به زودی)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>تایم‌کپسول LLM</h1></p><p><em>یک مدل زبانی که <strong>از پایه</strong> و منحصراً بر اساس داده‌های مکان‌ها و دوره‌های زمانی خاص آموزش دیده تا سوگیری‌های مدرن را کاهش داده و لحن، واژگان و جهان‌بینی همان عصر را بازآفرینی کند.</em></p><p>تصور کنید اگر یک مدل هوش مصنوعی فقط نقش تاریخی بازی نمی‌کرد بلکه واقعاً تاریخی بود.</p><p>نسخه‌های v0 و v0.5 با استفاده از <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT اثر آندری کارپاتی</a> ساخته شده‌اند. اسکریپت‌های اصلی آموزش و معماری مدل متعلق به اوست.</p><p>نسخه v1 مبتنی بر <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Phi 1.5 توسط مایکروسافت</a></p><p><a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">لینک هاجینگ فیس</a></p><h2> رفتار مدل و محدودیت‌ها</h2></p><h3><strong>نسخه v0</strong>  </h3></p><p>در درخواست‌های اولیه، مدل با زبان و رفتار قرن نوزدهم پاسخ می‌دهد.
مثال: درخواست: "Henry کیست؟" و جواب داد: "من آن مرد را می‌شناسم، من نکردم سیاه، طوفان بود."</p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="نمونه خروجی TimeLockLLM"></p><ul><li>هیچ اشاره‌ای به مفاهیم مدرن  </li>
<li>عمدتاً واژگان متناسب با آن دوره  </li>
<li>جملات عمدتاً نامفهوم (با توجه به حجم داده آموزشی ~۱۸۷ مگابایت انتظار می‌رود)</li></p><p></ul><h3><strong>نسخه v0.5</strong> </h3></p><p>بهبود چشمگیر نسبت به v0.  
<ul><li>سبک نگارش ویکتوریایی، نقطه‌گذاری صحیح، جملات عمدتاً دستور زبان مناسب  </li>
<li>هنوز نرخ بالای هذیان‌گویی واقعی  </li>
<li>نویز OCR ("Digitized by Google") هنوز در خروجی‌ها وجود دارد</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="نمونه خروجی TimeLockLLM"></p><h3><strong>نسخه v1</strong></h3></p><p>اولین مدلی که یک رویداد تاریخی واقعی را به یک شخصیت حقیقی از مجموعه داده‌ها مرتبط می‌کند.</p><p>مثال: درخواست: "سال خداوند ما ۱۸۳۴ بود"</p><p>خروجی: "سال خداوند ما ۱۸۳۴ بود و خیابان‌های لندن پر از اعتراض و دادخواهی بود. علت، همان‌طور که بسیاری ذکر کردند، فقط خصوصی نبود، بلکه در همان روز با لرد پالمرستون مطرح شد، عموم مردم اطلاعیه‌ای کوتاه درباره دشواری‌هایی که قانون به آن دچار شده دریافت خواهند کرد. جای تأسف عمیق است که رویدادهای فعلی در تاریخ جهان واضح هستند و بنابراین شناخته خواهند شد. درست نیست که همان مردانی که اولین بار انجیل را در اورشلیم بنیان گذاشتند، باید چنین سابقه گسترده و جالبی از شکوفایی و رونق داشته باشند."</p><p>ابتدا تصور کردم که شاید اعتراضی به طور تصادفی در همان سال رخ داده باشد اما به این تصویر نگاه کنید: <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="اعتراض ۱۸۳۴"></p><h3><strong>نسخه v2mini-eval1</strong></h3></p><p>با استفاده از نمونه ۱۵ گیگابایتی از مجموعه داده ۹۰ گیگابایتی نسخه v2 آموزش داده شده است.
مدل فقط تا ۱۰ هزار گام آموزش داده شده است.</p><p>مشکلی در توکنیزه‌سازی وجود داشت که باعث شد خروجی به این شکل ظاهر شود:</p><p>ورودی:
چارلز دیکنز کیست؟</p><p>
W ho is Charles D ic ens ? D oes that work more of h ise x cell ent st ir ring , in his pl ays , int he G reat C omp any 's f arm ? What I have y et to qu ote from J ack P ick ett ? D oy oun ot know th att hey were as pe cies of g all oping , ors aw ing oft heir bre asts , or what w ast ob ed one about the t im ew hen J acks on was looking ont hew ind ow ? What ist hes uccess of an English man , and which h isson has not be end is cover ing t ome , where by to acc omp lish such a we ight ? D idy ou ever m ake ap ass age int othe old road way , ort o an anch or - b ree ze att he foot of our boat , which you m ust le ave us ? The fact is , that whe ther the wind would rise up from the pl ain on S atur day night orn o ont ide , ort ill then orth , or other wise , wes hall be com pelled t od esc ribe af orm idable bar rier , with t hes ame e ffect s ast he p resent . In th iss itu ation , at le ast , itis not to omuch t os ay that we have le ft that room . I bel ieve there are three c op ies int he " F ive H undred - fold ," to bere fer red to , ast he first n umber of our read ers wh ow is ht
اصلاح‌شده:</p><p>"چارلز دیکنز کیست؟ آیا آثار بیشتری از برانگیختگی عالی او در نمایشنامه‌هایش، در مزرعه شرکت بزرگ وجود دارد؟ هنوز چه چیزی باید از جک پیکت نقل کنم؟ آیا نمی‌دانید که آنها نوعی تاخت‌وتاز، یا بریدن سینه‌هایشان بودند، یا چه کاری باید انجام می‌شد در زمانی که جکسون از پنجره نگاه می‌کرد؟ موفقیت یک انگلیسی چیست، و آن چیزی که پسرش هنوز برای من کشف نکرده است، تا بتوان چنین وزنی را به انجام رساند؟ آیا تا به حال گذری به جاده قدیمی داشته‌اید، یا به نسیم لنگر در پای قایقمان، که باید ما را ترک کنید؟ واقعیت این است که چه باد از دشت در شب شنبه یا ظهر، یا تا شمال، یا غیر از آن برخیزد یا نه، ما مجبور خواهیم بود مانعی عظیم را توصیف کنیم، با همان اثراتی که اکنون وجود دارد. حداقل در این وضعیت، گفتن اینکه ما آن اتاق را ترک کرده‌ایم، چندان زیاد نیست. فکر می‌کنم سه نسخه در «پانصد نسخه» وجود دارد که باید به آنها اشاره شود، به عنوان اولین شماره خوانندگان ما که مایلند...[به]..."</p><h3><strong>v2mini-eval2</strong></h3></p><p>با استفاده از همان نمونه ۱۵ گیگابایتی که برای آموزش eval1 استفاده شده بود، آموزش داده شده است.
مدل دوباره فقط تا ۱۰ هزار مرحله آموزش دیده است.</p><p>پرامپت: چارلز داروین</p><p>چارلز داروینECCEMACY. آقا، — مورد زیر برای من جالب است: — من دو هفته در لندن بودم و به شدت دچار حمله روماتیسم شدم. اولین حمله روماتیسم یک هفته قبل از دیدار با شما بود، و دومین زمانی که شما را دیدم، و سومین نیز زمانی که شما را دیدم، و سومین در همان زمان. با این حال، دومین حمله نقرس با هیچ علامت تب همراه نبود، اما با افزایش جریان ادرار و دفع بیشتر ادرار همراه بود. سومین حمله یک ساعت پس از دیدار با شما بود و با بازگشت حمله نقرس و بازگشت سریع‌تر نقرس دنبال شد. چهارمین حمله نیز با تب همراه بود اما همیشه با هیچ علامت تب همراه نبود. سومین حمله نقرس دو هفته پس از بیمار شدن شما بود و چهارمین با حمله نقرس دنبال شد. چهارمین حمله دو هفته پس از حمله به شما بود و با حس</p><h2> داده‌کاوی‌ها</h2></p><h3><strong>v2</strong></h3></p><ul><li>۹۰ گیگابایت متون لندن ۱۸۰۰-۱۸۷۵</li>
<li>۱۳۶,۳۴۴ سند</li>
<li>کل ۹۰ گیگابایت هنوز در دسترس نیست زیرا هنوز توکنیزه نشده اما نمونه ۱۵ گیگابایتی را می‌توانید در اینجا بیابید: https://huggingface.co/datasets/haykgrigorian/TimeCapsuleLLM-London-1800-1875-v2-15GB</li></p><p> </ul>### آمار سوگیری 
  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/pronoun_bias.png" alt="سوگیری ضمیر"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/geographic_bias.png" alt="سوگیری جغرافیایی"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/temporal_bias.png" alt="سوگیری زمانی"></p><p>برای اطلاعات بیشتر به <a href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/v2_bias_report.json" target="_blank" rel="noopener noreferrer">گزارش سوگیری v2</a> مراجعه کنید.</p><h2>نحوه استفاده</h2></p><p>این پروژه عمدتاً بر گردآوری داده‌های تاریخی، آماده‌سازی آن برای آموزش و ساخت توکنایزر تمرکز دارد. من قرار نیست فرآیند کامل آموزش LLM را پوشش دهم، برای آن به nanoGPT توسط آندری کارپاتی مراجعه کنید.</p><h3>مرحله ۱: جمع‌آوری و آماده‌سازی متون تاریخی</h3></p><ul><li>جمع‌آوری فایل‌های .txt از کتاب‌ها، اسناد و غیره در دامنه عمومی از دوره زمانی انتخابی شما (مثلاً لندن ۱۸۰۰-۱۸۵۰)</li></p><p>
<li>آن‌ها را در بازه زمانی/مکانی انتخاب‌شده خود نگه دارید  </li>
<li>فایل‌های متنی را با استفاده از اسکریپت یا حذف دستی سرصفحه/پاصفحه‌های پروژه گوتنبرگ، حاشیه‌نویسی‌های مدرن یا مواردی مانند خطاهای OCR پاک‌سازی کنید.</li></p><p></ul><h3>مرحله ۲: ساخت یک توکنایزر سفارشی</h3></p><ul><li>train_tokenizer.py یا train_tokenizer_hf.py را روی داده‌های پاک‌شده اجرا کنید.</li>
<li>این کار به شما vocab.json و merges.txt را می‌دهد.</li>
<li>این فایل‌ها واژگان و قواعد ادغام را برای مدل شما تعریف می‌کنند.</li></p><p></ul><h3>مرحله ۳: مدل خود را آموزش دهید</h3></p><ul><li>برای فرآیند آموزش به <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT اثر آندری کارپاتی</a> یا مستندات معماری انتخابی خود مراجعه کنید.</li></p><p></ul><h1>پرسش‌های متداول</h1></p><h2>آموزش زمانی انتخابی چیست؟</h2></p><p>آموزش زمانی انتخابی (STT) یک روش یادگیری ماشین است که در آن تمام داده‌های آموزشی به طور خاص انتخاب می‌شوند تا در یک بازه تاریخی خاص قرار بگیرند. این کار برای مدل‌سازی زبان و دانش آن دوره بدون تأثیر مفاهیم مدرن انجام می‌شود. برای مثال، مدل فعلی من (v0.5) فقط بر اساس داده‌های ۱۸۰۰-۱۸۷۵ آموزش دیده است، و از ابتدا آموزش داده شده تا خروجی آن بازتاب‌دهنده سبک زبانی و زمینه تاریخی آن زمان باشد.</p><h2>چرا فقط از فاین‌تیون یا LoRA استفاده نمی‌کنید؟</h2></p><p>برای این پروژه من تلاش می‌کنم یک مدل زبانی بسازم که تحت تأثیر سوگیری‌های مدرن نباشد. اگر چیزی مثل GPT-2 را فاین‌تیون کنم، آن مدل قبلاً آموزش دیده و آن اطلاعات از بین نمی‌رود. اگر از ابتدا آموزش دهم، مدل زبانی تظاهر به قدیمی بودن نمی‌کند، بلکه واقعاً قدیمی خواهد بود. هدف فعلی این پروژه ساخت مدلی است که فقط با استفاده از دانش کتاب‌های لندن منتشر شده بین ۱۸۰۰ تا ۱۸۷۵ استدلال کند.</p><h2>چه نوع داده‌ای برای آموزش استفاده کردید؟</h2></p><p>من از کتاب‌ها، اسناد حقوقی، روزنامه‌ها و نوشته‌های دیگر از لندن ۱۸۰۰–۱۸۷۵ استفاده کردم. لیستی که پیوند داده‌ام (برای v0) حدود ۲۰۰ مورد دارد اما برای اولین آموزش فقط از ۵۰ فایل با حجم ~۱۸۷ مگابایت استفاده کردم. می‌توانید لیست اسناد را مشاهده کنید:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>اندازه دیتاست‌ها:
<ul><li>v0: ~۱۸۷MB</li>
<li>v0.5: ~۴۳۵MB </li>
<li>v1: ~۶.۲۵GB </li>
<li>v2mini-eval1: ۱۵GB</li></p><p></ul><h2>مدل‌ها چقدر بزرگ هستند؟</h2></p><p>v0: ۱۶ میلیون پارامتر</p><p>v0.5: ۱۲۳ میلیون پارامتر</p><p>v1: 700M Parameters</p><p>v2mini-eval1: 300M Parameters</p><h1>Training Specs ? </h1></p><h1>v0/v0.5</h1>
GPU: Geforce rtx 4060
CPU: i5-13400F 
Ram: 16GB DDR5.</p><h1>v1</h1>
GPU: A100 SXM rented</p><h1>v2mini-eval1</h1></p><p>GPU: A100 SXM rented</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-01-09

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-01-09 
    </div>
    
</body>
</html>