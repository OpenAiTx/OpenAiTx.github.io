<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - Ein LLM, der ausschlie&#223;lich mit Daten aus bestimmten Zeitr&#228;umen trainiert wurde, um moderne Verzerrungen zu reduzieren.</title>
    <meta name="description" content="Ein LLM, der ausschlie&#223;lich mit Daten aus bestimmten Zeitr&#228;umen trainiert wurde, um moderne Verzerrungen zu reduzieren.">
    <meta name="keywords" content="TimeCapsuleLLM, German, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "Ein LLM, der ausschließlich mit Daten aus bestimmten Zeiträumen trainiert wurde, um moderne Verzerrungen zu reduzieren.",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 349
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-de.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 349 stars</span>
                <span class="language">German</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Sprache</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">Englisch</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="#" title="Coming soon">繁體中文 (bald verfügbar)</a> |
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">Japanisch</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">Koreanisch</a>
        | <a href="#" title="Coming soon">हिन्दी (bald verfügbar)</a> |
        | <a href="#" title="Coming soon">ไทย (bald verfügbar)</a> |
        | <a href="#" title="Coming soon">Französisch (bald verfügbar)</a>
        | <a href="#" title="Coming soon">Deutsch (bald verfügbar)</a>
        | <a href="#" title="Coming soon">Spanisch (bald verfügbar)</a>
        | <a href="#" title="Coming soon">Italienisch (bald verfügbar)</a>
        | <a href="#" title="Coming soon">Russisch (bald verfügbar)</a>
        | <a href="#" title="Coming soon">Portugiesisch (bald verfügbar)</a>
        | <a href="#" title="Coming soon">Niederländisch (bald verfügbar)</a>
        | <a href="#" title="Coming soon">Polnisch (bald verfügbar)</a>
        | <a href="#" title="Coming soon">العربية (bald verfügbar)</a>
        | <a href="#" title="Coming soon">فارسی (bald verfügbar)</a>
        | <a href="#" title="Coming soon">Türkisch (bald verfügbar)</a>
        | <a href="#" title="Coming soon">Vietnamesisch (bald verfügbar)</a>
        | <a href="#" title="Coming soon">Bahasa Indonesia (bald verfügbar)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1></p><p><em>Ein Sprachmodell, das <strong>von Grund auf</strong> ausschließlich mit Daten aus bestimmten Orten und Zeitperioden trainiert wurde, um moderne Verzerrungen zu reduzieren und die Stimme, den Wortschatz und die Weltanschauung der jeweiligen Epoche zu verkörpern.</em></p><p>Stellen Sie sich vor, ein KI-Modell würde nicht nur historisch erscheinen, sondern tatsächlich historisch sein.</p><p>v0 und v0.5 basieren auf <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT von Andrej Karpathy</a>. Die zentralen Trainingsskripte und die Modellarchitektur stammen von ihm. </p><p>v1 basiert auf <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Phi 1.5 von Microsoft</a></p><h2> Modellverhalten & Einschränkungen</h2></p><h3><strong>v0</strong>  </h3></p><p>Frühe Eingaben zeigen, dass das Modell mit Sprache und Verhalten aus dem 19. Jahrhundert antwortet. 
Beispiel: Eingabe: „Who art Henry?“ und es antwortete: „I know that man, I have did not a black, the storm.“</p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="TimeLockLLM Beispielausgabe"></p><ul><li>Keine Erwähnung moderner Konzepte  </li>
<li>Meistens zeitgenössischer Wortschatz  </li>
<li>Sätze sind größtenteils unzusammenhängend (zu erwarten bei ~187MB Trainingsdaten)</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>Eine deutliche Verbesserung gegenüber v0.  
<ul><li>Viktorianischer Schreibstil, korrekte Interpunktion, meist grammatikalisch korrekte Sätze  </li>
<li>Immer noch hohe Rate an faktischen Halluzinationen  </li>
<li>OCR-Rauschen („Digitized by Google“) weiterhin in den Ausgaben enthalten</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="TimeLockLLM Beispielausgabe"></p><h3><strong>v1</strong></h3></p><p>Erstes Modell, das ein tatsächliches historisches Ereignis mit einer echten Person aus dem Datensatz verknüpft.</p><p>Beispiel: Eingabe: „It was the year of our Lord 1834“</p><p>Die Ausgabe: „It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity“</p><p>Zunächst nahm ich an, dass zufällig im selben Jahr ein Protest stattgefunden haben könnte, aber sehen Sie sich das an: <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3>Warum das wichtig ist:</h3></p><p>Dies ist das erste Beispiel, bei dem eines meiner Modelle ein Jahr sowohl mit einem realen historischen Ereignis als auch mit einer realen Person, die mit diesem Ereignis verbunden ist (Lord Palmerston), verknüpft. Frühere Modelle (v0 und v0.5) konnten zwar Schreibstile des 19. Jahrhunderts nachahmen, halluzinierten jedoch immer Ereignisse, Personen und Fakten. Dies zeigt, dass das Modell beginnt, sich an Inhalte aus dem Datensatz zu erinnern.</p><h2>Kommende Pläne</h2></p><ul><li>Es gibt fast 175.000 Texte, die zwischen 1800-1875 in London veröffentlicht wurden und im Internet Archive verfügbar sind</li>
<li>Ich plane, das Korpus zu erweitern und weiter zu bereinigen, um bessere Schlussfolgerungsfähigkeiten zu ermöglichen</li>
<li>Erweiterung auf verschiedene Regionen und Zeiträume für historischere Modelle</li></p><p>
</ul><h2>Verwendung</h2></p><p>Dieses Projekt konzentriert sich hauptsächlich auf die Kuratierung historischer Daten, deren Vorbereitung für das Training und den Aufbau eines Tokenizers. Ich werde nicht den vollständigen LLM-Trainingsprozess abdecken, dafür siehe nanoGPT von Andrej Karpathy.</p><h3>Schritt 1: Historische Texte sammeln und vorbereiten</h3></p><ul><li>Sammle .txt-Dateien von gemeinfreien Büchern, Dokumenten usw. aus deinem gewählten Zeitraum (z. B. London 1800-1850)</li>
<li>Halte dich an das gewählte Zeit-/Ortsfenster</li>
<li>Bereinige die Textdateien mit einem Skript oder entferne manuell Kopf-/Fußzeilen von Project Gutenberg, moderne Anmerkungen oder Fehler wie OCR-Fehler.</li></p><p></ul><h3>Schritt 2: Eigenen Tokenizer bauen</h3></p><ul><li>Starte train_tokenizer.py oder train_tokenizer_hf.py auf den bereinigten Daten.</li>
<li>Dies liefert dir vocab.json und merges.txt</li>
<li>Diese Dateien definieren Vokabular und Zusammenführungsregeln für dein Modell</li></p><p></ul><h3>Schritt 3: Trainiere dein Modell</h3></p><ul><li>Siehe <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT von Andrej Karpathy</a> für den Trainingsprozess oder die Dokumentation deiner gewählten Architektur.</li></p><p></ul><h1>FAQ</h1></p><h2>Was ist Selective Temporal Training?</h2></p><p>Selective Temporal Training (STT) ist eine Machine-Learning-Methodik, bei der alle Trainingsdaten gezielt so ausgewählt werden, dass sie aus einem bestimmten historischen Zeitraum stammen. Dies dient dazu, die Sprache und das Wissen jener Ära zu modellieren, ohne von modernen Konzepten beeinflusst zu werden. Zum Beispiel: Das aktuelle Modell (v0.5) wurde ausschließlich mit Daten von 1800-1875 trainiert, nicht feinabgestimmt, sondern von Grund auf, wodurch die Ausgabe den Sprachstil und historischen Kontext jener Zeit widerspiegelt.</p><h2>Warum nicht einfach Fine-Tuning oder LoRA verwenden?</h2></p><p>Für dieses Projekt versuche ich, ein Sprachmodell zu erstellen, das nicht von modernem Bias beeinflusst ist. Wenn ich etwa GPT-2 feinabstimme, ist es bereits vortrainiert und diese Information verschwindet nicht. Wenn ich von Grund auf trainiere, tut das Sprachmodell nicht so, als wäre es alt – es ist es einfach. Das Ziel dieses Projekts ist aktuell, etwas zu erschaffen, das ausschließlich mit Wissen aus Londoner Büchern von 1800 bis 1875 schlussfolgern kann.</p><h2>Welche Daten wurden für das Training verwendet?</h2></p><p>Ich verwende Bücher, juristische Dokumente, Zeitungen und andere Schriften aus London von 1800–1875. Die von mir verlinkte Liste (für v0) enthält etwa 200, aber für das erste Training habe ich nur 50 Dateien mit insgesamt ca. 187 MB verwendet. Eine Liste der Dokumente findest du hier:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>Datensatzgrößen:
v0: ~187MB
v0.5: ~435MB
v1: ~6,25GB</p><h2>Wie groß sind die Modelle?</h2></p><p>V0: 16M Parameter</p><p>V0.5: 123M Parameter</p><p>V1: 700M Parameter</p><h1>Trainingsspezifikationen?</h1></p><h1>V0/V0.5</h1>
GPU: Geforce RTX 4060
CPU: i5-13400F
Ram: 16GB DDR5.</p><h1>V1</h1>
GPU: A100 gemietet</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-08-19

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>