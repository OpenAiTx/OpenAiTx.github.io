<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - 一个仅在特定时间段的数据上训练的大型语言模型，以减少现代偏见</title>
    <meta name="description" content="一个仅在特定时间段的数据上训练的大型语言模型，以减少现代偏见">
    <meta name="keywords" content="TimeCapsuleLLM, Simplified Chinese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "一个仅在特定时间段的数据上训练的大型语言模型，以减少现代偏见",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 349
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-zh-CN.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2025-08-19",
  "dateModified": "2025-08-19"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 349 stars</span>
                <span class="language">Simplified Chinese</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 语言</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="#" title="Coming soon">繁體中文（即将推出）</a> |
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">한국어</a>
        | <a href="#" title="Coming soon">हिन्दी（即将推出）</a> |
        | <a href="#" title="Coming soon">ไทย（即将推出）</a> |
        | <a href="#" title="Coming soon">Français（即将推出）</a>
        | <a href="#" title="Coming soon">Deutsch（即将推出）</a>
        | <a href="#" title="Coming soon">Español（即将推出）</a>
        | <a href="#" title="Coming soon">Italiano（即将推出）</a>
        | <a href="#" title="Coming soon">Русский（即将推出）</a>
        | <a href="#" title="Coming soon">Português（即将推出）</a>
        | <a href="#" title="Coming soon">Nederlands（即将推出）</a>
        | <a href="#" title="Coming soon">Polski（即将推出）</a>
        | <a href="#" title="Coming soon">العربية（即将推出）</a>
        | <a href="#" title="Coming soon">فارسی（即将推出）</a>
        | <a href="#" title="Coming soon">Türkçe（即将推出）</a>
        | <a href="#" title="Coming soon">Tiếng Việt（即将推出）</a>
        | <a href="#" title="Coming soon">Bahasa Indonesia（即将推出）</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1></p><p><em>一个从零开始训练的语言模型，仅使用特定地点和时期的数据，以减少现代偏见，模拟那个时代的声音、词汇和世界观。</em></p><p>想象一下，如果一个 AI 模型不仅仅是伪装成历史，而是真正成为历史。</p><p>v0 和 v0.5 基于 <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">Andrej Karpathy 的 nanoGPT</a> 构建，核心训练脚本和模型架构均来自于他。</p><p>v1 基于 <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">微软的 Phi 1.5</a> 构建</p><h2> 模型行为与局限性</h2></p><h3><strong>v0</strong>  </h3></p><p>早期提示显示模型以 1800 年代的语言和行为进行响应。
示例：提示：“Who art Henry?”，模型回复：“I know that man, I have did not a black, the storm.”</p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="TimeLockLLM 示例输出"></p><ul><li>未提及现代概念  </li>
<li>主要使用该时代准确的词汇  </li>
<li>句子大多不连贯（约 187MB 训练数据，预期如此）</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>相比 v0 有显著提升。  
<ul><li>维多利亚时期的写作风格，标点规范，句子基本语法正确  </li>
<li>事实幻觉率仍然很高  </li>
<li>OCR 噪声（如“Digitized by Google”）仍出现在输出中</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="TimeLockLLM 示例输出"></p><h3><strong>v1</strong></h3></p><p>首个能回忆并关联真实历史事件与数据集实际人物的模型。</p><p>示例：提示：“It was the year of our Lord 1834” </p><p>输出：“It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity" </p><p>起初我以为抗议活动可能只是巧合地发生在同一年，但请看这个： <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3>为什么这很重要：</h3></p><p>这是我的模型首次将某一年与真实历史事件以及与该事件相关的真实人物（Palmerston 勋爵）关联起来。早期模型（v0 和 v0.5）虽然能模仿 19 世纪的写作风格，但总是幻想事件、人物和事实。这表明模型开始记住数据集中的内容。</p><h2>后续计划</h2>
<ul><li>伦敦在1800-1875年间出版的文本在互联网档案馆上有近175,000份</li>
<li>我计划扩展语料库并进一步清理，以提升推理能力</li>
<li>将扩展到不同地区和时期，以构建更多历史模型</li></p><p></ul><h2>如何使用</h2></p><p>本项目主要专注于历史数据的整理、训练准备以及分词器的构建。不会涵盖完整的大型语言模型训练流程，详细内容请参考Andrej Karpathy的nanoGPT项目。</p><h3>步骤1：收集并准备历史文本</h3></p><ul><li>收集所选时期的公共领域书籍、文档等的.txt文件（如：伦敦1800-1850年）</li>
<li>保持在你选择的时间/地点范围内</li>
<li>使用脚本或手动清理文本文件，去除古腾堡项目的页眉/页脚、现代注释或OCR错误等内容。</li></p><p></ul><h3>步骤2：构建自定义分词器</h3></p><ul><li>在清理后的数据上运行train_tokenizer.py或train_tokenizer_hf.py。</li>
<li>这样会生成vocab.json和merges.txt</li>
<li>这些文件定义了你的模型的词汇表和合并规则</li></p><p></ul><h3>步骤3：训练你的模型</h3></p><ul><li>有关训练流程请参考<a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">Andrej Karpathy的nanoGPT</a>或你所选架构的文档。</li></p><p></ul><h1>常见问题解答</h1></p><h2>什么是选择性时序训练？</h2></p><p>选择性时序训练（STT）是一种机器学习方法，所有训练数据都专门筛选在特定历史时期内。这样做是为了模拟那个时代的语言和知识，不受现代概念影响。例如，我目前的模型（v0.5）只用1800-1875年的数据训练，完全从零开始训练，未经过微调，因此输出能反映那个时期的语言风格和历史语境。</p><h2>为什么不直接用微调或LoRA？</h2></p><p>这个项目旨在创建一个不受现代偏见影响的语言模型。如果对GPT-2等进行微调，它已经预训练过，原有信息无法消除。从零开始训练的模型不会“假装”是旧的，而本身就是。当前目标是打造一个只用1800至1875年伦敦书籍知识进行推理的模型。</p><h2>训练用的数据有哪些？</h2></p><p>我使用的是1800–1875年伦敦的书籍、法律文档、报纸及其他著作。链接的列表（v0）有约200份文档，但第一次训练只用了50个文件，约187 MB。你可以查看文档列表：
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>数据集大小：
v0: 约187MB
v0.5: 约435MB
v1: 约6.25GB</p><h2>模型有多大？</h2></p><p>V0：1600万参数</p><p>V0.5：1.23亿参数</p><p>V1：7亿参数</p><h1>训练规格？</h1></p><h1>V0/V0.5</h1>
GPU：Geforce rtx 4060
CPU：i5-13400F
内存：16GB DDR5。</p><h1>V1</h1>
GPU：租用A100</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-08-19

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-08-19 
    </div>
    
</body>
</html>