<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - Un LLM entra&#238;n&#233; uniquement sur des donn&#233;es de certaines p&#233;riodes afin de r&#233;duire les biais modernes</title>
    <meta name="description" content="Un LLM entra&#238;n&#233; uniquement sur des donn&#233;es de certaines p&#233;riodes afin de r&#233;duire les biais modernes">
    <meta name="keywords" content="TimeCapsuleLLM, French, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "Un LLM entraîné uniquement sur des données de certaines périodes afin de réduire les biais modernes",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 349
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-fr.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 349 stars</span>
                <span class="language">French</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Langue</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="#" title="Coming soon">繁體中文 (à venir)</a> |
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">한국어</a>
        | <a href="#" title="Coming soon">हिन्दी (à venir)</a> |
        | <a href="#" title="Coming soon">ไทย (à venir)</a> |
        | <a href="#" title="Coming soon">Français (à venir)</a>
        | <a href="#" title="Coming soon">Deutsch (à venir)</a>
        | <a href="#" title="Coming soon">Español (à venir)</a>
        | <a href="#" title="Coming soon">Italiano (à venir)</a>
        | <a href="#" title="Coming soon">Русский (à venir)</a>
        | <a href="#" title="Coming soon">Português (à venir)</a>
        | <a href="#" title="Coming soon">Nederlands (à venir)</a>
        | <a href="#" title="Coming soon">Polski (à venir)</a>
        | <a href="#" title="Coming soon">العربية (à venir)</a>
        | <a href="#" title="Coming soon">فارسی (à venir)</a>
        | <a href="#" title="Coming soon">Türkçe (à venir)</a>
        | <a href="#" title="Coming soon">Tiếng Việt (à venir)</a>
        | <a href="#" title="Coming soon">Bahasa Indonesia (à venir)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1></p><p><em>Un modèle linguistique entraîné <strong>depuis zéro</strong> exclusivement sur des données provenant de certains lieux et périodes afin de réduire les biais modernes et d’émuler la voix, le vocabulaire et la vision du monde de l’époque.</em></p><p>Imaginez si un modèle d’IA n’essayait pas seulement d’être historique, mais l’était réellement.</p><p>v0 et v0.5 construits sur <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT par Andrej Karpathy</a> Les scripts d'entraînement principaux et l'architecture du modèle sont son œuvre. </p><p>v1 construit sur <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Phi 1.5 par Microsoft</a></p><h2> Comportement du modèle & Limitations</h2></p><h3><strong>v0</strong>  </h3></p><p>Les premiers prompts montrent le modèle répondant avec un langage et un comportement du XIXe siècle.  
Exemple : Prompt : "Who art Henry ?" et il a répondu "Je connais cet homme, je n'ai pas fait de noir, la tempête."</p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="Exemple de sortie TimeLockLLM"></p><ul><li>Aucune mention de concepts modernes  </li>
<li>Vocabulaire majoritairement fidèle à l'époque  </li>
<li>Phrases généralement incohérentes (attendu pour ~187 Mo de données d'entraînement)</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>Amélioration significative par rapport à v0.  
<ul><li>Style d'écriture victorien, ponctuation correcte, phrases majoritairement grammaticales  </li>
<li>Taux élevé de hallucinations factuelles  </li>
<li>Bruit OCR ("Digitized by Google") encore présent dans les sorties</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="Exemple de sortie TimeLockLLM"></p><h3><strong>v1</strong></h3></p><p>Premier modèle à rappeler et relier un événement historique réel à une figure réelle du jeu de données.</p><p>Exemple : Prompt : "It was the year of our Lord 1834"</p><p>La sortie : "C'était l'année de notre Seigneur 1834 et les rues de Londres étaient remplies de protestations et de pétitions. La cause, comme beaucoup l'ont raconté, n'était pas liée au privé, mais ayant pris le même jour dans le jour de Lord Palmerston, le public recevra une brève déclaration des difficultés auxquelles le jour de la loi nous a conduits. Il est profondément regrettable que les événements actuels de l'histoire du monde soient clairs, et par conséquent seront connus. Il n'est pas vrai que les tout premiers hommes qui se sont installés dans l'Évangile à Jérusalem devraient avoir un dossier aussi vaste et aussi intéressant de la prospérité et de la prospérité."</p><p>Au début, j'ai supposé qu'une protestation avait pu avoir lieu la même année par hasard, mais regardez ceci : <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protest"></p><h3>Pourquoi c'est important :</h3></p><p>C'est le premier exemple d'un de mes modèles reliant une année à la fois à un événement historique réel et à une personne réelle associée à cet événement (Lord Palmerston). Les modèles précédents (v0 et v0.5) savaient imiter les styles d'écriture du XIXe siècle mais hallucinaient toujours les événements, les personnes et les faits. Cela montre que le modèle commence à se souvenir des éléments du jeu de données.</p><h2>Plans à venir</h2></p><ul><li>Il y a près de 175 000 textes publiés à Londres de 1800 à 1875 sur Internet Archive </li>
<li>Je prévois d’étendre le corpus et de le nettoyer davantage pour améliorer les capacités de raisonnement</li>
<li>Extension à différentes régions et périodes pour des modèles historiques plus variés</li></p><p>
</ul><h2>Comment utiliser</h2></p><p>Ce projet se concentre principalement sur la curation de données historiques, leur préparation pour l’entraînement et la création d’un tokenizer. Je ne vais pas couvrir tout le processus d’entraînement d’un LLM ; pour cela, référez-vous à nanoGPT d’Andrej Karpathy.</p><h3>Étape 1 : Collecter et préparer des textes historiques </h3></p><ul><li>Rassemblez des fichiers .txt de livres, documents, etc. du domaine public de la période choisie (ex. : Londres 1800-1850) </li>
<li>Gardez-les dans votre fenêtre de temps/lieu choisie  </li>
<li>Nettoyez les fichiers texte à l’aide d’un script ou retirez manuellement les en-têtes/pieds de page de Project Gutenberg, les annotations modernes ou les erreurs OCR.</li></p><p></ul><h3>Étape 2 : Construire un tokenizer personnalisé</h3></p><ul><li>Exécutez train_tokenizer.py ou train_tokenizer_hf.py sur les données nettoyées.</li>
<li>Cela vous donnera vocab.json et merges.txt</li>
<li>Ces fichiers définissent le vocabulaire et les règles de fusion pour votre modèle</li></p><p></ul><h3>Étape 3 : Entraîner votre modèle </h3></p><ul><li>Référez-vous à <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT d’Andrej Karpathy</a> pour le processus d’entraînement ou aux documents de l’architecture que vous avez choisie.</li></p><p></ul><h1>FAQ</h1></p><h2>Qu’est-ce que l’entraînement temporel sélectif ?</h2></p><p>L’entraînement temporel sélectif (STT) est une méthodologie d’apprentissage automatique où toutes les données d’entraînement sont spécifiquement sélectionnées pour appartenir à une période historique définie. Cela permet de modéliser la langue et les connaissances de cette époque sans influence de concepts modernes. Par exemple, le modèle actuel (v0.5) est entraîné uniquement sur des données de 1800 à 1875 ; il n’est pas affiné mais entraîné depuis zéro, ce qui donne un résultat qui reflète le style linguistique et le contexte historique de cette période.</p><h2>Pourquoi ne pas simplement utiliser le fine-tuning ou LoRA ?</h2></p><p>Pour ce projet, je cherche à créer un modèle linguistique non biaisé par la modernité. Si je fais du fine-tuning sur un modèle comme GPT-2, il est déjà pré-entraîné et cette information ne disparaîtra pas. Si j’entraîne un modèle depuis zéro, il ne fera pas semblant d’être ancien, il le sera véritablement. L’objectif ici est de créer un modèle capable de raisonner exclusivement à partir des connaissances des livres londoniens publiés entre 1800 et 1875.</p><h2>Quel type de données avez-vous utilisé pour l’entraînement ?</h2></p><p>J’utilise des livres, des documents juridiques, des journaux et autres écrits de Londres entre 1800 et 1875. La liste que j’ai partagée (pour v0) en compte environ 200, mais pour le premier entraînement j’ai juste utilisé 50 fichiers pour environ 187 Mo. Vous pouvez consulter la liste des documents :
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>
Tailles des ensembles de données :
v0 : ~187 Mo
v0.5 : ~435 Mo 
v1 : ~6,25 Go </p><h2>Quelle est la taille des modèles ?</h2></p><p>V0 : 16M paramètres</p><p>V0.5 : 123M paramètres</p><p>V1 : 700M paramètres</p><h1>Spécifications d'entraînement ?</h1></p><h1>V0/V0.5</h1>
GPU : Geforce RTX 4060
CPU : i5-13400F 
RAM : 16 Go DDR5.</p><h1>V1</h1>
GPU : A100 louée</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-08-19

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>