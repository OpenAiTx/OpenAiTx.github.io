<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - Un LLM entrenado &#250;nicamente con datos de ciertos per&#237;odos de tiempo para reducir el sesgo moderno</title>
    <meta name="description" content="Un LLM entrenado &#250;nicamente con datos de ciertos per&#237;odos de tiempo para reducir el sesgo moderno">
    <meta name="keywords" content="TimeCapsuleLLM, Spanish, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "Un LLM entrenado únicamente con datos de ciertos períodos de tiempo para reducir el sesgo moderno",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 349
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-es.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2025-08-19",
  "dateModified": "2025-08-19"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 349 stars</span>
                <span class="language">Spanish</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Idioma</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="#" title="Próximamente">繁體中文 (próximamente)</a> |
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">한국어</a>
        | <a href="#" title="Próximamente">हिन्दी (próximamente)</a> |
        | <a href="#" title="Próximamente">ไทย (próximamente)</a> |
        | <a href="#" title="Próximamente">Français (próximamente)</a>
        | <a href="#" title="Próximamente">Deutsch (próximamente)</a>
        | <a href="#" title="Próximamente">Español (próximamente)</a>
        | <a href="#" title="Próximamente">Italiano (próximamente)</a>
        | <a href="#" title="Próximamente">Русский (próximamente)</a>
        | <a href="#" title="Próximamente">Português (próximamente)</a>
        | <a href="#" title="Próximamente">Nederlands (próximamente)</a>
        | <a href="#" title="Próximamente">Polski (próximamente)</a>
        | <a href="#" title="Próximamente">العربية (próximamente)</a>
        | <a href="#" title="Próximamente">فارسی (próximamente)</a>
        | <a href="#" title="Próximamente">Türkçe (próximamente)</a>
        | <a href="#" title="Próximamente">Tiếng Việt (próximamente)</a>
        | <a href="#" title="Próximamente">Bahasa Indonesia (próximamente)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1></p><p><em>Un modelo de lenguaje entrenado <strong>desde cero</strong> exclusivamente con datos de ciertos lugares y períodos de tiempo para reducir el sesgo moderno y emular la voz, el vocabulario y la visión del mundo de la época.</em></p><p>Imagina si un modelo de IA no solo pretendiera ser histórico, sino que realmente lo fuera.</p><p>v0 y v0.5 construidos sobre <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT por Andrej Karpathy</a> Los scripts principales de entrenamiento y la arquitectura del modelo son de su autoría. </p><p>v1 construido sobre <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Phi 1.5 de Microsoft</a></p><h2> Comportamiento del modelo y limitaciones</h2></p><h3><strong>v0</strong>  </h3></p><p>Las primeras pruebas muestran al modelo respondiendo con lenguaje y comportamiento de los años 1800.
Ejemplo: Prompt: "¿Quién es Henry?" y respondió "Conozco a ese hombre, no he hecho un negro, la tormenta."</p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="Salida de muestra de TimeLockLLM"></p><ul><li>Sin mención de conceptos modernos  </li>
<li>Mayormente vocabulario preciso de la época  </li>
<li>Las oraciones son en su mayoría incoherentes (lo esperado para ~187MB de datos de entrenamiento)</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>Una mejora significativa sobre v0.  
<ul><li>Estilo de escritura victoriano, puntuación adecuada, oraciones mayormente gramaticales  </li>
<li>Aún alta tasa de alucinación factual  </li>
<li>Ruido de OCR (“Digitized by Google”) todavía presente en las salidas</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="Salida de muestra de TimeLockLLM"></p><h3><strong>v1</strong></h3></p><p>Primer modelo en recordar y conectar un evento histórico real con una figura real del conjunto de datos.</p><p>Ejemplo: Prompt: "Era el año de nuestro Señor 1834"</p><p>La salida: "Era el año de nuestro Señor 1834 y las calles de Londres estaban llenas de protesta y petición. La causa, como muchos relataron, no estaba ligada a lo privado, sino que se había tomado el mismo día en el día de Lord Palmerston, el público recibirá una breve declaración de las dificultades bajo las cuales el día de la ley nos ha alcanzado. Es motivo de profundo pesar, que los presentes acontecimientos en la historia del mundo sean claros, y por consiguiente serán conocidos. No es cierto que los mismos hombres que primero se asentaron en el Evangelio en Jerusalén debieran tener un registro tan extenso e interesante de la prosperidad y prosperidad"</p><p>Al principio asumí que una protesta pudo haber ocurrido casualmente ese mismo año pero mira esto: <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protesta"></p><h3>Por qué esto es importante:</h3></p><p>Este es el primer ejemplo de uno de mis modelos conectando un año con un evento histórico real y una persona real vinculada a ese evento (Lord Palmerston). Los modelos anteriores (v0 y v0.5) podían imitar estilos de escritura del siglo XIX pero siempre alucinaban eventos, personas y hechos. Esto demuestra que el modelo está comenzando a recordar cosas del conjunto de datos</p><h2>Próximos planes</h2>
<ul><li>Hay cerca de 175,000 textos publicados en Londres entre 1800-1875 en Internet Archive </li>
<li>Planeo expandir el corpus y limpiarlo más para mejorar las capacidades de razonamiento</li>
<li>Ampliando a diferentes regiones y períodos para crear modelos históricos más variados</li></p><p>
</ul><h2>Cómo usar</h2></p><p>Este proyecto se enfoca principalmente en curar datos históricos, prepararlos para el entrenamiento y construir un tokenizador. No voy a cubrir el proceso completo de entrenamiento de LLM, para eso consulta nanoGPT de Andrej Karpathy.</p><h3>Paso 1: Recolecta y prepara textos históricos </h3></p><ul><li>Recopila archivos .txt de libros, documentos, etc. de dominio público de tu período elegido (por ejemplo, Londres 1800-1850) </li>
<li>Mantenlos dentro de tu ventana de tiempo/lugar elegida  </li>
<li>Limpia los archivos de texto usando un script o elimina manualmente encabezados/pies de página de Project Gutenberg, anotaciones modernas o errores de OCR.</li></p><p></ul><h3>Paso 2: Construye un tokenizador personalizado</h3></p><ul><li>Ejecuta train_tokenizer.py o train_tokenizer_hf.py en los datos limpios.</li>
<li>Esto te dará vocab.json y merges.txt</li>
<li>Estos archivos definen el vocabulario y reglas de combinación para tu modelo</li></p><p></ul><h3>Paso 3: Entrena tu modelo </h3></p><ul><li>Consulta <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT de Andrej Karpathy</a> para el proceso de entrenamiento o la documentación de la arquitectura que elijas.</li></p><p></ul><h1>FAQ</h1></p><h2>¿Qué es el Entrenamiento Temporal Selectivo?</h2></p><p>El Entrenamiento Temporal Selectivo (STT) es una metodología de aprendizaje automático donde todos los datos de entrenamiento se seleccionan específicamente para que pertenezcan a un período histórico determinado. Se realiza para modelar el lenguaje y el conocimiento de esa época sin influencia de conceptos modernos. Por ejemplo, el modelo actual que tengo (v0.5) está entrenado exclusivamente con datos de 1800-1875, no está ajustado finamente sino entrenado desde cero, lo que resulta en una salida que refleja el estilo lingüístico y el contexto histórico de ese período.</p><h2>¿Por qué no usar fine-tuning o LoRA?</h2></p><p>Para este proyecto intento crear un modelo de lenguaje libre de sesgos modernos. Si hago fine-tuning a algo como GPT-2, ya está preentrenado y esa información no desaparece. Si entreno desde cero el modelo no va a pretender ser antiguo, simplemente lo será. El objetivo de este proyecto por ahora es crear algo que pueda razonar exclusivamente usando conocimiento de libros de Londres publicados entre 1800 y 1875.</p><h2>¿Qué tipo de datos usaste para el entrenamiento?</h2></p><p>Estoy utilizando libros, documentos legales, periódicos y otros escritos de Londres entre 1800–1875. La lista que enlacé (para v0) tiene como 200, pero para el primer entrenamiento solo usé 50 archivos, aproximadamente ~187 MB. Puedes ver una lista de los documentos:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>
Tamaños de los conjuntos de datos:
v0: ~187MB
v0.5: ~435MB 
v1: ~6.25GB </p><h2>¿Qué tan grandes son los modelos?</h2></p><p>V0: 16M Parámetros</p><p>V0.5 123M Parámetros</p><p>V1: 700M Parámetros</p><h1>¿Especificaciones de entrenamiento?</h1></p><h1>V0/V0.5</h1>
GPU: Geforce rtx 4060
CPU: i5-13400F 
Ram: 16GB DDR5.</p><h1>V1</h1>
GPU: A100 alquilada</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-08-19

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-08-19 
    </div>
    
</body>
</html>