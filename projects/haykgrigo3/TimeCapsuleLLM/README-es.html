<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TimeCapsuleLLM - Un LLM entrenado &#250;nicamente con datos de ciertos per&#237;odos de tiempo para reducir el sesgo moderno.</title>
    <meta name="description" content="Un LLM entrenado &#250;nicamente con datos de ciertos per&#237;odos de tiempo para reducir el sesgo moderno.">
    <meta name="keywords" content="TimeCapsuleLLM, Spanish, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TimeCapsuleLLM",
  "description": "Un LLM entrenado únicamente con datos de ciertos períodos de tiempo para reducir el sesgo moderno.",
  "author": {
    "@type": "Person",
    "name": "haykgrigo3"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 1248
  },
  "url": "https://OpenAiTx.github.io/projects/haykgrigo3/TimeCapsuleLLM/README-es.html",
  "sameAs": "https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md",
  "datePublished": "2026-01-13",
  "dateModified": "2026-01-13"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/haykgrigo3/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TimeCapsuleLLM
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 1248 stars</span>
                <span class="language">Spanish</span>
                <span>by haykgrigo3</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align="right">
  <details>
    <summary >🌐 Idioma</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=zh-TW">繁體中文</a> 
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=haykgrigo3&project=TimeCapsuleLLM&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=as">हिन्दी</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=th">ไทย</a> 
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=es">Español</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=ar">العربية</a>
        | <a href="#" title="Coming soon">فارسی (próximamente)</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/#/view?user=haykgrigo3&project=TimeCapsuleLLM&lang=vi">Tiếng Việt</a>
        | <a href="#" title="Coming soon">Bahasa Indonesia (próximamente)</a></p><p>      </div>
    </div>
  </details>
</div></p><h1>TimeCapsule LLM</h1></p><p><em>Un modelo de lenguaje entrenado <strong>desde cero</strong> exclusivamente con datos de ciertos lugares y períodos de tiempo para reducir el sesgo moderno y emular la voz, vocabulario y visión del mundo de la época.</em></p><p>Imagina si un modelo de IA no solo fingiera ser histórico, sino que realmente lo fuera.</p><p>v0 y v0.5 construidos sobre <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT por Andrej Karpathy</a> Los scripts de entrenamiento principales y la arquitectura del modelo son obra suya. </p><p>v1 construido sobre <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noopener noreferrer">Phi 1.5 de Microsoft</a></p><p>v2 construido sobre llamaforcausallm</p><p><a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" target="_blank" rel="noopener noreferrer">Enlace a Hugging Face</a></p><h2> Comportamiento del modelo y limitaciones</h2></p><h3><strong>v0</strong>  </h3></p><p>Las primeras pruebas muestran que el modelo responde con lenguaje y comportamiento de los años 1800.  
Ejemplo: Prompt: "¿Quién es Henry?" y respondió "Conozco a ese hombre, no he hecho un negro, la tormenta." </p><p><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="Salida de muestra de TimeLockLLM"></p><ul><li>Sin mención de conceptos modernos  </li>
<li>Vocabulario mayormente preciso de la época  </li>
<li>Las oraciones son en su mayoría incoherentes (esperado para ~187MB de datos de entrenamiento)</li></p><p></ul><h3><strong>v0.5</strong> </h3></p><p>Una mejora significativa respecto a v0.  
<ul><li>Estilo de escritura victoriano, puntuación adecuada, oraciones mayormente gramaticales  </li>
<li>Aún alta tasa de alucinación factual  </li>
<li>Ruido OCR (“Digitized by Google”) aún presente en las salidas</li></p><p></ul><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="Salida de muestra de TimeLockLLM"></p><h3><strong>v1</strong></h3></p><p>Primer modelo en recordar y conectar un evento histórico real con una figura auténtica del conjunto de datos.</p><p>Ejemplo: Prompt: "Era el año de nuestro Señor 1834" </p><p>La salida: "Era el año de nuestro Señor 1834 y las calles de Londres estaban llenas de protesta y petición. La causa, como muchos recordaron, no estaba ligada en la forma privada, sino que se había tomado el mismo día en el día de Lord Palmerston, el público recibirá una breve declaración de las dificultades bajo las cuales el día de la ley nos ha alcanzado. Es motivo de profundo pesar que los acontecimientos actuales en la historia del mundo sean claros y, en consecuencia, serán conocidos. No es cierto que los mismos hombres que primero se establecieron en el Evangelio en Jerusalén deban tener un registro tan extenso e interesante de la prosperidad y prosperidad" </p><p>Al principio asumí que una protesta pudo haber ocurrido casualmente ese mismo año, pero mira esto: <img src="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/1834protest.png" alt="1834protesta"></p><h3><strong>v2mini-eval1</strong></h3></p><p>
Entrenado usando una muestra de 15GB del conjunto de datos de 90GB de v2.
Modelo entrenado solo hasta 10K pasos.</p><p>Hubo un problema con la tokenización que hace que la salida se vea así:</p><p>INDICACIÓN:
¿Quién es Charles Dickens?</p><p>
W ho is Charles D ic ens ? D oes that work more of h ise x cell ent st ir ring , in his pl ays , int he G reat C omp any 's f arm ? What I have y et to qu ote from J ack P ick ett ? D oy oun ot know th att hey were as pe cies of g all oping , ors aw ing oft heir bre asts , or what w ast ob ed one about the t im ew hen J acks on was looking ont hew ind ow ? What ist hes uccess of an English man , and which h isson has not be end is cover ing t ome , where by to acc omp lish such a we ight ? D idy ou ever m ake ap ass age int othe old road way , ort o an anch or - b ree ze att he foot of our boat , which you m ust le ave us ? The fact is , that whe ther the wind would rise up from the pl ain on S atur day night orn o ont ide , ort ill then orth , or other wise , wes hall be com pelled t od esc ribe af orm idable bar rier , with t hes ame e ffect s ast he p resent . In th iss itu ation , at le ast , itis not to omuch t os ay that we have le ft that room . I bel ieve there are three c op ies int he " F ive H undred - fold ," to bere fer red to , ast he first n umber of our read ers wh ow is ht
Corregido:</p><p>"¿Quién es Charles Dickens? ¿Hace ese trabajo más de su excelente agitación, en sus obras, en la gran granja de la Compañía? ¿Qué tengo aún que citar de Jack Pickett? ¿No sabes que eran una especie de galopar, o de serrar sus pechos, o qué se debía hacer en la época en que Jackson miraba por la ventana? ¿Cuál es el éxito de un inglés, y cuál su hijo no ha descubierto para mí, por lo que ha de lograr tal peso? ¿Alguna vez has hecho un pasaje hacia el viejo camino, o hacia una brisa de ancla al pie de nuestro bote, que debes dejarnos? El hecho es que, tanto si el viento se levanta desde la llanura el sábado por la noche o al mediodía, o hacia el norte, o de otra manera, nos veremos obligados a describir una barrera formidable, con los mismos efectos que los actuales. En esta situación, al menos, no es exagerado decir que hemos dejado esa habitación. Creo que hay tres copias en el 'Quinientos veces', a las que se debe referir, como el primer número de nuestros lectores que deseen t[o]..."</p><h3><strong>v2mini-eval2</strong></h3></p><p>Entrenado usando la misma muestra de 15GB utilizada para entrenar eval1.
El modelo se entrena nuevamente solo hasta 10K pasos.</p><p>PROMPT:Charles Darwin</p><p>Charles DarwinECCEMACY. Señor, — El siguiente caso me resulta interesante: — Estuve en Londres dos semanas y me afectó mucho un ataque de reumatismo. El primer ataque de reumatismo fue una semana antes de verlo, y el segundo cuando lo vi, y el tercero cuando lo vi, y el tercero en el mismo tiempo. El segundo ataque de gota, sin embargo, no estuvo acompañado de ningún síntoma febril, pero sí de un aumento en el flujo de orina, y una descarga más copiosa de orina. El tercer ataque fue una hora después de verlo, y fue seguido por el regreso de un paroxismo de gota, y un retorno más rápido de la gota. El cuarto ataque también estuvo acompañado de fiebre, pero no siempre con síntomas febriles. El tercer ataque de gota fue dos semanas después de que usted estuvo enfermo, y el cuarto fue seguido por un paroxismo de gota. El cuarto ataque fue dos semanas después de que usted fue atacado, y estuvo acompañado por una sensación</p><h2> Conjuntos de datos</h2></p><h3><strong>v2</strong></h3></p><ul><li>90GB de textos londinenses de 1800-1875</li>
<li>136,344 documentos</li>
<li>El total de 90GB aún no está disponible ya que no se ha tokenizado, pero puede encontrar una muestra de 15GB aquí: https://huggingface.co/datasets/haykgrigorian/TimeCapsuleLLM-London-1800-1875-v2-15GB</li></p><p> </ul>### Estadísticas de sesgo 
  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/pronoun_bias.png" alt="Sesgo de pronombres"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/geographic_bias.png" alt="Sesgo geográfico"></p><p>  <img src="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/temporal_bias.png" alt="Sesgo temporal"></p><p>Consulte el <a href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/v2_bias_report.json" target="_blank" rel="noopener noreferrer">informe de sesgo v2</a> para más información.</p><h2>Cómo usar</h2></p><p>Este proyecto se centra principalmente en la curación de datos históricos, prepararlos para entrenamiento y construir un tokenizador. No voy a cubrir el proceso completo de entrenamiento LLM, para eso consulte nanoGPT de Andrej Karpathy.</p><h3>Paso 1: Recolectar y preparar textos históricos </h3></p><ul><li>Reúna archivos .txt de libros de dominio público, documentos, etc., de su periodo elegido (por ejemplo, Londres 1800-1850)</li></p><p><li>Manténgalos dentro de la ventana de tiempo/lugar que haya elegido  </li>
<li>Limpie los archivos de texto usando un script o elimine manualmente encabezados/pies de página de Project Gutenberg, anotaciones modernas o errores de OCR.</li></p><p></ul><h3>Paso 2: Construya un Tokenizador Personalizado</h3></p><ul><li>Ejecute train_tokenizer.py o train_tokenizer_hf.py en los datos limpios.</li>
<li>Esto le dará vocab.json y merges.txt</li>
<li>Estos archivos definen el vocabulario y las reglas de combinación para su modelo</li></p><p></ul><h3>Paso 3: Entrene Su Modelo </h3></p><ul><li>Consulte <a href="https://github.com/karpathy/nanoGPT" target="_blank" rel="noopener noreferrer">nanoGPT de Andrej Karpathy</a> para el proceso de entrenamiento o la documentación de la arquitectura elegida.</li></p><p></ul><h1>FAQ</h1></p><h2>¿Qué es el Entrenamiento Temporal Selectivo?</h2></p><p>El Entrenamiento Temporal Selectivo (STT) es una metodología de aprendizaje automático donde todos los datos de entrenamiento se curan específicamente para que pertenezcan a un periodo histórico específico. Se hace para modelar el lenguaje y el conocimiento de esa época sin influencia de conceptos modernos. Por ejemplo, el modelo actual que tengo (v0.5) está entrenado exclusivamente con datos de 1800-1875, no está afinado sino entrenado desde cero, lo que resulta en una salida que refleja el estilo lingüístico y el contexto histórico de ese periodo.</p><h2>¿Por qué no simplemente usar fine-tuning o LoRA?</h2></p><p>Para este proyecto estoy intentando crear un modelo de lenguaje que no esté contaminado por sesgos modernos. Si hago fine-tuning a algo como GPT-2, ya está pre-entrenado y esa información no desaparecerá. Si entreno desde cero, el modelo de lenguaje no fingirá ser antiguo, simplemente lo será. El objetivo de este proyecto ahora mismo es crear algo que pueda razonar exclusivamente usando conocimiento de libros de Londres publicados entre 1800 y 1875.</p><h2>¿Qué tipo de datos utilizó para el entrenamiento?</h2></p><p>Estoy usando libros, documentos legales, periódicos y otros escritos de Londres entre 1800 y 1875. La lista que enlacé (para v0) tiene como 200, pero para el primer entrenamiento solo usé 50 archivos de aproximadamente ~187 MB. Puede ver una lista de los documentos:
https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</p><p>Tamaños de los conjuntos de datos:
<ul><li>v0: ~187MB</li>
<li>v0.5: ~435MB </li>
<li>v1: ~6.25GB </li>
<li>v2mini-eval1: 15GB</li></p><p></ul><h2>¿Qué tamaño tienen los modelos?</h2></p><p>v0: 16M Parámetros</p><p>v0.5 123M Parámetros</p><p>v1: 700M Parameters</p><p>v2mini-eval1: 300M Parameters</p><h1>Training Specs ? </h1></p><h1>v0/v0.5</h1>
GPU: Geforce rtx 4060
CPU: i5-13400F 
Ram: 16GB DDR5.</p><h1>v1</h1>
GPU: A100 SXM rented</p><h1>v2mini-eval1</h1></p><p>GPU: A100 SXM rented</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-01-13

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/haykgrigo3/TimeCapsuleLLM/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-01-13 
    </div>
    
</body>
</html>