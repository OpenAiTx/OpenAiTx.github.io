<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>llama-github - Llama-github est une biblioth&#232;que Python open-source qui permet aux chatbots LLM, agents IA et solutions de d&#233;veloppement automatis&#233; de r&#233;aliser un RAG agentique &#224; partir de projets publics GitHub s&#233;lectionn&#233;s activement. Elle s’appuie sur les LLMs pour g&#233;n&#233;rer du contexte pour toute question de programmation, afin de faciliter le d&#233;veloppement d’applications avanc&#233;es pilot&#233;es par l’IA.</title>
    <meta name="description" content="Llama-github est une biblioth&#232;que Python open-source qui permet aux chatbots LLM, agents IA et solutions de d&#233;veloppement automatis&#233; de r&#233;aliser un RAG agentique &#224; partir de projets publics GitHub s&#233;lectionn&#233;s activement. Elle s’appuie sur les LLMs pour g&#233;n&#233;rer du contexte pour toute question de programmation, afin de faciliter le d&#233;veloppement d’applications avanc&#233;es pilot&#233;es par l’IA.">
    <meta name="keywords" content="llama-github, French, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "llama-github",
  "description": "Llama-github est une bibliothèque Python open-source qui permet aux chatbots LLM, agents IA et solutions de développement automatisé de réaliser un RAG agentique à partir de projets publics GitHub sélectionnés activement. Elle s’appuie sur les LLMs pour générer du contexte pour toute question de programmation, afin de faciliter le développement d’applications avancées pilotées par l’IA.",
  "author": {
    "@type": "Person",
    "name": "JetXu-LLM"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 297
  },
  "url": "https://OpenAiTx.github.io/projects/JetXu-LLM/llama-github/README-fr.html",
  "sameAs": "https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/README.md",
  "datePublished": "2025-07-28",
  "dateModified": "2025-07-28"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/JetXu-LLM/llama-github" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    llama-github
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 297 stars</span>
                <span class="language">French</span>
                <span>by JetXu-LLM</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Langue</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=id">Bahasa Indonesia</a>
        | <a href="https://openaitx.github.io/view.html?user=JetXu-LLM&project=llama-github&lang=as">অসমীয়া</
      </div>
    </div>
  </details>
</div></p><h1>llama-github</h1></p><p>[Document détaillé] https://deepwiki.com/JetXu-LLM/llama-github</p><p><a href="https://badge.fury.io/py/llama-github" target="_blank" rel="noopener noreferrer"><img src="https://badge.fury.io/py/llama-github.svg" alt="Version PyPI"></a>
<a href="https://pepy.tech/project/Llama-github" target="_blank" rel="noopener noreferrer"><img src="https://static.pepy.tech/badge/Llama-github" alt="Téléchargements"></a>
<a href="https://opensource.org/licenses/Apache-2.0" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg" alt="Licence"></a></p><p>Llama-github est un outil puissant qui vous aide à récupérer (basé sur Agentic RAG) les extraits de code, problèmes et informations de dépôt les plus pertinents depuis GitHub selon vos requêtes, les transformant en contexte de connaissance précieux. Il permet aux chatbots LLM, agents IA et agents Auto-dev de résoudre des tâches de codage complexes. Que vous soyez un développeur cherchant des solutions rapides ou un ingénieur implémentant des agents IA Auto Dev avancés, llama-github rend cela facile et efficace.</p><p>Si vous appréciez ce projet ou pensez qu'il a du potentiel, merci de lui attribuer une ⭐️. Votre soutien est notre plus grande motivation !</p><h2>Architecture</h2>
<img src="https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/high_level_architecture.drawio.svg" alt="Architecture de haut niveau"></p><h2>Installation</h2>
<pre><code class="language-">pip install llama-github</code></pre></p><h2>Utilisation</h2></p><p>Voici un exemple simple de comment utiliser llama-github :</p><pre><code class="language-python">from llama_github import GithubRAG</p><h1>Initialize GithubRAG with your credentials</h1>
github_rag = GithubRAG(
    github_access_token="your_github_access_token", 
    openai_api_key="your_openai_api_key", # Optional in Simple Mode
    jina_api_key="your_jina_api_key" # Optional - unless you want high concurrency production deployment (s.jina.ai API will be used in llama-github)
)</p><h1>Retrieve context for a coding question (simple_mode is default set to False)</h1>
query = "How to create a NumPy array in Python?"
context = github_rag.retrieve_context(
    query, # In professional mode, one query will take nearly 1 min to generate final contexts. You could set log level to INFO to monitor the retrieval progress
    # simple_mode = True
)</p><p>print(context)</code></pre>
Pour un usage plus avancé et des exemples, veuillez consulter la <a href="https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/docs/usage.md" target="_blank" rel="noopener noreferrer">documentation</a>.</p><h2>Fonctionnalités clés</h2></p><ul><li><strong>🔍 Recherche intelligente sur GitHub</strong> : Exploitez la puissance de llama-github pour récupérer des extraits de code, des issues et des informations sur les dépôts hautement pertinents sur GitHub en fonction des requêtes des utilisateurs. Nos techniques avancées de recherche garantissent que vous trouvez rapidement et efficacement les informations les plus pertinentes.</li></p><p><li><strong>⚡ Mise en cache du pool de dépôts</strong> : Llama-github dispose d’un mécanisme innovant de mise en cache du pool de dépôts. En mettant en cache les dépôts (y compris les README, structures, codes et issues) à travers les threads, llama-github accélère significativement l’efficacité de la recherche sur GitHub et minimise la consommation des jetons API GitHub. Déployez llama-github dans des environnements de production multithread en toute confiance, sachant qu’il fonctionnera de manière optimale et vous fera économiser des ressources précieuses.</li></p><p><li><strong>🧠 Analyse des questions alimentée par LLM</strong> : Profitez des modèles de langage de pointe pour analyser les questions des utilisateurs et générer des stratégies et critères de recherche très efficaces. Llama-github décompose intelligemment les requêtes complexes, garantissant que vous récupérez les informations les plus pertinentes du vaste réseau de dépôts GitHub.</li></p><p><li><strong>📚 Génération de contexte complète</strong> : Générez des réponses riches et contextuellement pertinentes en combinant de manière fluide les informations récupérées sur GitHub avec les capacités de raisonnement des modèles de langage avancés. Llama-github excelle dans le traitement des questions les plus complexes et longues, fournissant des réponses complètes et perspicaces incluant un contexte étendu pour soutenir vos besoins en développement.</li></p><p><li><strong>🚀 Excellence dans le traitement asynchrone</strong> : Llama-github est conçu dès le départ pour exploiter tout le potentiel de la programmation asynchrone. Avec des mécanismes asynchrones minutieusement implémentés dans tout le code, llama-github peut gérer plusieurs requêtes simultanément, augmentant significativement la performance globale. Expérimentez la différence alors que llama-github gère efficacement des charges de travail élevées sans compromettre la rapidité ni la qualité.</li></p><p><li><strong>🔧 Intégration flexible des LLM</strong> : Intégrez facilement llama-github avec divers fournisseurs de LLM, modèles d’incorporation et modèles de reranking pour adapter les capacités de la bibliothèque à vos besoins spécifiques. Notre architecture extensible vous permet de personnaliser et d’améliorer les fonctionnalités de llama-github, garantissant une adaptation fluide à votre environnement de développement unique.</li></p><p><li><strong>🔒 Options robustes d’authentification</strong> : Llama-github supporte à la fois les jetons d’accès personnel et l’authentification via GitHub App, vous offrant la flexibilité de l’intégrer dans différents environnements de développement. Que vous soyez un développeur individuel ou travailliez dans un contexte organisationnel, llama-github vous couvre avec des mécanismes d’authentification sécurisés et fiables.</li></p><p><li><strong>🛠️ Journalisation et gestion des erreurs</strong> : Nous comprenons l’importance d’un fonctionnement fluide et d’un dépannage facile. C’est pourquoi llama-github est équipé de mécanismes complets de journalisation et de gestion des erreurs. Obtenez des informations approfondies sur le comportement de la bibliothèque, diagnostiquez rapidement les problèmes et maintenez un flux de travail de développement stable et fiable.</li></p><p></ul><h2>🤖 Essayez notre assistant de revue de PR alimenté par IA : LlamaPReview</h2></p><p>Si vous trouvez llama-github utile, vous pourriez également être intéressé par notre assistant de revue de PR GitHub alimenté par IA, LlamaPReview. Il est conçu pour compléter votre flux de développement et améliorer encore la qualité du code.</p><h3>Fonctionnalités clés de LlamaPReview :</h3>
<ul><li>🚀 Installation en un clic, aucune configuration requise, fonctionnement entièrement automatique</li>
<li>💯 Actuellement gratuit - pas besoin de carte de crédit ni d’informations de paiement</li>
<li>🧠 Revues automatiques de PR alimentées par IA avec une compréhension profonde du code</li>
<li>🌐 Supporte plusieurs langages de programmation</li></p><p></ul><strong>LlamaPReview utilise la récupération contextuelle avancée de llama-github et l’analyse alimentée par LLM</strong> pour fournir des revues de code intelligentes et conscientes du contexte. C’est comme avoir un développeur senior, armé du contexte complet de votre dépôt, qui révise automatiquement chaque PR !</p><p>👉 <a href="https://github.com/marketplace/llamapreview/" target="_blank" rel="noopener noreferrer">Installer LlamaPReview Maintenant</a> (Gratuit)</p><p>En utilisant llama-github pour la récupération de contexte et LlamaPReview pour les revues de code, vous pouvez créer un environnement de développement puissant et enrichi par l’IA.</p><h2>Vision et feuille de route</h2></p><h3>Vision</h3></p><p>Notre vision est de devenir un module clé dans l’avenir des solutions de développement pilotées par IA, s’intégrant parfaitement avec GitHub pour permettre aux LLM de résoudre automatiquement des tâches de codage complexes.</p><p><img src="https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/./docs/vision.drawio.svg" alt="Vision Architecture"></p><h3>Feuille de route</h3></p><p>Pour une vue détaillée de notre feuille de route projet, veuillez visiter notre <a href="https://github.com/users/JetXu-LLM/projects/2" target="_blank" rel="noopener noreferrer">Feuille de route du projet</a>.</p><h2>Remerciements</h2></p><p>Nous souhaitons exprimer notre gratitude aux projets open source suivants pour leur soutien et leurs contributions :</p><ul><li><strong><a href="https://github.com/langchain-ai/langchain" target="_blank" rel="noopener noreferrer">LangChain</a></strong> : Pour avoir fourni le cadre fondamental qui alimente les capacités de prompting et de traitement LLM dans llama-github.</li>
<li><strong><a href="https://github.com/jina-ai/reader" target="_blank" rel="noopener noreferrer">Jina.ai</a></strong> : Pour avoir offert l’API s.jina.ai ainsi que des modèles open source de reranking et d’incorporation qui améliorent la précision et la pertinence des contextes générés dans llama-github.</li></p><p></ul>Leurs contributions ont été essentielles au développement de llama-github, et nous recommandons vivement de consulter leurs projets pour plus de solutions innovantes.</p><h2>Contribution</h2></p><p>Nous accueillons les contributions à llama-github ! Veuillez consulter nos <a href="https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">directives de contribution</a> pour plus d’informations.</p><h2>Licence</h2></p><p>Ce projet est sous licence Apache 2.0. Voir le fichier <a href="LICENSE" target="_blank" rel="noopener noreferrer">LICENSE</a> pour plus de détails.</p><h2>Contact</h2></p><p>Si vous avez des questions, suggestions ou retours, n’hésitez pas à nous contacter à <a href="https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/mailto:Voldemort.xu@foxmail.com" target="_blank" rel="noopener noreferrer">email de Jet Xu</a>.</p><hr></p><p>Merci d’avoir choisi llama-github ! Nous espérons que cette bibliothèque améliorera votre expérience de développement IA et vous aidera à créer des applications puissantes en toute simplicité.</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-28

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/JetXu-LLM/llama-github/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-28 
    </div>
    
</body>
</html>