<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KVzip - Read KVzip documentation in Vietnamese. This project has 70 stars on GitHub.</title>
    <meta name="description" content="Read KVzip documentation in Vietnamese. This project has 70 stars on GitHub.">
    <meta name="keywords" content="KVzip, Vietnamese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "KVzip",
  "description": "Read KVzip documentation in Vietnamese. This project has 70 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "snu-mllab"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 70
  },
  "url": "https://OpenAiTx.github.io/projects/snu-mllab/KVzip/README-vi.html",
  "sameAs": "https://raw.githubusercontent.com/snu-mllab/KVzip/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/snu-mllab/KVzip" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    KVzip
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 70 stars</span>
                <span class="language">Vietnamese</span>
                <span>by snu-mllab</span>
            </div>
        </div>
        
        <div class="content">
            <h1>KVzip: Nén Bộ Nhớ Đệm KV Không Phụ Thuộc Truy Vấn với Tái Tạo Ngữ Cảnh</h1></p><p><a href="https://arxiv.org/abs/2505.23416" target="_blank" rel="noopener noreferrer">[Bài báo</a>] <a href="https://janghyun1230.github.io/kvzip/" target="_blank" rel="noopener noreferrer">[Blog</a>] </p><p><img src="https://raw.githubusercontent.com/snu-mllab/KVzip/main/images/method.png" width="800"></p><h2>Có Gì Mới?</h2>
<ul><li>KVzip nén bộ nhớ đệm KV để hỗ trợ <strong>đa dạng truy vấn tương lai</strong>.</li>
<li>[Phụ thuộc ngữ cảnh] Đạt được <strong>giảm 3–4× kích thước bộ nhớ đệm KV</strong> và <strong>giảm 2× độ trễ giải mã</strong>, với suy giảm hiệu năng tối thiểu.</li>
<li>[Không phụ thuộc ngữ cảnh] Nâng cao nén KV cấp đầu theo phong cách <a href="https://github.com/mit-han-lab/duo-attention" target="_blank" rel="noopener noreferrer">DuoAttention</a>, chỉ sử dụng <strong>vài lần truyền thẳng trong vòng một phút</strong> để tối ưu điểm quan trọng cấp đầu (nhanh hơn 100 lần).</li>
<li>Chạy demo.py:</li>
</ul><img src="https://raw.githubusercontent.com/snu-mllab/KVzip/main/images/demo.png" width="800"></p><h3>Đánh giá trên thiết lập không phụ thuộc truy vấn</h3>
<ul><li>Nhiệm vụ: <a href="https://huggingface.co/datasets/rajpurkar/squad" target="_blank" rel="noopener noreferrer">SQuAD</a>, <a href="https://github.com/gkamradt/LLMTest_NeedleInAHaystack" target="_blank" rel="noopener noreferrer">NIAH</a>, <a href="https://github.com/microsoft/MInference/tree/main/scbench" target="_blank" rel="noopener noreferrer">SCBench</a>, <a href="https://huggingface.co/datasets/openai/gsm8k/viewer/main/train?row=7294" target="_blank" rel="noopener noreferrer">GSM8K</a>. </li>
<li>Mô hình: <a href="https://huggingface.co/Qwen/Qwen2.5-7B-Instruct" target="_blank" rel="noopener noreferrer">Qwen2.5-7B-Instruct-1M</a></li></p><p></ul><img src="https://raw.githubusercontent.com/snu-mllab/KVzip/main/images/benchmark.png" width="800"></p><h2>Cài Đặt</h2>
Chúng tôi sử dụng CUDA 12.1 và Python 3.10
<pre><code class="language-bash">cd KVzip
pip install -r requirements.txt
pip install flash-attn==2.7.4.post1 --no-build-isolation
make i</code></pre>
<ul><li>Để sử dụng lượng tử hóa <a href="https://github.com/mit-han-lab/omniserve" target="_blank" rel="noopener noreferrer">QServe</a>, vui lòng theo dõi <a href="https://github.com/snu-mllab/KVzip/tree/main/model/quant_model" target="_blank" rel="noopener noreferrer"><code>./model/quant_model</code></a>.</li>
</ul><h3>Bộ dữ liệu</h3>
<ul><li>Vui lòng tải bộ dữ liệu SCBench đã được tiền xử lý từ <a href="https://drive.google.com/file/d/1cqoR6pxxFcjFqvPZkuAmF-fBSAlAbjbN/view?usp=share_link" target="_blank" rel="noopener noreferrer">Google Drive</a>.</li>
<li>Nếu bạn đã giải nén các tệp, chỉ cần di chuyển thư mục scbench.</li>
</ul><pre><code class="language-bash">mv scbench.zip kvzip/data/
cd kvzip/data
unzip scbench.zip  </code></pre></p><h2>Bắt Đầu Nhanh</h2>
<pre><code class="language-python">from model import ModelKVzip</p><p>model = ModelKVzip("Qwen/Qwen2.5-7B-Instruct-1M")
context = "This is my basic profile. My name is Kim living in Seoul. My major is computer science."
queries = ["What is my name?", "Do I live in Seoul?"]</p><p>kv = model.prefill(context, load_score=False)  # điền trước bộ nhớ đệm KV + tính điểm quan trọng
kv.prune(ratio=0.3)  # tỉ lệ nén, loại bỏ 70% KV</p><p>for q in queries:
    query_ids = model.apply_template(q)
    output = model.generate(query_ids, kv=kv, update_cache=False)  # suy luận hiệu quả
    print(q, output)</code></pre>
<ul><li>Các mô hình được hỗ trợ được liệt kê trong <a href="https://github.com/snu-mllab/KVzip/blob/main/model/load.py" target="_blank" rel="noopener noreferrer"><code>model/load.py</code></a>, bao gồm <strong>LLaMA3, Qwen2.5/3, Gemma3</strong>.</li>
<li>Đặt <code>load_score=True</code> để loại bỏ chi phí nén. Điều này cho phép loại bỏ KV không phụ thuộc ngữ cảnh, với sự đánh đổi tỉ lệ nén là <code>ratio=0.6</code>.</li>
<li>Sau khi sinh, các cặp KV tương ứng với truy vấn và token sinh ra được loại bỏ chọn lọc khỏi bộ nhớ đệm để xử lý tiếp. Đặt <code>update_cache=True</code> để kích hoạt suy luận đa lượt, giữ lại toàn bộ lịch sử tương tác trong suốt quá trình suy luận. </li></p><p></ul><h2>Đo Hiệu Năng Bộ Nhớ và Thời Gian Tính Toán</h2>
<h3>Loại bỏ phụ thuộc ngữ cảnh</h3>
<pre><code class="language-bash">python -B test.py -m [model_name] -d [data_name] --kv_type evict --ratio 0.3</code></pre>
<ul><li>Mã trên cũng so sánh kết quả sinh ra với bộ nhớ đệm KV đầy đủ và đã bị loại bỏ.</li>
<li>Để thử nhanh, dùng <code>-d squad</code>. Để thử với ngữ cảnh dài, dùng <code>-d scbench_kv</code>.</li>
  <li>Tên dữ liệu có sẵn: <a href="https://github.com/snu-mllab/KVzip/blob/main/data/load.py" target="_blank" rel="noopener noreferrer"><code>data/load.py</code></a>.</li>
  <li>Tên mô hình có sẵn: <a href="https://github.com/snu-mllab/KVzip/blob/main/model/load.py" target="_blank" rel="noopener noreferrer"><code>model/load.py</code></a>, ví dụ llama3.1-8b, qwen2.5-7b (hoặc Qwen/Qwen2.5-7B-Instruct-1M).</li>
<li>Chúng tôi điều chỉnh kernel CUDA từ <a href="https://github.com/FFY0/AdaKV/tree/main" target="_blank" rel="noopener noreferrer">AdaKV</a>, hỗ trợ phân bổ ngân sách đầu không đồng đều.</li>
  <li>Hiện tại, mã của chúng tôi thiếu kernel tối ưu cho Gemma3 sử dụng bộ nhớ đệm KV tĩnh, nên mã không mang lại hiệu quả thực tế. Tuy nhiên, hiệu năng mô hình vẫn có thể đánh giá bằng chú ý giảm với chọn mẫu KV (<code>--kv_type retain</code>).</li></p><p>
</ul><h3>Loại bỏ không phụ thuộc ngữ cảnh (không có chi phí nén thời gian chạy)</h3>
<ul><li>Dùng cờ <code>--level head</code> với <code>--ratio 0.6</code> (khuyến nghị).</li>
  <li>Loại bỏ toàn bộ cặp KV ngữ cảnh liên quan đến một đầu cụ thể trong khi giữ lại cặp KV lời nhắc hệ thống và truy vấn.</li>
  <li>Điểm đầu đã tính trước có sẵn cho LLaMA3.1-8B và Qwen2.5-7/14B trong <code>./utils/head_score</code>.</li>
<li>Để tính điểm đầu cho các mô hình khác:</li>
  </ul><pre><code class="language-bash">  python -B test.py -m [model_name] -d scbench_qa_eng --save_head_score
  ``<code>
  <ul><li>Kết quả sẽ được lưu ở </code>./utils/head_score<code>.</li>
  <li>Nếu nhắm đến nhiệm vụ lập trình, chúng tôi khuyên bạn chạy thêm lệnh với </code>-d scbench_repoqa<code>. Điều này cho phép mô hình dùng điểm đầu tối đa từ cả ngôn ngữ tự nhiên và lập trình, cải thiện hiệu năng.</li>
<li>Những điểm này có thể tích hợp liền mạch với bộ máy suy luận tối ưu của <a href="https://github.com/mit-han-lab/duo-attention" target="_blank" rel="noopener noreferrer">DuoAttention</a> bằng cách thay thế dữ liệu điểm đầu của họ bằng của chúng tôi.</li></p><p>
</ul><h2>Đánh Giá</h2>
<ul><li>Để sinh câu trả lời mô hình với các tỉ lệ nén KV từ 0.1 đến 1.0:</li>
    </ul></code>`<code>bash
    python -B eval.py -m [model_name] -d [data_name] --kv_type retain --num 100
    </code>`<code> 
  <ul><li>Kết quả sẽ được lưu tại </code>./results/[data_name]<code>.</li>
  <li>Các bộ dữ liệu được hỗ trợ liệt kê trong </code>data/load.py<code>.</li>
<li>Để tính toán các chỉ số đánh giá từ kết quả sinh:</li>
  </ul></code>`<code>bash
  python -B -m results.parse -m [model_name] -d [data_name]
  </code>`<code></p><h2>Áp Dụng Cho Mô Hình Mới</h2>
Để tích hợp KVzip cho mô hình mới, bạn cần cập nhật các tệp sau:
<ul><li></code>attention/attn.py<code>  </li>
  </ul>Sửa logic truyền thẳng attention theo nhu cầu. Trong một số trường hợp, cần cập nhật thêm kvcache.py và score.py.
<ul><li></code>model/monkeypatch.py<code>  </li>
  </ul>Triển khai monkey patch đặc thù mô hình để tích hợp.
<ul><li></code>model/template.py<code>   </li>
  </ul>Định nghĩa lời nhắc hệ thống và mẫu định dạng chat của mô hình.</p><h2>Trích Dẫn</code></pre>bibtex</h2>
@article{kim2025kvzip,
        title={KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction},
        author={Kim, Jang-Hyun and Kim, Jinuk and Kwon, Sangwoo and Lee, Jae W and Yun, Sangdoo and Song, Hyun Oh},
        journal={arXiv preprint arXiv:2505.23416},
        year={2025}
}
</code>``</p><h2>Giấy Phép</h2>
Giấy phép MIT

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-11

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/snu-mllab/KVzip/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>