<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KVzip - Read KVzip documentation in Arabic. This project has 70 stars on GitHub.</title>
    <meta name="description" content="Read KVzip documentation in Arabic. This project has 70 stars on GitHub.">
    <meta name="keywords" content="KVzip, Arabic, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "KVzip",
  "description": "Read KVzip documentation in Arabic. This project has 70 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "snu-mllab"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 70
  },
  "url": "https://OpenAiTx.github.io/projects/snu-mllab/KVzip/README-ar.html",
  "sameAs": "https://raw.githubusercontent.com/snu-mllab/KVzip/main/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/snu-mllab/KVzip" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    KVzip
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 70 stars</span>
                <span class="language">Arabic</span>
                <span>by snu-mllab</span>
            </div>
        </div>
        
        <div class="content">
            <h1>KVzip: ضغط ذاكرة KV للكاش مستقل عن الاستعلام مع إعادة بناء السياق</h1></p><p><a href="https://arxiv.org/abs/2505.23416" target="_blank" rel="noopener noreferrer">[ورقة بحثية</a>] <a href="https://janghyun1230.github.io/kvzip/" target="_blank" rel="noopener noreferrer">[مدونة</a>] </p><p><img src="https://raw.githubusercontent.com/snu-mllab/KVzip/main/images/method.png" width="800"></p><h2>ما الجديد؟</h2>
<ul><li>يقوم KVzip بضغط ذاكرة KV للكاش لدعم <strong>استعلامات مستقبلية متنوعة</strong>.</li>
<li>[معتمد على السياق] تحقيق <strong>تقليل بحجم ذاكرة KV بمقدار 3–4×</strong> و <strong>تقليل زمن فك التشفير بمقدار 2×</strong>، مع أدنى تدهور في الأداء.</li>
<li>[غير معتمد على السياق] تحسين ضغط KV على مستوى الرؤوس بأسلوب <a href="https://github.com/mit-han-lab/duo-attention" target="_blank" rel="noopener noreferrer">DuoAttention</a>، باستخدام فقط <strong>بضع تمريرات أمامية خلال دقيقة واحدة</strong> لتحسين درجات أهمية الرؤوس (أسرع 100 مرة).</li>
<li>تشغيل demo.py:</li>
</ul><img src="https://raw.githubusercontent.com/snu-mllab/KVzip/main/images/demo.png" width="800"></p><h3>تقييم الأداء في إعداد مستقل عن الاستعلام</h3>
<ul><li>المهام: <a href="https://huggingface.co/datasets/rajpurkar/squad" target="_blank" rel="noopener noreferrer">SQuAD</a>، <a href="https://github.com/gkamradt/LLMTest_NeedleInAHaystack" target="_blank" rel="noopener noreferrer">NIAH</a>، <a href="https://github.com/microsoft/MInference/tree/main/scbench" target="_blank" rel="noopener noreferrer">SCBench</a>، <a href="https://huggingface.co/datasets/openai/gsm8k/viewer/main/train?row=7294" target="_blank" rel="noopener noreferrer">GSM8K</a>. </li>
<li>النموذج: <a href="https://huggingface.co/Qwen/Qwen2.5-7B-Instruct" target="_blank" rel="noopener noreferrer">Qwen2.5-7B-Instruct-1M</a></li></p><p></ul><img src="https://raw.githubusercontent.com/snu-mllab/KVzip/main/images/benchmark.png" width="800"></p><h2>التثبيت</h2>
استخدمنا CUDA 12.1 و Python 3.10
<pre><code class="language-bash">cd KVzip
pip install -r requirements.txt
pip install flash-attn==2.7.4.post1 --no-build-isolation
make i</code></pre>
<ul><li>لاستخدام التكميم <a href="https://github.com/mit-han-lab/omniserve" target="_blank" rel="noopener noreferrer">QServe</a>، يرجى اتباع <a href="https://github.com/snu-mllab/KVzip/tree/main/model/quant_model" target="_blank" rel="noopener noreferrer"><code>./model/quant_model</code></a>.</li>
</ul><h3>مجموعة البيانات</h3>
<ul><li>يرجى تحميل مجموعة بيانات SCBench المعالجة مسبقًا من <a href="https://drive.google.com/file/d/1cqoR6pxxFcjFqvPZkuAmF-fBSAlAbjbN/view?usp=share_link" target="_blank" rel="noopener noreferrer">Google Drive</a>.</li>
<li>إذا قمت بتحميل الملفات غير مضغوطة، فقط انقل مجلد scbench.</li>
</ul><pre><code class="language-bash">mv scbench.zip kvzip/data/
cd kvzip/data
unzip scbench.zip  </code></pre></p><h2>بداية سريعة</h2>
<pre><code class="language-python">from model import ModelKVzip</p><p>model = ModelKVzip("Qwen/Qwen2.5-7B-Instruct-1M")
context = "This is my basic profile. My name is Kim living in Seoul. My major is computer science."
queries = ["What is my name?", "Do I live in Seoul?"]</p><p>kv = model.prefill(context, load_score=False)  # تعبئة ذاكرة KV + تقييم الأهمية
kv.prune(ratio=0.3)  # نسبة الضغط، التخلص من 70% من KV</p><p>for q in queries:
    query_ids = model.apply_template(q)
    output = model.generate(query_ids, kv=kv, update_cache=False)  # استدلال فعال
    print(q, output)</code></pre>
<ul><li>النماذج المدعومة مدرجة في <a href="https://github.com/snu-mllab/KVzip/blob/main/model/load.py" target="_blank" rel="noopener noreferrer"><code>model/load.py</code></a>، بما في ذلك <strong>LLaMA3، Qwen2.5/3، Gemma3</strong>.</li>
<li>ضبط <code>load_score=True</code> لإلغاء تحميل ضغط الذاكرة. هذا يتيح التخلص من KV مستقل عن السياق، مع تنازل في نسبة الضغط عند <code>ratio=0.6</code>.</li>
<li>بعد التوليد، يتم التخلص انتقائيًا من أزواج KV المرتبطة بالاستعلامات والرموز المولدة من الكاش للمعالجة اللاحقة. اضبط <code>update_cache=True</code> لتمكين الاستدلال متعدد الجولات، مع الاحتفاظ بسجلات التفاعل الكاملة طوال الاستدلال.</li></p><p></ul><h2>قياس الذاكرة ووقت الحوسبة</h2>
<h3>التخلص المعتمد على السياق</h3>
<pre><code class="language-bash">python -B test.py -m [model_name] -d [data_name] --kv_type evict --ratio 0.3</code></pre>
<ul><li>الكود أعلاه يقارن أيضًا بين المخرجات الناتجة باستخدام ذاكرة KV كاملة مقابل مضغوطة.</li>
<li>للاختبار السريع، استخدم <code>-d squad</code>. للاختبار في سياق طويل، استخدم <code>-d scbench_kv</code>.</li>
  <li>أسماء البيانات المتاحة: <a href="https://github.com/snu-mllab/KVzip/blob/main/data/load.py" target="_blank" rel="noopener noreferrer"><code>data/load.py</code></a>.</li>
  <li>أسماء النماذج المتاحة: <a href="https://github.com/snu-mllab/KVzip/blob/main/model/load.py" target="_blank" rel="noopener noreferrer"><code>model/load.py</code></a>، مثل llama3.1-8b، qwen2.5-7b (أو Qwen/Qwen2.5-7B-Instruct-1M).</li>
<li>قمنا بتكييف نواة CUDA من <a href="https://github.com/FFY0/AdaKV/tree/main" target="_blank" rel="noopener noreferrer">AdaKV</a>، تدعم تخصيص ميزانية غير متجانسة للرؤوس.</li>
  <li>حاليًا، لا يحتوي كودنا على نواة محسنة لـ Gemma3 التي تستخدم ذاكرة KV ثابتة، لذلك لا يحقق الكود كفاءة فعلية. ومع ذلك، يمكن تقييم أداء النموذج باستخدام الانتباه المخفض مع أخذ عينات KV (<code>--kv_type retain</code>).</li></p><p>
</ul><h3>التخلص غير المعتمد على السياق (بدون تحميل ضغط وقت التشغيل)</h3>
<ul><li>استخدم العلامة <code>--level head</code> مع <code>--ratio 0.6</code> (موصى به).</li>
  <li>نقوم بإزالة جميع أزواج KV المرتبطة برأس معين مع الاحتفاظ بأزواج KV الخاصة بنظام المطالبة والاستعلام.</li>
  <li>درجات الرؤوس المحسوبة مسبقًا متوفرة لـ LLaMA3.1-8B و Qwen2.5-7/14B في <code>./utils/head_score</code>.</li>
<li>لحساب درجات الرؤوس لنماذج أخرى:</li>
  </ul><pre><code class="language-bash">  python -B test.py -m [model_name] -d scbench_qa_eng --save_head_score
  ``<code>
  <ul><li>سيتم حفظ النتائج في </code>./utils/head_score<code>.</li>
  <li>إذا كنت تستهدف مهمة ترميز، نوصي أيضًا بتشغيل الأمر مع </code>-d scbench_repoqa<code>. هذا يسمح للنموذج باستخدام درجات الرأس القصوى من اللغتين الطبيعية والبرمجية، مما يحسن الأداء.</li>
<li>يمكن دمج هذه الدرجات بسهولة مع محرك الاستدلال المحسن لـ <a href="https://github.com/mit-han-lab/duo-attention" target="_blank" rel="noopener noreferrer">DuoAttention</a> عن طريق استبدال بيانات درجات الرأس الخاصة بهم ببياناتنا.</li></p><p>
</ul><h2>التقييم</h2>
<ul><li>لتوليد ردود النموذج مع نسب ضغط KV تتراوح من 0.1 إلى 1.0:</li>
    </ul></code>`<code>bash
    python -B eval.py -m [model_name] -d [data_name] --kv_type retain --num 100
    </code>`<code> 
  <ul><li>سيتم حفظ النتائج في </code>./results/[data_name]<code>.</li>
  <li>مجموعات البيانات المدعومة مدرجة في </code>data/load.py<code>.</li>
<li>لحساب مقاييس التقييم من النتائج المولدة:</li>
  </ul></code>`<code>bash
  python -B -m results.parse -m [model_name] -d [data_name]
  </code>`<code></p><h2>التطبيق على نماذج جديدة</h2>
لدمج KVzip مع نموذج جديد، ستحتاج إلى تحديث الملفات التالية:
<ul><li></code>attention/attn.py<code>  </li>
  </ul>تعديل منطق تمرير الانتباه الأمامي حسب الحاجة. في بعض الحالات، قد يكون مطلوبًا تحديث </code>kvcache.py<code> و </code>score.py<code>.
<ul><li></code>model/monkeypatch.py<code>  </li>
  </ul>تنفيذ تصحيح القرد الخاص بالنموذج للدمج.
<ul><li></code>model/template.py<code>   </li>
  </ul>تعريف مطالبة نظام النموذج وقوالب تنسيق المحادثة.</p><h2>الاقتباس</code></pre>bibtex</h2>
@article{kim2025kvzip,
        title={KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction},
        author={Kim, Jang-Hyun and Kim, Jinuk and Kwon, Sangwoo and Lee, Jae W and Yun, Sangdoo and Song, Hyun Oh},
        journal={arXiv preprint arXiv:2505.23416},
        year={2025}
}
</code>``</p><h2>الترخيص</h2>
رخصة MIT

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-11

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/snu-mllab/KVzip/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>