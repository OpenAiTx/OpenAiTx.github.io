<!DOCTYPE html>
<html lang="hi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KVzip - Read KVzip documentation in Hindi. This project has 70 stars on GitHub.</title>
    <meta name="description" content="Read KVzip documentation in Hindi. This project has 70 stars on GitHub.">
    <meta name="keywords" content="KVzip, Hindi, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "KVzip",
  "description": "Read KVzip documentation in Hindi. This project has 70 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "snu-mllab"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 70
  },
  "url": "https://OpenAiTx.github.io/projects/snu-mllab/KVzip/README-hi.html",
  "sameAs": "https://raw.githubusercontent.com/snu-mllab/KVzip/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/snu-mllab/KVzip" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    KVzip
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 70 stars</span>
                <span class="language">Hindi</span>
                <span>by snu-mllab</span>
            </div>
        </div>
        
        <div class="content">
            <h1>KVzip: संदर्भ पुनर्निर्माण के साथ क्वेरी-एग्नोस्टिक KV कैश संपीड़न</h1></p><p><a href="https://arxiv.org/abs/2505.23416" target="_blank" rel="noopener noreferrer">[पेपर</a>] <a href="https://janghyun1230.github.io/kvzip/" target="_blank" rel="noopener noreferrer">[ब्लॉग</a>] </p><p><img src="https://raw.githubusercontent.com/snu-mllab/KVzip/main/images/method.png" width="800"></p><h2>क्या नया है?</h2>
<ul><li>KVzip KV कैश को संपीड़ित करता है ताकि <strong>विविध भविष्य की क्वेरियों</strong> का समर्थन किया जा सके।</li>
<li>[संदर्भ-निर्भर] <strong>3–4× KV कैश आकार में कमी</strong> और <strong>2× डिकोडिंग विलंबता में कमी</strong> प्राप्त करें, न्यूनतम प्रदर्शन ह्रास के साथ।</li>
<li>[संदर्भ-स्वतंत्र] <a href="https://github.com/mit-han-lab/duo-attention" target="_blank" rel="noopener noreferrer">DuoAttention</a>-शैली के हेड-स्तर KV संपीड़न को बढ़ाएं, केवल <strong>एक मिनट के भीतर कुछ फॉरवर्ड पास</strong> का उपयोग करके हेड-स्तर महत्व-स्कोर अनुकूलन के लिए (100 गुना तेज)।</li>
<li>demo.py चलाएँ:</li>
</ul><img src="https://raw.githubusercontent.com/snu-mllab/KVzip/main/images/demo.png" width="800"></p><h3>क्वेरी-एग्नोस्टिक सेटिंग पर बेंचमार्किंग</h3>
<ul><li>कार्य: <a href="https://huggingface.co/datasets/rajpurkar/squad" target="_blank" rel="noopener noreferrer">SQuAD</a>, <a href="https://github.com/gkamradt/LLMTest_NeedleInAHaystack" target="_blank" rel="noopener noreferrer">NIAH</a>, <a href="https://github.com/microsoft/MInference/tree/main/scbench" target="_blank" rel="noopener noreferrer">SCBench</a>, <a href="https://huggingface.co/datasets/openai/gsm8k/viewer/main/train?row=7294" target="_blank" rel="noopener noreferrer">GSM8K</a>। </li>
<li>मॉडल: <a href="https://huggingface.co/Qwen/Qwen2.5-7B-Instruct" target="_blank" rel="noopener noreferrer">Qwen2.5-7B-Instruct-1M</a></li></p><p></ul><img src="https://raw.githubusercontent.com/snu-mllab/KVzip/main/images/benchmark.png" width="800"></p><h2>इंस्टॉलेशन</h2>
हमने CUDA 12.1 और Python 3.10 का उपयोग किया
<pre><code class="language-bash">cd KVzip
pip install -r requirements.txt
pip install flash-attn==2.7.4.post1 --no-build-isolation
make i</code></pre>
<ul><li><a href="https://github.com/mit-han-lab/omniserve" target="_blank" rel="noopener noreferrer">QServe</a> क्वांटाइजेशन का उपयोग करने के लिए कृपया <a href="https://github.com/snu-mllab/KVzip/tree/main/model/quant_model" target="_blank" rel="noopener noreferrer"><code>./model/quant_model</code></a> का पालन करें।</li>
</ul><h3>डेटासेट</h3>
<ul><li>कृपया पूर्व-संसाधित SCBench डेटासेट <a href="https://drive.google.com/file/d/1cqoR6pxxFcjFqvPZkuAmF-fBSAlAbjbN/view?usp=share_link" target="_blank" rel="noopener noreferrer">Google Drive</a> से डाउनलोड करें।</li>
<li>यदि आपने फाइलों को अनजिप कर लिया है, तो बस scbench फ़ोल्डर को स्थानांतरित करें।</li>
</ul><pre><code class="language-bash">mv scbench.zip kvzip/data/
cd kvzip/data
unzip scbench.zip  </code></pre></p><h2>त्वरित प्रारंभ</h2>
<pre><code class="language-python">from model import ModelKVzip</p><p>model = ModelKVzip("Qwen/Qwen2.5-7B-Instruct-1M")
context = "यह मेरी मूल प्रोफ़ाइल है। मेरा नाम किम है जो सियोल में रहता है। मेरा प्रमुख विषय कंप्यूटर विज्ञान है।"
queries = ["मेरा नाम क्या है?", "क्या मैं सियोल में रहता हूँ?"]</p><p>kv = model.prefill(context, load_score=False)  # KV कैश भरें + महत्व स्कोरिंग
kv.prune(ratio=0.3)  # संपीड़न अनुपात, 70% KV निकालें</p><p>for q in queries:
    query_ids = model.apply_template(q)
    output = model.generate(query_ids, kv=kv, update_cache=False)  # कुशल अनुमान
    print(q, output)</code></pre>
<ul><li>समर्थित मॉडल <a href="https://github.com/snu-mllab/KVzip/blob/main/model/load.py" target="_blank" rel="noopener noreferrer"><code>model/load.py</code></a> में सूचीबद्ध हैं, जिनमें <strong>LLaMA3, Qwen2.5/3, Gemma3</strong> शामिल हैं।</li>
<li>संपीड़न ओवरहेड को समाप्त करने के लिए <code>load_score=True</code> सेट करें। यह संदर्भ-स्वतंत्र KV निकासी सक्षम करता है, जिसमें <code>ratio=0.6</code> के संपीड़न अनुपात का व्यापार होता है।</li>
<li>जनरेशन के बाद, क्वेरियों और उत्पन्न टोकनों से संबंधित KV जोड़े चयनात्मक रूप से कैश से निकाले जाते हैं ताकि आगे प्रसंस्करण किया जा सके। मल्टी-टर्न अनुमान सक्षम करने के लिए <code>update_cache=True</code> सेट करें, जिससे अनुमान के दौरान पूर्ण इंटरैक्शन इतिहास संरक्षित रहता है। </li></p><p></ul><h2>मेमोरी और कम्प्यूटेशन समय प्रोफाइलिंग</h2>
<h3>संदर्भ-निर्भर निकासी</h3>
<pre><code class="language-bash">python -B test.py -m [model_name] -d [data_name] --kv_type evict --ratio 0.3</code></pre>
<ul><li>ऊपर दिया गया कोड पूर्ण और संकुचित KV कैश के साथ उत्पन्न आउटपुट की तुलना भी करता है।</li>
<li>त्वरित परीक्षण के लिए <code>-d squad</code> का उपयोग करें। लंबी संदर्भ परीक्षण के लिए <code>-d scbench_kv</code> का उपयोग करें।</li>
  <li>उपलब्ध डेटा नाम: <a href="https://github.com/snu-mllab/KVzip/blob/main/data/load.py" target="_blank" rel="noopener noreferrer"><code>data/load.py</code></a>।</li>
  <li>उपलब्ध मॉडल नाम: <a href="https://github.com/snu-mllab/KVzip/blob/main/model/load.py" target="_blank" rel="noopener noreferrer"><code>model/load.py</code></a>, उदाहरण के लिए llama3.1-8b, qwen2.5-7b (या Qwen/Qwen2.5-7B-Instruct-1M)।</li>
<li>हम <a href="https://github.com/FFY0/AdaKV/tree/main" target="_blank" rel="noopener noreferrer">AdaKV</a> से CUDA कर्नेल को अनुकूलित करते हैं, जो गैर-समान हेड बजट आवंटन का समर्थन करता है।</li>
  <li>वर्तमान में, हमारे कोड में Gemma3 के लिए एक अनुकूलित कर्नेल नहीं है जो स्थैतिक KV कैश का उपयोग करता है, इसलिए यह कोड वास्तविक दक्षता लाभ प्रदान नहीं करता। हालांकि, KV सबसैंपलिंग (<code>--kv_type retain</code>) के साथ कम ध्यान का उपयोग करके मॉडल प्रदर्शन का मूल्यांकन अभी भी किया जा सकता है।</li></p><p>
</ul><h3>संदर्भ-स्वतंत्र निकासी (कोई रनटाइम संपीड़न ओवरहेड नहीं)</h3>
<ul><li><code>--level head</code> ध्वज के साथ <code>--ratio 0.6</code> (अनुशंसित) का उपयोग करें।</li>
  <li>हम एक विशिष्ट हेड से जुड़े सभी संदर्भ KV जोड़े निकाल देते हैं जबकि सिस्टम प्रॉम्प्ट और क्वेरी KV जोड़े बनाए रखते हैं।</li>
  <li>पूर्व-गणना किए गए हेड स्कोर LLaMA3.1-8B और Qwen2.5-7/14B के लिए <code>./utils/head_score</code> में उपलब्ध हैं।</li>
<li>अन्य मॉडलों के लिए हेड स्कोर गणना करने के लिए:</li>
  </ul><pre><code class="language-bash">  python -B test.py -m [model_name] -d scbench_qa_eng --save_head_score
  ``<code>
  <ul><li>परिणाम </code>./utils/head_score<code> में सहेजे जाएंगे।</li>
  <li>यदि कोडिंग कार्य लक्षित है, तो हम अतिरिक्त रूप से </code>-d scbench_repoqa<code> के साथ कमांड चलाने की सलाह देते हैं। यह मॉडल को प्राकृतिक और कोडिंग भाषाओं दोनों से अधिकतम हेड स्कोर का उपयोग करने की अनुमति देता है, जो प्रदर्शन में सुधार करता है।</li>
<li>ये स्कोर <a href="https://github.com/mit-han-lab/duo-attention" target="_blank" rel="noopener noreferrer">DuoAttention</a> के अनुकूलित अनुमान इंजन के साथ निर्बाध रूप से एकीकृत किए जा सकते हैं, बस उनके हेड स्कोर डेटा को हमारे स्कोर से बदलकर।</li></p><p>
</ul><h2>मूल्यांकन</h2>
<ul><li>0.1 से 1.0 तक के KV संपीड़न अनुपात के साथ मॉडल प्रतिक्रियाएँ उत्पन्न करने के लिए:</li>
    </ul></code>`<code>bash
    python -B eval.py -m [model_name] -d [data_name] --kv_type retain --num 100
    </code>`<code> 
  <ul><li>परिणाम </code>./results/[data_name]<code> में सहेजे जाएंगे।</li>
  <li>समर्थित डेटासेट </code>data/load.py<code> में सूचीबद्ध हैं।</li>
<li>उत्पन्न परिणामों से मूल्यांकन मेट्रिक्स गणना करने के लिए:</li>
  </ul></code>`<code>bash
  python -B -m results.parse -m [model_name] -d [data_name]
  </code>`<code></p><h2>नए मॉडलों पर लागू करना</h2>
KVzip को नए मॉडल के लिए एकीकृत करने के लिए, आपको निम्न फाइलों को अपडेट करना होगा:
<ul><li></code>attention/attn.py<code>  </li>
  </ul>आवश्यकतानुसार ध्यान फॉरवर्ड पास लॉजिक संशोधित करें। कुछ मामलों में, kvcache.py और score.py में भी अपडेट आवश्यक हो सकते हैं।
<ul><li></code>model/monkeypatch.py<code>  </li>
  </ul>एकीकरण के लिए मॉडल-विशिष्ट मंकी पैचिंग लागू करें।
<ul><li></code>model/template.py<code>   </li>
  </ul>मॉडल के सिस्टम प्रॉम्प्ट और चैट फॉर्मेटिंग टेम्पलेट परिभाषित करें।</p><h2>संदर्भ</code></pre>bibtex</h2>
@article{kim2025kvzip,
        title={KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction},
        author={Kim, Jang-Hyun and Kim, Jinuk and Kwon, Sangwoo and Lee, Jae W and Yun, Sangdoo and Song, Hyun Oh},
        journal={arXiv preprint arXiv:2505.23416},
        year={2025}
}
</code>``</p><h2>लाइसेंस</h2>
MIT लाइसेंस

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-11

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/snu-mllab/KVzip/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>