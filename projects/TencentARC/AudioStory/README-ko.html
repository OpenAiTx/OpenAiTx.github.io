<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AudioStory - AudioStory: 대형 언어 모델을 활용한 장편 내러티브 오디오 생성</title>
    <meta name="description" content="AudioStory: 대형 언어 모델을 활용한 장편 내러티브 오디오 생성">
    <meta name="keywords" content="AudioStory, Korean, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "AudioStory",
  "description": "AudioStory: 대형 언어 모델을 활용한 장편 내러티브 오디오 생성",
  "author": {
    "@type": "Person",
    "name": "TencentARC"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 116
  },
  "url": "https://OpenAiTx.github.io/projects/TencentARC/AudioStory/README-ko.html",
  "sameAs": "https://raw.githubusercontent.com/TencentARC/AudioStory/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/TencentARC/AudioStory" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    AudioStory
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 116 stars</span>
                <span class="language">Korean</span>
                <span>by TencentARC</span>
            </div>
        </div>
        
        <div class="content">
            <h1>AudioStory: 대규모 언어 모델을 활용한 장편 내러티브 오디오 생성</h1></p><p><em></em><a href="https://scholar.google.com/citations?user=x_0spxgAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Yuxin Guo<sup>1,2</sup></a>,  
<a href="http://ttengwang.com/" target="_blank" rel="noopener noreferrer">Teng Wang<sup>2,&#9993;</sup></a>,  
<a href="https://geyuying.github.io/" target="_blank" rel="noopener noreferrer">Yuying Ge<sup>2</sup></a>,  
<a href="https://mashijie1028.github.io/" target="_blank" rel="noopener noreferrer">Shijie Ma<sup>1,2</sup></a>,  
<a href="https://geyixiao.com/" target="_blank" rel="noopener noreferrer">Yixiao Ge<sup>2</sup></a>,  
<a href="https://people.ucas.ac.cn/~zouwei" target="_blank" rel="noopener noreferrer">Wei Zou<sup>1</sup></a>,  
<a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Ying Shan<sup>2</sup></a><em></em>  
<br>  
<sup>1</sup>중국과학원 자동화연구소  
<sup>2</sup>텐센트 PCG ARC 연구실  
<br>  </p><h2>📖 공개</h2></p><p>[2025/8/28] 🔥🔥 추론 코드를 공개합니다!</p><p>[2025/8/28] 🔥🔥 데모 영상을 공개합니다!</p><h2>🔎 소개</h2></p><p><img src="https://raw.githubusercontent.com/TencentARC/AudioStory/main/audiostory.png" alt="audiostory"></p><p>✨ <strong>요약: 우리는 통합된 이해-생성 프레임워크를 기반으로 한 장편 내러티브 오디오 생성 모델을 제안하며, 영상 더빙, 오디오 연속 재생, 장편 내러티브 오디오 합성을 모두 처리할 수 있습니다.</strong></p><p>최근 텍스트-투-오디오(TTA) 생성 기술은 짧은 오디오 클립 합성에 뛰어나지만, 시간적 일관성과 구성적 추론이 필요한 장편 내러티브 오디오에서는 어려움을 겪고 있습니다. 이 격차를 해소하기 위해, 우리는 대규모 언어 모델(LLM)과 TTA 시스템을 통합하여 구조화된 장편 오디오 내러티브를 생성하는 통합 프레임워크 AudioStory를 제안합니다. AudioStory는 강력한 명령 수행 추론 생성 능력을 갖추고 있습니다. LLM을 활용하여 복잡한 내러티브 쿼리를 시간 순서에 따른 하위 작업과 맥락 단서로 분해하여 일관된 장면 전환과 감정 톤의 일관성을 가능하게 합니다. AudioStory의 두 가지 매력적인 특징은 다음과 같습니다:</p><p>1) 분리된 브리징 메커니즘: AudioStory는 LLM과 디퓨저 협업을 두 개의 전문화된 구성 요소로 분리합니다—내부 이벤트 의미 정렬을 위한 브리징 쿼리와 이벤트 간 일관성 유지를 위한 일관성 쿼리.  
2) 엔드-투-엔드 훈련: 명령 이해와 오디오 생성을 단일 엔드-투-엔드 프레임워크 내에서 통합하여 모듈별 훈련 파이프라인이 필요 없으며, 구성 요소 간 시너지를 강화합니다.  
    또한, 우리는 애니메이션 사운드스케이프 및 자연 사운드 내러티브 등 다양한 도메인을 포함하는 벤치마크 AudioStory-10K를 구축했습니다.</p><p>광범위한 실험 결과, AudioStory는 단일 오디오 생성과 내러티브 오디오 생성 모두에서 우수한 성능을 보이며, 이전 TTA 기준 모델들을 명령 수행 능력과 오디오 품질 양면에서 능가합니다.</p><h2>⭐ 데모</h2></p><h3>1. 비디오 더빙 (톰과 제리 스타일)</h3>
<blockquote>더빙은 비디오에서 추출한 시각적 캡션과 함께 톰과 제리로 훈련된 AudioStory를 사용하여 이루어집니다.</blockquote></p><p><table class="center">
  <td><video src="https://github.com/user-attachments/assets/f06b5999-6649-44d3-af38-63fdcecd833c"></video></td>
  <td><video src="https://github.com/user-attachments/assets/17727c2a-bfea-4252-9aa8-48fc9ac33500"></video></td>
  <td><video src="https://github.com/user-attachments/assets/09589d82-62c9-47a6-838a-5a62319f35e2"></video></td>
  <tr>
</table ></p><h3>2. 교차 도메인 비디오 더빙 (톰과 제리 스타일)</h3></p><p><table class="center">
    <td><video src="https://github.com/user-attachments/assets/e62d0c09-cdf0-4e51-b550-0a2c23f8d68d"></video></td>
    <td><video src="https://github.com/user-attachments/assets/736d22ca-6636-4ef0-99f3-768e4dfb112a"></video></td>
    <td><video src="https://github.com/user-attachments/assets/f2f7c94c-7f72-4cc0-8edc-290910980b04"></video></td>
  <tr>
  <td><video src="https://github.com/user-attachments/assets/d3e58dd4-31ae-4e32-aef1-03f1e649cb0c"></video></td>
  <td><video src="https://github.com/user-attachments/assets/4f68199f-e48a-4be7-b6dc-1acb8d377a6e"></video></td>
  <td><video src="https://github.com/user-attachments/assets/062236c3-1d26-4622-b843-cc0cd0c58053"></video></td>
	<tr>
  <td><video src="https://github.com/user-attachments/assets/8931f428-dd4d-430f-9927-068f2912dd36"></video></td>
  <td><video src="https://github.com/user-attachments/assets/ab7e46d5-f42c-472e-b66e-df786b658210"></video></td>      
  <td><video src="https://github.com/user-attachments/assets/9a0998ad-b5a4-42ac-bdaf-ceaf796fc586"></video></td>
  <tr>
</table ></p><h3>3. 텍스트-투-롱 오디오 (자연 소리)</h3></p><p><table class="center">
  <td style="text-align:center;" width="480">지시문: "제이크 시마부쿠로가 스튜디오에서 복잡한 우쿨렐레 곡을 연주하고, 박수를 받으며, 인터뷰에서 자신의 경력에 대해 이야기하는 내용을 완벽하게 표현하는 종합적인 오디오를 개발하십시오. 총 길이는 49.9초입니다."</td>
  <td><video src="https://github.com/user-attachments/assets/461e8a34-4217-454e-87b3-e4285f36ec43"></video></td>
	<tr>
  <td style="text-align:center;" width="480">지시문: "소방차가 사이렌을 울리며 출동 신호를 보내고, 긴급 출동을 알리며 출발하는 장면을 완벽하게 표현하는 종합적인 오디오를 개발하십시오. 총 길이는 35.1초입니다."</td>
  <td><video src="https://github.com/user-attachments/assets/aac0243f-5d12-480e-9850-a7f6720e4f9c"></video></td>
	<tr>
     <td style="text-align:center;" width="480">지시사항: "입력된 오디오를 이해하고, 이후의 사건을 추론하며, 코치가 선수들에게 농구 수업을 계속해서 진행하는 오디오를 생성합니다. 총 지속 시간은 36.6초입니다."</td>    
    <td><video src="https://github.com/user-attachments/assets/c4ed306a-651e-43d6-aeea-ee159542418a"></video></td>
	<tr>
</table ></p><h2>🔎 방법</h2></p><p><img src="https://raw.githubusercontent.com/TencentARC/AudioStory/main/audiostory_framework.png" alt="audiostory_framework"></p><p>효과적인 지시 따르기 오디오 생성을 달성하기 위해서는 입력된 지시문이나 오디오 스트림을 이해하고 관련된 오디오 하위 이벤트를 추론하는 능력이 필수적입니다. 이를 위해 AudioStory는 통합된 이해-생성 프레임워크(Fig.)를 채택했습니다. 구체적으로, 텍스트 지시나 오디오 입력이 주어지면, LLM은 이를 분석하고 맥락과 함께 구조화된 오디오 하위 이벤트로 분해합니다. 추론된 하위 이벤트를 바탕으로 LLM은 <strong>교차 추론 생성</strong>을 수행하여 각 오디오 클립에 대해 캡션, 의미 토큰, 잔여 토큰을 순차적으로 생성합니다. 이 두 종류의 토큰은 융합되어 DiT로 전달되며, 이는 LLM과 오디오 생성기를 효과적으로 연결합니다. 점진적 훈련을 통해 AudioStory는 강력한 지시 이해와 고품질 오디오 생성을 최종적으로 달성합니다.</p><h2>🔩 설치</h2></p><h3>의존성</h3></p><ul><li>Python >= 3.10 (<a href="https://www.anaconda.com/download/#linux" target="_blank" rel="noopener noreferrer">Anaconda</a> 사용 권장)</li>
<li><a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">PyTorch >=2.1.0</a></li>
<li>NVIDIA GPU + <a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener noreferrer">CUDA</a></li></p><p></ul><h3>설치</h3></p><pre><code class="language-">git clone https://github.com/TencentARC/AudioStory.git
cd AudioStory
conda create -n audiostory python=3.10 -y
conda activate audiostory
bash install_audiostory.sh</code></pre></p><h2>📊 Evaluation</h2></p><h3>inference</h3></p><pre><code class="language-">python evaluate/inference.py --model_path /path/to/ckpt --guidance 4.0 --save_folder_name audiostory --total_duration 50</code></pre>
<h2>🔋 감사의 말씀</h2></p><p>연속 디노이저 코드베이스를 구축할 때, <a href="https://github.com/AILab-CVC/SEED-X" target="_blank" rel="noopener noreferrer">SEED-X</a>와 <a href="https://github.com/declare-lab/TangoFlux" target="_blank" rel="noopener noreferrer">TangoFlux</a>를 참고하였습니다. 훌륭한 프로젝트에 감사드립니다.</p><h2>📆 해야 할 일</h2></p><ul><li>[ ] 그라디오 데모 공개.</li>
<li>[ ] AudioStory 체크포인트 공개.</li>
<li>[ ] 세 단계 모두의 훈련 코드 공개.</li></p><p></ul><h2>📜 라이선스</h2></p><p>이 저장소는 <a href="https://github.com/mashijie1028/Gen4Rep/blob/main/LICENSE" target="_blank" rel="noopener noreferrer">Apache 2 라이선스</a>를 따릅니다.</p><h2>📚 BibTeX</h2></p><pre><code class="language-">@misc{guo2025audiostory,
      title={AudioStory: Generating Long-Form Narrative Audio with Large Language Models}, 
      author={Yuxin Guo and Teng Wang and Yuying Ge and Shijie Ma and Yixiao Ge and Wei Zou and Ying Shan},
      year={2025},
      eprint={2508.20088},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2508.20088}, 
}</code></pre>
<h2>📧 연락처</h2></p><p>추가 질문이 있으시면 언제든지 연락해 주세요: guoyuxin2021@ia.ac.cn</p><p>토론 및 잠재적 협업도 환영합니다.</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-09-01

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/TencentARC/AudioStory/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>