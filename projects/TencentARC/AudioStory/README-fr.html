<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AudioStory - AudioStory : G&#233;n&#233;ration d&#39;audio narratif long format avec de grands mod&#232;les de langage</title>
    <meta name="description" content="AudioStory : G&#233;n&#233;ration d&#39;audio narratif long format avec de grands mod&#232;les de langage">
    <meta name="keywords" content="AudioStory, French, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "AudioStory",
  "description": "AudioStory : Génération d'audio narratif long format avec de grands modèles de langage",
  "author": {
    "@type": "Person",
    "name": "TencentARC"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 116
  },
  "url": "https://OpenAiTx.github.io/projects/TencentARC/AudioStory/README-fr.html",
  "sameAs": "https://raw.githubusercontent.com/TencentARC/AudioStory/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/TencentARC/AudioStory" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    AudioStory
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 116 stars</span>
                <span class="language">French</span>
                <span>by TencentARC</span>
            </div>
        </div>
        
        <div class="content">
            <h1>AudioStory : Génération d'audio narratif long format avec de grands modèles de langage</h1></p><p><em></em><a href="https://scholar.google.com/citations?user=x_0spxgAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Yuxin Guo<sup>1,2</sup></a>,  
<a href="http://ttengwang.com/" target="_blank" rel="noopener noreferrer">Teng Wang<sup>2,&#9993;</sup></a>,  
<a href="https://geyuying.github.io/" target="_blank" rel="noopener noreferrer">Yuying Ge<sup>2</sup></a>,  
<a href="https://mashijie1028.github.io/" target="_blank" rel="noopener noreferrer">Shijie Ma<sup>1,2</sup></a>,  
<a href="https://geyixiao.com/" target="_blank" rel="noopener noreferrer">Yixiao Ge<sup>2</sup></a>,  
<a href="https://people.ucas.ac.cn/~zouwei" target="_blank" rel="noopener noreferrer">Wei Zou<sup>1</sup></a>,  
<a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Ying Shan<sup>2</sup></a><em></em>  
<br>  
<sup>1</sup>Institut d’Automatisation, CAS  
<sup>2</sup>ARC Lab, Tencent PCG  
<br>  </p><h2>📖 Publication</h2></p><p>[2025/8/28] 🔥🔥 Nous publions le code d’inférence !</p><p>[2025/8/28] 🔥🔥 Nous publions nos vidéos de démonstration !</p><h2>🔎 Introduction</h2></p><p><img src="https://raw.githubusercontent.com/TencentARC/AudioStory/main/audiostory.png" alt="audiostory"></p><p>✨ <strong>TL; DR : Nous proposons un modèle de génération audio narrative long format basé sur un cadre unifié de compréhension–génération, capable de gérer le doublage vidéo, la continuation audio et la synthèse audio narrative longue.</strong></p><p>Les avancées récentes dans la génération texte-à-audio (TTA) excellent à synthétiser de courts clips audio mais peinent avec l’audio narratif long format, qui requiert cohérence temporelle et raisonnement compositionnel. Pour combler ce vide, nous proposons AudioStory, un cadre unifié intégrant de grands modèles de langage (LLM) avec des systèmes TTA pour générer des narrations audio longues et structurées. AudioStory possède de fortes capacités de génération raisonnée suivant des instructions. Il utilise les LLM pour décomposer des requêtes narratives complexes en sous-tâches ordonnées temporellement avec des indices contextuels, permettant des transitions de scènes cohérentes et une consistance du ton émotionnel. AudioStory présente deux caractéristiques attrayantes :</p><p>1) Mécanisme de liaison découplé : AudioStory dissocie la collaboration LLM-diffuseur en deux composants spécialisés — une requête de liaison pour l’alignement sémantique intra-événement et une requête de cohérence pour la préservation de la cohérence inter-événements.  
2) Entraînement de bout en bout : En unifiant la compréhension des instructions et la génération audio dans un cadre unique de bout en bout, AudioStory élimine le besoin de pipelines d’entraînement modulaires tout en renforçant la synergie entre les composants.  
    De plus, nous établissons un benchmark AudioStory-10K, englobant divers domaines tels que paysages sonores animés et narrations de sons naturels.</p><p>Des expériences approfondies démontrent la supériorité d’AudioStory tant sur la génération audio unique que sur la génération audio narrative, surpassant les baselines TTA antérieures en capacité de suivi d’instructions et fidélité audio.</p><h2>⭐ Démos</h2></p><h3>1. Doublage vidéo (style Tom & Jerry)</h3>
<blockquote>Le doublage est réalisé à l'aide d'AudioStory (entraîné sur Tom & Jerry) avec des sous-titres visuels extraits des vidéos.</blockquote></p><p><table class="center">
  <td><video src="https://github.com/user-attachments/assets/f06b5999-6649-44d3-af38-63fdcecd833c"></video></td>
  <td><video src="https://github.com/user-attachments/assets/17727c2a-bfea-4252-9aa8-48fc9ac33500"></video></td>
  <td><video src="https://github.com/user-attachments/assets/09589d82-62c9-47a6-838a-5a62319f35e2"></video></td>
  <tr>
</table ></p><h3>2. Doublage vidéo inter-domaines (style Tom & Jerry)</h3></p><p><table class="center">
    <td><video src="https://github.com/user-attachments/assets/e62d0c09-cdf0-4e51-b550-0a2c23f8d68d"></video></td>
    <td><video src="https://github.com/user-attachments/assets/736d22ca-6636-4ef0-99f3-768e4dfb112a"></video></td>
    <td><video src="https://github.com/user-attachments/assets/f2f7c94c-7f72-4cc0-8edc-290910980b04"></video></td>
  <tr>
  <td><video src="https://github.com/user-attachments/assets/d3e58dd4-31ae-4e32-aef1-03f1e649cb0c"></video></td>
  <td><video src="https://github.com/user-attachments/assets/4f68199f-e48a-4be7-b6dc-1acb8d377a6e"></video></td>
  <td><video src="https://github.com/user-attachments/assets/062236c3-1d26-4622-b843-cc0cd0c58053"></video></td>
	<tr>
  <td><video src="https://github.com/user-attachments/assets/8931f428-dd4d-430f-9927-068f2912dd36"></video></td>
  <td><video src="https://github.com/user-attachments/assets/ab7e46d5-f42c-472e-b66e-df786b658210"></video></td>      
  <td><video src="https://github.com/user-attachments/assets/9a0998ad-b5a4-42ac-bdaf-ceaf796fc586"></video></td>
  <tr>
</table ></p><h3>3. Texte vers audio long (Son naturel)</h3></p><p><table class="center">
  <td style="text-align:center;" width="480">Instruction : "Développez un audio complet qui représente pleinement Jake Shimabukuro interprétant un morceau complexe de ukulélé en studio, reçoit des applaudissements, et parle de sa carrière lors d'une interview. La durée totale est de 49,9 secondes."</td>
  <td><video src="https://github.com/user-attachments/assets/461e8a34-4217-454e-87b3-e4285f36ec43"></video></td>
	<tr>
  <td style="text-align:center;" width="480">Instruction : "Développez un audio complet qui représente pleinement un camion de pompiers quittant la caserne avec les sirènes hurlantes, signalant une intervention d'urgence, et s'éloignant. La durée totale est de 35,1 secondes."</td>
  <td><video src="https://github.com/user-attachments/assets/aac0243f-5d12-480e-9850-a7f6720e4f9c"></video></td>
	<tr>
     <td style="text-align:center;" width="480">Instruction : "Comprendre l'audio d'entrée, déduire les événements suivants, et générer l'audio continu du coach donnant des leçons de basketball aux joueurs. La durée totale est de 36,6 secondes."</td>    
    <td><video src="https://github.com/user-attachments/assets/c4ed306a-651e-43d6-aeea-ee159542418a"></video></td>
	<tr>
</table ></p><h2>🔎 Méthodes</h2></p><p><img src="https://raw.githubusercontent.com/TencentARC/AudioStory/main/audiostory_framework.png" alt="audiostory_framework"></p><p>Pour parvenir à une génération audio suivant efficacement les instructions, la capacité à comprendre l'instruction ou le flux audio d'entrée et à raisonner sur les sous-événements audio pertinents est essentielle. À cette fin, AudioStory adopte un cadre unifié de compréhension-génération (Fig.). Plus précisément, donné une instruction textuelle ou une entrée audio, le LLM l'analyse et la décompose en sous-événements audio structurés avec contexte. Sur la base des sous-événements déduits, le LLM effectue une <strong>génération par raisonnement entrelacé</strong>, produisant séquentiellement des légendes, des tokens sémantiques, et des tokens résiduels pour chaque clip audio. Ces deux types de tokens sont fusionnés et transmis au DiT, reliant efficacement le LLM au générateur audio. Grâce à un entraînement progressif, AudioStory atteint finalement à la fois une forte compréhension des instructions et une génération audio de haute qualité.</p><h2>🔩 Installation</h2></p><h3>Dépendances</h3></p><ul><li>Python >= 3.10 (Recommandé d'utiliser <a href="https://www.anaconda.com/download/#linux" target="_blank" rel="noopener noreferrer">Anaconda</a>)</li>
<li><a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">PyTorch >=2.1.0</a></li>
<li>GPU NVIDIA + <a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener noreferrer">CUDA</a></li></p><p></ul><h3>Installation</h3></p><pre><code class="language-">git clone https://github.com/TencentARC/AudioStory.git
cd AudioStory
conda create -n audiostory python=3.10 -y
conda activate audiostory
bash install_audiostory.sh</code></pre></p><h2>📊 Evaluation</h2></p><h3>inference</h3></p><pre><code class="language-">python evaluate/inference.py --model_path /path/to/ckpt --guidance 4.0 --save_folder_name audiostory --total_duration 50</code></pre>
<h2>🔋 Remerciements</h2></p><p>Lors de la création de la base de code des débruiteurs continus, nous nous sommes référés à <a href="https://github.com/AILab-CVC/SEED-X" target="_blank" rel="noopener noreferrer">SEED-X</a> et <a href="https://github.com/declare-lab/TangoFlux" target="_blank" rel="noopener noreferrer">TangoFlux</a>. Merci pour leurs projets remarquables.</p><h2>📆 À FAIRE</h2></p><ul><li>[ ] Publier notre démonstration gradio.</li>
<li>[ ] Publier les points de contrôle d'AudioStory.</li>
<li>[ ] Publier les codes d'entraînement des trois étapes.</li></p><p></ul><h2>📜 Licence</h2></p><p>Ce dépôt est sous la <a href="https://github.com/mashijie1028/Gen4Rep/blob/main/LICENSE" target="_blank" rel="noopener noreferrer">Licence Apache 2</a>.</p><h2>📚 BibTeX</h2></p><pre><code class="language-">@misc{guo2025audiostory,
      title={AudioStory: Generating Long-Form Narrative Audio with Large Language Models}, 
      author={Yuxin Guo and Teng Wang and Yuying Ge and Shijie Ma and Yixiao Ge and Wei Zou and Ying Shan},
      year={2025},
      eprint={2508.20088},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2508.20088}, 
}</code></pre>
<h2>📧 Contact</h2></p><p>Si vous avez d'autres questions, n'hésitez pas à me contacter : guoyuxin2021@ia.ac.cn</p><p>Les discussions et les collaborations potentielles sont également les bienvenues.</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-09-01

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/TencentARC/AudioStory/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>