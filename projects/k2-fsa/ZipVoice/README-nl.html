<!DOCTYPE html>
<html lang="nl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ZipVoice - Snelle en hoogwaardige zero-shot tekst-naar-spraak met Flow Matching</title>
    <meta name="description" content="Snelle en hoogwaardige zero-shot tekst-naar-spraak met Flow Matching">
    <meta name="keywords" content="ZipVoice, Dutch, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ZipVoice",
  "description": "Snelle en hoogwaardige zero-shot tekst-naar-spraak met Flow Matching",
  "author": {
    "@type": "Person",
    "name": "k2-fsa"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 661
  },
  "url": "https://OpenAiTx.github.io/projects/k2-fsa/ZipVoice/README-nl.html",
  "sameAs": "https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md",
  "datePublished": "2025-10-06",
  "dateModified": "2025-10-06"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/k2-fsa/ZipVoice" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    ZipVoice
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 661 stars</span>
                <span class="language">Dutch</span>
                <span>by k2-fsa</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Taal</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div></p><p><div align="center"></p><h1>ZipVoice⚡</h1></p><h2>Snel en Hoogwaardige Zero-Shot Tekst-naar-Spraak met Flow Matching</h2>
</div></p><h2>Overzicht</h2></p><p>ZipVoice is een serie snelle en hoogwaardige zero-shot TTS-modellen gebaseerd op flow matching.</p><h3>1. Belangrijkste kenmerken</h3></p><ul><li>Klein en snel: slechts 123M parameters.</li></p><p><li>Hoogwaardige stemkloning: state-of-the-art prestaties in spreker-gelijkenis, verstaanbaarheid en natuurlijkheid.</li></p><p><li>Meertalig: ondersteunt Chinees en Engels.</li></p><p><li>Multi-modus: ondersteunt zowel enkelspreker als dialoogspraakgeneratie.</li></p><p></ul><h3>2. Modelvarianten</h3></p><p><table>
  <thead>
    <tr>
      <th>Modelnaam</th>
      <th>Beschrijving</th>
      <th>Paper</th>
      <th>Demo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>Het basismodel dat zero-shot enkelspreker TTS ondersteunt in zowel Chinees als Engels.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>De gedistilleerde versie van ZipVoice, met verbeterde snelheid en minimale prestatiedaling.</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>Een dialooggeneratiemodel gebaseerd op ZipVoice, dat enkelkanaals tweezijdige gesproken dialogen kan genereren.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>De stereo-variant van ZipVoice-Dialog, waarmee tweekanaals dialooggeneratie mogelijk is waarbij elke spreker aan een afzonderlijk kanaal wordt toegewezen.</td>
    </tr>
  </tbody>
</table></p><h2>Nieuws</h2></p><p><strong>2025/07/14</strong>: <strong>ZipVoice-Dialog</strong> en <strong>ZipVoice-Dialog-Stereo</strong>, twee modellen voor gesproken dialooggeneratie, zijn uitgebracht. <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice-dialog.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><p><strong>2025/07/14</strong>: <strong>OpenDialog</strong> dataset, een 6,8k-uur gesproken dialoogdataset, is uitgebracht. Download via <a href="https://huggingface.co/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow" alt="hf"></a>, <a href="https://www.modelscope.cn/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data" alt="ms"></a>. Bekijk details via <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a>.</p><p><strong>2025/06/16</strong>: <strong>ZipVoice</strong> en <strong>ZipVoice-Distill</strong> zijn uitgebracht. <a href="https://arxiv.org/abs/2506.13053" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><h2>Installatie</h2></p><h3>1. Clone de ZipVoice repository</h3></p><pre><code class="language-bash">git clone https://github.com/k2-fsa/ZipVoice.git</code></pre>
<h3>2. (Optioneel) Maak een Python virtuele omgeving aan</h3></p><pre><code class="language-bash">python3 -m venv zipvoice
source zipvoice/bin/activate</code></pre>
<h3>3. Installeer de vereiste pakketten</h3></p><pre><code class="language-bash">pip install -r requirements.txt</code></pre>
<h3>4. Installeer k2 voor training of efficiënte inferentie</h3></p><p><strong>k2 is noodzakelijk voor training</strong> en kan de inferentie versnellen. Toch kun je de inferentiemodus van ZipVoice gebruiken zonder k2 te installeren.</p><blockquote><strong>Opmerking:</strong> Zorg ervoor dat je de k2-versie installeert die overeenkomt met jouw PyTorch- en CUDA-versie. Bijvoorbeeld, als je pytorch 2.5.1 en CUDA 12.1 gebruikt, kun je k2 als volgt installeren:</blockquote></p><pre><code class="language-bash">pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html</code></pre>
Raadpleeg https://k2-fsa.org/get-started/k2/ voor meer informatie.
Gebruikers op het Chinese vasteland kunnen terecht op https://k2-fsa.org/zh-CN/get-started/k2/.</p><ul><li>Om de installatie van k2 te controleren:</li></p><p>
</ul><pre><code class="language-bash">python3 -c "import k2; print(k2.__file__)"</code></pre>
<h2>Gebruik</h2></p><h3>1. Enkelspreker spraakgeneratie</h3></p><p>Om enkelspreker spraak te genereren met onze voorgetrainde ZipVoice of ZipVoice-Distill modellen, gebruikt u de volgende commando's (Vereiste modellen worden gedownload van HuggingFace):</p><p>#### 1.1 Inferentie van een enkele zin</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav</code></pre>
<ul><li><code>--model-name</code> kan <code>zipvoice</code> of <code>zipvoice_distill</code> zijn, wat respectievelijk de modellen vóór en na distillatie zijn.</li>
<li>Als <code><></code> of <code>[]</code> in de tekst verschijnen, worden de door hen omsloten strings behandeld als speciale tokens. <code><></code> duidt op Chinese pinyin en <code>[]</code> op andere speciale tags.</li></p><p></ul>#### 1.2 Inferentie van een lijst met zinnen</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li>Elke regel van <code>test.tsv</code> heeft het formaat <code>{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code>.</li></p><p></ul><h3>2. Dialoogspraakgeneratie</h3></p><p>#### 2.1 Inferentiecommando</p><p>Om tweepartijgesprekken te genereren met onze voorgetrainde ZipVoice-Dialogue of ZipVoice-Dialogue-Stereo modellen, gebruikt u de volgende commando's (Benodigde modellen worden gedownload van HuggingFace):</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li><code>--model-name</code> kan <code>zipvoice_dialog</code> of <code>zipvoice_dialog_stereo</code> zijn,</li>
    </ul>die respectievelijk mono- en stereodialogen genereren.</p><p>#### 2.2 Invoerformaten</p><p>Elke regel van <code>test.tsv</code> is in een van de volgende formaten:</p><p>(1) <strong>Samengevoegd promptformaat</strong> waarbij de audio's en transcripties van de prompts van twee sprekers zijn samengevoegd in één prompt-wav-bestand:</p><pre><code class="language-">{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code></pre></p><ul><li><code>wav_name</code> is de naam van het uitvoer-wav-bestand.</li>
<li><code>prompt_transcription</code> is de transcriptie van de conversatieprompt-wav, bijvoorbeeld: "[S1] Hallo. [S2] Hoe gaat het?"</li>
<li><code>prompt_wav</code> is het pad naar de prompt-wav.</li>
<li><code>text</code> is de te synthetiseren tekst, bijvoorbeeld: "[S1] Het gaat goed. [S2] Hoe heet je? [S1] Ik ben Eric. [S2] Hallo Eric."</li></p><p></ul>(2) <strong>Gesplitst promptformaat</strong> waarbij de audio's en transcripties van twee sprekers in afzonderlijke bestanden staan:</p><pre><code class="language-">{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}</code></pre></p><ul><li><code>wav_name</code> is de naam van het uitvoer-wav-bestand.</li>
<li><code>spk1_prompt_transcription</code> is de transcriptie van het prompt-wav-bestand van de eerste spreker, bijvoorbeeld "Hallo".</li>
<li><code>spk2_prompt_transcription</code> is de transcriptie van het prompt-wav-bestand van de tweede spreker, bijvoorbeeld "Hoe gaat het?"</li>
<li><code>spk1_prompt_wav</code> is het pad naar het prompt-wav-bestand van de eerste spreker.</li>
<li><code>spk2_prompt_wav</code> is het pad naar het prompt-wav-bestand van de tweede spreker.</li>
<li><code>text</code> is de te synthetiseren tekst, bijvoorbeeld "[S1] Het gaat goed. [S2] Hoe heet je? [S1] Ik ben Eric. [S2] Hallo Eric."</li></p><p></ul><h3>3 Richtlijnen voor beter gebruik:</h3></p><p>#### 3.1 Promptlengte</p><p>Wij raden een kort prompt-wav-bestand aan (bijvoorbeeld minder dan 3 seconden voor spraakgeneratie met één spreker, minder dan 10 seconden voor dialoogspraakgeneratie) voor een snellere inferentiesnelheid. Een erg lang prompt zal de inferentie vertragen en de spraakkwaliteit verminderen.</p><p>#### 3.2 Snelheidsoptimalisatie</p><p>Als de inferentiesnelheid onbevredigend is, kun je deze versnellen als volgt:</p><ul><li><strong>Gedistilleerd model en minder stappen</strong>: Voor het spraakgeneratiemodel met één spreker gebruiken we standaard het <code>zipvoice</code> model voor betere spraakkwaliteit. Als een snellere snelheid prioriteit heeft, kun je overschakelen naar <code>zipvoice_distill</code> en het aantal stappen (<code>--num-steps</code>) verlagen tot minimaal <code>4</code> (standaard 8).</li></p><p><li><strong>CPU-versnelling met multithreading</strong>: Bij gebruik van de CPU kun je de parameter <code>--num-thread</code> meegeven (bijvoorbeeld <code>--num-thread 4</code>) om het aantal threads te verhogen voor een snellere snelheid. Standaard gebruiken we 1 thread.</li></p><p><li><strong>CPU-versnelling met ONNX</strong>: Bij gebruik van de CPU kun je ONNX-modellen gebruiken met <code>zipvoice.bin.infer_zipvoice_onnx</code> voor een snellere snelheid (ONNX voor dialooggeneratiemodellen wordt nog niet ondersteund). Voor nog snellere snelheid kun je <code>--onnx-int8 True</code> instellen om een INT8-gekwantiseerd ONNX-model te gebruiken. Let op: het gekwantiseerde model levert een zekere mate van spraakkwaliteitsverlies op. <strong>Gebruik ONNX niet op GPU</strong>, omdat het langzamer is dan PyTorch op GPU.</li></p><p></ul>#### 3.3 Geheugenbeheer</p><p>De opgegeven tekst wordt gesplitst in stukken op basis van interpunctie (voor spraakgeneratie met één spreker) of sprekerwisselsymbool (voor dialoogspraakgeneratie). Vervolgens worden de gesplitste teksten in batches verwerkt. Hierdoor kan het model willekeurig lange tekst verwerken met vrijwel constant geheugengebruik. Je kunt het geheugengebruik regelen door de parameter <code>--max-duration</code> aan te passen.</p><p>#### 3.4 "Ruwe" evaluatie</p><p>Standaard preprocessen we invoer (prompt-wav, prompttranscriptie en tekst) voor efficiënte inferentie en betere prestaties. Als je de "ruwe" prestaties van het model wilt evalueren met exact de opgegeven invoer (bijvoorbeeld om de resultaten uit ons artikel te reproduceren), kun je <code>--raw-evaluation True</code> meegeven.</p><p>#### 3.5 Korte tekst</p><p>Bij het genereren van spraak voor zeer korte teksten (bijvoorbeeld één of twee woorden) kan het soms gebeuren dat bepaalde uitspraken ontbreken in de gegenereerde spraak. Om dit probleem op te lossen, kun je <code>--speed 0.3</code> meegeven (waarbij 0.3 een instelbare waarde is) om de duur van de gegenereerde spraak te verlengen.</p><p>#### 3.6 Corrigeren van verkeerd uitgesproken Chinese polyfone karakters</p><p>We gebruiken <a href="https://github.com/mozillazg/python-pinyin" target="_blank" rel="noopener noreferrer">pypinyin</a> om Chinese karakters naar pinyin om te zetten. Soms worden <strong>polyfone karakters</strong> (多音字) echter verkeerd uitgesproken.</p><p>Om deze verkeerde uitspraken handmatig te corrigeren, plaats de <strong>gecorrigeerde pinyin</strong> tussen hoekhaken <code>< ></code> en voeg het <strong>toonaccent</strong> toe.</p><p><strong>Voorbeeld:</strong></p><ul><li>Originele tekst: <code>这把剑长三十公分</code></li>
<li>Corrigeer de pinyin van <code>长</code>:  <code>这把剑<chang2>三十公分</code></li></p><p></ul>> <strong>Opmerking:</strong> Als je handmatig meerdere pinyins wilt toewijzen, plaats elke pinyin tussen <code><></code>, bijvoorbeeld: <code>这把<jian4><chang2><san1>十公分</code></p><p>#### 3.7 Verwijder lange stiltes uit het gegenereerde spraakfragment</p><p>Het model bepaalt automatisch de posities en lengtes van stiltes in het gegenereerde spraakfragment. Soms zijn er lange stiltes in het midden van het spraakfragment. Als je dit niet wilt, kun je <code>--remove-long-sil</code> gebruiken om lange stiltes in het midden van het gegenereerde spraakfragment te verwijderen (stiltes aan het begin en einde worden standaard verwijderd).</p><p>#### 3.8 Model downloaden</p><p>Als je problemen hebt met het verbinden met HuggingFace bij het downloaden van de voorgetrainde modellen, probeer dan over te schakelen naar de mirror-site: <code>export HF_ENDPOINT=https://hf-mirror.com</code>.</p><h2>Train Je Eigen Model</h2></p><p>Zie de <a href="egs" target="_blank" rel="noopener noreferrer">egs</a> map voor voorbeelden van training, fine-tuning en evaluatie.</p><h2>C++ Implementatie</h2></p><p>Bekijk <a href="https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498" target="_blank" rel="noopener noreferrer">sherpa-onnx</a> voor de C++ implementatie-oplossing op CPU.</p><h2>Discussie & Communicatie</h2></p><p>Je kunt direct discussiëren op <a href="https://github.com/k2-fsa/ZipVoice/issues" target="_blank" rel="noopener noreferrer">Github Issues</a>.</p><p>Je kunt ook de QR-code scannen om lid te worden van onze Wechat-groep of ons officiële Wechat-account te volgen.</p><p>| Wechat Groep | Wechat Officieel Account |
| ------------ | ------------------------ |
|<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg" alt="wechat"> |<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg" alt="wechat"> |</p><h2>Referentie</h2></p><pre><code class="language-bibtex">@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}</p><p>@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}</code></pre></p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-10-06

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-10-06 
    </div>
    
</body>
</html>