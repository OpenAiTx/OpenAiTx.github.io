<!DOCTYPE html>
<html lang="hi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ZipVoice - Read ZipVoice documentation in Hindi. This project has 308 stars on GitHub.</title>
    <meta name="description" content="Read ZipVoice documentation in Hindi. This project has 308 stars on GitHub.">
    <meta name="keywords" content="ZipVoice, Hindi, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ZipVoice",
  "description": "Read ZipVoice documentation in Hindi. This project has 308 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "k2-fsa"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 308
  },
  "url": "https://OpenAiTx.github.io/projects/k2-fsa/ZipVoice/README-hi.html",
  "sameAs": "https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/k2-fsa/ZipVoice" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    ZipVoice
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 308 stars</span>
                <span class="language">Hindi</span>
                <span>by k2-fsa</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align="right">
  <details>
    <summary >🌐 भाषा</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div></p><p><div align="center"></p><h1>ZipVoice⚡</h1></p><h2>फ्लो मैचिंग के साथ तेज़ और उच्च गुणवत्ता वाली शून्य-शॉट टेक्स्ट-टू-स्पीच</h2>
</div></p><h2>अवलोकन</h2></p><p>ZipVoice फ्लो मैचिंग पर आधारित तेज़ और उच्च गुणवत्ता वाली शून्य-शॉट TTS मॉडल्स की एक श्रृंखला है।</p><h3>1. मुख्य विशेषताएँ</h3></p><ul><li>छोटा और तेज़: केवल 123M पैरामीटर्स।</li></p><p><li>उच्च गुणवत्ता वाली वॉयस क्लोनिंग: स्पीकर समानता, बोधगम्यता और स्वाभाविकता में अत्याधुनिक प्रदर्शन।</li></p><p><li>बहु-भाषी: चीनी और अंग्रेज़ी का समर्थन।</li></p><p><li>बहु-मोड: एकल-वक्ता और संवाद भाषण निर्माण दोनों का समर्थन।</li></p><p></ul><h3>2. मॉडल वेरिएंट्स</h3></p><p><table>
  <thead>
    <tr>
      <th>मॉडल नाम</th>
      <th>विवरण</th>
      <th>पेपर</th>
      <th>डेमो</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>मूलभूत मॉडल, जो चीनी और अंग्रेज़ी दोनों में शून्य-शॉट एकल-वक्ता TTS का समर्थन करता है।</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>ZipVoice का डिस्टिल्ड संस्करण, जिसमें न्यूनतम प्रदर्शन हानि के साथ बेहतर गति है।</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>ZipVoice पर आधारित एक संवाद निर्माण मॉडल, जो एकल-चैनल दो-पक्षीय बोले गए संवाद जनरेट कर सकता है।</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>ZipVoice-Dialog का स्टीरियो वेरिएंट, जिसमें प्रत्येक वक्ता को अलग चैनल सौंपकर दो-चैनल संवाद उत्पन्न किया जा सकता है।</td>
    </tr>
  </tbody>
</table></p><h2>समाचार</h2></p><p><strong>2025/07/14</strong>: <strong>ZipVoice-Dialog</strong> और <strong>ZipVoice-Dialog-Stereo</strong>, दो बोले जाने वाले संवाद निर्माण मॉडल्स जारी किए गए हैं। <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice-dialog.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><p><strong>2025/07/14</strong>: <strong>OpenDialog</strong> डेटासेट, 6.8k-घंटे का बोले जाने वाला संवाद डेटासेट, जारी किया गया है। डाउनलोड करें <a href="https://huggingface.co/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow" alt="hf"></a>, <a href="https://www.modelscope.cn/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data" alt="ms"></a>। विवरण देखें <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a>।</p><p><strong>2025/06/16</strong>: <strong>ZipVoice</strong> और <strong>ZipVoice-Distill</strong> जारी किए गए हैं। <a href="https://arxiv.org/abs/2506.13053" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><h2>इंस्टॉलेशन</h2></p><h3>1. ZipVoice रिपॉजिटरी क्लोन करें</h3></p><pre><code class="language-bash">git clone https://github.com/k2-fsa/ZipVoice.git</code></pre>
<h3>2. (वैकल्पिक) एक पायथन वर्चुअल एनवायरनमेंट बनाएं</h3></p><pre><code class="language-bash">python3 -m venv zipvoice
source zipvoice/bin/activate</code></pre>
<h3>3. आवश्यक पैकेज इंस्टॉल करें</h3></p><pre><code class="language-bash">pip install -r requirements.txt</code></pre>
<h3>4. प्रशिक्षण या कुशल अनुकरण के लिए k2 स्थापित करें</h3></p><p><strong>प्रशिक्षण के लिए k2 आवश्यक है</strong> और यह अनुकरण को तेज कर सकता है। फिर भी, आप k2 स्थापित किए बिना भी ZipVoice के अनुकरण मोड का उपयोग कर सकते हैं।</p><blockquote><strong>नोट:</strong>  सुनिश्चित करें कि आप अपने PyTorch और CUDA संस्करण के अनुसार k2 का संस्करण स्थापित कर रहे हैं। उदाहरण के लिए, यदि आप pytorch 2.5.1 और CUDA 12.1 उपयोग कर रहे हैं, तो आप इस प्रकार k2 स्थापित कर सकते हैं:</blockquote></p><pre><code class="language-bash">pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html</code></pre>
कृपया विवरण के लिए https://k2-fsa.org/get-started/k2/ देखें।
चीन मुख्यभूमि के उपयोगकर्ता https://k2-fsa.org/zh-CN/get-started/k2/ देख सकते हैं।</p><ul><li>k2 इंस्टॉलेशन जांचने के लिए:</li></p><p>
</ul><pre><code class="language-">python3 -c "import k2; print(k2.__file__)"</code></pre>
<h2>उपयोग</h2></p><h3>1. एकल-वक्ता भाषण जनरेशन</h3></p><p>हमारे प्री-ट्रेंड ZipVoice या ZipVoice-Distill मॉडल के साथ एकल-वक्ता भाषण जनरेट करने के लिए, निम्नलिखित कमांड्स का उपयोग करें (आवश्यक मॉडल HuggingFace से डाउनलोड किए जाएंगे):</p><p>#### 1.1 एकल वाक्य का इनफरेंस</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav</code></pre>
<ul><li><code>--model-name</code> को <code>zipvoice</code> या <code>zipvoice_distill</code> सेट किया जा सकता है, जो क्रमशः डिस्टिलेशन से पहले और बाद के मॉडल हैं।</li>
<li>यदि पाठ में <code><></code> या <code>[]</code> दिखाई देते हैं, तो उनके द्वारा संलग्न स्ट्रिंग्स को विशेष टोकन के रूप में माना जाएगा। <code><></code> चीनी पिनयिन को दर्शाता है और <code>[]</code> अन्य विशेष टैग्स को।</li>
<li><code>zipvoice.bin.infer_zipvoice_onnx</code> के साथ ONNX मॉडल्स को CPU पर तेज़ी से चला सकते हैं।</li></p><p></ul>> <strong>ध्यान दें:</strong> यदि आपको HuggingFace से कनेक्ट करने में समस्या हो रही है, तो आज़माएँ:
<blockquote><pre><code class="language-bash">> export HF_ENDPOINT=https://hf-mirror.com</blockquote>
<blockquote>``<code></blockquote></p><p>#### 1.2 वाक्य सूची का इनफेरेंस</p><p></code></pre>bash
python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results
<pre><code class="language-">- </code>test.tsv<code> की प्रत्येक पंक्ति इस प्रारूप में होती है: </code>{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}<code>।</p><h3>2. संवाद भाषण निर्माण</h3></p><p>#### 2.1 पूर्वानुमान कमांड</p><p>हमारे प्री-ट्रेंड ZipVoice-Dialogue या ZipVoice-Dialogue-Stereo मॉडल के साथ दो-पक्षीय बोले गए संवाद उत्पन्न करने के लिए, निम्नलिखित कमांड का उपयोग करें (आवश्यक मॉडल HuggingFace से डाउनलोड किए जाएंगे):</p><p></code></pre>bash
python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results
<pre><code class="language-">- </code>--model-name<code> या तो </code>zipvoice_dialog<code> या </code>zipvoice_dialog_stereo<code> हो सकता है,
    जो क्रमशः मोनो और स्टीरियो संवाद उत्पन्न करते हैं।</p><p>#### 2.2 इनपुट प्रारूप</p><p></code>test.tsv<code> की प्रत्येक पंक्ति निम्नलिखित प्रारूपों में से एक में होती है:</p><p>(1) <strong>मर्ज्ड प्रॉम्प्ट प्रारूप</strong> जिसमें दो वक्ताओं के प्रॉम्प्ट ऑडियो और ट्रांसक्रिप्शन को एक प्रॉम्प्ट वेव फ़ाइल में मर्ज कर दिया जाता है:
</code></pre>
{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}
<pre><code class="language-">- </code>wav_name<code> आउटपुट वेव फाइल का नाम है।
<ul><li></code>prompt_transcription<code> वार्तालाप संकेत वेव का ट्रांसक्रिप्शन है, जैसे, "[S1] हेलो। [S2] आप कैसे हैं?"</li>
<li></code>prompt_wav<code> संकेत वेव का पथ है।</li>
<li></code>text<code> वह पाठ है जिसे सिंथेसाइज़ किया जाना है, जैसे "[S1] मैं ठीक हूँ। [S2] आपका नाम क्या है?"</li></p><p></ul>(2) <strong>स्प्लिटेड प्रॉम्प्ट फॉर्मेट</strong> जहाँ दो वक्ताओं के ऑडियो और ट्रांसक्रिप्शन अलग-अलग फाइलों में होते हैं:</p><p></code></pre>
{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}'
<pre><code class="language-">- </code>wav_name<code> आउटपुट वेव फाइल का नाम है।
<ul><li></code>spk1_prompt_transcription<code> पहले वक्ता के प्रॉम्प्ट वेव की ट्रांसक्रिप्शन है, जैसे, "Hello"</li>
<li></code>spk2_prompt_transcription<code> दूसरे वक्ता के प्रॉम्प्ट वेव की ट्रांसक्रिप्शन है, जैसे, "How are you?"</li>
<li></code>spk1_prompt_wav<code> पहले वक्ता के प्रॉम्प्ट वेव फाइल का पथ है।</li>
<li></code>spk2_prompt_wav<code> दूसरे वक्ता के प्रॉम्प्ट वेव फाइल का पथ है।</li>
<li></code>text<code> वह टेक्स्ट है जिसे सिंथेसाइज़ किया जाना है, जैसे, "[S1] I'm fine. [S2] What's your name?"</li></p><p></ul><h3>3. अन्य सुविधाएँ</h3></p><p>#### 3.1 चीनी बहुध्वनिक अक्षरों का गलत उच्चारण सुधारना</p><p>हम <a href="https://github.com/mozillazg/python-pinyin" target="_blank" rel="noopener noreferrer">pypinyin</a> का उपयोग चीनी अक्षरों को पिनयिन में बदलने के लिए करते हैं। हालांकि, यह कभी-कभी <strong>बहुध्वनिक अक्षरों</strong> (多音字) का गलत उच्चारण कर सकता है।</p><p>इन गलत उच्चारणों को मैन्युअली सुधारने के लिए, <strong>सही पिनयिन</strong> को कोणीय ब्रैकेट </code>< ><code> में रखें और <strong>स्वर चिन्ह</strong> शामिल करें।</p><p><strong>उदाहरण:</strong></p><ul><li>मूल टेक्स्ट: </code>这把剑长三十公分<code></li>
<li></code>长<code> का पिनयिन सुधारें:  </code>这把剑<chang2>三十公分<code></li></p><p></ul>> <strong>नोट:</strong> यदि आप मैन्युअली एक से अधिक पिनयिन असाइन करना चाहते हैं, तो प्रत्येक पिनयिन को </code><><code> में रखें, जैसे, </code>这把<jian4><chang2><san1>十公分<code></p><h2>अपना मॉडल ट्रेन करें</h2></p><p>ट्रेनिंग, फाइन-ट्यूनिंग और इवैल्युएशन के उदाहरणों के लिए <a href="egs" target="_blank" rel="noopener noreferrer">egs</a> डायरेक्टरी देखें।</p><h2>चर्चा और संवाद</h2></p><p>आप सीधे <a href="https://github.com/k2-fsa/ZipVoice/issues" target="_blank" rel="noopener noreferrer">Github Issues</a> पर चर्चा कर सकते हैं।</p><p>आप हमारे वीचैट ग्रुप में शामिल होने या हमारे वीचैट ऑफिशियल अकाउंट को फॉलो करने के लिए क्यूआर कोड भी स्कैन कर सकते हैं।</p><p>| वीचैट ग्रुप | वीचैट ऑफिशियल अकाउंट |
| ------------ | ----------------------- |
|<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg" alt="wechat"> |<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg" alt="wechat"> |</p><h2>संदर्भ</h2></p><p></code></pre>bibtex
@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}</p><p>@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}
</code>``</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-22

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>