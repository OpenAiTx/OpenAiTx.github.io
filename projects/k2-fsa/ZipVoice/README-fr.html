<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ZipVoice - Read ZipVoice documentation in French. This project has 308 stars on GitHub.</title>
    <meta name="description" content="Read ZipVoice documentation in French. This project has 308 stars on GitHub.">
    <meta name="keywords" content="ZipVoice, French, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ZipVoice",
  "description": "Read ZipVoice documentation in French. This project has 308 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "k2-fsa"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 308
  },
  "url": "https://OpenAiTx.github.io/projects/k2-fsa/ZipVoice/README-fr.html",
  "sameAs": "https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/k2-fsa/ZipVoice" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    ZipVoice
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 308 stars</span>
                <span class="language">French</span>
                <span>by k2-fsa</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align="right">
  <details>
    <summary >🌐 Langue</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div></p><p><div align="center"></p><h1>ZipVoice⚡</h1></p><h2>Synthèse vocale rapide et de haute qualité zéro-shot avec Flow Matching</h2>
</div></p><h2>Aperçu</h2></p><p>ZipVoice est une série de modèles TTS zéro-shot rapides et de haute qualité basés sur le flow matching.</p><h3>1. Principales fonctionnalités</h3></p><ul><li>Petit et rapide : seulement 123M de paramètres.</li></p><p><li>Clonage vocal de haute qualité : performances de pointe en similarité de locuteur, intelligibilité et naturel.</li></p><p><li>Multilingue : prend en charge le chinois et l'anglais.</li></p><p><li>Multi-mode : prend en charge la génération de parole à locuteur unique et de dialogues.</li></p><p></ul><h3>2. Variantes du modèle</h3></p><p><table>
  <thead>
    <tr>
      <th>Nom du modèle</th>
      <th>Description</th>
      <th>Article</th>
      <th>Démo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>Le modèle de base prenant en charge le TTS zéro-shot à locuteur unique en chinois et en anglais.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>La version distillée de ZipVoice, avec une vitesse améliorée et une dégradation minimale des performances.</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>Un modèle de génération de dialogues basé sur ZipVoice, capable de générer des dialogues parlés à deux voix sur un seul canal.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>La variante stéréo de ZipVoice-Dialog, permettant la génération de dialogues à deux canaux avec chaque locuteur sur un canal distinct.</td>
    </tr>
  </tbody>
</table></p><h2>Actualités</h2></p><p><strong>2025/07/14</strong> : <strong>ZipVoice-Dialog</strong> et <strong>ZipVoice-Dialog-Stereo</strong>, deux modèles de génération de dialogues parlés, sont publiés. <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice-dialog.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><p><strong>2025/07/14</strong> : Le jeu de données <strong>OpenDialog</strong>, un jeu de données de dialogues parlés de 6,8k heures, est disponible. Téléchargez-le sur <a href="https://huggingface.co/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow" alt="hf"></a>, <a href="https://www.modelscope.cn/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data" alt="ms"></a>. Détails sur <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a>.</p><p><strong>2025/06/16</strong> : <strong>ZipVoice</strong> et <strong>ZipVoice-Distill</strong> sont publiés. <a href="https://arxiv.org/abs/2506.13053" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><h2>Installation</h2></p><h3>1. Clonez le dépôt ZipVoice</h3></p><pre><code class="language-bash">git clone https://github.com/k2-fsa/ZipVoice.git</code></pre>
<h3>2. (Optionnel) Créez un environnement virtuel Python</h3></p><pre><code class="language-bash">python3 -m venv zipvoice
source zipvoice/bin/activate</code></pre>
<h3>3. Installez les paquets requis</h3></p><pre><code class="language-bash">pip install -r requirements.txt</code></pre>
<h3>4. Installer k2 pour l'entraînement ou l'inférence efficace</h3></p><p><strong>k2 est nécessaire pour l'entraînement</strong> et peut accélérer l'inférence. Néanmoins, vous pouvez toujours utiliser le mode inférence de ZipVoice sans installer k2.</p><blockquote><strong>Remarque :</strong> Assurez-vous d'installer la version de k2 qui correspond à votre version de PyTorch et CUDA. Par exemple, si vous utilisez pytorch 2.5.1 et CUDA 12.1, vous pouvez installer k2 comme suit :</blockquote></p><pre><code class="language-bash">pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html</code></pre>
Veuillez consulter https://k2-fsa.org/get-started/k2/ pour plus de détails.
Les utilisateurs en Chine continentale peuvent consulter https://k2-fsa.org/zh-CN/get-started/k2/.</p><ul><li>Pour vérifier l'installation de k2 :</li></p><p>
</ul><pre><code class="language-">python3 -c "import k2; print(k2.__file__)"</code></pre>
<h2>Utilisation</h2></p><h3>1. Génération de parole à un seul locuteur</h3></p><p>Pour générer de la parole à un seul locuteur avec nos modèles ZipVoice ou ZipVoice-Distill pré-entraînés, utilisez les commandes suivantes (Les modèles requis seront téléchargés depuis HuggingFace) :</p><p>#### 1.1 Inférence d'une seule phrase</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav</code></pre>
<ul><li><code>--model-name</code> peut être <code>zipvoice</code> ou <code>zipvoice_distill</code>, qui sont respectivement les modèles avant et après distillation.</li>
<li>Si <code><></code> ou <code>[]</code> apparaissent dans le texte, les chaînes qu'ils entourent seront traitées comme des jetons spéciaux. <code><></code> désigne le pinyin chinois et <code>[]</code> désigne d'autres balises spéciales.</li>
<li>Il est possible d'exécuter les modèles ONNX plus rapidement sur le CPU avec <code>zipvoice.bin.infer_zipvoice_onnx</code>.</li></p><p></ul>> <strong>Remarque :</strong> Si vous avez des difficultés à vous connecter à HuggingFace, essayez :
<blockquote><pre><code class="language-bash">> export HF_ENDPOINT=https://hf-mirror.com</blockquote>
<blockquote>``<code></blockquote></p><p>#### 1.2 Inférence d'une liste de phrases</p><p></code></pre>bash
python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results
<pre><code class="language-">- Chaque ligne de </code>test.tsv<code> est au format </code>{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}<code>.</p><h3>2. Génération de la parole en dialogue</h3></p><p>#### 2.1 Commande d'inférence</p><p>Pour générer des dialogues parlés à deux voix avec nos modèles pré-entraînés ZipVoice-Dialogue ou ZipVoice-Dialogue-Stereo, utilisez les commandes suivantes (les modèles requis seront téléchargés depuis HuggingFace) :</p><p></code></pre>bash
python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results
<pre><code class="language-">- </code>--model-name<code> peut être </code>zipvoice_dialog<code> ou </code>zipvoice_dialog_stereo<code>,
    qui génèrent respectivement des dialogues mono et stéréo.</p><p>#### 2.2 Formats d'entrée</p><p>Chaque ligne de </code>test.tsv<code> est dans l'un des formats suivants :</p><p>(1) <strong>Format de prompt fusionné</strong> où les audios et transcriptions des prompts des deux locuteurs sont fusionnés en un seul fichier wav de prompt :
</code></pre>
{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}
<pre><code class="language-">- </code>wav_name<code> est le nom du fichier wav de sortie.
<ul><li></code>prompt_transcription<code> est la transcription du fichier wav du prompt conversationnel, par exemple, "[S1] Bonjour. [S2] Comment ça va ?"</li>
<li></code>prompt_wav<code> est le chemin vers le fichier wav du prompt.</li>
<li></code>text<code> est le texte à synthétiser, par exemple, "[S1] Je vais bien. [S2] Comment tu t'appelles ?"</li></p><p></ul>(2) <strong>Format de prompt séparé</strong> où les audios et les transcriptions des deux intervenants existent dans des fichiers distincts :</p><p></code></pre>
{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}'
<pre><code class="language-">- </code>wav_name<code> est le nom du fichier wav de sortie.
<ul><li></code>spk1_prompt_transcription<code> est la transcription du prompt wav du premier locuteur, par exemple, "Bonjour"</li>
<li></code>spk2_prompt_transcription<code> est la transcription du prompt wav du deuxième locuteur, par exemple, "Comment ça va ?"</li>
<li></code>spk1_prompt_wav<code> est le chemin du fichier wav du prompt du premier locuteur.</li>
<li></code>spk2_prompt_wav<code> est le chemin du fichier wav du prompt du deuxième locuteur.</li>
<li></code>text<code> est le texte à synthétiser, par exemple, "[S1] Je vais bien. [S2] Comment tu t'appelles ?"</li></p><p></ul><h3>3. Autres fonctionnalités</h3></p><p>#### 3.1 Correction des caractères chinois polyphoniques mal prononcés</p><p>Nous utilisons <a href="https://github.com/mozillazg/python-pinyin" target="_blank" rel="noopener noreferrer">pypinyin</a> pour convertir les caractères chinois en pinyin. Cependant, il peut parfois mal prononcer les <strong>caractères polyphoniques</strong> (多音字).</p><p>Pour corriger manuellement ces erreurs de prononciation, entourez le <strong>pinyin corrigé</strong> avec des chevrons </code>< ><code> et incluez la <strong>marque de ton</strong>.</p><p><strong>Exemple :</strong></p><ul><li>Texte original : </code>这把剑长三十公分<code></li>
<li>Corrigez le pinyin de </code>长<code> :  </code>这把剑<chang2>三十公分<code></li></p><p></ul>> <strong>Remarque :</strong> Si vous souhaitez attribuer manuellement plusieurs pinyins, entourez chaque pinyin avec </code><><code>, par exemple, </code>这把<jian4><chang2><san1>十公分<code></p><h2>Entraînez votre propre modèle</h2></p><p>Consultez le répertoire <a href="egs" target="_blank" rel="noopener noreferrer">egs</a> pour des exemples d'entraînement, de fine-tuning et d'évaluation.</p><h2>Discussion & Communication</h2></p><p>Vous pouvez discuter directement sur <a href="https://github.com/k2-fsa/ZipVoice/issues" target="_blank" rel="noopener noreferrer">Github Issues</a>.</p><p>Vous pouvez également scanner le code QR pour rejoindre notre groupe wechat ou suivre notre compte officiel wechat.</p><p>| Groupe Wechat | Compte officiel Wechat |
| ------------- | ---------------------- |
|<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg" alt="wechat"> |<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg" alt="wechat"> |</p><h2>Citation</h2></p><p></code></pre>bibtex
@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}</p><p>@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}
</code>``</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-22

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>