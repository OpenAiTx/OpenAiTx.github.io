<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ZipVoice - 基於流匹配的快速高品質零樣本文本轉語音</title>
    <meta name="description" content="基於流匹配的快速高品質零樣本文本轉語音">
    <meta name="keywords" content="ZipVoice, Traditional Chinese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ZipVoice",
  "description": "基於流匹配的快速高品質零樣本文本轉語音",
  "author": {
    "@type": "Person",
    "name": "k2-fsa"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 748
  },
  "url": "https://OpenAiTx.github.io/projects/k2-fsa/ZipVoice/README-zh-TW.html",
  "sameAs": "https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md",
  "datePublished": "2025-12-30",
  "dateModified": "2025-12-30"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/k2-fsa/ZipVoice" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    ZipVoice
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 748 stars</span>
                <span class="language">Traditional Chinese</span>
                <span>by k2-fsa</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 語言</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">簡體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div></p><p><div align="center"></p><h1>ZipVoice⚡</h1></p><h2>極速且高品質的零樣本文本轉語音，採用流匹配技術</h2>
</div></p><h2>概述</h2></p><p>ZipVoice 是一系列基於流匹配的快速且高品質零樣本 TTS 模型。</p><h3>1. 主要特點</h3></p><ul><li>小巧且快速：僅有 123M 參數。</li></p><p><li>高品質語音克隆：在說話人相似度、可懂度和自然度上均達到最先進水平。</li></p><p><li>多語言：支援中文和英文。</li></p><p><li>多模式：支援單一說話人及對話語音生成。</li></p><p></ul><h3>2. 模型變體</h3></p><p><table>
  <thead>
    <tr>
      <th>模型名稱</th>
      <th>描述</th>
      <th>論文</th>
      <th>演示</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>基礎模型，支援中英文零樣本單說話人 TTS。</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>ZipVoice 的蒸餾版本，速度更快且性能損失極小。</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>基於 ZipVoice 的對話生成模型，可生成單聲道雙方語音對話。</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>ZipVoice-Dialog 的立體聲變體，支援雙聲道對話生成，讓每位說話者分配至不同的聲道。</td>
    </tr>
  </tbody>
</table></p><h2>最新消息</h2></p><p><strong>2025/07/14</strong>：<strong>ZipVoice-Dialog</strong> 和 <strong>ZipVoice-Dialog-Stereo</strong> 兩款語音對話生成模型正式釋出。<a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice-dialog.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><p><strong>2025/07/14</strong>：<strong>OpenDialog</strong> 資料集，包含 6.8k 小時語音對話資料，正式釋出。下載連結：<a href="https://huggingface.co/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow" alt="hf"></a>, <a href="https://www.modelscope.cn/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data" alt="ms"></a>。詳情請見 <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a>。</p><p><strong>2025/06/16</strong>：<strong>ZipVoice</strong> 和 <strong>ZipVoice-Distill</strong> 模型正式釋出。<a href="https://arxiv.org/abs/2506.13053" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><h2>安裝</h2></p><h3>1. 複製 ZipVoice 原始碼庫</h3></p><pre><code class="language-bash">git clone https://github.com/k2-fsa/ZipVoice.git</code></pre>
<h3>2.（可選）建立 Python 虛擬環境</h3></p><pre><code class="language-bash">python3 -m venv zipvoice
source zipvoice/bin/activate</code></pre>
<h3>3. 安裝所需的套件</h3></p><pre><code class="language-bash">pip install -r requirements.txt</code></pre>
<h3>4. 安裝 k2 以進行訓練或高效推理</h3></p><p><strong>k2 是訓練所必需的</strong>，並且可以加速推理。然而，即使不安裝 k2，你仍然可以使用 ZipVoice 的推理模式。</p><blockquote><strong>注意：</strong> 請確保安裝與你的 PyTorch 和 CUDA 版本相符的 k2 版本。例如，如果你使用的是 pytorch 2.5.1 和 CUDA 12.1，你可以按照以下方式安裝 k2：</blockquote></p><pre><code class="language-bash">pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html</code></pre>
請參閱 https://k2-fsa.org/get-started/k2/ 以了解詳情。
中國大陸用戶可參考 https://k2-fsa.org/zh-CN/get-started/k2/。</p><ul><li>檢查 k2 是否安裝：</li></p><p>
</ul><pre><code class="language-bash">python3 -c "import k2; print(k2.__file__)"</code></pre>
<h2>使用方式</h2></p><h3>1. 單一說話者語音生成</h3></p><p>要使用我們預訓練的 ZipVoice 或 ZipVoice-Distill 模型生成單一說話者語音，請使用以下指令（所需模型將自 HuggingFace 下載）：</p><p>#### 1.1 單句推論</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav</code></pre>
<ul><li><code>--model-name</code> 可以是 <code>zipvoice</code> 或 <code>zipvoice_distill</code>，分別代表蒸餾前和蒸餾後的模型。</li>
<li>若文字中出現 <code><></code> 或 <code>[]</code>，則被括號包住的字串將被視為特殊標記。<code><></code> 表示中文拼音，<code>[]</code> 表示其他特殊標籤。</li></p><p></ul>#### 1.2 一系列句子的推論</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li><code>test.tsv</code> 的每一行格式為 <code>{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code>。</li></p><p></ul><h3>2. 對話語音生成</h3></p><p>#### 2.1 推論指令</p><p>要使用我們預訓練的 ZipVoice-Dialogue 或 ZipVoice-Dialogue-Stereo 模型生成雙方對話語音，請使用以下指令（所需模型將從 HuggingFace 下載）：</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li><code>--model-name</code> 可以是 <code>zipvoice_dialog</code> 或 <code>zipvoice_dialog_stereo</code>，</li>
    </ul>分別產生單聲道和立體聲對話。</p><p>#### 2.2 輸入格式</p><p><code>test.tsv</code> 的每一行都是以下格式之一：</p><p>(1) <strong>合併提示格式</strong>，其中兩位說話者的提示音訊和轉錄被合併為一個提示 wav 檔案：</p><pre><code class="language-">{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code></pre></p><ul><li><code>wav_name</code> 是輸出 wav 檔案的名稱。</li>
<li><code>prompt_transcription</code> 是對話提示 wav 的文字轉錄，例如：「[S1] 你好。 [S2] 你好嗎？」</li>
<li><code>prompt_wav</code> 是提示 wav 的路徑。</li>
<li><code>text</code> 是要合成的文字，例如：「[S1] 我很好。 [S2] 你叫什麼名字？ [S1] 我叫 Eric。 [S2] 嗨 Eric。」</li></p><p></ul>(2) <strong>分割提示格式</strong>，其中兩位說話者的音檔和文字轉錄分別存在不同檔案中：</p><pre><code class="language-">{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}</code></pre>
<ul><li><code>wav_name</code> 是輸出 wav 檔案的名稱。</li>
<li><code>spk1_prompt_transcription</code> 是第一位說話者的提示 wav 文字轉錄，例如「Hello」</li>
<li><code>spk2_prompt_transcription</code> 是第二位說話者的提示 wav 文字轉錄，例如「How are you?」</li>
<li><code>spk1_prompt_wav</code> 是第一位說話者的提示 wav 檔案路徑。</li>
<li><code>spk2_prompt_wav</code> 是第二位說話者的提示 wav 檔案路徑。</li>
<li><code>text</code> 是要合成的文字，例如：「[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric.」</li></p><p></ul><h3>3 使用指引：</h3></p><p>#### 3.1 提示長度</p><p>我們建議使用較短的提示 wav 檔案（例如單一說話者語音生成少於 3 秒，對話語音生成少於 10 秒），以加快推論速度。過長的提示會降低推論速度並影響語音品質。</p><p>#### 3.2 速度優化</p><p>如果推論速度不理想，可以透過以下方式加快速度：</p><ul><li><strong>精簡模型與減少步數</strong>：單一說話者語音生成模型預設使用 <code>zipvoice</code> 模型以獲得更佳語音品質。如優先考量速度，可切換至 <code>zipvoice_distill</code> 並將 <code>--num-steps</code> 降至最低 <code>4</code>（預設為 8）。</li></p><p><li><strong>CPU 多執行緒加速</strong>：在 CPU 執行時，可傳入 <code>--num-thread</code> 參數（例如 <code>--num-thread 4</code>）以增加執行緒數量加快速度。預設為 1 執行緒。</li></p><p><li><strong>CPU ONNX 加速</strong>：在 CPU 執行時，可使用 ONNX 模型搭配 <code>zipvoice.bin.infer_zipvoice_onnx</code> 以提升速度（目前尚未支援對話生成模型的 ONNX）。若需更快速度，可進一步設定 <code>--onnx-int8 True</code> 使用 INT8 量化 ONNX 模型。注意量化模型會造成語音品質一定程度下降。<strong>請勿在 GPU 上使用 ONNX</strong>，因其在 GPU 上比 PyTorch 慢。</li></p><p><li><strong>NVIDIA TensorRT GPU 加速</strong>：如需在 NVIDIA GPU 上大幅提升效能，請先使用 zipvoice.bin.tensorrt_export 將模型匯出為 TensorRT 引擎。然後以 zipvoice.bin.infer_zipvoice 在您的資料集（如 Hugging Face 資料集）上執行推論。此方式可達到約 2 倍於 GPU 上標準 PyTorch 實作的吞吐量。</li></p><p></ul>#### 3.3 記憶體控制</p><p>所提供的文字將依標點符號（單一說話者語音生成）或說話者換人符號（對話語音生成）分段。分段後的文字將以批次處理。因此，模型可用幾乎固定的記憶體用量處理任意長度文字。可透過調整 <code>--max-duration</code> 參數控制記憶體使用量。</p><p>#### 3.4 「原始」評估</p><p>預設會對輸入（提示 wav、提示文字轉錄及文字）進行預處理，以提升推論效率及效能。如欲以完全原始輸入評估模型（例如重現論文結果），可傳入 <code>--raw-evaluation True</code>。</p><p>#### 3.5 短文字</p><p>在生成非常短的語音（例如一兩個字）時，生成語音可能會略掉部分發音。此時可傳入 <code>--speed 0.3</code>（0.3 為可調參數），以延長生成語音時間。</p><p>#### 3.6 修正中文多音字發音錯誤</p><p>
我們使用 <a href="https://github.com/mozillazg/python-pinyin" target="_blank" rel="noopener noreferrer">pypinyin</a> 來將中文字符轉換為拼音。然而，它偶爾會將<strong>多音字</strong>拼錯。</p><p>要手動更正這些錯誤發音，請將<strong>正確的拼音</strong>用尖括號 <code>< ></code> 括起，並包含<strong>聲調標記</strong>。</p><p><strong>範例：</strong></p><ul><li>原文：<code>这把剑长三十公分</code></li>
<li>更正 <code>长</code> 的拼音： <code>这把剑<chang2>三十公分</code></li></p><p></ul>> <strong>注意：</strong>如果需要手動指定多個拼音，每個拼音都用 <code><></code> 括起，例如：<code>这把<jian4><chang2><san1>十公分</code></p><p>#### 3.7 移除生成語音中的長時間靜音</p><p>模型會自動判斷生成語音中的靜音位置和長度。有時在語音中間會有較長的靜音。如果您不希望這樣，可以傳遞 <code>--remove-long-sil</code> 來移除生成語音中間的長時間靜音（邊緣靜音預設會被移除）。</p><p>#### 3.8 模型下載</p><p>如果您在下載預訓練模型時連接 HuggingFace 有困難，請嘗試將端點切換為鏡像站：<code>export HF_ENDPOINT=https://hf-mirror.com</code>。</p><h2>訓練您自己的模型</h2></p><p>請參閱 <a href="egs" target="_blank" rel="noopener noreferrer">egs</a> 目錄以獲取訓練、微調和評估的範例。</p><h2>生產部署</h2></p><h3>NVIDIA Triton GPU 執行環境</h3></p><p>如需具備高效能與可擴展性的生產級部署，請參閱 <a href="runtime/nvidia_triton/" target="_blank" rel="noopener noreferrer">Triton Inference Server 整合</a>，該方案提供最佳化的 TensorRT 引擎、並發請求處理，以及同時支援 gRPC/HTTP API 以供企業使用。</p><h3>CPU 部署</h3></p><p>請參閱 <a href="https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498" target="_blank" rel="noopener noreferrer">sherpa-onnx</a> 以獲得基於 CPU 的 C++ 部署解決方案。</p><h2>討論與交流</h2></p><p>您可以直接在 <a href="https://github.com/k2-fsa/ZipVoice/issues" target="_blank" rel="noopener noreferrer">Github Issues</a> 上討論。</p><p>您也可以掃描二維碼加入我們的微信群或關注我們的微信公眾號。</p><p>| 微信群 | 微信公眾號 |
| ------------ | ----------------------- |
|<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg" alt="wechat"> |<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg" alt="wechat"> |</p><h2>引用</h2></p><pre><code class="language-bibtex">@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}</p><p>@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}</code></pre></p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-12-30

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-12-30 
    </div>
    
</body>
</html>