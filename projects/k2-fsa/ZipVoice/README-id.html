<!DOCTYPE html>
<html lang="id">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ZipVoice - Teks ke Ucapan Zero-Shot yang Cepat dan Berkualitas Tinggi dengan Flow Matching</title>
    <meta name="description" content="Teks ke Ucapan Zero-Shot yang Cepat dan Berkualitas Tinggi dengan Flow Matching">
    <meta name="keywords" content="ZipVoice, Indonesian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ZipVoice",
  "description": "Teks ke Ucapan Zero-Shot yang Cepat dan Berkualitas Tinggi dengan Flow Matching",
  "author": {
    "@type": "Person",
    "name": "k2-fsa"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 748
  },
  "url": "https://OpenAiTx.github.io/projects/k2-fsa/ZipVoice/README-id.html",
  "sameAs": "https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md",
  "datePublished": "2025-12-30",
  "dateModified": "2025-12-30"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/k2-fsa/ZipVoice" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    ZipVoice
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 748 stars</span>
                <span class="language">Indonesian</span>
                <span>by k2-fsa</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Bahasa</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div></p><p><div align="center"></p><h1>ZipVoice⚡</h1></p><h2>Teks-ke-Ucapan Zero-Shot yang Cepat dan Berkualitas Tinggi dengan Flow Matching</h2>
</div></p><h2>Ikhtisar</h2></p><p>ZipVoice adalah serangkaian model TTS zero-shot yang cepat dan berkualitas tinggi berbasis flow matching.</p><h3>1. Fitur utama</h3></p><ul><li>Kecil dan cepat: hanya 123M parameter.</li></p><p><li>Kloning suara berkualitas tinggi: performa terbaik dalam kemiripan pembicara, kejelasan, dan kealamian.</li></p><p><li>Multi-bahasa: mendukung Bahasa Mandarin dan Inggris.</li></p><p><li>Multi-mode: mendukung generasi ucapan pembicara tunggal dan dialog.</li></p><p></ul><h3>2. Varian model</h3></p><p><table>
  <thead>
    <tr>
      <th>Nama Model</th>
      <th>Deskripsi</th>
      <th>Paper</th>
      <th>Demo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>Model dasar yang mendukung TTS zero-shot pembicara tunggal dalam Bahasa Mandarin dan Inggris.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>Versi distilasi dari ZipVoice, dengan kecepatan yang ditingkatkan dan penurunan performa yang minimal.</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>Model generasi dialog yang dibangun di atas ZipVoice, mampu menghasilkan dialog dua pihak dalam satu kanal.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>Varian stereo dari ZipVoice-Dialog, memungkinkan generasi dialog dua saluran dengan masing-masing pembicara ditempatkan pada saluran yang berbeda.</td>
    </tr>
  </tbody>
</table></p><h2>Berita</h2></p><p><strong>2025/07/14</strong>: <strong>ZipVoice-Dialog</strong> dan <strong>ZipVoice-Dialog-Stereo</strong>, dua model generasi dialog lisan, telah dirilis. <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice-dialog.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><p><strong>2025/07/14</strong>: Dataset <strong>OpenDialog</strong>, dataset dialog lisan berdurasi 6.8k-jam, telah dirilis. Unduh di <a href="https://huggingface.co/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow" alt="hf"></a>, <a href="https://www.modelscope.cn/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data" alt="ms"></a>. Lihat detailnya di <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a>.</p><p><strong>2025/06/16</strong>: <strong>ZipVoice</strong> dan <strong>ZipVoice-Distill</strong> telah dirilis. <a href="https://arxiv.org/abs/2506.13053" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><h2>Instalasi</h2></p><h3>1. Clone repositori ZipVoice</h3></p><pre><code class="language-bash">git clone https://github.com/k2-fsa/ZipVoice.git</code></pre>
<h3>2. (Opsional) Buat lingkungan virtual Python</h3></p><pre><code class="language-bash">python3 -m venv zipvoice
source zipvoice/bin/activate</code></pre>
<h3>3. Instal paket yang diperlukan</h3></p><pre><code class="language-bash">pip install -r requirements.txt</code></pre>
<h3>4. Instal k2 untuk pelatihan atau inferensi efisien</h3></p><p><strong>k2 diperlukan untuk pelatihan</strong> dan dapat mempercepat inferensi. Namun demikian, Anda masih dapat menggunakan mode inferensi ZipVoice tanpa menginstal k2.</p><blockquote><strong>Catatan:</strong> Pastikan untuk menginstal versi k2 yang sesuai dengan versi PyTorch dan CUDA Anda. Sebagai contoh, jika Anda menggunakan pytorch 2.5.1 dan CUDA 12.1, Anda dapat menginstal k2 sebagai berikut:</blockquote></p><pre><code class="language-bash">pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html</code></pre>
Silakan merujuk ke https://k2-fsa.org/get-started/k2/ untuk detailnya.
Pengguna di Tiongkok daratan dapat merujuk ke https://k2-fsa.org/zh-CN/get-started/k2/.</p><ul><li>Untuk memeriksa instalasi k2:</li></p><p>
</ul><pre><code class="language-bash">python3 -c "import k2; print(k2.__file__)"</code></pre>
<h2>Penggunaan</h2></p><h3>1. Pembuatan Ucapan Satu Pembicara</h3></p><p>Untuk menghasilkan ucapan satu pembicara dengan model pra-latih ZipVoice atau ZipVoice-Distill kami, gunakan perintah berikut (Model yang diperlukan akan diunduh dari HuggingFace):</p><p>#### 1.1 Inferensi satu kalimat</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav</code></pre>
<ul><li><code>--model-name</code> dapat berupa <code>zipvoice</code> atau <code>zipvoice_distill</code>, yang masing-masing adalah model sebelum dan sesudah distilasi.</li>
<li>Jika <code><></code> atau <code>[]</code> muncul dalam teks, string yang diapit olehnya akan diperlakukan sebagai token khusus. <code><></code> menunjukkan pinyin Tiongkok dan <code>[]</code> menunjukkan tag khusus lainnya.</li></p><p></ul>#### 1.2 Inferensi daftar kalimat</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li>Setiap baris dari <code>test.tsv</code> memiliki format <code>{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code>.</li></p><p></ul><h3>2. Generasi Ucapan Dialog</h3></p><p>#### 2.1 Perintah Inferensi</p><p>Untuk menghasilkan dialog lisan dua pihak dengan model ZipVoice-Dialogue atau ZipVoice-Dialogue-Stereo pra-latih kami, gunakan perintah berikut (Model yang diperlukan akan diunduh dari HuggingFace):</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li><code>--model-name</code> dapat berupa <code>zipvoice_dialog</code> atau <code>zipvoice_dialog_stereo</code>,</li>
    </ul>yang masing-masing menghasilkan dialog mono dan stereo.</p><p>#### 2.2 Format Input</p><p>Setiap baris dari <code>test.tsv</code> menggunakan salah satu format berikut:</p><p>(1) <strong>Format prompt gabungan</strong> di mana audio dan transkripsi dari dua pembicara digabungkan menjadi satu file wav prompt:</p><pre><code class="language-">{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code></pre></p><ul><li><code>wav_name</code> adalah nama file wav output.</li>
<li><code>prompt_transcription</code> adalah transkripsi dari prompt percakapan wav, misalnya, "[S1] Halo. [S2] Apa kabar?"</li>
<li><code>prompt_wav</code> adalah path menuju prompt wav.</li>
<li><code>text</code> adalah teks yang akan disintesis, misalnya "[S1] Saya baik-baik saja. [S2] Siapa nama Anda? [S1] Saya Eric. [S2] Hai Eric."</li></p><p></ul>(2) <strong>Format prompt terpisah</strong> di mana audio dan transkripsi dari dua pembicara ada di file terpisah:</p><pre><code class="language-">{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}</code></pre></p><ul><li><code>wav_name</code> adalah nama file wav keluaran.</li>
<li><code>spk1_prompt_transcription</code> adalah transkripsi dari file wav prompt pembicara pertama, misalnya, "Halo"</li>
<li><code>spk2_prompt_transcription</code> adalah transkripsi dari file wav prompt pembicara kedua, misalnya, "Apa kabar?"</li>
<li><code>spk1_prompt_wav</code> adalah path ke file wav prompt pembicara pertama.</li>
<li><code>spk2_prompt_wav</code> adalah path ke file wav prompt pembicara kedua.</li>
<li><code>text</code> adalah teks yang akan disintesis, misalnya, "[S1] Saya baik-baik saja. [S2] Siapa namamu? [S1] Saya Eric. [S2] Hai Eric."</li></p><p></ul><h3>3 Panduan penggunaan yang lebih baik:</h3></p><p>#### 3.1 Panjang prompt</p><p>Kami merekomendasikan file wav prompt yang pendek (misalnya, kurang dari 3 detik untuk generasi suara satu pembicara, kurang dari 10 detik untuk generasi suara dialog) untuk kecepatan inferensi yang lebih cepat. Prompt yang sangat panjang akan memperlambat inferensi dan menurunkan kualitas suara.</p><p>#### 3.2 Optimasi kecepatan</p><p>Jika kecepatan inferensi tidak memuaskan, Anda dapat mempercepatnya sebagai berikut:</p><ul><li><strong>Model distilasi dan langkah lebih sedikit</strong>: Untuk model generasi suara satu pembicara, kami menggunakan model <code>zipvoice</code> secara default untuk kualitas suara yang lebih baik. Jika kecepatan menjadi prioritas, Anda dapat beralih ke <code>zipvoice_distill</code> dan dapat mengurangi <code>--num-steps</code> serendah <code>4</code> (default 8).</li></p><p><li><strong>CPU lebih cepat dengan multi-threading</strong>: Saat berjalan di CPU, Anda dapat menambahkan parameter <code>--num-thread</code> (misalnya, <code>--num-thread 4</code>) untuk meningkatkan jumlah thread agar lebih cepat. Secara default kami menggunakan 1 thread.</li></p><p><li><strong>CPU lebih cepat dengan ONNX</strong>: Saat berjalan di CPU, Anda dapat menggunakan model ONNX dengan <code>zipvoice.bin.infer_zipvoice_onnx</code> untuk kecepatan yang lebih tinggi (belum mendukung ONNX untuk model generasi dialog). Untuk kecepatan lebih tinggi lagi, Anda dapat mengatur <code>--onnx-int8 True</code> untuk menggunakan model ONNX INT8-kuantisasi. Perlu diperhatikan bahwa model kuantisasi akan menyebabkan penurunan kualitas suara tertentu. <strong>Jangan gunakan ONNX di GPU</strong>, karena lebih lambat daripada PyTorch di GPU.</li></p><p><li><strong>Akselerasi GPU dengan NVIDIA TensorRT</strong>: Untuk peningkatan performa signifikan di GPU NVIDIA, ekspor model ke engine TensorRT menggunakan zipvoice.bin.tensorrt_export terlebih dahulu. Kemudian, lakukan inferensi pada dataset Anda (misal, dataset Hugging Face) dengan zipvoice.bin.infer_zipvoice. Ini dapat mencapai throughput sekitar 2x dibandingkan implementasi PyTorch standar di GPU.</li></p><p></ul>#### 3.3 Kontrol memori</p><p>Teks yang diberikan akan dipotong menjadi beberapa bagian berdasarkan tanda baca (untuk generasi suara satu pembicara) atau simbol pergantian pembicara (untuk generasi suara dialog). Kemudian, teks yang sudah dipotong akan diproses secara batch. Oleh karena itu, model dapat memproses teks sepanjang apapun dengan penggunaan memori yang hampir konstan. Anda dapat mengontrol penggunaan memori dengan mengatur parameter <code>--max-duration</code>.</p><p>#### 3.4 Evaluasi "Raw"</p><p>Secara default, kami memproses input (prompt wav, transkripsi prompt, dan teks) untuk inferensi yang efisien dan kinerja lebih baik. Jika Anda ingin mengevaluasi performa "raw" model menggunakan input persis seperti yang diberikan (misalnya, untuk mereproduksi hasil di makalah kami), Anda dapat menambahkan <code>--raw-evaluation True</code>.</p><p>#### 3.5 Teks pendek</p><p>Saat menghasilkan suara untuk teks yang sangat pendek (misalnya, satu atau dua kata), suara yang dihasilkan kadang-kadang dapat melewatkan beberapa pelafalan. Untuk mengatasi masalah ini, Anda dapat menambahkan <code>--speed 0.3</code> (di mana 0.3 adalah nilai yang dapat diubah) untuk memperpanjang durasi suara yang dihasilkan.</p><p>#### 3.6 Koreksi pelafalan karakter polifon Tiongkok yang salah</p><p>Kami menggunakan <a href="https://github.com/mozillazg/python-pinyin" target="_blank" rel="noopener noreferrer">pypinyin</a> untuk mengonversi karakter Tiongkok ke pinyin. Namun, terkadang dapat salah mengucapkan <strong>karakter polifonik</strong> (多音字).</p><p>Untuk memperbaiki pengucapan yang salah secara manual, lampirkan <strong>pinyin yang dikoreksi</strong> dalam tanda sudut <code>< ></code> dan sertakan <strong>tanda nada</strong>.</p><p><strong>Contoh:</strong></p><ul><li>Teks asli: <code>这把剑长三十公分</code></li>
<li>Koreksi pinyin untuk <code>长</code>:  <code>这把剑<chang2>三十公分</code></li></p><p></ul>> <strong>Catatan:</strong> Jika Anda ingin menetapkan beberapa pinyin secara manual, lampirkan setiap pinyin dengan <code><></code>, misalnya <code>这把<jian4><chang2><san1>十公分</code></p><p>#### 3.7 Hapus keheningan panjang dari suara yang dihasilkan</p><p>Model secara otomatis akan menentukan posisi dan durasi keheningan pada suara yang dihasilkan. Kadang-kadang terdapat keheningan panjang di tengah suara. Jika Anda tidak menginginkan ini, Anda dapat menambahkan <code>--remove-long-sil</code> untuk menghapus keheningan panjang di tengah suara yang dihasilkan (keheningan pada tepi akan dihapus secara default).</p><p>#### 3.8 Pengunduhan model</p><p>Jika Anda mengalami masalah saat menghubungkan ke HuggingFace ketika mengunduh model pra-latih, coba ubah endpoint ke situs mirror: <code>export HF_ENDPOINT=https://hf-mirror.com</code>.</p><h2>Latih Model Anda Sendiri</h2></p><p>Lihat direktori <a href="egs" target="_blank" rel="noopener noreferrer">egs</a> untuk contoh pelatihan, fine-tuning, dan evaluasi.</p><h2>Deployment Produksi</h2></p><h3>NVIDIA Triton GPU Runtime</h3></p><p>Untuk deployment siap produksi dengan performa tinggi dan skalabilitas, lihat <a href="runtime/nvidia_triton/" target="_blank" rel="noopener noreferrer">integrasi Triton Inference Server</a> yang menyediakan engine TensorRT yang telah dioptimalkan, penanganan permintaan secara bersamaan, dan API gRPC/HTTP untuk penggunaan enterprise.</p><h3>Deployment CPU</h3></p><p>Lihat <a href="https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498" target="_blank" rel="noopener noreferrer">sherpa-onnx</a> untuk solusi deployment C++ pada CPU.</p><h2>Diskusi & Komunikasi</h2></p><p>Anda dapat berdiskusi langsung di <a href="https://github.com/k2-fsa/ZipVoice/issues" target="_blank" rel="noopener noreferrer">Github Issues</a>.</p><p>Anda juga dapat memindai kode QR untuk bergabung dengan grup wechat kami atau mengikuti akun resmi wechat kami.</p><p>| Grup Wechat | Akun Resmi Wechat |
| ------------ | ----------------------- |
|<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg" alt="wechat"> |<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg" alt="wechat"> |</p><h2>Sitasi</h2></p><pre><code class="language-bibtex">@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}</p><p>@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}</code></pre></p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-12-30

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-12-30 
    </div>
    
</body>
</html>