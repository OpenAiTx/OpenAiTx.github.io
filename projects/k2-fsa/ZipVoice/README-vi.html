<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ZipVoice - Chuyển văn bản th&#224;nh giọng n&#243;i Zero-Shot nhanh v&#224; chất lượng cao với Flow Matching</title>
    <meta name="description" content="Chuyển văn bản th&#224;nh giọng n&#243;i Zero-Shot nhanh v&#224; chất lượng cao với Flow Matching">
    <meta name="keywords" content="ZipVoice, Vietnamese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ZipVoice",
  "description": "Chuyển văn bản thành giọng nói Zero-Shot nhanh và chất lượng cao với Flow Matching",
  "author": {
    "@type": "Person",
    "name": "k2-fsa"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 748
  },
  "url": "https://OpenAiTx.github.io/projects/k2-fsa/ZipVoice/README-vi.html",
  "sameAs": "https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md",
  "datePublished": "2025-12-30",
  "dateModified": "2025-12-30"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/k2-fsa/ZipVoice" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    ZipVoice
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 748 stars</span>
                <span class="language">Vietnamese</span>
                <span>by k2-fsa</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Ngôn ngữ</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div></p><p><div align="center"></p><h1>ZipVoice⚡</h1></p><h2>Chuyển văn bản thành giọng nói nhanh và chất lượng cao với Flow Matching</h2>
</div></p><h2>Tổng quan</h2></p><p>ZipVoice là một loạt các mô hình TTS zero-shot nhanh và chất lượng cao dựa trên flow matching.</p><h3>1. Đặc điểm chính</h3></p><ul><li>Nhỏ gọn và nhanh: chỉ 123 triệu tham số.</li></p><p><li>Nhân bản giọng nói chất lượng cao: hiệu suất hàng đầu về độ tương đồng, độ rõ ràng và tự nhiên của giọng nói.</li></p><p><li>Đa ngôn ngữ: hỗ trợ tiếng Trung và tiếng Anh.</li></p><p><li>Đa chế độ: hỗ trợ cả tạo giọng nói một người và đối thoại.</li></p><p></ul><h3>2. Các biến thể mô hình</h3></p><p><table>
  <thead>
    <tr>
      <th>Tên mô hình</th>
      <th>Mô tả</th>
      <th>Bài báo</th>
      <th>Demo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>Mô hình cơ bản hỗ trợ TTS zero-shot cho cả tiếng Trung và tiếng Anh với giọng nói một người.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>Phiên bản rút gọn của ZipVoice, tăng tốc độ với suy giảm hiệu năng tối thiểu.</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>Mô hình tạo đối thoại dựa trên ZipVoice, có khả năng tạo hội thoại hai bên trên một kênh âm thanh.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>Biến thể stereo của ZipVoice-Dialog, cho phép tạo cuộc hội thoại hai kênh với mỗi người nói được gán vào một kênh riêng biệt.</td>
    </tr>
  </tbody>
</table></p><h2>Tin tức</h2></p><p><strong>2025/07/14</strong>: <strong>ZipVoice-Dialog</strong> và <strong>ZipVoice-Dialog-Stereo</strong>, hai mô hình tạo hội thoại nói, đã được phát hành. <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice-dialog.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><p><strong>2025/07/14</strong>: Bộ dữ liệu <strong>OpenDialog</strong>, bộ dữ liệu hội thoại nói với thời lượng 6.8k giờ, đã được phát hành. Tải về tại <a href="https://huggingface.co/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow" alt="hf"></a>, <a href="https://www.modelscope.cn/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data" alt="ms"></a>. Xem chi tiết tại <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a>.</p><p><strong>2025/06/16</strong>: <strong>ZipVoice</strong> và <strong>ZipVoice-Distill</strong> đã được phát hành. <a href="https://arxiv.org/abs/2506.13053" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><h2>Cài đặt</h2></p><h3>1. Nhân bản kho lưu trữ ZipVoice</h3></p><pre><code class="language-bash">git clone https://github.com/k2-fsa/ZipVoice.git</code></pre>
<h3>2. (Tùy chọn) Tạo một môi trường ảo Python</h3></p><pre><code class="language-bash">python3 -m venv zipvoice
source zipvoice/bin/activate</code></pre>
<h3>3. Cài đặt các gói cần thiết</h3></p><pre><code class="language-bash">pip install -r requirements.txt</code></pre>
<h3>4. Cài đặt k2 để huấn luyện hoặc suy luận hiệu quả</h3></p><p><strong>k2 là cần thiết cho việc huấn luyện</strong> và có thể tăng tốc quá trình suy luận. Tuy nhiên, bạn vẫn có thể sử dụng chế độ suy luận của ZipVoice mà không cần cài đặt k2.</p><blockquote><strong>Lưu ý:</strong> Đảm bảo cài đặt phiên bản k2 phù hợp với phiên bản PyTorch và CUDA của bạn. Ví dụ, nếu bạn đang sử dụng pytorch 2.5.1 và CUDA 12.1, bạn có thể cài đặt k2 như sau:</blockquote></p><pre><code class="language-bash">pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html</code></pre>
Vui lòng tham khảo https://k2-fsa.org/get-started/k2/ để biết chi tiết.
Người dùng tại Trung Quốc đại lục có thể tham khảo https://k2-fsa.org/zh-CN/get-started/k2/.</p><ul><li>Để kiểm tra cài đặt k2:</li></p><p>
</ul><pre><code class="language-bash">python3 -c "import k2; print(k2.__file__)"</code></pre>
<h2>Sử dụng</h2></p><h3>1. Tạo giọng nói một người nói</h3></p><p>Để tạo giọng nói một người nói với các mô hình ZipVoice hoặc ZipVoice-Distill đã được huấn luyện trước của chúng tôi, hãy sử dụng các lệnh sau (Các mô hình cần thiết sẽ được tải xuống từ HuggingFace):</p><p>#### 1.1 Suy luận một câu đơn lẻ</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav</code></pre>
<ul><li><code>--model-name</code> có thể là <code>zipvoice</code> hoặc <code>zipvoice_distill</code>, lần lượt là các mô hình trước và sau khi chưng cất.</li>
<li>Nếu <code><></code> hoặc <code>[]</code> xuất hiện trong văn bản, các chuỗi được bao quanh bởi chúng sẽ được xử lý như các token đặc biệt. <code><></code> biểu thị cho pinyin tiếng Trung và <code>[]</code> biểu thị cho các thẻ đặc biệt khác.</li></p><p></ul>#### 1.2 Suy luận một danh sách các câu</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li>Mỗi dòng của <code>test.tsv</code> có định dạng <code>{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code>.</li></p><p></ul><h3>2. Tạo sinh lời thoại</h3></p><p>#### 2.1 Lệnh suy luận</p><p>Để tạo sinh các cuộc hội thoại hai người nói với các mô hình ZipVoice-Dialogue hoặc ZipVoice-Dialogue-Stereo đã được huấn luyện trước của chúng tôi, hãy sử dụng các lệnh sau (Các mô hình cần thiết sẽ được tải xuống từ HuggingFace):</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li><code>--model-name</code> có thể là <code>zipvoice_dialog</code> hoặc <code>zipvoice_dialog_stereo</code>,</li>
    </ul>lần lượt tạo ra các đoạn hội thoại mono và stereo.</p><p>#### 2.2 Định dạng đầu vào</p><p>Mỗi dòng của <code>test.tsv</code> sẽ thuộc một trong các định dạng sau:</p><p>(1) <strong>Định dạng prompt gộp</strong> trong đó âm thanh và bản ghi lời thoại của hai người nói được gộp vào một tệp wav prompt:</p><pre><code class="language-">{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code></pre></p><ul><li><code>wav_name</code> là tên của file wav đầu ra.</li>
<li><code>prompt_transcription</code> là bản phiên âm của file wav hội thoại gợi ý, ví dụ, "[S1] Xin chào. [S2] Bạn khỏe không?"</li>
<li><code>prompt_wav</code> là đường dẫn đến file wav gợi ý.</li>
<li><code>text</code> là văn bản cần tổng hợp, ví dụ: "[S1] Tôi khỏe. [S2] Bạn tên gì? [S1] Tôi là Eric. [S2] Chào Eric."</li></p><p></ul>(2) <strong>Định dạng gợi ý tách riêng</strong> nơi các tệp âm thanh và phiên âm của hai người nói tồn tại ở các tệp riêng biệt:</p><pre><code class="language-">{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}</code></pre>
<ul><li><code>wav_name</code> là tên của tệp wav đầu ra.</li>
<li><code>spk1_prompt_transcription</code> là bản ghi lời nói của tệp wav nhắc nhở của người nói thứ nhất, ví dụ: "Hello"</li>
<li><code>spk2_prompt_transcription</code> là bản ghi lời nói của tệp wav nhắc nhở của người nói thứ hai, ví dụ: "How are you?"</li>
<li><code>spk1_prompt_wav</code> là đường dẫn đến tệp wav nhắc nhở của người nói thứ nhất.</li>
<li><code>spk2_prompt_wav</code> là đường dẫn đến tệp wav nhắc nhở của người nói thứ hai.</li>
<li><code>text</code> là đoạn văn bản cần tổng hợp, ví dụ: "[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric."</li></p><p></ul><h3>3 Hướng dẫn sử dụng tốt hơn:</h3></p><p>#### 3.1 Độ dài prompt</p><p>Chúng tôi khuyến nghị sử dụng tệp wav nhắc nhở ngắn (ví dụ, dưới 3 giây cho tạo giọng nói một người, dưới 10 giây cho tạo hội thoại) để tăng tốc độ suy luận. Tệp nhắc nhở quá dài sẽ làm chậm quá trình suy luận và giảm chất lượng giọng nói.</p><p>#### 3.2 Tối ưu hóa tốc độ</p><p>Nếu tốc độ suy luận chưa đạt yêu cầu, bạn có thể tăng tốc như sau:</p><ul><li><strong>Rút gọn mô hình và giảm số bước</strong>: Với mô hình tạo giọng nói một người, chúng tôi sử dụng mô hình <code>zipvoice</code> mặc định để có chất lượng giọng nói tốt hơn. Nếu ưu tiên tốc độ, bạn có thể chuyển sang <code>zipvoice_distill</code> và giảm <code>--num-steps</code> xuống tối thiểu là <code>4</code> (mặc định là 8).</li></p><p><li><strong>Tăng tốc CPU với đa luồng</strong>: Khi chạy trên CPU, bạn có thể truyền tham số <code>--num-thread</code> (ví dụ, <code>--num-thread 4</code>) để tăng số luồng, giúp tăng tốc độ. Mặc định chúng tôi sử dụng 1 luồng.</li></p><p><li><strong>Tăng tốc CPU với ONNX</strong>: Khi chạy trên CPU, bạn có thể sử dụng các mô hình ONNX với <code>zipvoice.bin.infer_zipvoice_onnx</code> để tăng tốc (chưa hỗ trợ ONNX cho mô hình tạo hội thoại). Để tăng tốc hơn nữa, bạn có thể đặt <code>--onnx-int8 True</code> để dùng mô hình ONNX đã lượng tử hóa INT8. Lưu ý mô hình lượng tử hóa sẽ làm giảm chất lượng giọng nói nhất định. <strong>Không sử dụng ONNX trên GPU</strong>, vì nó chậm hơn PyTorch trên GPU.</li></p><p><li><strong>Tăng tốc GPU với NVIDIA TensorRT</strong>: Để tăng hiệu suất đáng kể trên GPU NVIDIA, đầu tiên hãy xuất mô hình sang định dạng TensorRT bằng zipvoice.bin.tensorrt_export. Sau đó, chạy suy luận trên bộ dữ liệu của bạn (ví dụ, bộ dữ liệu Hugging Face) với zipvoice.bin.infer_zipvoice. Cách này có thể đạt tốc độ xử lý gấp đôi so với PyTorch tiêu chuẩn trên GPU.</li></p><p></ul>#### 3.3 Kiểm soát bộ nhớ</p><p>Văn bản đầu vào sẽ được chia thành các đoạn nhỏ dựa trên dấu câu (cho tạo giọng nói một người) hoặc ký hiệu đổi người nói (cho tạo hội thoại). Sau đó, các đoạn văn bản sẽ được xử lý theo lô. Do đó, mô hình có thể xử lý văn bản dài bất kỳ với mức sử dụng bộ nhớ gần như không đổi. Bạn có thể kiểm soát bộ nhớ bằng cách điều chỉnh tham số <code>--max-duration</code>.</p><p>#### 3.4 Đánh giá "Raw"</p><p>Mặc định, chúng tôi sẽ tiền xử lý các đầu vào (wav nhắc nhở, bản ghi nhắc nhở và văn bản) để tối ưu hóa suy luận và hiệu suất. Nếu bạn muốn đánh giá hiệu suất "gốc" của mô hình bằng đúng đầu vào cung cấp (ví dụ, để tái tạo kết quả trong bài báo của chúng tôi), bạn có thể truyền <code>--raw-evaluation True</code>.</p><p>#### 3.5 Văn bản ngắn</p><p>Khi tạo giọng nói cho các văn bản rất ngắn (ví dụ, một hoặc hai từ), giọng nói tạo ra đôi khi có thể bị thiếu một số âm tiết. Để khắc phục vấn đề này, bạn có thể truyền <code>--speed 0.3</code> (trong đó 0.3 là giá trị có thể điều chỉnh) để kéo dài thời lượng của giọng nói tạo ra.</p><p>#### 3.6 Sửa lỗi phát âm sai các ký tự đa âm tiếng Trung</p><p>
Chúng tôi sử dụng <a href="https://github.com/mozillazg/python-pinyin" target="_blank" rel="noopener noreferrer">pypinyin</a> để chuyển đổi ký tự tiếng Trung sang pinyin. Tuy nhiên, đôi khi nó có thể phát âm sai <strong>chữ đa âm</strong> (多音字).</p><p>Để sửa các phát âm sai này một cách thủ công, hãy đặt <strong>pinyin đã chỉnh sửa</strong> trong dấu ngoặc nhọn <code>< ></code> và thêm <strong>dấu thanh</strong>.</p><p><strong>Ví dụ:</strong></p><ul><li>Văn bản gốc: <code>这把剑长三十公分</code></li>
<li>Sửa pinyin cho <code>长</code>:  <code>这把剑<chang2>三十公分</code></li></p><p></ul>> <strong>Lưu ý:</strong> Nếu bạn muốn gán thủ công nhiều pinyin, hãy đặt mỗi pinyin trong <code><></code>, ví dụ: <code>这把<jian4><chang2><san1>十公分</code></p><p>#### 3.7 Loại bỏ khoảng lặng dài khỏi giọng nói đã tạo</p><p>Mô hình sẽ tự động xác định vị trí và độ dài của các khoảng lặng trong giọng nói đã tạo. Đôi khi có khoảng lặng dài ở giữa bài nói. Nếu bạn không muốn điều này, bạn có thể truyền <code>--remove-long-sil</code> để loại bỏ các khoảng lặng dài ở giữa giọng nói đã tạo (các khoảng lặng ở đầu/cuối sẽ được loại bỏ mặc định).</p><p>#### 3.8 Tải mô hình</p><p>Nếu bạn gặp sự cố khi kết nối với HuggingFace để tải các mô hình đã huấn luyện trước, hãy thử chuyển endpoint sang trang mirror: <code>export HF_ENDPOINT=https://hf-mirror.com</code>.</p><h2>Huấn luyện mô hình của bạn</h2></p><p>Xem thư mục <a href="egs" target="_blank" rel="noopener noreferrer">egs</a> để biết ví dụ về huấn luyện, fine-tuning và đánh giá.</p><h2>Triển khai sản xuất</h2></p><h3>NVIDIA Triton GPU Runtime</h3></p><p>Để triển khai sản xuất sẵn sàng với hiệu năng và khả năng mở rộng cao, hãy tham khảo <a href="runtime/nvidia_triton/" target="_blank" rel="noopener noreferrer">Triton Inference Server integration</a> cung cấp các engine TensorRT tối ưu, xử lý yêu cầu đồng thời và các API gRPC/HTTP cho doanh nghiệp.</p><h3>Triển khai CPU</h3></p><p>Xem <a href="https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498" target="_blank" rel="noopener noreferrer">sherpa-onnx</a> để biết giải pháp triển khai C++ trên CPU.</p><h2>Thảo luận & Trao đổi</h2></p><p>Bạn có thể thảo luận trực tiếp trên <a href="https://github.com/k2-fsa/ZipVoice/issues" target="_blank" rel="noopener noreferrer">Github Issues</a>.</p><p>Bạn cũng có thể quét mã QR để tham gia nhóm wechat của chúng tôi hoặc theo dõi tài khoản wechat chính thức.</p><p>| Nhóm Wechat | Tài khoản Wechat chính thức |
| ------------ | ----------------------- |
|<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg" alt="wechat"> |<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg" alt="wechat"> |</p><h2>Trích dẫn</h2></p><pre><code class="language-bibtex">@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}</p><p>@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}</code></pre></p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-12-30

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-12-30 
    </div>
    
</body>
</html>