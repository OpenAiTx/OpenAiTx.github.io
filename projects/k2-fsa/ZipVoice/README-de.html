<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ZipVoice - Read ZipVoice documentation in German. This project has 308 stars on GitHub.</title>
    <meta name="description" content="Read ZipVoice documentation in German. This project has 308 stars on GitHub.">
    <meta name="keywords" content="ZipVoice, German, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ZipVoice",
  "description": "Read ZipVoice documentation in German. This project has 308 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "k2-fsa"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 308
  },
  "url": "https://OpenAiTx.github.io/projects/k2-fsa/ZipVoice/README-de.html",
  "sameAs": "https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/k2-fsa/ZipVoice" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    ZipVoice
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 308 stars</span>
                <span class="language">German</span>
                <span>by k2-fsa</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align="right">
  <details>
    <summary >🌐 Sprache</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div></p><p><div align="center"></p><h1>ZipVoice⚡</h1></p><h2>Schnelle und hochwertige Zero-Shot-Text-zu-Sprache mit Flow Matching</h2>
</div></p><h2>Übersicht</h2></p><p>ZipVoice ist eine Serie schneller und hochwertiger Zero-Shot-TTS-Modelle, die auf Flow Matching basieren.</p><h3>1. Hauptmerkmale</h3></p><ul><li>Klein und schnell: nur 123M Parameter.</li></p><p><li>Hochwertiges Voice Cloning: State-of-the-Art-Leistung bei Sprecherähnlichkeit, Verständlichkeit und Natürlichkeit.</li></p><p><li>Mehrsprachig: unterstützt Chinesisch und Englisch.</li></p><p><li>Multi-Mode: unterstützt sowohl Einzelsprecher- als auch Dialog-Sprachgenerierung.</li></p><p></ul><h3>2. Modellvarianten</h3></p><p><table>
  <thead>
    <tr>
      <th>Modellname</th>
      <th>Beschreibung</th>
      <th>Paper</th>
      <th>Demo</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>Das Basismodell, das Zero-Shot-Einzelsprecher-TTS in Chinesisch und Englisch unterstützt.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>Die destillierte Version von ZipVoice, mit verbesserter Geschwindigkeit und minimalem Leistungsverlust.</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>Ein Dialoggenerierungsmodell auf Basis von ZipVoice, das in der Lage ist, einspurige Zwei-Parteien-Gespräche zu erzeugen.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>Die Stereo-Variante von ZipVoice-Dialog, die Zwei-Kanal-Dialoggenerierung ermöglicht, wobei jeder Sprecher einem eigenen Kanal zugewiesen wird.</td>
    </tr>
  </tbody>
</table></p><h2>Neuigkeiten</h2></p><p><strong>2025/07/14</strong>: <strong>ZipVoice-Dialog</strong> und <strong>ZipVoice-Dialog-Stereo</strong>, zwei gesprochene Dialoggenerierungsmodelle, sind veröffentlicht. <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice-dialog.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><p><strong>2025/07/14</strong>: <strong>OpenDialog</strong>-Datensatz, ein 6.8k-Stunden-Sprachdialogdatensatz, ist veröffentlicht. Download unter <a href="https://huggingface.co/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow" alt="hf"></a>, <a href="https://www.modelscope.cn/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data" alt="ms"></a>. Details unter <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a>.</p><p><strong>2025/06/16</strong>: <strong>ZipVoice</strong> und <strong>ZipVoice-Distill</strong> sind veröffentlicht. <a href="https://arxiv.org/abs/2506.13053" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><h2>Installation</h2></p><h3>1. Klonen Sie das ZipVoice-Repository</h3></p><pre><code class="language-bash">git clone https://github.com/k2-fsa/ZipVoice.git</code></pre>
<h3>2. (Optional) Erstellen Sie eine Python-virtuelle Umgebung</h3></p><pre><code class="language-bash">python3 -m venv zipvoice
source zipvoice/bin/activate</code></pre>
<h3>3. Installieren Sie die erforderlichen Pakete</h3></p><pre><code class="language-bash">pip install -r requirements.txt</code></pre>
<h3>4. Installieren Sie k2 für das Training oder effizientes Inferenzieren</h3></p><p><strong>k2 ist für das Training notwendig</strong> und kann die Inferenz beschleunigen. Dennoch können Sie den Inferenzmodus von ZipVoice auch ohne die Installation von k2 verwenden.</p><blockquote><strong>Hinweis:</strong> Stellen Sie sicher, dass Sie die k2-Version installieren, die zu Ihrer PyTorch- und CUDA-Version passt. Wenn Sie beispielsweise pytorch 2.5.1 und CUDA 12.1 verwenden, können Sie k2 wie folgt installieren:</blockquote></p><pre><code class="language-bash">pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html</code></pre>
Bitte beachten Sie https://k2-fsa.org/get-started/k2/ für weitere Details.
Nutzer in Festlandchina können https://k2-fsa.org/zh-CN/get-started/k2/ nutzen.</p><ul><li>Um die k2-Installation zu überprüfen:</li></p><p>
</ul><pre><code class="language-">python3 -c "import k2; print(k2.__file__)"</code></pre>
<h2>Verwendung</h2></p><h3>1. Sprachgenerierung mit einem Sprecher</h3></p><p>Um Sprachaufnahmen mit nur einem Sprecher mithilfe unserer vortrainierten ZipVoice- oder ZipVoice-Distill-Modelle zu erzeugen, verwenden Sie die folgenden Befehle (Erforderliche Modelle werden von HuggingFace heruntergeladen):</p><p>#### 1.1 Inferenz eines einzelnen Satzes</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav</code></pre>
<ul><li><code>--model-name</code> kann <code>zipvoice</code> oder <code>zipvoice_distill</code> sein, was jeweils die Modelle vor und nach der Destillation bezeichnet.</li>
<li>Wenn <code><></code> oder <code>[]</code> im Text erscheinen, werden die darin eingeschlossenen Zeichenfolgen als spezielle Tokens behandelt. <code><></code> steht für chinesische Pinyin und <code>[]</code> für andere spezielle Tags.</li>
<li>Mit <code>zipvoice.bin.infer_zipvoice_onnx</code> können ONNX-Modelle auf der CPU schneller ausgeführt werden.</li></p><p></ul>> <strong>Hinweis:</strong> Wenn Sie Probleme beim Verbinden mit HuggingFace haben, versuchen Sie Folgendes:
<blockquote><pre><code class="language-bash">> export HF_ENDPOINT=https://hf-mirror.com</blockquote>
<blockquote>``<code></blockquote></p><p>#### 1.2 Inferenz einer Liste von Sätzen</p><p></code></pre>bash
python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results
<pre><code class="language-">- Jede Zeile von </code>test.tsv<code> hat das Format </code>{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}<code>.</p><h3>2. Dialog-Sprachgenerierung</h3></p><p>#### 2.1 Inferenzbefehl</p><p>Um Zwei-Parteien-Dialoge mit unseren vortrainierten ZipVoice-Dialogue oder ZipVoice-Dialogue-Stereo Modellen zu generieren, verwenden Sie die folgenden Befehle (Die benötigten Modelle werden von HuggingFace heruntergeladen):</p><p></code></pre>bash
python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results
<pre><code class="language-">- </code>--model-name<code> kann entweder </code>zipvoice_dialog<code> oder </code>zipvoice_dialog_stereo<code> sein,
    wobei jeweils Mono- bzw. Stereo-Dialoge erzeugt werden.</p><p>#### 2.2 Eingabeformate</p><p>Jede Zeile in </code>test.tsv<code> hat eines der folgenden Formate:</p><p>(1) <strong>Zusammengeführtes Prompt-Format</strong>, bei dem die Audiodateien und Transkriptionen der Prompts beider Sprecher in einer Prompt-WAV-Datei zusammengeführt werden:
</code></pre>
{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}
<pre><code class="language-">- </code>wav_name<code> ist der Name der Ausgabedatei im wav-Format.
<ul><li></code>prompt_transcription<code> ist die Transkription der Gesprächsvorgabe-wav, z. B. "[S1] Hallo. [S2] Wie geht es dir?"</li>
<li></code>prompt_wav<code> ist der Pfad zur Vorgabe-wav.</li>
<li></code>text<code> ist der zu synthetisierende Text, z. B. "[S1] Mir geht es gut. [S2] Wie heißt du?"</li></p><p></ul>(2) <strong>Geteiltes Prompt-Format</strong>, bei dem die Audiodateien und Transkriptionen der beiden Sprecher in separaten Dateien vorliegen:</p><p></code></pre>
{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}'
<pre><code class="language-">- </code>wav_name<code> ist der Name der Ausgabedatei im wav-Format.
<ul><li></code>spk1_prompt_transcription<code> ist die Transkription der Prompt-wav des ersten Sprechers, z. B. "Hallo"</li>
<li></code>spk2_prompt_transcription<code> ist die Transkription der Prompt-wav des zweiten Sprechers, z. B. "Wie geht's?"</li>
<li></code>spk1_prompt_wav<code> ist der Pfad zur Prompt-wav-Datei des ersten Sprechers.</li>
<li></code>spk2_prompt_wav<code> ist der Pfad zur Prompt-wav-Datei des zweiten Sprechers.</li>
<li></code>text<code> ist der zu synthetisierende Text, z. B. "[S1] Mir geht's gut. [S2] Wie heißt du?"</li></p><p></ul><h3>3. Weitere Funktionen</h3></p><p>#### 3.1 Korrektur falsch ausgesprochener chinesischer Polyphon-Zeichen</p><p>Wir verwenden <a href="https://github.com/mozillazg/python-pinyin" target="_blank" rel="noopener noreferrer">pypinyin</a>, um chinesische Zeichen in Pinyin umzuwandeln. Allerdings kann es gelegentlich <strong>Polyphon-Zeichen</strong> (多音字) falsch aussprechen.</p><p>Um diese Fehlinterpretationen manuell zu korrigieren, setzen Sie das <strong>korrigierte Pinyin</strong> in spitze Klammern </code>< ><code> und fügen Sie die <strong>Tonmarkierung</strong> hinzu.</p><p><strong>Beispiel:</strong></p><ul><li>Originaltext: </code>这把剑长三十公分<code></li>
<li>Korrigiere das Pinyin von </code>长<code>:  </code>这把剑<chang2>三十公分<code></li></p><p></ul>> <strong>Hinweis:</strong> Wenn Sie mehreren Zeichen manuell Pinyin zuweisen möchten, setzen Sie jedes Pinyin in </code><><code>, z. B. </code>这把<jian4><chang2><san1>十公分<code></p><h2>Eigenes Modell trainieren</h2></p><p>Siehe das Verzeichnis <a href="egs" target="_blank" rel="noopener noreferrer">egs</a> für Trainings-, Feinabstimmungs- und Bewertungsbeispiele.</p><h2>Diskussion & Kommunikation</h2></p><p>Sie können direkt auf <a href="https://github.com/k2-fsa/ZipVoice/issues" target="_blank" rel="noopener noreferrer">Github Issues</a> diskutieren.</p><p>Sie können auch den QR-Code scannen, um unserer WeChat-Gruppe beizutreten oder unserem offiziellen WeChat-Account zu folgen.</p><p>| WeChat-Gruppe | Offizieller WeChat-Account |
| ------------- | -------------------------- |
|<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg" alt="wechat"> |<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg" alt="wechat"> |</p><h2>Zitation</h2></p><p></code></pre>bibtex
@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}</p><p>@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}
</code>``</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-22

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>