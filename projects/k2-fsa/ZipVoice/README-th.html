<!DOCTYPE html>
<html lang="th">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ZipVoice - การแปลงข้อความเป็นเสียงแบบ Zero-Shot ที่รวดเร็วและคุณภาพสูงด้วย Flow Matching</title>
    <meta name="description" content="การแปลงข้อความเป็นเสียงแบบ Zero-Shot ที่รวดเร็วและคุณภาพสูงด้วย Flow Matching">
    <meta name="keywords" content="ZipVoice, Thai, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ZipVoice",
  "description": "การแปลงข้อความเป็นเสียงแบบ Zero-Shot ที่รวดเร็วและคุณภาพสูงด้วย Flow Matching",
  "author": {
    "@type": "Person",
    "name": "k2-fsa"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 661
  },
  "url": "https://OpenAiTx.github.io/projects/k2-fsa/ZipVoice/README-th.html",
  "sameAs": "https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md",
  "datePublished": "2025-10-06",
  "dateModified": "2025-10-06"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/k2-fsa/ZipVoice" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    ZipVoice
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 661 stars</span>
                <span class="language">Thai</span>
                <span>by k2-fsa</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 ภาษา</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div></p><p><div align="center"></p><h1>ZipVoice⚡</h1></p><h2>ระบบแปลงข้อความเป็นเสียงคุณภาพสูงและรวดเร็วแบบ Zero-Shot ด้วย Flow Matching</h2>
</div></p><h2>ภาพรวม</h2></p><p>ZipVoice เป็นชุดโมเดล TTS แบบ zero-shot ที่รวดเร็วและคุณภาพสูงโดยใช้ flow matching</p><h3>1. คุณสมบัติเด่น</h3></p><ul><li>ขนาดเล็กและรวดเร็ว: มีเพียง 123M พารามิเตอร์</li></p><p><li>โคลนนิ่งเสียงคุณภาพสูง: ประสิทธิภาพล้ำสมัยในด้านความคล้ายคลึงของผู้พูด ความชัดเจน และความเป็นธรรมชาติ</li></p><p><li>รองรับหลายภาษา: รองรับภาษาจีนและภาษาอังกฤษ</li></p><p><li>รองรับหลายโหมด: รองรับการสร้างเสียงพูดแบบผู้พูดเดี่ยวและบทสนทนา</li></p><p></ul><h3>2. รุ่นของโมเดล</h3></p><p><table>
  <thead>
    <tr>
      <th>ชื่อโมเดล</th>
      <th>คำอธิบาย</th>
      <th>เอกสารวิจัย</th>
      <th>เดโม</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>โมเดลพื้นฐานที่รองรับ TTS zero-shot สำหรับผู้พูดเดี่ยวในภาษาจีนและอังกฤษ</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>เวอร์ชันกลั่นของ ZipVoice ที่เพิ่มความเร็วโดยลดความเสื่อมของประสิทธิภาพให้น้อยที่สุด</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>โมเดลสร้างบทสนทนาที่พัฒนาบน ZipVoice สามารถสร้างบทสนทนาแบบสองฝ่ายในช่องเสียงเดียว</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>รูปแบบสเตอริโอของ ZipVoice-Dialog ที่รองรับการสร้างบทสนทนาแบบสองช่อง โดยแต่ละผู้พูดจะอยู่ในช่องเสียงที่แตกต่างกัน</td>
    </tr>
  </tbody>
</table></p><h2>ข่าวสาร</h2></p><p><strong>2025/07/14</strong>: <strong>ZipVoice-Dialog</strong> และ <strong>ZipVoice-Dialog-Stereo</strong> สองโมเดลสร้างบทสนทนาแบบเสียง ได้เปิดตัวแล้ว <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice-dialog.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><p><strong>2025/07/14</strong>: ชุดข้อมูล <strong>OpenDialog</strong> ชุดข้อมูลบทสนทนาเสียงขนาด 6.8k ชั่วโมง ได้เปิดให้ดาวน์โหลดแล้วที่ <a href="https://huggingface.co/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow" alt="hf"></a>, <a href="https://www.modelscope.cn/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data" alt="ms"></a> ดูรายละเอียดได้ที่ <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a></p><p><strong>2025/06/16</strong>: <strong>ZipVoice</strong> และ <strong>ZipVoice-Distill</strong> เปิดตัวแล้ว <a href="https://arxiv.org/abs/2506.13053" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><h2>การติดตั้ง</h2></p><h3>1. โคลนคลังข้อมูล ZipVoice</h3></p><pre><code class="language-bash">git clone https://github.com/k2-fsa/ZipVoice.git</code></pre>
<h3>2. (ไม่บังคับ) สร้างสภาพแวดล้อมเสมือนของ Python</h3></p><pre><code class="language-bash">python3 -m venv zipvoice
source zipvoice/bin/activate</code></pre>
<h3>3. ติดตั้งแพ็กเกจที่จำเป็น</h3></p><pre><code class="language-bash">pip install -r requirements.txt</code></pre>
<h3>4. ติดตั้ง k2 สำหรับการฝึกหรือการอนุมานที่มีประสิทธิภาพ</h3></p><p><strong>k2 จำเป็นสำหรับการฝึก</strong> และสามารถเพิ่มความเร็วในการอนุมานได้ อย่างไรก็ตาม คุณยังสามารถใช้โหมดอนุมานของ ZipVoice ได้โดยไม่ต้องติดตั้ง k2</p><blockquote><strong>หมายเหตุ:</strong> โปรดตรวจสอบให้แน่ใจว่าคุณติดตั้ง k2 เวอร์ชันที่ตรงกับเวอร์ชันของ PyTorch และ CUDA ของคุณ ตัวอย่างเช่น หากคุณใช้ pytorch 2.5.1 และ CUDA 12.1 คุณสามารถติดตั้ง k2 ได้ดังนี้:</blockquote></p><pre><code class="language-bash">pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html</code></pre>
โปรดดูรายละเอียดได้ที่ https://k2-fsa.org/get-started/k2/
ผู้ใช้ในจีนแผ่นดินใหญ่สามารถดูได้ที่ https://k2-fsa.org/zh-CN/get-started/k2/</p><ul><li>เพื่อตรวจสอบการติดตั้ง k2:</li></p><p>
</ul><pre><code class="language-bash">python3 -c "import k2; print(k2.__file__)"</code></pre>
<h2>วิธีการใช้งาน</h2></p><h3>1. การสร้างเสียงพูดจากผู้พูดเดียว</h3></p><p>เพื่อสร้างเสียงพูดจากผู้พูดเดียวด้วยโมเดล ZipVoice หรือ ZipVoice-Distill ที่ผ่านการฝึกมาแล้ว กรุณาใช้คำสั่งต่อไปนี้ (โมเดลที่จำเป็นจะถูกดาวน์โหลดจาก HuggingFace):</p><p>#### 1.1 การทำนายผลของประโยคเดียว</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav</code></pre>
<ul><li><code>--model-name</code> สามารถเป็น <code>zipvoice</code> หรือ <code>zipvoice_distill</code> ซึ่งเป็นโมเดลก่อนและหลังการกลั่นกรองตามลำดับ</li>
<li>หากมี <code><></code> หรือ <code>[]</code> ปรากฏในข้อความ สตริงที่อยู่ภายในจะถูกจัดการเป็นโทเคนพิเศษ โดย <code><></code> หมายถึงพินอินภาษาจีน และ <code>[]</code> หมายถึงแท็กพิเศษอื่น ๆ</li></p><p></ul>#### 1.2 การอนุมานรายการประโยค</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li>แต่ละบรรทัดของ <code>test.tsv</code> อยู่ในรูปแบบ <code>{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code></li></p><p></ul><h3>2. การสร้างเสียงสนทนา</h3></p><p>#### 2.1 คำสั่งสำหรับการอนุมาน</p><p>เพื่อสร้างเสียงสนทนาแบบสองฝ่ายด้วยโมเดล ZipVoice-Dialogue หรือ ZipVoice-Dialogue-Stereo ที่ฝึกมาแล้วของเรา ให้ใช้คำสั่งดังต่อไปนี้ (โมเดลที่จำเป็นจะถูกดาวน์โหลดจาก HuggingFace):</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li><code>--model-name</code> สามารถเป็น <code>zipvoice_dialog</code> หรือ <code>zipvoice_dialog_stereo</code> ซึ่งจะสร้างบทสนทนาแบบโมโนและสเตอริโอตามลำดับ</li></p><p></ul>#### 2.2 รูปแบบอินพุต</p><p>แต่ละบรรทัดของ <code>test.tsv</code> จะอยู่ในหนึ่งในรูปแบบต่อไปนี้:</p><p>(1) <strong>รูปแบบพรอมต์รวม</strong> ซึ่งไฟล์เสียงและข้อความถอดเสียงของผู้พูดสองคนจะถูกรวมเป็นไฟล์พรอมต์ wav เดียว:</p><pre><code class="language-">{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code></pre></p><ul><li><code>wav_name</code> คือชื่อของไฟล์ wav ผลลัพธ์</li>
<li><code>prompt_transcription</code> คือข้อความถอดเสียงของไฟล์ wav บทสนทนา เช่น "[S1] สวัสดี [S2] สบายดีไหม?"</li>
<li><code>prompt_wav</code> คือเส้นทางไปยังไฟล์ wav ของบทสนทนา</li>
<li><code>text</code> คือข้อความที่ต้องการสังเคราะห์ เช่น "[S1] ฉันสบายดี [S2] คุณชื่ออะไร? [S1] ฉันชื่อเอริค [S2] สวัสดีเอริค"</li></p><p></ul>(2) <strong>รูปแบบแยกไฟล์บทสนทนา</strong> ที่ไฟล์เสียงและข้อความถอดเสียงของผู้พูดสองคนอยู่ในไฟล์แยกกัน:</p><pre><code class="language-">{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}</code></pre>
<ul><li><code>wav_name</code> คือชื่อของไฟล์ wav ที่จะถูกสร้างขึ้น</li>
<li><code>spk1_prompt_transcription</code> คือการถอดเสียงของไฟล์ wav ตัวอย่างของผู้พูดคนแรก เช่น "Hello"</li>
<li><code>spk2_prompt_transcription</code> คือการถอดเสียงของไฟล์ wav ตัวอย่างของผู้พูดคนที่สอง เช่น "How are you?"</li>
<li><code>spk1_prompt_wav</code> คือเส้นทางไปยังไฟล์ wav ตัวอย่างของผู้พูดคนแรก</li>
<li><code>spk2_prompt_wav</code> คือเส้นทางไปยังไฟล์ wav ตัวอย่างของผู้พูดคนที่สอง</li>
<li><code>text</code> คือข้อความที่จะใช้สังเคราะห์เสียง เช่น "[S1] I'm fine. [S2] What's your name? [S1] I'm Eric. [S2] Hi Eric."</li></p><p></ul><h3>3 แนวทางการใช้งานที่ดียิ่งขึ้น:</h3></p><p>#### 3.1 ความยาวของตัวอย่างเสียง</p><p>เราแนะนำให้ใช้ไฟล์ wav ตัวอย่างที่สั้น (เช่น น้อยกว่า 3 วินาทีสำหรับการสร้างเสียงผู้พูดเดียว น้อยกว่า 10 วินาทีสำหรับการสร้างเสียงสนทนา) เพื่อความเร็วในการประมวลผลที่ดีกว่า ไฟล์ตัวอย่างที่ยาวมากจะทำให้การประมวลผลช้าลงและคุณภาพเสียงลดลง</p><p>#### 3.2 การปรับแต่งความเร็ว</p><p>หากความเร็วในการประมวลผลไม่เป็นที่น่าพอใจ คุณสามารถเพิ่มความเร็วได้ดังนี้:</p><ul><li><strong>ลดขนาดโมเดลและจำนวนขั้นตอน</strong>: สำหรับโมเดลสร้างเสียงผู้พูดเดียว เราใช้โมเดล <code>zipvoice</code> เป็นค่าเริ่มต้นเพื่อคุณภาพเสียงที่ดีกว่า หากต้องการเน้นความเร็ว สามารถเปลี่ยนไปใช้ <code>zipvoice_distill</code> และลดค่า <code>--num-steps</code> ได้ต่ำสุดถึง <code>4</code> (ค่าเริ่มต้นคือ 8)</li></p><p><li><strong>เพิ่มความเร็ว CPU ด้วยมัลติเทรด</strong>: เมื่อรันบน CPU สามารถใช้พารามิเตอร์ <code>--num-thread</code> (เช่น <code>--num-thread 4</code>) เพื่อเพิ่มจำนวนเทรดสำหรับความเร็วที่มากขึ้น ค่าเริ่มต้นคือ 1 เทรด</li></p><p><li><strong>เพิ่มความเร็ว CPU ด้วย ONNX</strong>: เมื่อรันบน CPU สามารถใช้โมเดล ONNX กับ <code>zipvoice.bin.infer_zipvoice_onnx</code> เพื่อความเร็วที่มากขึ้น (ยังไม่รองรับ ONNX สำหรับโมเดลสร้างเสียงสนทนา) เพื่อความเร็วที่มากยิ่งขึ้น สามารถตั้งค่า <code>--onnx-int8 True</code> เพื่อใช้โมเดล ONNX ที่ถูกควอนไทซ์เป็น INT8 โปรดทราบว่าโมเดลควอนไทซ์จะมีคุณภาพเสียงลดลง <strong>อย่าใช้ ONNX บน GPU</strong> เพราะจะช้ากว่า PyTorch บน GPU</li></p><p></ul>#### 3.3 การควบคุมหน่วยความจำ</p><p>ข้อความที่ให้มาจะถูกแบ่งเป็นส่วนๆ ตามเครื่องหมายวรรคตอน (สำหรับสร้างเสียงผู้พูดเดียว) หรือสัญลักษณ์เปลี่ยนผู้พูด (สำหรับสร้างเสียงสนทนา) จากนั้นข้อความที่แบ่งส่วนจะถูกประมวลผลแบบแบทช์ ดังนั้นโมเดลสามารถประมวลผลข้อความที่ยาวมากได้โดยใช้หน่วยความจำเกือบคงที่ สามารถควบคุมการใช้หน่วยความจำได้โดยปรับพารามิเตอร์ <code>--max-duration</code></p><p>#### 3.4 การประเมิน "Raw"</p><p>โดยค่าเริ่มต้น เราจะประมวลผลอินพุต (ไฟล์ตัวอย่าง, การถอดเสียงตัวอย่าง, และข้อความ) เพื่อการประมวลผลที่มีประสิทธิภาพและผลลัพธ์ที่ดีกว่า หากต้องการประเมินประสิทธิภาพ "raw" ของโมเดลโดยใช้อินพุตตามที่ให้มา (เช่น เพื่อจำลองผลการทดลองในเอกสารของเรา) สามารถใช้ <code>--raw-evaluation True</code></p><p>#### 3.5 ข้อความสั้น</p><p>เมื่อสร้างเสียงสำหรับข้อความที่สั้นมาก (เช่น หนึ่งหรือสองคำ) เสียงที่สร้างขึ้นอาจละบางเสียงบางส่วน เพื่อแก้ไขปัญหานี้ สามารถใช้ <code>--speed 0.3</code> (โดยที่ 0.3 เป็นค่าที่ปรับได้) เพื่อยืดระยะเวลาของเสียงที่สร้างขึ้น</p><p>#### 3.6 การแก้ไขการออกเสียงผิดของอักขระจีนที่ออกเสียงได้หลายแบบ</p><p>เราใช้ <a href="https://github.com/mozillazg/python-pinyin" target="_blank" rel="noopener noreferrer">pypinyin</a> เพื่อแปลงอักขระจีนเป็น pinyin อย่างไรก็ตาม อาจเกิดการออกเสียงผิดสำหรับ <strong>อักขระหลายเสียง</strong> (多音字) ได้เป็นครั้งคราว</p><p>
ในการแก้ไขการออกเสียงผิดด้วยตนเอง ให้วงเล็บ <strong>พินอินที่ถูกต้อง</strong> ไว้ในเครื่องหมายมุม <code>< ></code> และใส่ <strong>เครื่องหมายวรรณยุกต์</strong> ด้วย</p><p><strong>ตัวอย่าง:</strong></p><ul><li>ข้อความต้นฉบับ: <code>这把剑长三十公分</code></li>
<li>แก้พินอินของ <code>长</code>:  <code>这把剑<chang2>三十公分</code></li></p><p></ul>> <strong>หมายเหตุ:</strong> หากต้องการกำหนดหลายพินอินด้วยตนเอง ให้วงเล็บแต่ละพินอินด้วย <code><></code> เช่น <code>这把<jian4><chang2><san1>十公分</code></p><p>#### 3.7 การลบช่วงเงียบที่ยาวจากเสียงที่สร้างขึ้น</p><p>โมเดลจะกำหนดตำแหน่งและระยะเวลาของช่วงเงียบในเสียงที่สร้างขึ้นโดยอัตโนมัติ บางครั้งจะมีช่วงเงียบที่ยาวในกลางเสียง หากไม่ต้องการ สามารถใช้ <code>--remove-long-sil</code> เพื่อลบช่วงเงียบที่ยาวในกลางเสียงที่สร้างขึ้น (ช่วงเงียบที่ขอบจะถูกลบโดยค่าเริ่มต้น)</p><p>#### 3.8 การดาวน์โหลดโมเดล</p><p>หากคุณมีปัญหาในการเชื่อมต่อกับ HuggingFace ขณะดาวน์โหลดโมเดลที่ผ่านการฝึกมาแล้ว ลองเปลี่ยน endpoint ไปยังเว็บไซต์มิเรอร์: <code>export HF_ENDPOINT=https://hf-mirror.com</code></p><h2>ฝึกโมเดลของคุณเอง</h2></p><p>ดูไดเรกทอรี <a href="egs" target="_blank" rel="noopener noreferrer">egs</a> สำหรับตัวอย่างการฝึก การปรับแต่ง และการประเมินผล</p><h2>การใช้งาน C++</h2></p><p>ตรวจสอบ <a href="https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498" target="_blank" rel="noopener noreferrer">sherpa-onnx</a> สำหรับโซลูชันการใช้งาน C++ บน CPU</p><h2>การพูดคุยและสื่อสาร</h2></p><p>คุณสามารถพูดคุยโดยตรงผ่าน <a href="https://github.com/k2-fsa/ZipVoice/issues" target="_blank" rel="noopener noreferrer">Github Issues</a></p><p>คุณยังสามารถสแกน QR code เพื่อเข้าร่วมกลุ่ม wechat ของเรา หรือกดติดตามบัญชีทางการ wechat ของเรา</p><p>| กลุ่ม Wechat | บัญชีทางการ Wechat |
| ------------ | ----------------------- |
|<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg" alt="wechat"> |<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg" alt="wechat"> |</p><h2>การอ้างอิง</h2></p><pre><code class="language-bibtex">@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}</p><p>@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}</code></pre></p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-10-06

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-10-06 
    </div>
    
</body>
</html>