<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ZipVoice - تحويل النص إلى كلام سريع وعالي الجودة بدون تدريب مسبق باستخدام مطابقة التدفق</title>
    <meta name="description" content="تحويل النص إلى كلام سريع وعالي الجودة بدون تدريب مسبق باستخدام مطابقة التدفق">
    <meta name="keywords" content="ZipVoice, Arabic, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ZipVoice",
  "description": "تحويل النص إلى كلام سريع وعالي الجودة بدون تدريب مسبق باستخدام مطابقة التدفق",
  "author": {
    "@type": "Person",
    "name": "k2-fsa"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 661
  },
  "url": "https://OpenAiTx.github.io/projects/k2-fsa/ZipVoice/README-ar.html",
  "sameAs": "https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md",
  "datePublished": "2025-10-06",
  "dateModified": "2025-10-06"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/k2-fsa/ZipVoice" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    ZipVoice
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 661 stars</span>
                <span class="language">Arabic</span>
                <span>by k2-fsa</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 اللغة</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">Itapano</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">Bahasa Indonesia</a>
      </div>
    </div>
  </details>
</div></p><p><div align="center"></p><h1>ZipVoice⚡</h1></p><h2>تحويل النص إلى كلام سريع وعالي الجودة بدون تدريب مسبق باستخدام مطابقة التدفق</h2>
</div></p><h2>نظرة عامة</h2></p><p>ZipVoice هي سلسلة من نماذج تحويل النص إلى كلام (TTS) السريعة وعالية الجودة بدون تدريب مسبق، تعتمد على تقنية مطابقة التدفق.</p><h3>1. الميزات الرئيسية</h3></p><ul><li>صغيرة وسريعة: تحتوي فقط على 123 مليون معامل.</li></p><p><li>استنساخ صوت عالي الجودة: أداء متقدم في تشابه المتحدث، والوضوح، والطبيعية.</li></p><p><li>متعددة اللغات: تدعم الصينية والإنجليزية.</li></p><p><li>متعددة الأنماط: تدعم توليد الكلام لمتحدث واحد أو الحوار.</li></p><p></ul><h3>2. أنواع النماذج</h3></p><p><table>
  <thead>
    <tr>
      <th>اسم النموذج</th>
      <th>الوصف</th>
      <th>البحث العلمي</th>
      <th>التجربة</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>النموذج الأساسي الذي يدعم تحويل النص إلى كلام بدون تدريب مسبق لمتحدث واحد بالصينية والإنجليزية.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>النسخة المقطرة من ZipVoice، وتتميز بسرعة محسنة مع تدهور طفيف في الأداء.</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>نموذج توليد الحوار مبني على ZipVoice، وقادر على توليد حوارات منطوقة لطرفين في قناة واحدة.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>النسخة الستيريو من ZipVoice-Dialog، والتي تتيح توليد حوارات ثنائية القناة مع تخصيص كل متحدث لقناة منفصلة.</td>
    </tr>
  </tbody>
</table></p><h2>الأخبار</h2></p><p><strong>2025/07/14</strong>: تم إصدار <strong>ZipVoice-Dialog</strong> و <strong>ZipVoice-Dialog-Stereo</strong>، وهما نموذجان لتوليد الحوارات المنطوقة. <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice-dialog.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><p><strong>2025/07/14</strong>: تم إصدار قاعدة بيانات <strong>OpenDialog</strong>، وهي قاعدة بيانات للحوارات المنطوقة مدتها 6.8 ألف ساعة. يمكن التحميل من <a href="https://huggingface.co/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow" alt="hf"></a>، <a href="https://www.modelscope.cn/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data" alt="ms"></a>. تفاصيل إضافية على <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a>.</p><p><strong>2025/06/16</strong>: تم إصدار <strong>ZipVoice</strong> و <strong>ZipVoice-Distill</strong>. <a href="https://arxiv.org/abs/2506.13053" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><h2>التثبيت</h2></p><h3>1. استنساخ مستودع ZipVoice</h3></p><pre><code class="language-bash">git clone https://github.com/k2-fsa/ZipVoice.git</code></pre>
<h3>2. (اختياري) إنشاء بيئة افتراضية في بايثون</h3></p><pre><code class="language-bash">python3 -m venv zipvoice
source zipvoice/bin/activate</code></pre>
<h3>3. تثبيت الحزم المطلوبة</h3></p><pre><code class="language-bash">pip install -r requirements.txt</code></pre>
<h3>4. تثبيت k2 للتدريب أو الاستدلال الفعال</h3></p><p><strong>k2 ضروري للتدريب</strong> ويمكنه تسريع الاستدلال. ومع ذلك، لا يزال بإمكانك استخدام وضع الاستدلال في ZipVoice دون تثبيت k2.</p><blockquote><strong>ملاحظة:</strong> تأكد من تثبيت إصدار k2 الذي يتوافق مع إصدار PyTorch و CUDA لديك. على سبيل المثال، إذا كنت تستخدم pytorch 2.5.1 و CUDA 12.1، يمكنك تثبيت k2 كما يلي:</blockquote></p><pre><code class="language-bash">pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html</code></pre>
يرجى الرجوع إلى https://k2-fsa.org/get-started/k2/ لمزيد من التفاصيل.
يمكن للمستخدمين في الصين القارية الرجوع إلى https://k2-fsa.org/zh-CN/get-started/k2/.</p><ul><li>للتحقق من تثبيت k2:</li></p><p>
</ul><pre><code class="language-bash">python3 -c "import k2; print(k2.__file__)"</code></pre>
<h2>الاستخدام</h2></p><h3>1. توليد الكلام لمتحدث واحد</h3></p><p>لتوليد كلام لمتحدث واحد باستخدام نماذج ZipVoice أو ZipVoice-Distill المدربة مسبقًا، استخدم الأوامر التالية (سيتم تنزيل النماذج المطلوبة من HuggingFace):</p><p>#### 1.1 الاستدلال على جملة واحدة</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav</code></pre>
<ul><li>يمكن أن تكون قيمة <code>--model-name</code> هي <code>zipvoice</code> أو <code>zipvoice_distill</code>، حيث تمثل النماذج قبل وبعد التقطير على التوالي.</li>
<li>إذا ظهرت <code><></code> أو <code>[]</code> في النص، فسيتم التعامل مع السلاسل المحاطة بها على أنها رموز خاصة. تشير <code><></code> إلى كتابة بينيين الصينية، و<code>[]</code> تشير إلى علامات خاصة أخرى.</li></p><p></ul>#### 1.2 استنتاج قائمة من الجمل</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li>كل سطر في ملف <code>test.tsv</code> يكون بالصيغة <code>{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code>.</li></p><p></ul><h3>2. توليد الكلام الحواري</h3></p><p>#### 2.1 أمر الاستدلال</p><p>لإنشاء حوارات منطوقة ثنائية الأطراف باستخدام نماذج ZipVoice-Dialogue أو ZipVoice-Dialogue-Stereo المدربة مسبقًا، استخدم الأوامر التالية (سيتم تحميل النماذج المطلوبة من HuggingFace):</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li>يمكن أن تكون قيمة <code>--model-name</code> هي <code>zipvoice_dialog</code> أو <code>zipvoice_dialog_stereo</code>,</li>
    </ul>حيث تقوم بتوليد حوارات أحادية أو ثنائية القناة على التوالي.</p><p>#### 2.2 تنسيقات الإدخال</p><p>كل سطر في ملف <code>test.tsv</code> يكون بأحد التنسيقات التالية:</p><p>(1) <strong>تنسيق الموجه المدمج</strong> حيث يتم دمج ملفات الصوت والنصوص الخاصة بمتحدثين اثنين في ملف موجه واحد:</p><pre><code class="language-">{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code></pre></p><ul><li><code>wav_name</code> هو اسم ملف wav الناتج.</li>
<li><code>prompt_transcription</code> هو نص تفريغ ملف wav الخاص بالمحادثة، مثل "[S1] مرحباً. [S2] كيف حالك؟"</li>
<li><code>prompt_wav</code> هو مسار ملف wav الخاص بالمحادثة.</li>
<li><code>text</code> هو النص المراد توليفه، مثل "[S1] أنا بخير. [S2] ما اسمك؟ [S1] أنا إريك. [S2] مرحباً إريك."</li></p><p></ul>(2) <strong>تنسيق المحادثة المقسمة</strong> حيث توجد تسجيلات الصوت والنصوص التفريغية للمتحدثين الاثنين في ملفات منفصلة:</p><pre><code class="language-">{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}</code></pre>
<ul><li><code>wav_name</code> هو اسم ملف wav الناتج.</li>
<li><code>spk1_prompt_transcription</code> هو نص الموجه لملف wav الخاص بالمتحدث الأول، مثل "مرحباً"</li>
<li><code>spk2_prompt_transcription</code> هو نص الموجه لملف wav الخاص بالمتحدث الثاني، مثل "كيف حالك؟"</li>
<li><code>spk1_prompt_wav</code> هو مسار ملف wav الخاص بالموجه للمتحدث الأول.</li>
<li><code>spk2_prompt_wav</code> هو مسار ملف wav الخاص بالموجه للمتحدث الثاني.</li>
<li><code>text</code> هو النص المراد توليده، مثل "[S1] أنا بخير. [S2] ما اسمك؟ [S1] اسمي إريك. [S2] مرحباً إريك."</li></p><p></ul><h3>3 إرشادات للاستخدام الأفضل:</h3></p><p>#### 3.1 طول الموجه</p><p>نوصي باستخدام ملف wav موجه قصير (على سبيل المثال، أقل من 3 ثوانٍ لتوليد الكلام لمتحدث واحد، وأقل من 10 ثوانٍ لتوليد كلام الحوار) لزيادة سرعة الاستنتاج. الموجه الطويل جداً سيبطئ الاستنتاج ويؤدي إلى تدهور جودة الصوت.</p><p>#### 3.2 تحسين السرعة</p><p>إذا كانت سرعة الاستنتاج غير مرضية، يمكنك تسريعها كما يلي:</p><ul><li><strong>نمذجة التكثيف وخطوات أقل</strong>: بالنسبة لنموذج توليد الكلام للمتحدث الواحد، نستخدم نموذج <code>zipvoice</code> افتراضياً لجودة صوت أفضل. إذا كانت السرعة أولوية، يمكنك التبديل إلى <code>zipvoice_distill</code> وتقليل قيمة <code>--num-steps</code> إلى أدنى حد وهو <code>4</code> (القيمة الافتراضية 8).</li></p><p><li><strong>تسريع وحدة المعالجة المركزية باستخدام تعدد الخيوط</strong>: عند التشغيل على وحدة المعالجة المركزية، يمكنك تمرير معامل <code>--num-thread</code> (مثلاً، <code>--num-thread 4</code>) لزيادة عدد الخيوط وتسريع الأداء. القيمة الافتراضية هي خيط واحد.</li></p><p><li><strong>تسريع وحدة المعالجة المركزية باستخدام ONNX</strong>: عند التشغيل على وحدة المعالجة المركزية، يمكنك استخدام نماذج ONNX مع <code>zipvoice.bin.infer_zipvoice_onnx</code> لزيادة السرعة (لم يتم دعم ONNX بعد لنماذج توليد الحوار). لمزيد من السرعة، يمكنك ضبط <code>--onnx-int8 True</code> لاستخدام نموذج ONNX كمي INT8. لاحظ أن النموذج المكمي يؤدي إلى تدهور جودة الصوت بدرجة معينة. <strong>لا تستخدم ONNX على وحدة معالجة الرسومات</strong>، لأنه أبطأ من PyTorch على وحدة معالجة الرسومات.</li></p><p></ul>#### 3.3 التحكم في الذاكرة</p><p>سيتم تقسيم النص المقدم إلى أجزاء بناءً على علامات الترقيم (لتوليد الكلام للمتحدث الواحد) أو رمز تبديل المتحدث (لتوليد كلام الحوار). بعد ذلك، تتم معالجة النصوص المجزأة على دفعات. وبالتالي، يمكن للنموذج معالجة نص طويل جداً باستخدام ذاكرة شبه ثابتة. يمكنك التحكم في استخدام الذاكرة عن طريق ضبط معامل <code>--max-duration</code>.</p><p>#### 3.4 التقييم "الخام"</p><p>بشكل افتراضي، نقوم بمعالجة المدخلات مسبقاً (ملف wav للموجه، نص الموجه، والنص) لتحقيق استنتاج فعال وأداء أفضل. إذا رغبت في تقييم أداء النموذج "الخام" باستخدام المدخلات المقدمة بالضبط (مثل لإعادة إنتاج نتائج بحثنا)، يمكنك تمرير <code>--raw-evaluation True</code>.</p><p>#### 3.5 النصوص القصيرة</p><p>عند توليد الكلام لنصوص قصيرة جداً (مثل كلمة أو كلمتين)، قد يتجاهل الكلام الناتج أحياناً بعض النطق. لحل هذه المشكلة، يمكنك تمرير <code>--speed 0.3</code> (حيث 0.3 قيمة قابلة للضبط) لتمديد مدة الكلام الناتج.</p><p>#### 3.6 تصحيح نطق حروف الصينية متعددة الأصوات</p><p>نستخدم <a href="https://github.com/mozillazg/python-pinyin" target="_blank" rel="noopener noreferrer">pypinyin</a> لتحويل الحروف الصينية إلى بينيين. ومع ذلك، قد يخطئ أحياناً في نطق <strong>الحروف متعددة الأصوات</strong> (多音字).</p><p>
لتصحيح هذه الأخطاء في النطق يدويًا، ضع <strong>التهجئة الصحيحة (بينيين)</strong> بين علامات الزاوية <code>< ></code> وضمنها <strong>علامة النبرة</strong>.</p><p><strong>مثال:</strong></p><ul><li>النص الأصلي: <code>这把剑长三十公分</code></li>
<li>صحح تهجئة كلمة <code>长</code>:  <code>这把剑<chang2>三十公分</code></li></p><p></ul>> <strong>ملاحظة:</strong> إذا أردت تعيين عدة تهجئات يدويًا، ضع كل تهجئة بين <code><></code>، مثل: <code>这把<jian4><chang2><san1>十公分</code></p><p>#### 3.7 إزالة الفترات الطويلة من الصمت في الكلام الناتج</p><p>سيحدد النموذج تلقائيًا مواضع وأطوال الفترات الصامتة في الكلام الناتج. أحيانًا تظهر فترات صمت طويلة في منتصف الكلام. إذا كنت لا ترغب بذلك، يمكنك تمرير الخيار <code>--remove-long-sil</code> لإزالة الفترات الطويلة في منتصف الكلام الناتج (سيتم إزالة الفترات الصامتة في الأطراف تلقائيًا).</p><p>#### 3.8 تنزيل النموذج</p><p>إذا واجهت مشكلة في الاتصال بـ HuggingFace أثناء تنزيل النماذج المدربة مسبقًا، جرب تغيير نقطة النهاية إلى الموقع المرآة: <code>export HF_ENDPOINT=https://hf-mirror.com</code>.</p><h2>تدريب نموذجك الخاص</h2></p><p>راجع دليل <a href="egs" target="_blank" rel="noopener noreferrer">egs</a> لأمثلة التدريب، وضبط النموذج، والتقييم.</p><h2>النشر باستخدام C++</h2></p><p>راجع <a href="https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498" target="_blank" rel="noopener noreferrer">sherpa-onnx</a> لحل النشر باستخدام لغة C++ على وحدة المعالجة المركزية.</p><h2>المناقشة والتواصل</h2></p><p>يمكنك المناقشة مباشرة عبر <a href="https://github.com/k2-fsa/ZipVoice/issues" target="_blank" rel="noopener noreferrer">Github Issues</a>.</p><p>يمكنك أيضًا مسح رمز الاستجابة السريعة للانضمام إلى مجموعة Wechat أو متابعة الحساب الرسمي لـ Wechat.</p><p>| مجموعة Wechat | الحساب الرسمي لـ Wechat |
| ------------- | ----------------------- |
|<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg" alt="wechat"> |<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg" alt="wechat"> |</p><h2>الاقتباس</h2></p><pre><code class="language-bibtex">@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}</p><p>@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}</code></pre></p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-10-06

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-10-06 
    </div>
    
</body>
</html>