<!DOCTYPE html>
<html lang="fa">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ZipVoice - تبدیل متن به گفتار سریع و با کیفیت بالا به روش Zero-Shot با استفاده از Flow Matching</title>
    <meta name="description" content="تبدیل متن به گفتار سریع و با کیفیت بالا به روش Zero-Shot با استفاده از Flow Matching">
    <meta name="keywords" content="ZipVoice, Persian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ZipVoice",
  "description": "تبدیل متن به گفتار سریع و با کیفیت بالا به روش Zero-Shot با استفاده از Flow Matching",
  "author": {
    "@type": "Person",
    "name": "k2-fsa"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 748
  },
  "url": "https://OpenAiTx.github.io/projects/k2-fsa/ZipVoice/README-fa.html",
  "sameAs": "https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md",
  "datePublished": "2025-12-30",
  "dateModified": "2025-12-30"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/k2-fsa/ZipVoice" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    ZipVoice
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 748 stars</span>
                <span class="language">Persian</span>
                <span>by k2-fsa</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 زبان</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">انگلیسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">ژاپنی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">کره‌ای</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">هندی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">تایلندی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">فرانسوی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">آلمانی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">اسپانیایی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">ایتالیایی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">روسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">پرتغالی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">هلندی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">لهستانی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">عربی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">ترکی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">ویتنامی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">اندونزیایی</a>
      </div>
    </div>
  </details>
</div></p><p><div align="center"></p><h1>ZipVoice⚡</h1></p><h2>تبدیل متن به گفتار سریع و باکیفیت بدون نمونه‌گیری با تطبیق جریان</h2>
</div></p><h2>مرور کلی</h2></p><p>ZipVoice مجموعه‌ای از مدل‌های TTS سریع و با کیفیت بالا به صورت zero-shot است که بر پایه flow matching توسعه یافته‌اند.</p><h3>۱. ویژگی‌های کلیدی</h3></p><ul><li>کوچک و سریع: تنها ۱۲۳ میلیون پارامتر دارد.</li></p><p><li>کلونینگ صدای با کیفیت بالا: عملکرد پیشرفته در شباهت گوینده، وضوح و طبیعی بودن.</li></p><p><li>چندزبانه: پشتیبانی از زبان‌های چینی و انگلیسی.</li></p><p><li>چندحالته: پشتیبانی از تولید گفتار تک‌گوینده و دیالوگ.</li></p><p></ul><h3>۲. انواع مدل</h3></p><p><table>
  <thead>
    <tr>
      <th>نام مدل</th>
      <th>توضیحات</th>
      <th>مقاله</th>
      <th>دمو</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>مدل پایه که از TTS zero-shot تک‌گوینده به زبان‌های چینی و انگلیسی پشتیبانی می‌کند.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>نسخه تقطیر شده ZipVoice که سرعت بهبود یافته با افت حداقلی عملکرد را ارائه می‌دهد.</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>مدل تولید دیالوگ مبتنی بر ZipVoice که قادر به تولید دیالوگ‌های گفتاری دوطرفه در یک کانال است.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>نوع استریوی ZipVoice-Dialog که امکان تولید گفتگوی دو کاناله را فراهم می‌کند، به طوری که هر سخنگو در یک کانال مجزا قرار می‌گیرد.</td>
    </tr>
  </tbody>
</table></p><h2>اخبار</h2></p><p><strong>۱۴۰۴/۰۴/۲۳</strong>: <strong>ZipVoice-Dialog</strong> و <strong>ZipVoice-Dialog-Stereo</strong>، دو مدل تولید گفتگوی گفتاری منتشر شدند. <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice-dialog.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><p><strong>۱۴۰۴/۰۴/۲۳</strong>: مجموعه داده <strong>OpenDialog</strong>، یک مجموعه داده گفتگوی گفتاری با مدت زمان ۶.۸ هزار ساعت منتشر شد. دانلود از <a href="https://huggingface.co/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow" alt="hf"></a>، <a href="https://www.modelscope.cn/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data" alt="ms"></a>. جزئیات در <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a>.</p><p><strong>۱۴۰۴/۰۳/۲۶</strong>: <strong>ZipVoice</strong> و <strong>ZipVoice-Distill</strong> منتشر شدند. <a href="https://arxiv.org/abs/2506.13053" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><h2>نصب</h2></p><h3>۱. مخزن ZipVoice را کلون کنید</h3></p><pre><code class="language-bash">git clone https://github.com/k2-fsa/ZipVoice.git</code></pre>
<h3>۲. (اختیاری) ایجاد یک محیط مجازی پایتون</h3></p><pre><code class="language-bash">python3 -m venv zipvoice
source zipvoice/bin/activate</code></pre>
<h3>۳. بسته‌های مورد نیاز را نصب کنید</h3></p><pre><code class="language-bash">pip install -r requirements.txt</code></pre>
<h3>۴. نصب k2 برای آموزش یا استنتاج بهینه</h3></p><p><strong>k2 برای آموزش لازم است</strong> و می‌تواند سرعت استنتاج را افزایش دهد. با این حال، همچنان می‌توانید از حالت استنتاج ZipVoice بدون نصب k2 استفاده کنید.</p><blockquote><strong>توجه:</strong> مطمئن شوید که نسخه k2 مناسب با نسخه PyTorch و CUDA خود را نصب می‌کنید. به عنوان مثال، اگر از pytorch 2.5.1 و CUDA 12.1 استفاده می‌کنید، می‌توانید k2 را به صورت زیر نصب کنید:</blockquote></p><pre><code class="language-bash">pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html</code></pre>
لطفاً برای جزئیات به https://k2-fsa.org/get-started/k2/ مراجعه کنید.
کاربران سرزمین اصلی چین می‌توانند به https://k2-fsa.org/zh-CN/get-started/k2/ مراجعه کنند.</p><ul><li>برای بررسی نصب k2:</li></p><p>
</ul><pre><code class="language-bash">python3 -c "import k2; print(k2.__file__)"</code></pre>
<h2>نحوه استفاده</h2></p><h3>۱. تولید گفتار تک‌گوینده</h3></p><p>برای تولید گفتار تک‌گوینده با مدل‌های ZipVoice یا ZipVoice-Distill آموزش‌دیده ما، از دستورات زیر استفاده کنید (مدل‌های مورد نیاز از HuggingFace دانلود خواهند شد):</p><p>#### ۱.۱ استنتاج یک جمله منفرد</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav</code></pre>
<ul><li><code>--model-name</code> می‌تواند <code>zipvoice</code> یا <code>zipvoice_distill</code> باشد، که به ترتیب مدل‌های قبل و بعد از تقطیر هستند.</li>
<li>اگر <code><></code> یا <code>[]</code> در متن ظاهر شوند، رشته‌هایی که توسط آن‌ها احاطه شده‌اند به عنوان توکن‌های ویژه در نظر گرفته خواهند شد. <code><></code> نشان‌دهنده پین‌یین چینی و <code>[]</code> نشان‌دهنده سایر برچسب‌های ویژه است.</li></p><p></ul>#### 1.2 استنتاج یک لیست از جملات</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li>هر خط از فایل <code>test.tsv</code> به صورت <code>{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code> است.</li></p><p></ul><h3>2. تولید گفتار گفتگو</h3></p><p>#### 2.1 فرمان استنتاج</p><p>برای تولید گفتگوهای گفتاری دو نفره با مدل‌های ZipVoice-Dialogue یا ZipVoice-Dialogue-Stereo که از پیش آموزش دیده‌اند، از دستورات زیر استفاده کنید (مدل‌های مورد نیاز از HuggingFace دانلود خواهند شد):</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li><code>--model-name</code> می‌تواند <code>zipvoice_dialog</code> یا <code>zipvoice_dialog_stereo</code> باشد،</li>
    </ul>که به ترتیب دیالوگ‌های مونو و استریو تولید می‌کنند.</p><p>#### 2.2 فرمت‌های ورودی</p><p>هر خط از فایل <code>test.tsv</code> یکی از فرمت‌های زیر را دارد:</p><p>(1) <strong>فرمت پرامپت ادغام‌شده</strong> که در آن صداها و رونوشت‌های دو گوینده در یک فایل صوتی پرامپت ترکیب شده‌اند:</p><pre><code class="language-">{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code></pre></p><ul><li><code>wav_name</code> نام فایل خروجی wav است.</li>
<li><code>prompt_transcription</code> متن رونویسی شده فایل صوتی مکالمه‌ی ورودی است، مثلاً "[S1] سلام. [S2] حالت چطوره؟"</li>
<li><code>prompt_wav</code> مسیر فایل صوتی مکالمه‌ی ورودی است.</li>
<li><code>text</code> متنی است که قرار است سنتز شود، مثلاً "[S1] من خوبم. [S2] اسم شما چیه؟ [S1] من اریک هستم. [S2] سلام اریک."</li></p><p></ul>(2) <strong>فرمت مکالمه‌ی جداشده</strong> که فایل‌های صوتی و رونویسی دو گوینده به صورت جداگانه وجود دارند:</p><pre><code class="language-">{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}</code></pre>
<ul><li><code>wav_name</code> نام فایل خروجی wav است.</li>
<li><code>spk1_prompt_transcription</code> رونویسی فایل wav نمونه گوینده اول است، مثلا "سلام"</li>
<li><code>spk2_prompt_transcription</code> رونویسی فایل wav نمونه گوینده دوم است، مثلا "حالت چطوره؟"</li>
<li><code>spk1_prompt_wav</code> مسیر فایل wav نمونه گوینده اول است.</li>
<li><code>spk2_prompt_wav</code> مسیر فایل wav نمونه گوینده دوم است.</li>
<li><code>text</code> متنی است که باید سنتز شود، مثلا "[S1] من خوبم. [S2] اسم شما چیست؟ [S1] من اریک هستم. [S2] سلام اریک."</li></p><p></ul><h3>3 راهنمایی برای استفاده بهتر:</h3></p><p>#### 3.1 طول نمونه</p><p>ما یک فایل نمونه wav کوتاه (مثلاً کمتر از ۳ ثانیه برای تولید گفتار تک‌گوینده، کمتر از ۱۰ ثانیه برای تولید گفتار محاوره‌ای) را برای افزایش سرعت استنتاج توصیه می‌کنیم. یک نمونه بسیار طولانی باعث کاهش سرعت استنتاج و افت کیفیت گفتار می‌شود.</p><p>#### 3.2 بهینه‌سازی سرعت</p><p>اگر سرعت استنتاج مطلوب نیست، می‌توانید با روش‌های زیر آن را افزایش دهید:</p><ul><li><strong>مدل تقطیرشده و مراحل کمتر</strong>: برای مدل تولید گفتار تک‌گوینده، به طور پیش‌فرض از مدل <code>zipvoice</code> برای کیفیت گفتار بهتر استفاده می‌کنیم. اگر سرعت بالاتر اولویت دارد، می‌توانید به <code>zipvoice_distill</code> سوئیچ کنید و مقدار <code>--num-steps</code> را تا حداقل <code>4</code> (پیش‌فرض ۸) کاهش دهید.</li></p><p><li><strong>افزایش سرعت CPU با چندریسمانی</strong>: هنگام اجرا روی CPU، می‌توانید با پارامتر <code>--num-thread</code> (مثلاً <code>--num-thread 4</code>) تعداد ریسه‌ها را برای سرعت بیشتر افزایش دهید. به طور پیش‌فرض از ۱ ریسه استفاده می‌کنیم.</li></p><p><li><strong>افزایش سرعت CPU با ONNX</strong>: هنگام اجرا روی CPU، می‌توانید از مدل‌های ONNX با <code>zipvoice.bin.infer_zipvoice_onnx</code> برای سرعت بیشتر استفاده کنید (هنوز مدل‌های تولید گفتار محاوره‌ای از ONNX پشتیبانی نمی‌کنند). برای سرعت بالاتر، می‌توانید مقدار <code>--onnx-int8 True</code> را برای استفاده از مدل ONNX با کمیت INT8 تنظیم کنید. توجه داشته باشید که مدل کمیت شده باعث کاهش کیفیت گفتار می‌شود. <strong>از ONNX روی GPU استفاده نکنید</strong>، چون نسبت به PyTorch روی GPU کندتر است.</li></p><p><li><strong>شتاب GPU با NVIDIA TensorRT</strong>: برای افزایش قابل توجه عملکرد روی کارت‌های NVIDIA، ابتدا مدل را با zipvoice.bin.tensorrt_export به موتور TensorRT تبدیل کنید. سپس استنتاج را روی مجموعه داده خود (مثلاً مجموعه داده Hugging Face) با zipvoice.bin.infer_zipvoice انجام دهید. این کار می‌تواند تقریباً دو برابر عملکرد نسبت به پیاده‌سازی استاندارد PyTorch روی GPU داشته باشد.</li></p><p></ul>#### 3.3 کنترل حافظه</p><p>متن داده شده بر اساس علائم نگارشی (برای تولید گفتار تک‌گوینده) یا نماد تغییر گوینده (برای تولید گفتار محاوره‌ای) به بخش‌هایی تقسیم می‌شود. سپس، متن‌های بخش‌بندی شده به صورت دسته‌ای پردازش می‌شوند. بنابراین، مدل می‌تواند متن‌های بسیار طولانی را با تقریباً حافظه ثابت پردازش کند. شما می‌توانید با تنظیم پارامتر <code>--max-duration</code> میزان مصرف حافظه را کنترل کنید.</p><p>#### 3.4 ارزیابی "خام"</p><p>به طور پیش‌فرض، ورودی‌ها (فایل نمونه wav، رونویسی نمونه، و متن) را برای استنتاج بهینه و عملکرد بهتر پیش‌پردازش می‌کنیم. اگر می‌خواهید عملکرد "خام" مدل را با ورودی‌های دقیقاً داده شده ارزیابی کنید (مثلاً برای بازتولید نتایج مقاله ما)، می‌توانید مقدار <code>--raw-evaluation True</code> را وارد کنید.</p><p>#### 3.5 متن کوتاه</p><p>هنگام تولید گفتار برای متن‌های بسیار کوتاه (مثلاً یک یا دو کلمه)، ممکن است گفتار تولیدشده برخی تلفظ‌ها را حذف کند. برای رفع این مشکل، می‌توانید مقدار <code>--speed 0.3</code> (که عدد ۰.۳ قابل تنظیم است) را وارد کنید تا مدت زمان گفتار تولیدشده افزایش یابد.</p><p>#### 3.6 اصلاح تلفظ اشتباه نویسه‌های چندآوایی چینی</p><p>
ما از <a href="https://github.com/mozillazg/python-pinyin" target="_blank" rel="noopener noreferrer">pypinyin</a> برای تبدیل حروف چینی به پین‌یین استفاده می‌کنیم. با این حال، گاهی اوقات ممکن است <strong>حروف چندآوایی</strong> (多音字) را اشتباه تلفظ کند.</p><p>برای اصلاح دستی این تلفظ‌های اشتباه، پین‌یین <strong>اصلاح‌شده</strong> را درون علامت زاویه‌ای <code>< ></code> قرار دهید و <strong>علامت نغمه</strong> را نیز درج کنید.</p><p><strong>مثال:</strong></p><ul><li>متن اصلی: <code>这把剑长三十公分</code></li>
<li>اصلاح پین‌یین واژه <code>长</code>:  <code>这把剑<chang2>三十公分</code></li></p><p></ul>> <strong>توجه:</strong> اگر می‌خواهید چند پین‌یین را به صورت دستی تعیین کنید، هر پین‌یین را داخل <code>< ></code> قرار دهید، مانند: <code>这把<jian4><chang2><san1>十公分</code></p><p>#### ۳.۷ حذف سکوت‌های طولانی از گفتار تولیدشده</p><p>مدل به طور خودکار موقعیت و طول سکوت‌ها در گفتار تولیدشده را تشخیص می‌دهد. گاهی اوقات سکوت طولانی در وسط گفتار ایجاد می‌شود. اگر این مورد را نمی‌خواهید، می‌توانید با پارامتر <code>--remove-long-sil</code> سکوت‌های طولانی در وسط گفتار تولیدشده را حذف کنید (سکوت‌های لبه‌ای به طور پیش‌فرض حذف خواهند شد).</p><p>#### ۳.۸ دانلود مدل</p><p>اگر هنگام دانلود مدل‌های از پیش آموزش‌دیده از HuggingFace با مشکل اتصال مواجه شدید، می‌توانید نقطه انتهایی را به سایت میرور تغییر دهید: <code>export HF_ENDPOINT=https://hf-mirror.com</code>.</p><h2>آموزش مدل اختصاصی</h2></p><p>برای مثال‌های آموزش، تنظیم دقیق و ارزیابی به دایرکتوری <a href="egs" target="_blank" rel="noopener noreferrer">egs</a> مراجعه کنید.</p><h2>استقرار در محیط تولید</h2></p><h3>اجرای GPU با NVIDIA Triton</h3></p><p>برای استقرار آماده تولید با کارایی و مقیاس‌پذیری بالا، به <a href="runtime/nvidia_triton/" target="_blank" rel="noopener noreferrer">ادغام سرور استنتاج Triton</a> مراجعه کنید که موتورهای بهینه‌شده TensorRT، مدیریت درخواست‌های همزمان و هر دو API گراف/HTTP برای استفاده سازمانی را ارائه می‌دهد.</p><h3>استقرار روی CPU</h3></p><p>برای راه‌حل استقرار C++ روی CPU به <a href="https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498" target="_blank" rel="noopener noreferrer">sherpa-onnx</a> مراجعه کنید.</p><h2>بحث و ارتباط</h2></p><p>می‌توانید به طور مستقیم در <a href="https://github.com/k2-fsa/ZipVoice/issues" target="_blank" rel="noopener noreferrer">Github Issues</a> بحث کنید.</p><p>همچنین می‌توانید کد QR را اسکن کنید تا به گروه وی‌چت ما بپیوندید یا حساب رسمی وی‌چت ما را دنبال کنید.</p><p>| گروه وی‌چت | حساب رسمی وی‌چت |
| ------------ | ----------------------- |
|<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg" alt="wechat"> |<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg" alt="wechat"> |</p><h2>ارجاع</h2></p><pre><code class="language-bibtex">@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}</p><p>@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}</code></pre></p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-12-30

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-12-30 
    </div>
    
</body>
</html>