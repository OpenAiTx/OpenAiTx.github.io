<!DOCTYPE html>
<html lang="fa">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ZipVoice - تبدیل متن به گفتار سریع و با کیفیت بالا بدون نیاز به داده‌های آموزشی با استفاده از Flow Matching</title>
    <meta name="description" content="تبدیل متن به گفتار سریع و با کیفیت بالا بدون نیاز به داده‌های آموزشی با استفاده از Flow Matching">
    <meta name="keywords" content="ZipVoice, Persian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "ZipVoice",
  "description": "تبدیل متن به گفتار سریع و با کیفیت بالا بدون نیاز به داده‌های آموزشی با استفاده از Flow Matching",
  "author": {
    "@type": "Person",
    "name": "k2-fsa"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 661
  },
  "url": "https://OpenAiTx.github.io/projects/k2-fsa/ZipVoice/README-fa.html",
  "sameAs": "https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md",
  "datePublished": "2025-10-06",
  "dateModified": "2025-10-06"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/k2-fsa/ZipVoice" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    ZipVoice
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 661 stars</span>
                <span class="language">Persian</span>
                <span>by k2-fsa</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 زبان</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=en">انگلیسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ja">ژاپنی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ko">کره‌ای</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=hi">هندی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=th">تایلندی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fr">فرانسوی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=de">آلمانی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=es">اسپانیایی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=it">ایتالیایی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ru">روسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pt">پرتغالی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=nl">هلندی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=pl">لهستانی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=ar">عربی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=tr">ترکی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=vi">ویتنامی</a>
        | <a href="https://openaitx.github.io/view.html?user=k2-fsa&project=ZipVoice&lang=id">اندونزیایی</a>
      </div>
    </div>
  </details>
</div></p><p><div align="center"></p><h1>ZipVoice⚡</h1></p><h2>تبدیل متن به گفتار سریع و باکیفیت بدون نمونه‌گیری با تطبیق جریان</h2>
</div></p><h2>مرور کلی</h2></p><p>ZipVoice مجموعه‌ای از مدل‌های TTS سریع و با کیفیت بالا به صورت zero-shot است که بر پایه flow matching توسعه یافته‌اند.</p><h3>۱. ویژگی‌های کلیدی</h3></p><ul><li>کوچک و سریع: تنها ۱۲۳ میلیون پارامتر دارد.</li></p><p><li>کلونینگ صدای با کیفیت بالا: عملکرد پیشرفته در شباهت گوینده، وضوح و طبیعی بودن.</li></p><p><li>چندزبانه: پشتیبانی از زبان‌های چینی و انگلیسی.</li></p><p><li>چندحالته: پشتیبانی از تولید گفتار تک‌گوینده و دیالوگ.</li></p><p></ul><h3>۲. انواع مدل</h3></p><p><table>
  <thead>
    <tr>
      <th>نام مدل</th>
      <th>توضیحات</th>
      <th>مقاله</th>
      <th>دمو</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ZipVoice</td>
      <td>مدل پایه که از TTS zero-shot تک‌گوینده به زبان‌های چینی و انگلیسی پشتیبانی می‌کند.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2506.13053"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Distill</td>
      <td>نسخه تقطیر شده ZipVoice که سرعت بهبود یافته با افت حداقلی عملکرد را ارائه می‌دهد.</td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog</td>
      <td>مدل تولید دیالوگ مبتنی بر ZipVoice که قادر به تولید دیالوگ‌های گفتاری دوطرفه در یک کانال است.</td>
      <td rowspan="2"><a href="https://arxiv.org/abs/2507.09318"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg"></a></td>
      <td rowspan="2"><a href="https://zipvoice-dialog.github.io"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square"></a></td>
    </tr>
    <tr>
      <td>ZipVoice-Dialog-Stereo</td>
      <td>نوع استریوی ZipVoice-Dialog که امکان تولید گفتگوی دو کاناله را فراهم می‌کند، به طوری که هر سخنگو در یک کانال مجزا قرار می‌گیرد.</td>
    </tr>
  </tbody>
</table></p><h2>اخبار</h2></p><p><strong>۱۴۰۴/۰۴/۲۳</strong>: <strong>ZipVoice-Dialog</strong> و <strong>ZipVoice-Dialog-Stereo</strong>، دو مدل تولید گفتگوی گفتاری منتشر شدند. <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice-dialog.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><p><strong>۱۴۰۴/۰۴/۲۳</strong>: مجموعه داده <strong>OpenDialog</strong>، یک مجموعه داده گفتگوی گفتاری با مدت زمان ۶.۸ هزار ساعت منتشر شد. دانلود از <a href="https://huggingface.co/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow" alt="hf"></a>، <a href="https://www.modelscope.cn/datasets/k2-fsa/OpenDialog" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/ModelScope-Dataset-blue?logo=data" alt="ms"></a>. جزئیات در <a href="https://arxiv.org/abs/2507.09318" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a>.</p><p><strong>۱۴۰۴/۰۳/۲۶</strong>: <strong>ZipVoice</strong> و <strong>ZipVoice-Distill</strong> منتشر شدند. <a href="https://arxiv.org/abs/2506.13053" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg" alt="arXiv"></a> <a href="https://zipvoice.github.io" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub.io-Demo_Page-blue?logo=Github&style=flat-square" alt="demo page"></a></p><h2>نصب</h2></p><h3>۱. مخزن ZipVoice را کلون کنید</h3></p><pre><code class="language-bash">git clone https://github.com/k2-fsa/ZipVoice.git</code></pre>
<h3>۲. (اختیاری) ایجاد یک محیط مجازی پایتون</h3></p><pre><code class="language-bash">python3 -m venv zipvoice
source zipvoice/bin/activate</code></pre>
<h3>۳. بسته‌های مورد نیاز را نصب کنید</h3></p><pre><code class="language-bash">pip install -r requirements.txt</code></pre>
<h3>۴. نصب k2 برای آموزش یا استنتاج بهینه</h3></p><p><strong>k2 برای آموزش لازم است</strong> و می‌تواند سرعت استنتاج را افزایش دهد. با این حال، همچنان می‌توانید از حالت استنتاج ZipVoice بدون نصب k2 استفاده کنید.</p><blockquote><strong>توجه:</strong> مطمئن شوید که نسخه k2 مناسب با نسخه PyTorch و CUDA خود را نصب می‌کنید. به عنوان مثال، اگر از pytorch 2.5.1 و CUDA 12.1 استفاده می‌کنید، می‌توانید k2 را به صورت زیر نصب کنید:</blockquote></p><pre><code class="language-bash">pip install k2==1.24.4.dev20250208+cuda12.1.torch2.5.1 -f https://k2-fsa.github.io/k2/cuda.html</code></pre>
لطفاً برای جزئیات به https://k2-fsa.org/get-started/k2/ مراجعه کنید.
کاربران سرزمین اصلی چین می‌توانند به https://k2-fsa.org/zh-CN/get-started/k2/ مراجعه کنند.</p><ul><li>برای بررسی نصب k2:</li></p><p>
</ul><pre><code class="language-bash">python3 -c "import k2; print(k2.__file__)"</code></pre>
<h2>نحوه استفاده</h2></p><h3>۱. تولید گفتار تک‌گوینده</h3></p><p>برای تولید گفتار تک‌گوینده با مدل‌های ZipVoice یا ZipVoice-Distill آموزش‌دیده ما، از دستورات زیر استفاده کنید (مدل‌های مورد نیاز از HuggingFace دانلود خواهند شد):</p><p>#### ۱.۱ استنتاج یک جمله منفرد</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --prompt-wav prompt.wav \
    --prompt-text "I am the transcription of the prompt wav." \
    --text "I am the text to be synthesized." \
    --res-wav-path result.wav</code></pre>
<ul><li><code>--model-name</code> می‌تواند <code>zipvoice</code> یا <code>zipvoice_distill</code> باشد، که به ترتیب مدل‌های قبل و بعد از تقطیر هستند.</li>
<li>اگر <code><></code> یا <code>[]</code> در متن ظاهر شوند، رشته‌هایی که توسط آن‌ها احاطه شده‌اند به عنوان توکن‌های ویژه در نظر گرفته خواهند شد. <code><></code> نشان‌دهنده پین‌یین چینی و <code>[]</code> نشان‌دهنده سایر برچسب‌های ویژه است.</li></p><p></ul>#### 1.2 استنتاج یک لیست از جملات</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice \
    --model-name zipvoice \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li>هر خط از فایل <code>test.tsv</code> به صورت <code>{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code> است.</li></p><p></ul><h3>2. تولید گفتار گفتگو</h3></p><p>#### 2.1 فرمان استنتاج</p><p>برای تولید گفتگوهای گفتاری دو نفره با مدل‌های ZipVoice-Dialogue یا ZipVoice-Dialogue-Stereo که از پیش آموزش دیده‌اند، از دستورات زیر استفاده کنید (مدل‌های مورد نیاز از HuggingFace دانلود خواهند شد):</p><pre><code class="language-bash">python3 -m zipvoice.bin.infer_zipvoice_dialog \
    --model-name "zipvoice_dialog" \
    --test-list test.tsv \
    --res-dir results</code></pre>
<ul><li><code>--model-name</code> می‌تواند <code>zipvoice_dialog</code> یا <code>zipvoice_dialog_stereo</code> باشد،</li>
    </ul>که به ترتیب دیالوگ‌های مونو و استریو تولید می‌کنند.</p><p>#### 2.2 فرمت‌های ورودی</p><p>هر خط از فایل <code>test.tsv</code> یکی از فرمت‌های زیر را دارد:</p><p>(1) <strong>فرمت پرامپت ادغام‌شده</strong> که در آن صداها و رونوشت‌های دو گوینده در یک فایل صوتی پرامپت ترکیب شده‌اند:</p><pre><code class="language-">{wav_name}\t{prompt_transcription}\t{prompt_wav}\t{text}</code></pre></p><ul><li><code>wav_name</code> نام فایل خروجی wav است.</li>
<li><code>prompt_transcription</code> متن رونویسی شده فایل صوتی مکالمه‌ی ورودی است، مثلاً "[S1] سلام. [S2] حالت چطوره؟"</li>
<li><code>prompt_wav</code> مسیر فایل صوتی مکالمه‌ی ورودی است.</li>
<li><code>text</code> متنی است که قرار است سنتز شود، مثلاً "[S1] من خوبم. [S2] اسم شما چیه؟ [S1] من اریک هستم. [S2] سلام اریک."</li></p><p></ul>(2) <strong>فرمت مکالمه‌ی جداشده</strong> که فایل‌های صوتی و رونویسی دو گوینده به صورت جداگانه وجود دارند:</p><pre><code class="language-">{wav_name}\t{spk1_prompt_transcription}\t{spk2_prompt_transcription}\t{spk1_prompt_wav}\t{spk2_prompt_wav}\t{text}</code></pre>
<ul><li><code>wav_name</code> نام فایل خروجی wav است.</li>
<li><code>spk1_prompt_transcription</code> رونوشت فایل wav نمونه گوینده اول است، مثلاً "سلام"</li>
<li><code>spk2_prompt_transcription</code> رونوشت فایل wav نمونه گوینده دوم است، مثلاً "حالت چطور است؟"</li>
<li><code>spk1_prompt_wav</code> مسیر فایل wav نمونه گوینده اول است.</li>
<li><code>spk2_prompt_wav</code> مسیر فایل wav نمونه گوینده دوم است.</li>
<li><code>text</code> متنی است که باید سنتز شود، مثلاً "[S1] خوبم. [S2] اسمت چیست؟ [S1] من اریک هستم. [S2] سلام اریک."</li></p><p></ul><h3>۳ راهنمای استفاده بهتر:</h3></p><p>#### ۳.۱ طول نمونه</p><p>پیشنهاد می‌کنیم فایل wav نمونه کوتاه باشد (مثلاً کمتر از ۳ ثانیه برای تولید گفتار تک‌گوینده، کمتر از ۱۰ ثانیه برای تولید گفتار دیالوگ) تا سرعت استنتاج بیشتر شود. نمونه بسیار طولانی باعث کندی استنتاج و افت کیفیت گفتار خواهد شد.</p><p>#### ۳.۲ بهینه‌سازی سرعت</p><p>اگر سرعت استنتاج رضایت‌بخش نیست، می‌توانید به روش‌های زیر آن را افزایش دهید:</p><ul><li><strong>مدل تقطیر شده و کاهش مراحل</strong>: برای مدل تولید گفتار تک‌گوینده، به طور پیش‌فرض از مدل <code>zipvoice</code> برای کیفیت بهتر گفتار استفاده می‌کنیم. اگر سرعت بیشتر اولویت دارد، می‌توانید به <code>zipvoice_distill</code> سوییچ کنید و مقدار <code>--num-steps</code> را تا حداقل <code>4</code> کاهش دهید (پیش‌فرض 8).</li></p><p><li><strong>افزایش سرعت CPU با چندریسمانی</strong>: هنگام اجرای روی CPU، می‌توانید پارامتر <code>--num-thread</code> (مثلاً <code>--num-thread 4</code>) را برای افزایش تعداد ریسمان‌ها و سرعت بیشتر وارد کنید. به طور پیش‌فرض ۱ ریسمان استفاده می‌شود.</li></p><p><li><strong>افزایش سرعت CPU با ONNX</strong>: هنگام اجرا روی CPU، می‌توانید از مدل‌های ONNX با <code>zipvoice.bin.infer_zipvoice_onnx</code> برای سرعت بیشتر استفاده کنید (هنوز برای مدل‌های تولید دیالوگ از ONNX پشتیبانی نشده). برای سرعت بیشتر، می‌توانید مقدار <code>--onnx-int8 True</code> را جهت استفاده از مدل ONNX با INT8 تنظیم کنید. توجه داشته باشید که مدل کوانتیزه شده باعث افت کیفیت گفتار خواهد شد. <strong>از ONNX روی GPU استفاده نکنید</strong>، زیرا روی GPU کندتر از PyTorch است.</li></p><p></ul>#### ۳.۳ کنترل حافظه</p><p>متن داده شده بر اساس علائم نگارشی (برای تولید گفتار تک‌گوینده) یا نماد تغییر گوینده (برای تولید گفتار دیالوگ) به بخش‌هایی تقسیم می‌شود. سپس متن‌های بخش‌بندی شده به صورت دسته‌ای پردازش می‌شوند. بنابراین مدل می‌تواند متن بسیار طولانی را با مصرف حافظه تقریباً ثابت پردازش کند. با تنظیم پارامتر <code>--max-duration</code> می‌توانید مصرف حافظه را کنترل کنید.</p><p>#### ۳.۴ ارزیابی "خام"</p><p>به طور پیش‌فرض، ورودی‌ها (فایل wav نمونه، رونوشت نمونه، و متن) را برای استنتاج بهینه و عملکرد بهتر پیش‌پردازش می‌کنیم. اگر می‌خواهید عملکرد "خام" مدل را با ورودی‌های دقیق ارائه‌شده ارزیابی کنید (مثلاً برای بازتولید نتایج مقاله ما)، می‌توانید پارامتر <code>--raw-evaluation True</code> را وارد کنید.</p><p>#### ۳.۵ متن کوتاه</p><p>هنگام تولید گفتار برای متن‌های بسیار کوتاه (مثلاً یک یا دو واژه)، گفتار تولیدشده گاهی برخی تلفظ‌ها را حذف می‌کند. برای رفع این مشکل، می‌توانید پارامتر <code>--speed 0.3</code> (که مقدار قابل تنظیم است) را وارد کنید تا مدت زمان گفتار تولیدی افزایش یابد.</p><p>#### ۳.۶ اصلاح تلفظ اشتباه حروف چندآوایی چینی</p><p>ما از <a href="https://github.com/mozillazg/python-pinyin" target="_blank" rel="noopener noreferrer">pypinyin</a> برای تبدیل کاراکترهای چینی به پین‌یین استفاده می‌کنیم. با این حال، گاهی اوقات <strong>حروف چندآوایی</strong> (多音字) را اشتباه تلفظ می‌کند.</p><p>
برای اصلاح دستی این تلفظ‌های اشتباه، <strong>پین‌یین اصلاح‌شده</strong> را در داخل علامت زاویه‌دار <code>< ></code> قرار دهید و <strong>علامت نوا</strong> را اضافه کنید.</p><p><strong>مثال:</strong></p><ul><li>متن اصلی: <code>这把剑长三十公分</code></li>
<li>اصلاح پین‌یین <code>长</code>:  <code>这把剑<chang2>三十公分</code></li></p><p></ul>> <strong>توجه:</strong> اگر می‌خواهید چندین پین‌یین را به صورت دستی تعیین کنید، هر پین‌یین را داخل <code><></code> قرار دهید، مانند: <code>这把<jian4><chang2><san1>十公分</code></p><p>#### 3.7 حذف سکوت‌های طولانی از گفتار تولید شده</p><p>مدل به طور خودکار موقعیت‌ها و طول سکوت‌ها را در گفتار تولیدشده تعیین می‌کند. گاهی اوقات سکوت طولانی در وسط گفتار ایجاد می‌شود. اگر نمی‌خواهید این اتفاق بیفتد، می‌توانید <code>--remove-long-sil</code> را استفاده کنید تا سکوت‌های طولانی وسط گفتار حذف شوند (سکوت‌های ابتدا و انتها به طور پیش‌فرض حذف می‌شوند).</p><p>#### 3.8 دانلود مدل</p><p>اگر هنگام دانلود مدل‌های از پیش آموزش‌دیده با HuggingFace مشکل اتصال داشتید، سعی کنید نقطه انتهایی را به سایت آینه تغییر دهید: <code>export HF_ENDPOINT=https://hf-mirror.com</code>.</p><h2>آموزش مدل شخصی خودتان</h2></p><p>برای نمونه‌های آموزش، تنظیم و ارزیابی، به دایرکتوری <a href="egs" target="_blank" rel="noopener noreferrer">egs</a> مراجعه کنید.</p><h2>استقرار C++</h2></p><p>راه‌حل استقرار C++ روی CPU را در <a href="https://github.com/k2-fsa/sherpa-onnx/pull/2487#issuecomment-3227884498" target="_blank" rel="noopener noreferrer">sherpa-onnx</a> بررسی کنید.</p><h2>بحث و ارتباط</h2></p><p>می‌توانید مستقیماً در <a href="https://github.com/k2-fsa/ZipVoice/issues" target="_blank" rel="noopener noreferrer">Github Issues</a> بحث کنید.</p><p>همچنین می‌توانید کد QR را برای پیوستن به گروه وی‌چت ما یا دنبال کردن حساب رسمی وی‌چت اسکن کنید.</p><p>| گروه وی‌چت | حساب رسمی وی‌چت |
| ------------ | ----------------------- |
|<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_group.jpg" alt="wechat"> |<img src="https://k2-fsa.org/zh-CN/assets/pic/wechat_account.jpg" alt="wechat"> |</p><h2>ارجاع</h2></p><pre><code class="language-bibtex">@article{zhu2025zipvoice,
      title={ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching},
      author={Zhu, Han and Kang, Wei and Yao, Zengwei and Guo, Liyong and Kuang, Fangjun and Li, Zhaoqing and Zhuang, Weiji and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2506.13053},
      year={2025}
}</p><p>@article{zhu2025zipvoicedialog,
      title={ZipVoice-Dialog: Non-Autoregressive Spoken Dialogue Generation with Flow Matching},
      author={Zhu, Han and Kang, Wei and Guo, Liyong and Yao, Zengwei and Kuang, Fangjun and Zhuang, Weiji and Li, Zhaoqing and Han, Zhifeng and Zhang, Dong and Zhang, Xin and Song, Xingchen and Lin, Long and Povey, Daniel},
      journal={arXiv preprint arXiv:2507.09318},
      year={2025}
}</code></pre></p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-10-06

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/k2-fsa/ZipVoice/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-10-06 
    </div>
    
</body>
</html>