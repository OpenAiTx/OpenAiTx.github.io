<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>agenticSeek - Read agenticSeek documentation in Spanish. This project has 18325 stars on GitHub.</title>
    <meta name="description" content="Read agenticSeek documentation in Spanish. This project has 18325 stars on GitHub.">
    <meta name="keywords" content="agenticSeek, Spanish, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "agenticSeek",
  "description": "Read agenticSeek documentation in Spanish. This project has 18325 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "Fosowl"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 18325
  },
  "url": "https://OpenAiTx.github.io/projects/Fosowl/agenticSeek/README-es.html",
  "sameAs": "https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/Fosowl/agenticSeek" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    agenticSeek
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 18325 stars</span>
                <span class="language">Spanish</span>
                <span>by Fosowl</span>
            </div>
        </div>
        
        <div class="content">
            <h1>AgenticSeek: Alternativa privada y local a Manus</h1></p><p><p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
<p>  English | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md" target="_blank" rel="noopener noreferrer">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md" target="_blank" rel="noopener noreferrer">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md" target="_blank" rel="noopener noreferrer">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md" target="_blank" rel="noopener noreferrer">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md" target="_blank" rel="noopener noreferrer">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md" target="_blank" rel="noopener noreferrer">Español</a></p><p><em>Una <strong>alternativa 100% local a Manus AI</strong>, este asistente de IA habilitado por voz navega autónomamente por la web, escribe código y planifica tareas, manteniendo todos los datos en tu dispositivo. Adaptado para modelos de razonamiento locales, se ejecuta completamente en tu hardware, garantizando total privacidad y cero dependencia de la nube.</em></p><p><a href="https://fosowl.github.io/agenticSeek.html" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?label=Website&message=AgenticSeek&color=blue&style=flat-square" alt="Visita AgenticSeek"></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="Licencia"> <a href="https://discord.gg/8hGDaME3TC" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&logoColor=white" alt="Discord"></a> <a href="https://x.com/Martin993886460" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&label=Update%20%40Fosowl" alt="Twitter"></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars"></a></p><h3>¿Por qué AgenticSeek?</h3></p><ul><li>🔒 Totalmente local y privado - Todo funciona en tu máquina — sin nube, sin compartir datos. Tus archivos, conversaciones y búsquedas permanecen privadas.</li></p><p><li>🌐 Navegación web inteligente - AgenticSeek puede navegar por Internet de forma autónoma — buscar, leer, extraer información, rellenar formularios web — todo manos libres.</li></p><p><li>💻 Asistente de codificación autónomo - ¿Necesitas código? Puede escribir, depurar y ejecutar programas en Python, C, Go, Java y más — todo sin supervisión.</li></p><p><li>🧠 Selección inteligente de agentes - Tú preguntas, él determina automáticamente el mejor agente para el trabajo. Como tener un equipo de expertos listo para ayudar.</li></p><p><li>📋 Planifica y ejecuta tareas complejas - Desde planificar viajes hasta proyectos complejos — puede dividir grandes tareas en pasos y realizarlas usando múltiples agentes de IA.</li></p><p><li>🎙️ Habilitado por voz - Voz limpia, rápida y futurista, y conversión de voz a texto que te permite hablarle como si fuera tu IA personal de una película de ciencia ficción. (En progreso)</li></p><p></ul><h3><strong>Demostración</strong></h3></p><blockquote><em>¿Puedes buscar el proyecto agenticSeek, aprender qué habilidades se requieren, luego abrir el archivo CV_candidates.zip y decirme cuáles coinciden mejor con el proyecto?</em></blockquote></p><p>https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</p><p>Aviso: Esta demostración, incluidos todos los archivos que aparecen (por ejemplo: CV_candidates.zip), es completamente ficticia. No somos una corporación, buscamos colaboradores de código abierto, no candidatos.</p><blockquote>🛠⚠️️ <strong>Trabajo activo en progreso</strong></blockquote></p><blockquote>🙏 Este proyecto comenzó como un proyecto paralelo y no tiene hoja de ruta ni financiación. Ha crecido mucho más de lo que esperaba al llegar a GitHub Trending. Se agradecen profundamente las contribuciones, comentarios y paciencia.</blockquote></p><h2>Prerrequisitos</h2></p><p>Antes de comenzar, asegúrate de tener instalado el siguiente software:</p><ul><li>  <strong>Git:</strong> Para clonar el repositorio. <a href="https://git-scm.com/downloads" target="_blank" rel="noopener noreferrer">Descargar Git</a></li>
<li>  <strong>Python 3.10.x:</strong> Recomendamos encarecidamente utilizar la versión 3.10.x de Python. Usar otras versiones podría causar errores de dependencias. <a href="https://www.python.org/downloads/release/python-3100/" target="_blank" rel="noopener noreferrer">Descargar Python 3.10</a> (elige una versión 3.10.x).</li>
<li>  <strong>Docker Engine & Docker Compose:</strong> Para ejecutar servicios integrados como SearxNG.</li>
    <li>  Instala Docker Desktop (que incluye Docker Compose V2): <a href="https://docs.docker.com/desktop/install/windows-install/" target="_blank" rel="noopener noreferrer">Windows</a> | <a href="https://docs.docker.com/desktop/install/mac-install/" target="_blank" rel="noopener noreferrer">Mac</a> | <a href="https://docs.docker.com/desktop/install/linux-install/" target="_blank" rel="noopener noreferrer">Linux</a></li>
    <li>  Alternativamente, instala Docker Engine y Docker Compose por separado en Linux: <a href="https://docs.docker.com/engine/install/" target="_blank" rel="noopener noreferrer">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/" target="_blank" rel="noopener noreferrer">Docker Compose</a> (asegúrate de instalar Compose V2, por ejemplo, <code>sudo apt-get install docker-compose-plugin</code>).</li></p><p></ul><h3>1. <strong>Clona el repositorio y haz la configuración inicial</strong></h3></p><pre><code class="language-sh">git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env</code></pre></p><h3>2. Cambia el contenido del archivo .env</h3></p><pre><code class="language-sh">SEARXNG_BASE_URL="http://127.0.0.1:8080"
REDIS_BASE_URL="redis://redis:6379/0"
WORK_DIR="/Users/mlg/Documents/workspace_for_ai"
OLLAMA_PORT="11434"
LM_STUDIO_PORT="1234"
CUSTOM_ADDITIONAL_LLM_PORT="11435"
OPENAI_API_KEY='optional'
DEEPSEEK_API_KEY='optional'
OPENROUTER_API_KEY='optional'
TOGETHER_API_KEY='optional'
GOOGLE_API_KEY='optional'
ANTHROPIC_API_KEY='optional'</code></pre></p><p>Actualiza el archivo <code>.env</code> con tus propios valores según sea necesario:</p><ul><li><strong>SEARXNG_BASE_URL</strong>: Déjalo sin cambios</li>
<li><strong>REDIS_BASE_URL</strong>: Déjalo sin cambios</li>
<li><strong>WORK_DIR</strong>: Ruta a tu directorio de trabajo en tu máquina local. AgenticSeek podrá leer e interactuar con estos archivos.</li>
<li><strong>OLLAMA_PORT</strong>: Número de puerto para el servicio Ollama.</li>
<li><strong>LM_STUDIO_PORT</strong>: Número de puerto para el servicio LM Studio.</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>: Puerto para cualquier servicio LLM adicional personalizado.</li></p><p></ul><strong>Las claves API son totalmente opcionales para el usuario que elija ejecutar LLM localmente, que es el propósito principal de este proyecto. Déjalas vacías si tienes hardware suficiente</strong></p><h3>3. <strong>Inicia Docker</strong></h3></p><p>Asegúrate de que Docker esté instalado y en funcionamiento en tu sistema. Puedes iniciar Docker usando los siguientes comandos:</p><ul><li><strong>En Linux/macOS:</strong>  </li>
    </ul>Abre una terminal y ejecuta:
    <pre><code class="language-sh">    sudo systemctl start docker
    ``<code>
    O lanza Docker Desktop desde el menú de aplicaciones si está instalado.</p><ul><li><strong>En Windows:</strong>  </li>
    </ul>Inicia Docker Desktop desde el menú Inicio.</p><p>Puedes verificar que Docker está funcionando ejecutando:</code></pre>sh
docker info
<pre><code class="language-">Si ves información sobre tu instalación de Docker, está funcionando correctamente.</p><p>Consulta la tabla de <a href="#list-of-local-providers" target="_blank" rel="noopener noreferrer">Proveedores Locales</a> a continuación para un resumen.</p><p>Siguiente paso: <a href="#start-services-and-run" target="_blank" rel="noopener noreferrer">Ejecutar AgenticSeek localmente</a></p><p><em>Consulta la sección de <a href="#troubleshooting" target="_blank" rel="noopener noreferrer">Solución de Problemas</a> si tienes inconvenientes.</em>
<em>Si tu hardware no puede ejecutar LLMs localmente, consulta <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">Configuración para usar con una API</a>.</em>
<em>Para explicaciones detalladas del </code>config.ini<code>, consulta la <a href="#config" target="_blank" rel="noopener noreferrer">Sección de Configuración</a>.</em></p><hr></p><h2>Configuración para ejecutar LLM localmente en tu máquina</h2></p><p><strong>Requisitos de hardware:</strong></p><p>Para ejecutar LLMs localmente, necesitarás hardware suficiente. Como mínimo, se requiere una GPU capaz de ejecutar Magistral, Qwen o Deepseek 14B. Consulta las recomendaciones de modelos/rendimiento en las preguntas frecuentes.</p><p><strong>Configura tu proveedor local</strong></p><p>Inicia tu proveedor local, por ejemplo con ollama:
</code></pre>sh
ollama serve
<pre><code class="language-">
Consulta abajo la lista de proveedores locales soportados.</p><p><strong>Actualiza el config.ini</strong></p><p>Cambia el archivo config.ini para establecer provider_name a un proveedor soportado y provider_model a un LLM soportado por tu proveedor. Recomendamos modelos de razonamiento como <em>Magistral</em> o <em>Deepseek</em>.</p><p>Consulta las <strong>FAQ</strong> al final del README para el hardware requerido.
</code></pre>sh
[MAIN]
is_local = True # Indica si estás ejecutando localmente o con proveedor remoto.
provider_name = ollama # o lm-studio, openai, etc.
provider_model = deepseek-r1:14b # elige un modelo que se ajuste a tu hardware
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # nombre de tu IA
recover_last_session = True # si se recupera la sesión previa
save_session = True # si se recuerda la sesión actual
speak = False # texto a voz
listen = False # voz a texto, solo para CLI, experimental
jarvis_personality = False # si usar una personalidad más tipo "Jarvis" (experimental)
languages = en zh # Lista de idiomas, texto a voz usará el primero por defecto
[BROWSER]
headless_browser = True # déjalo sin cambios salvo que uses CLI en el host.
stealth_mode = True # Usa selenium indetectable para reducir detección de navegador
<pre><code class="language-">
<strong>Advertencia</strong>:</p><ul><li>El formato del archivo </code>config.ini<code> no admite comentarios.</li>
</ul>No copies y pegues la configuración de ejemplo directamente, ya que los comentarios causarán errores. En su lugar, modifica manualmente el archivo </code>config.ini<code> con tus ajustes deseados, excluyendo cualquier comentario.</p><ul><li><em>NO</em> establezcas provider_name en </code>openai<code> si usas LM-studio para ejecutar LLMs. Debe ser </code>lm-studio<code>.</li></p><p><li>Algunos proveedores (ej: lm-studio) requieren que incluyas </code>http://<code> delante de la IP. Por ejemplo </code>http://127.0.0.1:1234<code></li></p><p></ul><strong>Lista de proveedores locales</strong></p><p>| Proveedor    | ¿Local? | Descripción                                                           |
|--------------|---------|-----------------------------------------------------------------------|
| ollama       | Sí      | Ejecuta LLMs localmente fácilmente usando ollama como proveedor LLM   |
| lm-studio    | Sí      | Ejecuta LLM localmente con LM studio (establece </code>provider_name<code> en </code>lm-studio<code>)|
| openai       | Sí      | Usa una API compatible con openai (ej: servidor llama.cpp)            |</p><p>Siguiente paso: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">Iniciar servicios y ejecutar AgenticSeek</a>  </p><p><em>Consulta la sección de <a href="#troubleshooting" target="_blank" rel="noopener noreferrer">Solución de Problemas</a> si tienes inconvenientes.</em>
<em>Si tu hardware no puede ejecutar LLMs localmente, consulta <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">Configuración para usar con una API</a>.</em>
<em>Para explicaciones detalladas del </code>config.ini<code>, consulta la <a href="#config" target="_blank" rel="noopener noreferrer">Sección de Configuración</a>.</em></p><h2>Configuración para usar con una API</h2></p><p>Esta configuración utiliza proveedores LLM externos en la nube. Necesitarás una clave API del servicio elegido.</p><p><strong>1. Elige un proveedor de API y obtén una clave API:</strong></p><p>Consulta la <a href="#list-of-api-providers" target="_blank" rel="noopener noreferrer">Lista de proveedores de API</a> a continuación. Visita sus sitios web para registrarte y obtener una clave API.</p><p><strong>2. Establece tu clave API como variable de entorno:</strong></p><ul><li>  <strong>Linux/macOS:</strong></li>
    </ul>Abre tu terminal y usa el comando </code>export<code>. Es mejor añadir esto al archivo de perfil de tu shell (por ejemplo, </code>~/.bashrc<code>, </code>~/.zshrc<code>) para que sea persistente.
    </code>`<code>sh
    export PROVIDER_API_KEY="tu_clave_api_aquí" 
    # Reemplaza PROVIDER_API_KEY por el nombre específico de la variable, por ejemplo, OPENAI_API_KEY, GOOGLE_API_KEY
    </code>`<code>
    Ejemplo para TogetherAI:
    </code>`<code>sh
    export TOGETHER_API_KEY="xxxxxxxxxxxxxxxxxxxxxx"
    </code>`<code>
<ul><li>  <strong>Windows:</strong></li>
<li>  <strong>Command Prompt (Temporal para la sesión actual):</strong></li>
    </ul></code>`<code>cmd
    set PROVIDER_API_KEY=tu_clave_api_aquí
    </code>`<code>
<ul><li>  <strong>PowerShell (Temporal para la sesión actual):</strong></li>
    </ul></code>`<code>powershell
    $env:PROVIDER_API_KEY="tu_clave_api_aquí"
    </code>`<code>
<ul><li>  <strong>Permanentemente:</strong> Busca "variables de entorno" en la barra de búsqueda de Windows, haz clic en "Editar las variables de entorno del sistema" y luego haz clic en el botón "Variables de entorno...". Añade una nueva variable de usuario con el nombre apropiado (por ejemplo, </code>OPENAI_API_KEY<code>) y tu clave como valor.</li></p><p></ul><em>(Consulta la FAQ: <a href="#how-do-i-set-api-keys" target="_blank" rel="noopener noreferrer">¿Cómo configuro las claves API?</a> para más detalles).</em></p><p>
<strong>3. Actualiza </code>config.ini<code>:</strong></code></pre>ini
[MAIN]
is_local = False
provider_name = openai # O google, deepseek, togetherAI, huggingface
provider_model = gpt-3.5-turbo # O gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 etc.
provider_server_address = # Normalmente se ignora o puede dejarse en blanco cuando is_local = False para la mayoría de APIs
<h1>... otros ajustes ...</h1>
<pre><code class="language-"><em>Advertencia:</em> Asegúrate de que no haya espacios al final de los valores en </code>config.ini<code>.</p><p><strong>Lista de Proveedores de API</strong></p><p>| Proveedor    | </code>provider_name<code> | ¿Local? | Descripción                                        | Enlace de Clave API (Ejemplos)                    |
|--------------|-----------------|---------|----------------------------------------------------|---------------------------------------------------|
| OpenAI       | </code>openai<code>        | No      | Usa modelos ChatGPT vía la API de OpenAI.           | <a href="https://platform.openai.com/signup" target="_blank" rel="noopener noreferrer">platform.openai.com/signup</a> |
| Google Gemini| </code>google<code>        | No      | Usa modelos Google Gemini vía Google AI Studio.     | <a href="https://aistudio.google.com/keys" target="_blank" rel="noopener noreferrer">aistudio.google.com/keys</a> |
| Deepseek     | </code>deepseek<code>      | No      | Usa modelos Deepseek vía su API.                    | <a href="https://platform.deepseek.com" target="_blank" rel="noopener noreferrer">platform.deepseek.com</a> |
| Hugging Face | </code>huggingface<code>   | No      | Usa modelos de la Hugging Face Inference API.       | <a href="https://huggingface.co/settings/tokens" target="_blank" rel="noopener noreferrer">huggingface.co/settings/tokens</a> |
| TogetherAI   | </code>togetherAI<code>    | No      | Usa varios modelos open-source vía la API de TogetherAI.| <a href="https://api.together.ai/settings/api-keys" target="_blank" rel="noopener noreferrer">api.together.ai/settings/api-keys</a> |</p><p><em>Nota:</em>
<ul><li>  Recomendamos no usar </code>gpt-4o<code> u otros modelos de OpenAI para tareas complejas de navegación web y planificación, ya que las optimizaciones actuales de prompts están diseñadas para modelos como Deepseek.</li>
<li>  Las tareas de codificación/bash pueden presentar problemas con Gemini, ya que puede que no siga estrictamente los prompts de formato optimizados para Deepseek.</li>
<li>  El campo </code>provider_server_address<code> en </code>config.ini<code> generalmente no se usa cuando </code>is_local = False<code>, ya que el endpoint de la API suele estar predefinido en la librería del proveedor correspondiente.</li></p><p></ul>Próximo paso: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">Iniciar servicios y ejecutar AgenticSeek</a></p><p><em>Consulta la sección <strong>Problemas conocidos</strong> si tienes inconvenientes</em></p><p><em>Consulta la sección <strong>Config</strong> para una explicación detallada del archivo de configuración.</em></p><hr></p><h2>Iniciar servicios y ejecutar</h2></p><p>Por defecto AgenticSeek se ejecuta completamente en docker.</p><p>Inicia los servicios necesarios. Esto iniciará todos los servicios definidos en docker-compose.yml, incluyendo:
    <ul><li>searxng</li>
    <li>redis (requerido por searxng)</li>
    <li>frontend</li>
    <li>backend (si usas </code>full<code>)</li>
</ul></code></pre>sh
./start_services.sh full # MacOS
start ./start_services.cmd full # Windows
<pre><code class="language-">
<strong>Advertencia:</strong> Este paso descargará y cargará todas las imágenes de Docker, lo cual puede tardar hasta 30 minutos. Después de iniciar los servicios, espera hasta que el servicio backend esté completamente funcionando (deberías ver <strong>backend: "GET /health HTTP/1.1" 200 OK</strong> en el log) antes de enviar cualquier mensaje. El backend puede tardar unos 5 minutos en iniciar en la primera ejecución.</p><p>Ve a </code>http://localhost:3000/<code> y deberías ver la interfaz web.</p><p><em>Solución de problemas al iniciar servicios:</em> Si estos scripts fallan, asegúrate de que Docker Engine esté en ejecución y que Docker Compose (V2, </code>docker compose<code>) esté correctamente instalado. Revisa la salida en la terminal para mensajes de error. Consulta <a href="#faq-troubleshooting" target="_blank" rel="noopener noreferrer">FAQ: ¡Ayuda! Obtengo un error al ejecutar AgenticSeek o sus scripts.</a></p><p><strong>Opcional:</strong> Ejecutar en el host (modo CLI):</p><p>Para ejecutar con interfaz CLI deberás instalar el paquete en el host:
</code></pre>sh
./install.sh
./install.bat # windows
<pre><code class="language-">
Inicia los servicios:
</code></pre>sh
./start_services.sh # MacOS
start ./start_services.cmd # Windows
<pre><code class="language-">
Usa la CLI: </code>python3 cli.py<code></p><hr></p><h2>Uso</h2></p><p>Asegúrate de que los servicios estén activos con </code>./start_services.sh full<code> y accede a </code>localhost:3000<code> para la interfaz web.</p><p>También puedes usar reconocimiento de voz configurando </code>listen = True<code> en el config. Solo para modo CLI.</p><p>Para salir, simplemente di/escribe </code>goodbye<code>.</p><p>Algunos ejemplos de uso:</p><blockquote><em>¡Crea un juego de la serpiente en python!</em></blockquote></p><blockquote><em>Busca en la web los mejores cafés en Rennes, Francia, y guarda una lista de tres con sus direcciones en rennes_cafes.txt.</em></blockquote></p><blockquote><em>Escribe un programa en Go que calcule el factorial de un número, guárdalo como factorial.go en tu espacio de trabajo</em></blockquote></p><blockquote><em>Busca en mi carpeta summer_pictures todos los archivos JPG, renómbralos con la fecha de hoy y guarda una lista de los archivos renombrados en photos_list.txt</em></blockquote></p><blockquote><em>Busca en línea películas populares de ciencia ficción del 2024 y elige tres para ver esta noche. Guarda la lista en movie_night.txt.</em></blockquote></p><blockquote><em>Busca en la web los últimos artículos de noticias de IA de 2025, selecciona tres y escribe un script en Python para extraer sus títulos y resúmenes. Guarda el script como news_scraper.py y los resúmenes en ai_news.txt en /home/projects</em></blockquote></p><blockquote><em>El viernes, busca en la web una API gratuita de precios de acciones, regístrate con supersuper7434567@gmail.com y escribe un script en Python para obtener los precios diarios de Tesla usando la API, guardando los resultados en stock_prices.csv</em></blockquote></p><p><em>Ten en cuenta que las capacidades de llenado de formularios aún son experimentales y podrían fallar.</em></p><p>Después de escribir tu consulta, AgenticSeek asignará el mejor agente para la tarea.</p><p>Dado que este es un prototipo temprano, el sistema de enrutamiento de agentes puede no asignar siempre el agente adecuado según tu consulta.</p><p>Por lo tanto, debes ser muy explícito en lo que deseas y cómo la IA debe proceder; por ejemplo, si quieres que realice una búsqueda web, no digas:</p><p></code>¿Conoces algunos buenos países para viajar solo?<code></p><p>En su lugar, pide:</p><p></code>Haz una búsqueda web y encuentra cuáles son los mejores países para viajar solo<code></p><hr></p><h2><strong>Configuración para ejecutar el LLM en tu propio servidor</strong>  </h2></p><p>Si tienes un ordenador potente o un servidor que puedas usar, pero quieres utilizarlo desde tu laptop, tienes la opción de ejecutar el LLM en un servidor remoto usando nuestro servidor LLM personalizado.</p><p>En tu "servidor" que ejecutará el modelo de IA, obtén la dirección IP
</code></pre>sh
ip a | grep "inet " | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # ip local
curl https://ipinfo.io/ip # ip pública
<pre><code class="language-">
Nota: Para Windows o macOS, utiliza ipconfig o ifconfig respectivamente para encontrar la dirección IP.</p><p>Clona el repositorio y entra en la carpeta </code>server/<code>.</p><p></code></pre>sh
git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
<pre><code class="language-">
Instala los requisitos específicos del servidor:
</code></pre>sh
pip3 install -r requirements.txt
<pre><code class="language-">
Ejecuta el script del servidor.
</code></pre>sh
python3 app.py --provider ollama --port 3333
<pre><code class="language-">
Puedes elegir entre usar </code>ollama<code> y </code>llamacpp<code> como servicio LLM.</p><p>
Ahora en tu ordenador personal:</p><p>Cambia el archivo </code>config.ini<code> para establecer </code>provider_name<code> a </code>server<code> y </code>provider_model<code> a </code>deepseek-r1:xxb<code>.
Configura </code>provider_server_address<code> con la dirección IP de la máquina que ejecutará el modelo.
</code></pre>sh
[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
<pre><code class="language-"></p><p>Próximo paso: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">Iniciar servicios y ejecutar AgenticSeek</a>  </p><hr></p><h2>Reconocimiento de Voz a Texto</h2></p><p>Advertencia: el reconocimiento de voz a texto solo funciona en modo CLI por el momento.</p><p>Ten en cuenta que actualmente el reconocimiento de voz a texto solo funciona en inglés.</p><p>La funcionalidad de reconocimiento de voz a texto está deshabilitada por defecto. Para habilitarla, establece la opción listen a True en el archivo config.ini:
</code></pre>
listen = True
<pre><code class="language-">
Cuando está habilitada, la función de voz a texto escucha una palabra clave de activación, que es el nombre del agente, antes de comenzar a procesar tu entrada. Puedes personalizar el nombre del agente actualizando el valor </code>agent_name<code> en el archivo <em>config.ini</em>:
</code></pre>
agent_name = Friday
<pre><code class="language-">
Para un reconocimiento óptimo, recomendamos usar un nombre inglés común como "John" o "Emma" como nombre del agente.</p><p>Una vez que vea que la transcripción comienza a aparecer, diga el nombre del agente en voz alta para activarlo (por ejemplo, "Friday").</p><p>Hable su consulta claramente.</p><p>Finalice su solicitud con una frase de confirmación para indicar al sistema que debe proceder. Ejemplos de frases de confirmación incluyen:</code></pre>
"hazlo", "adelante", "ejecuta", "corre", "inicia", "gracias", "harías eso", "por favor", "¿vale?", "proceder", "continuar", "sigue", "haz eso", "hazlo", "¿entiendes?"
<pre><code class="language-">
<h2>Configuración</h2></p><p>Ejemplo de configuración:</code></pre>
[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # Ejemplo para Ollama; use http://127.0.0.1:1234 para LM-Studio
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False</p><p>jarvis_personality = False
languages = en zh # Lista de idiomas para TTS y potencialmente enrutamiento.
[BROWSER]
headless_browser = False
stealth_mode = False
<pre><code class="language-">
<strong>Explicación de los ajustes en </code>config.ini<code></strong>:</p><ul><li>  <strong>Sección </code>[MAIN]<code>:</strong></li>
    <li>  </code>is_local<code>: </code>True<code> si utiliza un proveedor LLM local (Ollama, LM-Studio, servidor compatible con OpenAI local) o la opción de servidor autohospedado. </code>False<code> si usa una API en la nube (OpenAI, Google, etc.).</li>
    <li>  </code>provider_name<code>: Especifica el proveedor LLM.</li>
        <li>  Opciones locales: </code>ollama<code>, </code>lm-studio<code>, </code>openai<code> (para servidores locales compatibles con OpenAI), </code>server<code> (para configuración de servidor autohospedado).</li>
        <li>  Opciones de API: </code>openai<code>, </code>google<code>, </code>deepseek<code>, </code>huggingface<code>, </code>togetherAI<code>.</li>
    <li>  </code>provider_model<code>: El nombre o ID del modelo específico para el proveedor elegido (por ejemplo, </code>deepseekcoder:6.7b<code> para Ollama, </code>gpt-3.5-turbo<code> para OpenAI API, </code>mistralai/Mixtral-8x7B-Instruct-v0.1<code> para TogetherAI).</li>
    <li>  </code>provider_server_address<code>: La dirección de su proveedor LLM.</li>
        <li>  Para proveedores locales: por ejemplo, </code>http://127.0.0.1:11434<code> para Ollama, </code>http://127.0.0.1:1234<code> para LM-Studio.</li>
        <li>  Para el tipo de proveedor </code>server<code>: La dirección de su servidor LLM autohospedado (por ejemplo, </code>http://your_server_ip:3333<code>).</li>
        <li>  Para APIs en la nube (</code>is_local = False<code>): Normalmente se ignora o puede dejarse en blanco, ya que el endpoint API suele ser gestionado por la librería cliente.</li>
    <li>  </code>agent_name<code>: Nombre del asistente de IA (por ejemplo, Friday). Se utiliza como palabra clave para activación por voz si está habilitado.</li>
    <li>  </code>recover_last_session<code>: </code>True<code> para intentar restaurar el estado de la sesión anterior, </code>False<code> para comenzar de nuevo.</li>
    <li>  </code>save_session<code>: </code>True<code> para guardar el estado de la sesión actual para una posible recuperación, </code>False<code> en caso contrario.</li>
    <li>  </code>speak<code>: </code>True<code> para habilitar la salida de voz por texto a voz, </code>False<code> para deshabilitarla.</li>
    <li>  </code>listen<code>: </code>True<code> para habilitar la entrada de voz a texto (solo en modo CLI), </code>False<code> para deshabilitarla.</li>
    <li>  </code>work_dir<code>: <strong>Crucial:</strong> El directorio donde AgenticSeek leerá/escribirá archivos. <strong>Asegúrese de que esta ruta sea válida y accesible en su sistema.</strong></li>
    <li>  </code>jarvis_personality<code>: </code>True<code> para usar un prompt de sistema más tipo "Jarvis" (experimental), </code>False<code> para el prompt estándar.</li>
    <li>  </code>languages<code>: Una lista separada por comas de idiomas (por ejemplo, </code>en, zh, fr<code>). Se usa para la selección de voz TTS (por defecto el primero) y puede ayudar al enrutador LLM. Evite demasiados idiomas o muy similares para la eficiencia del enrutador.</li>
<li>  <strong>Sección </code>[BROWSER]<code>:</strong></li>
    <li>  </code>headless_browser<code>: </code>True<code> para ejecutar el navegador automatizado sin ventana visible (recomendado para interfaz web o uso no interactivo). </code>False<code> para mostrar la ventana del navegador (útil para modo CLI o depuración).</li>
    <li>  </code>stealth_mode<code>: </code>True<code> para habilitar medidas que dificultan la detección de la automatización del navegador. Puede requerir la instalación manual de extensiones como anticaptcha.</li></p><p>
</ul>Esta sección resume los tipos de proveedores LLM soportados. Configúrelos en </code>config.ini<code>.</p><p><strong>Proveedores locales (Ejecutados en su propio hardware):</strong></p><p>| Nombre del proveedor en </code>config.ini<code> | </code>is_local<code> | Descripción                                                                 | Sección de configuración                                                    |
|--------------------------------------|------------|-----------------------------------------------------------------------------|----------------------------------------------------------------------------|
| </code>ollama<code>                            | </code>True<code>     | Use Ollama para servir LLMs locales.                                        | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">Configuración para ejecutar LLM localmente</a> |
| </code>lm-studio<code>                         | </code>True<code>     | Use LM-Studio para servir LLMs locales.                                     | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">Configuración para ejecutar LLM localmente</a> |
| </code>openai<code> (para servidor local)       | </code>True<code>     | Conéctese a un servidor local que exponga una API compatible con OpenAI (por ejemplo, llama.cpp). | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">Configuración para ejecutar LLM localmente</a> |
| </code>server<code>                            | </code>False<code>    | Conéctese al servidor LLM autohospedado de AgenticSeek ejecutándose en otra máquina. | <a href="#setup-to-run-the-llm-on-your-own-server" target="_blank" rel="noopener noreferrer">Configuración para ejecutar el LLM en su propio servidor</a> |</p><p><strong>Proveedores de API (En la nube):</strong></p><p>| Nombre del proveedor en </code>config.ini<code> | </code>is_local<code> | Descripción                                      | Sección de configuración                              |
|--------------------------------------|------------|--------------------------------------------------|-------------------------------------------------------|
| </code>openai<code>                            | </code>False<code>    | Use la API oficial de OpenAI (por ejemplo, GPT-3.5, GPT-4). | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">Configuración para usar una API</a> |
| </code>google<code>                            | </code>False<code>    | Use los modelos Gemini de Google vía API.         | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">Configuración para usar una API</a> |
| </code>deepseek<code>                          | </code>False<code>    | Use la API oficial de Deepseek.                   | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">Configuración para usar una API</a> |
| </code>huggingface<code>                       | </code>False<code>    | Use la API de Inferencia de Hugging Face.         | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">Configuración para usar una API</a> |
| </code>togetherAI<code>                        | </code>False<code>    | Use la API de TogetherAI para varios modelos open.| <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">Configuración para usar una API</a> |</p><hr>
<h2>Solución de problemas</h2></p><p>Si encuentra problemas, esta sección proporciona orientación.</p><h1>Problemas conocidos</h1></p><h2>Problemas con ChromeDriver</h2></p><p><strong>Ejemplo de error:</strong> </code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX<code></p><ul><li>  <strong>Causa:</strong> La versión de ChromeDriver instalada no es compatible con la versión de su navegador Google Chrome.</li>
<li>  <strong>Solución:</strong></li>
    <li> <strong>Verifique la versión de Chrome:</strong> Abra Google Chrome, vaya a </code>Configuración > Acerca de Chrome<code> para encontrar la versión (por ejemplo, "Versión 120.0.6099.110").</li>
    <li> <strong>Descargue el ChromeDriver correspondiente:</strong></li>
        <li>  Para versiones de Chrome 115 y superiores: Vaya a los <a href="https://googlechromelabs.github.io/chrome-for-testing/" target="_blank" rel="noopener noreferrer">Chrome for Testing (CfT) JSON Endpoints</a>. Busque el canal "stable" y descargue el ChromeDriver para su SO que coincida con la versión principal de su Chrome.</li>
        <li>  Para versiones antiguas (menos común): Puede encontrarlas en la página de <a href="https://chromedriver.chromium.org/downloads" target="_blank" rel="noopener noreferrer">ChromeDriver - WebDriver for Chrome</a>.</li>
        <li>  La imagen a continuación muestra un ejemplo de la página CfT:</li>
            </ul><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="Descargue una versión específica de Chromedriver desde la página Chrome for Testing">
    <ul><li> <strong>Instale ChromeDriver:</strong></li>
        <li>  Asegúrese de que el </code>chromedriver<code> descargado (o </code>chromedriver.exe<code> en Windows) esté en un directorio incluido en la variable de entorno PATH de su sistema (por ejemplo, </code>/usr/local/bin<code> en Linux/macOS, o una carpeta de scripts personalizada añadida a PATH en Windows).</li>
        <li>  Alternativamente, colóquelo en el directorio raíz del proyecto </code>agenticSeek<code>.</li>
        <li>  Asegúrese de que el driver sea ejecutable (por ejemplo, </code>chmod +x chromedriver<code> en Linux/macOS).</li>
    <li> Consulte la sección <a href="#chromedriver-installation" target="_blank" rel="noopener noreferrer">Instalación de ChromeDriver</a> en la guía principal de instalación para más detalles.</li></p><p></ul>Si esta sección está incompleta o encuentra otros problemas con ChromeDriver, considere buscar en los <a href="https://github.com/Fosowl/agenticSeek/issues" target="_blank" rel="noopener noreferrer">Issues de GitHub</a> existentes o crear uno nuevo.</p><p></code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113
Current browser version is 134.0.6998.89 with binary path<code></p><p>Esto ocurre si hay un desajuste entre su versión de navegador y la versión de chromedriver.</p><p>Debe ir a descargar la versión más reciente:</p><p>https://developer.chrome.com/docs/chromedriver/downloads</p><p>Si está usando Chrome versión 115 o superior vaya a:</p><p>https://googlechromelabs.github.io/chrome-for-testing/</p><p>Y descargue la versión de chromedriver que coincida con su SO.</p><p><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="texto alternativo"></p><p>Si esta sección está incompleta por favor cree un issue.</p><h2>Problemas de adaptadores de conexión</h2>
</code></pre>
Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'</code> (Nota: el puerto puede variar)
<pre><code class="language-">
<ul><li>  <strong>Causa:</strong> La variable <code>provider_server_address</code> en <code>config.ini</code> para <code>lm-studio</code> (u otros servidores similares compatibles con OpenAI locales) no tiene el prefijo <code>http://</code> o apunta al puerto incorrecto.</li>
<li>  <strong>Solución:</strong></li>
    <li>  Asegúrese de que la dirección incluya <code>http://</code>. LM-Studio normalmente usa por defecto <code>http://127.0.0.1:1234</code>.</li>
    <li>  Corrija en <code>config.ini</code>: <code>provider_server_address = http://127.0.0.1:1234</code> (o el puerto real de su servidor LM-Studio).</li></p><p></ul><h2>URL base de SearxNG no proporcionada</h2>
</code></pre>
raise ValueError("SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.")
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.<code>
</code>`<code></p><h2>FAQ</h2></p><p><strong>P: ¿Qué hardware necesito?</strong>  </p><p>| Tamaño del modelo | GPU  | Comentario                                               |
|-------------------|------|---------------------------------------------------------|
| 7B                | 8GB Vram | ⚠️ No recomendado. Bajo rendimiento, frecuentes alucinaciones, y los agentes planificadores probablemente fallarán. |
| 14B               | 12 GB VRAM (ej. RTX 3060) | ✅ Usable para tareas simples. Puede tener problemas con navegación web y tareas de planificación. |
| 32B               | 24+ GB VRAM (ej. RTX 4090) | 🚀 Éxito en la mayoría de tareas, aún puede tener dificultades en planificación de tareas |
| 70B+              | 48+ GB Vram | 💪 Excelente. Recomendado para casos de uso avanzados. |</p><p><strong>P: Me aparece un error, ¿qué hago?</strong>  </p><p>Asegúrese de que el local esté en ejecución (</code>ollama serve<code>), que su </code>config.ini` coincida con su proveedor, y que las dependencias estén instaladas. Si nada funciona, siéntase libre de crear un issue.</p><p><strong>P: ¿Realmente puede funcionar 100% localmente?</strong>  </p><p>Sí, con Ollama, lm-studio o servidores, todos los modelos de voz a texto, LLM y texto a voz se ejecutan localmente. Las opciones no locales (OpenAI u otras APIs) son opcionales.</p><p><strong>P: ¿Por qué debería usar AgenticSeek si ya tengo Manus?</strong></p><p>A diferencia de Manus, AgenticSeek prioriza la independencia de sistemas externos, dándole más control, privacidad y evitando costos de API.</p><p><strong>P: ¿Quién está detrás del proyecto?</strong></p><p>El proyecto fue creado por mí, junto a dos amigos que actúan como mantenedores y colaboradores de la comunidad open-source en GitHub. Solo somos un grupo de personas apasionadas, no una startup ni afiliados a ninguna organización.</p><p>Cualquier cuenta de AgenticSeek en X que no sea mi cuenta personal (https://x.com/Martin993886460) es una suplantación.</p><h2>Contribuir</h2></p><p>¡Buscamos desarrolladores para mejorar AgenticSeek! Consulte los issues abiertos o las discusiones.</p><p><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">Guía de contribución</a></p><p><a href="https://www.star-history.com/#Fosowl/agenticSeek&Date" target="_blank" rel="noopener noreferrer"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&type=Date" alt="Gráfico de estrellas históricas"></a></p><h2>Mantenedores:</h2></p><p> > <a href="https://github.com/Fosowl" target="_blank" rel="noopener noreferrer">Fosowl</a> | Hora de París </p><p> > <a href="https://github.com/antoineVIVIES" target="_blank" rel="noopener noreferrer">antoineVIVIES</a> | Hora de Taipéi </p><p> > <a href="https://github.com/steveh8758" target="_blank" rel="noopener noreferrer">steveh8758</a> | Hora de Taipéi </p><h2>Agradecimientos especiales:</h2></p><p> > <a href="https://github.com/tcsenpai" target="_blank" rel="noopener noreferrer">tcsenpai</a> y <a href="https://github.com/plitc" target="_blank" rel="noopener noreferrer">plitc</a> por ayudar con la dockerización del backend</p><h2>Patrocinadores:</h2></p><p>Patrocinadores mensuales de 5$ o más aparecen aquí:
<ul><li><strong>tatra-labs</strong></li></p><p></ul>Certainly! Please provide the text for Part 4 of 4 so I can translate it as requested.

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-16

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>