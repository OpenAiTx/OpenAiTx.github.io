<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>agenticSeek - Read agenticSeek documentation in Japanese. This project has 18325 stars on GitHub.</title>
    <meta name="description" content="Read agenticSeek documentation in Japanese. This project has 18325 stars on GitHub.">
    <meta name="keywords" content="agenticSeek, Japanese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "agenticSeek",
  "description": "Read agenticSeek documentation in Japanese. This project has 18325 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "Fosowl"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 18325
  },
  "url": "https://OpenAiTx.github.io/projects/Fosowl/agenticSeek/README-ja.html",
  "sameAs": "https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/Fosowl/agenticSeek" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    agenticSeek
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 18325 stars</span>
                <span class="language">Japanese</span>
                <span>by Fosowl</span>
            </div>
        </div>
        
        <div class="content">
            <h1>AgenticSeek: プライベート・ローカル Manus 代替</h1></p><p><p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
<p>  English | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md" target="_blank" rel="noopener noreferrer">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md" target="_blank" rel="noopener noreferrer">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md" target="_blank" rel="noopener noreferrer">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md" target="_blank" rel="noopener noreferrer">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md" target="_blank" rel="noopener noreferrer">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md" target="_blank" rel="noopener noreferrer">Español</a></p><ul><li><strong>100%ローカルなManus AIの代替。</strong> この音声対応AIアシスタントは、すべてのデータをデバイス上に保持しながら、自律的にウェブを閲覧し、コードを書き、タスクを計画します。ローカル推論モデル向けに最適化されており、完全に自分のハードウェア上で動作し、完全なプライバシーとクラウド依存ゼロを保証します。</li></p><p></ul><a href="https://fosowl.github.io/agenticSeek.html" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?label=Website&message=AgenticSeek&color=blue&style=flat-square" alt="Visit AgenticSeek"></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License"> <a href="https://discord.gg/8hGDaME3TC" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&logoColor=white" alt="Discord"></a> <a href="https://x.com/Martin993886460" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&label=Update%20%40Fosowl" alt="Twitter"></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars"></a></p><h3>なぜAgenticSeekなのか？</h3></p><ul><li>🔒 完全ローカル＆プライベート - すべてがあなたのマシン上で動作します。クラウドなし、データ共有なし。ファイル、会話、検索内容はすべてプライベートに保たれます。</li></p><p><li>🌐 スマートなウェブブラウジング - AgenticSeekは自動でインターネットを閲覧できます。検索、読取、情報抽出、ウェブフォームへの入力もハンズフリーで可能です。</li></p><p><li>💻 自律型コーディングアシスタント - コードが必要ですか？Python、C、Go、Javaなどのプログラムを自動で作成、デバッグ、実行できます。</li></p><p><li>🧠 スマートエージェント選択 - あなたが依頼すれば、自動的に最適なエージェントを選択します。まるで専門家チームが常に助けてくれるようです。</li></p><p><li>📋 複雑なタスクの計画と実行 - 旅行計画から複雑なプロジェクトまで、大きなタスクをステップに分解し、複数のAIエージェントを使って完遂します。</li></p><p><li>🎙️ 音声対応 - クリアで高速、未来的な音声認識・テキスト変換機能により、まるでSF映画のAIのように会話できます。（開発中）</li></p><p></ul><h3><strong>デモ</strong></h3></p><blockquote><em>agenticSeekプロジェクトを検索し、必要なスキルを調べてからCV_candidates.zipを開き、プロジェクトに最も合致する候補者を教えてください</em></blockquote></p><p>https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</p><p>免責事項：このデモに登場する全てのファイル（例：CV_candidates.zip）は完全なフィクションです。私たちは法人ではなく、候補者でなくオープンソースのコントリビューターを募集しています。</p><blockquote>🛠⚠️️ <strong>活発な開発中</strong></blockquote></p><blockquote>🙏 このプロジェクトはサイドプロジェクトとして始まり、ロードマップも資金もありません。GitHub Trending入りで想像以上に成長しました。貢献・フィードバック・ご辛抱に深く感謝します。</blockquote></p><h2>前提条件</h2></p><p>開始する前に、以下のソフトウェアがインストールされていることを確認してください：</p><ul><li>  <strong>Git:</strong> リポジトリのクローン用。<a href="https://git-scm.com/downloads" target="_blank" rel="noopener noreferrer">Gitをダウンロード</a></li>
<li>  <strong>Python 3.10.x:</strong> Python 3.10.xバージョンを強く推奨します。他のバージョンでは依存関係エラーが発生することがあります。<a href="https://www.python.org/downloads/release/python-3100/" target="_blank" rel="noopener noreferrer">Python 3.10をダウンロード</a>（3.10.xバージョンを選択）</li>
<li>  <strong>Docker Engine & Docker Compose:</strong> SearxNGなどのバンドルサービス用。</li>
    <li>  Docker Desktop（Docker Compose V2を含む）をインストール：<a href="https://docs.docker.com/desktop/install/windows-install/" target="_blank" rel="noopener noreferrer">Windows</a> | <a href="https://docs.docker.com/desktop/install/mac-install/" target="_blank" rel="noopener noreferrer">Mac</a> | <a href="https://docs.docker.com/desktop/install/linux-install/" target="_blank" rel="noopener noreferrer">Linux</a></li>
    <li>  またはLinuxでDocker EngineとDocker Composeを個別にインストール：<a href="https://docs.docker.com/engine/install/" target="_blank" rel="noopener noreferrer">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/" target="_blank" rel="noopener noreferrer">Docker Compose</a>（必ずCompose V2をインストール、例：<code>sudo apt-get install docker-compose-plugin</code>）</li></p><p></ul><h3>1. <strong>リポジトリのクローンとセットアップ</strong></h3></p><pre><code class="language-sh">git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env</code></pre></p><h3>2. .envファイルの内容を変更</h3></p><pre><code class="language-sh">SEARXNG_BASE_URL="http://127.0.0.1:8080"
REDIS_BASE_URL="redis://redis:6379/0"
WORK_DIR="/Users/mlg/Documents/workspace_for_ai"
OLLAMA_PORT="11434"
LM_STUDIO_PORT="1234"
CUSTOM_ADDITIONAL_LLM_PORT="11435"
OPENAI_API_KEY='optional'
DEEPSEEK_API_KEY='optional'
OPENROUTER_API_KEY='optional'
TOGETHER_API_KEY='optional'
GOOGLE_API_KEY='optional'
ANTHROPIC_API_KEY='optional'</code></pre></p><p>必要に応じて <code>.env</code> ファイルを自分の値に更新してください：</p><ul><li><strong>SEARXNG_BASE_URL</strong>: 変更不要 </li>
<li><strong>REDIS_BASE_URL</strong>: 変更不要 </li>
<li><strong>WORK_DIR</strong>: ローカルマシン上の作業ディレクトリへのパス。AgenticSeekがこれらのファイルを読み書きできます。</li>
<li><strong>OLLAMA_PORT</strong>: Ollamaサービス用のポート番号。</li>
<li><strong>LM_STUDIO_PORT</strong>: LM Studioサービス用のポート番号。</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>: 追加のカスタムLLMサービス用のポート。</li></p><p></ul><strong>APIキーはローカルでLLMを動作させる場合は完全に任意です。本プロジェクトの主目的です。十分なハードウェアがある場合は空欄でOKです。</strong></p><h3>3. <strong>Dockerを起動</strong></h3></p><p>Dockerがインストールされ、システムで起動していることを確認してください。以下のコマンドでDockerを起動できます：</p><ul><li><strong>Linux/macOSの場合:</strong>  </li>
    </ul>ターミナルを開いて以下を実行：
    <pre><code class="language-sh">    sudo systemctl start docker
    ``<code>
    または、インストール済みの場合はアプリケーションメニューからDocker Desktopを起動。</p><ul><li><strong>Windowsの場合:</strong>  </li>
    </ul>スタートメニューからDocker Desktopを起動。</p><p>Dockerが動作しているかを確認するには、以下を実行：</code></pre>sh
docker info
<pre><code class="language-">Dockerインストール情報が表示されれば、正常に動作しています。</p><p>下記の<a href="#list-of-local-providers" target="_blank" rel="noopener noreferrer">ローカルプロバイダー一覧</a>を参照してください。</p><p>次のステップ：<a href="#start-services-and-run" target="_blank" rel="noopener noreferrer">AgenticSeekをローカルで実行</a></p><p><em>問題が発生した場合は<a href="#troubleshooting" target="_blank" rel="noopener noreferrer">トラブルシューティング</a>セクションを参照してください。</em>
<em>ハードウェアがローカルLLMに対応していない場合は<a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">APIでの実行セットアップ</a>を参照してください。</em>
<em>詳しい</code>config.ini<code>の説明は<a href="#config" target="_blank" rel="noopener noreferrer">Configセクション</a>を参照してください。</em></p><hr></p><h2>LLMをローカルマシンで実行するセットアップ</h2></p><p><strong>ハードウェア要件:</strong></p><p>LLMをローカルで動作させるには十分なハードウェアが必要です。最低でもMagistral、Qwen、Deepseek 14Bが動作するGPUが必要です。詳しいモデル・パフォーマンスの推奨はFAQを参照してください。</p><p><strong>ローカルプロバイダーの起動</strong></p><p>例としてollamaを起動する場合：
</code></pre>sh
ollama serve
<pre><code class="language-">
対応するローカルプロバイダーの一覧は下記参照。</p><p><strong>config.iniの更新</strong></p><p>config.iniファイルのprovider_nameを対応プロバイダーに、provider_modelを利用したいLLMモデル名に設定します。推論モデル（<em>Magistral</em>や<em>Deepseek</em>など）を推奨します。</p><p>必要ハードウェアはREADME末尾の<strong>FAQ</strong>参照。
</code></pre>sh
[MAIN]
is_local = True # ローカルまたはリモートプロバイダーの使用を選択
provider_name = ollama # lm-studio, openaiなども可
provider_model = deepseek-r1:14b # ハードウェアに合ったモデルを選択
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # AIの名前
recover_last_session = True # 前回セッションの復元
save_session = True # 現在のセッションを保存
speak = False # テキスト読み上げ
listen = False # 音声認識（CLIのみ、実験的）
jarvis_personality = False # Jarvis風パーソナリティ使用（実験的）
languages = en zh # 言語リスト、TTSはリスト先頭をデフォルト使用
[BROWSER]
headless_browser = True # CLIでの利用を除き変更不要
stealth_mode = True # ブラウザ検出防止のため未検出Seleniumを使用
<pre><code class="language-">
<strong>注意:</strong></p><ul><li></code>config.ini<code>の書式はコメントをサポートしていません。 </li>
</ul>例の設定をそのままコピー＆ペーストしないでください。コメントがエラーとなります。必要な設定のみ手動で編集してください。</p><ul><li>LM-studioでLLMを起動する場合、</code>provider_name<code>を</code>openai<code>に設定しないでください。</code>lm-studio<code>に設定してください。</li></p><p><li>一部プロバイダー（例：lm-studio）はIPの前に</code>http://<code>が必要です。例：</code>http://127.0.0.1:1234<code></li></p><p></ul><strong>ローカルプロバイダー一覧</strong></p><p>| プロバイダー  | ローカル対応 | 説明                                               |
|-----------|--------|-----------------------------------------------------------|
| ollama    | はい    | ollamaをLLMプロバイダーとして使い、簡単にローカルLLM実行       |
| lm-studio  | はい    | LM StudioでローカルLLM実行（</code>provider_name<code>は</code>lm-studio<code>に設定）|
| openai    | はい     | openai互換API使用（例：llama.cppサーバー）  |</p><p>次のステップ：<a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">AgenticSeekのサービス開始・実行</a>  </p><p><em>問題が発生した場合は<a href="#troubleshooting" target="_blank" rel="noopener noreferrer">トラブルシューティング</a>セクションを参照してください。</em>
<em>ハードウェアがローカルLLMに対応していない場合は<a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">APIでの実行セットアップ</a>を参照してください。</em>
<em>詳しい</code>config.ini<code>の説明は<a href="#config" target="_blank" rel="noopener noreferrer">Configセクション</a>を参照してください。</em></p><h2>APIでの実行セットアップ</h2></p><p>このセットアップでは、外部クラウドベースのLLMプロバイダーを利用します。選択したサービスのAPIキーが必要です。</p><p><strong>1. APIプロバイダーを選択しAPIキーを取得:</strong></p><p><a href="#list-of-api-providers" target="_blank" rel="noopener noreferrer">APIプロバイダー一覧</a>を参照し、各ウェブサイトでサインアップしAPIキーを取得してください。</p><p><strong>2. APIキーを環境変数として設定:</strong></p><ul><li>  <strong>Linux/macOS:</strong></li>
    </ul>ターミナルを開き、</code>export<code>コマンドを利用。永続化にはシェルのプロファイルファイル（例：</code>~/.bashrc<code>, </code>~/.zshrc<code>）に追加するのが最適です。
    </code>`<code>sh
    export PROVIDER_API_KEY="your_api_key_here" 
    # PROVIDER_API_KEYは各サービスの変数名（例：OPENAI_API_KEY, GOOGLE_API_KEY）に置き換えてください
    </code>`<code>
    TogetherAIの例：
    </code>`<code>sh
    export TOGETHER_API_KEY="xxxxxxxxxxxxxxxxxxxxxx"
    </code>`<code>
<ul><li>  <strong>Windows:</strong></li>
<li>  <strong>コマンドプロンプト（現在のセッションのみ一時的に設定）:</strong></li>
    </ul></code>`<code>cmd
    set PROVIDER_API_KEY=your_api_key_here
    </code>`<code>
<ul><li>  <strong>PowerShell（現在のセッションのみ一時的に設定）:</strong></li>
    </ul></code>`<code>powershell
    $env:PROVIDER_API_KEY="your_api_key_here"
    </code>`<code>
<ul><li>  <strong>永続的に設定:</strong> Windowsの検索バーで「環境変数」と検索し、「システム環境変数の編集」をクリックして、「環境変数...」ボタンを押します。適切な名前（例: </code>OPENAI_API_KEY<code>）と値（APIキー）で新しいユーザー変数を追加してください。</li></p><p></ul><em>（詳細はFAQ: <a href="#how-do-i-set-api-keys" target="_blank" rel="noopener noreferrer">APIキーの設定方法</a> を参照してください）。</em></p><p>
<strong>3. </code>config.ini<code> の更新:</strong></code></pre>ini
[MAIN]
is_local = False
provider_name = openai # または google, deepseek, togetherAI, huggingface
provider_model = gpt-3.5-turbo # または gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 など
provider_server_address = # 通常、is_local = False の場合はほとんどのAPIで無視されるか空欄でOK
<h1>... その他の設定 ...</h1>
<pre><code class="language-"><em>警告:</em> </code>config.ini<code> の値に末尾スペースが無いことを確認してください。</p><p><strong>APIプロバイダー一覧</strong></p><p>| プロバイダー   | </code>provider_name<code> | ローカル? | 説明                                              | APIキーリンク（例）                        |
|----------------|-----------------|-----------|--------------------------------------------------|---------------------------------------------|
| OpenAI         | </code>openai<code>        | いいえ    | OpenAIのAPI経由でChatGPTモデルを使用              | <a href="https://platform.openai.com/signup" target="_blank" rel="noopener noreferrer">platform.openai.com/signup</a> |
| Google Gemini  | </code>google<code>        | いいえ    | Google AI Studio経由でGoogle Geminiモデルを使用   | <a href="https://aistudio.google.com/keys" target="_blank" rel="noopener noreferrer">aistudio.google.com/keys</a> |
| Deepseek       | </code>deepseek<code>      | いいえ    | DeepseekのAPI経由でDeepseekモデルを使用           | <a href="https://platform.deepseek.com" target="_blank" rel="noopener noreferrer">platform.deepseek.com</a> |
| Hugging Face   | </code>huggingface<code>   | いいえ    | Hugging Face Inference API経由でモデルを使用      | <a href="https://huggingface.co/settings/tokens" target="_blank" rel="noopener noreferrer">huggingface.co/settings/tokens</a> |
| TogetherAI     | </code>togetherAI<code>    | いいえ    | TogetherAI API経由で様々なOSSモデルを利用可能     | <a href="https://api.together.ai/settings/api-keys" target="_blank" rel="noopener noreferrer">api.together.ai/settings/api-keys</a> |</p><p><em>注意:</em>
<ul><li>  複雑なウェブブラウジングやタスク計画には、現在のプロンプト最適化はDeepseek向けのため、</code>gpt-4o<code>や他のOpenAIモデルの利用は推奨しません。</li>
<li>  コーディングやbashのタスクはGeminiではDeepseek向けの書式に厳密に従わない可能性があり、問題が発生する場合があります。</li>
<li>  </code>config.ini<code> の </code>provider_server_address<code> は、</code>is_local = False<code> の場合、APIエンドポイントが各プロバイダーのライブラリでハードコーディングされているため通常使用しません。</li></p><p></ul>次のステップ: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">サービスの起動とAgenticSeekの実行</a></p><p><em>問題が発生した場合は「<strong>既知の問題</strong>」セクションを参照してください。</em></p><p><em>詳細な設定ファイルの説明は「<strong>Config</strong>」セクションを参照してください。</em></p><hr></p><h2>サービスの起動と実行</h2></p><p>デフォルトでは、AgenticSeekはすべてDocker内で実行されます。</p><p>必要なサービスを起動します。これによりdocker-compose.ymlから以下のすべてのサービスが起動します:
    <ul><li>searxng</li>
    <li>redis（searxngに必須）</li>
    <li>frontend</li>
    <li>backend（</code>full<code>を使用する場合）</li>
</ul></code></pre>sh
./start_services.sh full # MacOS
start ./start_services.cmd full # Window
<pre><code class="language-">
<strong>警告:</strong> このステップで全てのDockerイメージのダウンロード・ロードが行われ、最大30分かかる場合があります。サービス起動後、バックエンドサービスが完全に起動するまで（ログに <strong>backend: "GET /health HTTP/1.1" 200 OK</strong> と表示されるまで）メッセージの送信はお待ちください。初回起動時はバックエンドサービスの起動に最大5分かかることがあります。</p><p></code>http://localhost:3000/<code> にアクセスするとWebインターフェースが表示されます。</p><p><em>サービス起動時のトラブルシューティング:</em> これらのスクリプトが失敗する場合は、Docker Engineが起動しており、Docker Compose（V2, </code>docker compose<code>）が正しくインストールされていることを確認してください。エラーメッセージは端末の出力を確認してください。<a href="#faq-troubleshooting" target="_blank" rel="noopener noreferrer">FAQ: AgenticSeekやスクリプト実行時にエラーが出る場合の対処法</a>も参照してください。</p><p><strong>オプション:</strong> ホスト（CLIモード）での実行</p><p>CLIインターフェースで実行するには、ホストにパッケージをインストールしてください:
</code></pre>sh
./install.sh
./install.bat # windows
<pre><code class="language-">
サービスを起動します:
</code></pre>sh
./start_services.sh # MacOS
start ./start_services.cmd # Window
<pre><code class="language-">
CLIの利用: </code>python3 cli.py<code></p><hr></p><h2>利用方法</h2></p><p></code>./start_services.sh full<code> でサービスが稼働していることを確認し、Webインターフェースは </code>localhost:3000<code> で利用できます。</p><p>CLIモードのみ、configで </code>listen = True<code> に設定することで音声認識（speech to text）も利用可能です。</p><p>終了するには、単に </code>goodbye<code> と発話または入力してください。</p><p>利用例:</p><blockquote><em>pythonでスネークゲームを作って！</em></blockquote></p><blockquote><em>フランス・レンヌのトップカフェをWeb検索し、3つを住所付きでrennes_cafes.txtに保存して。</em></blockquote></p><blockquote><em>Goで階乗を計算するプログラムを書き、factorial.goとしてワークスペースに保存して</em></blockquote></p><blockquote><em>summer_picturesフォルダー内の全JPGファイルを今日の日付でリネームし、リネーム後のファイル一覧をphotos_list.txtに保存</em></blockquote></p><blockquote><em>2024年の人気SF映画をネットで調べて、今夜観る3本を選んで。リストをmovie_night.txtに保存。</em></blockquote></p><blockquote><em>2025年の最新AIニュース記事をネット検索し、3つ選んで、それらのタイトルと要約をスクレイピングするPythonスクリプトを書いて。スクリプトはnews_scraper.py、要約は/home/projectsのai_news.txtに保存</em></blockquote></p><blockquote><em>金曜日、無料の株価APIをWebで探し、supersuper7434567@gmail.comで登録、そのAPIでテスラの日次株価を取得するPythonスクリプトを書いて、結果をstock_prices.csvに保存</em></blockquote></p><p><em>なお、フォーム入力の自動化は実験的機能のため失敗する場合があります。</em></p><p>クエリを入力すると、AgenticSeekがタスクに最適なエージェントを割り当てます。</p><p>本プロトタイプは初期段階のため、エージェントルーティングが必ずしも最適なものとは限りません。</p><p>そのため、AIにしてほしいことや進め方をできるだけ明確に伝えてください。例えばWeb検索させたい場合は、</p><p></code>Do you know some good countries for solo-travel?<code></p><p>のように曖昧にせず、</p><p></code>Do a web search and find out which are the best country for solo-travel<code></p><p>のように具体的に指示しましょう。</p><hr></p><h2><strong>LLMを自分のサーバーで動かす設定</strong>  </h2></p><p>高性能なコンピュータやサーバーがあり、それをノートPCから利用したい場合は、独自のllmサーバーでLLMをリモート実行できます。</p><p>AIモデルを動かす「サーバー」でIPアドレスを取得します。
</code></pre>sh
ip a | grep "inet " | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # ローカルIP
curl https://ipinfo.io/ip # グローバルIP
<pre><code class="language-">
注: WindowsやmacOSの場合は、それぞれipconfigやifconfigでIPアドレスを確認してください。</p><p>リポジトリをクローンし、</code>server/<code>フォルダーに移動します。
</code></pre>sh
git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
<pre><code class="language-">
サーバー用の要件をインストール:
</code></pre>sh
pip3 install -r requirements.txt
<pre><code class="language-">
サーバースクリプトを実行します。
</code></pre>sh
python3 app.py --provider ollama --port 3333
<pre><code class="language-">
</code>ollama<code>または</code>llamacpp<code>をLLMサービスとして利用可能です。</p><p>
次に、個人PC側で:</p><p></code>config.ini<code>ファイルの</code>provider_name<code>を</code>server<code>、</code>provider_model<code>を</code>deepseek-r1:xxb<code>に設定します。
</code>provider_server_address<code>にはモデルを動かすマシンのIPアドレスを設定します。
</code></pre>sh
[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
<pre><code class="language-"></p><p>次のステップ: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">サービスの起動とAgenticSeekの実行</a>  </p><hr></p><h2>音声認識（Speech to Text）</h2></p><p>注意: 音声認識は現状CLIモードのみ対応です。</p><p>現時点では音声認識は英語のみ対応しています。</p><p>音声認識はデフォルトで無効です。有効にするには、config.iniのlistenオプションをTrueに設定してください:
</code></pre>
listen = True
<pre><code class="language-">
有効にすると、音声認識は入力処理の前にトリガーワード（エージェント名）を待ち受けます。エージェント名は<em>config.ini</em>ファイルの </code>agent_name<code> 値を更新してカスタマイズできます:
</code></pre>
agent_name = Friday
<pre><code class="language-">
最適な認識のため、エージェント名には「John」や「Emma」などの一般的な英語名を使用することを推奨します。</p><p>トランスクリプトが表示され始めたら、エージェント名（例：「Friday」）を声に出して呼びかけて起動します。</p><p>質問ははっきりと話してください。</p><p>リクエストの最後に、システムに処理を進めるよう伝える確認フレーズを付けてください。確認フレーズの例：</code></pre>
"do it", "go ahead", "execute", "run", "start", "thanks", "would ya", "please", "okay?", "proceed", "continue", "go on", "do that", "go it", "do you understand?"
<pre><code class="language-">
<h2>Config</h2></p><p>設定例：</code></pre>
[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # Ollamaの場合の例。LM-Studioの場合は http://127.0.0.1:1234
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False</p><p>jarvis_personality = False
languages = en zh # TTSやルーティングに利用する言語リスト
[BROWSER]
headless_browser = False
stealth_mode = False
<pre><code class="language-">
<strong></code>config.ini<code> 設定の説明</strong>:</p><ul><li>  <strong></code>[MAIN]<code> セクション:</strong></li>
    <li>  </code>is_local<code>: ローカルLLMプロバイダ（Ollama、LM-Studio、OpenAI互換ローカルサーバー、セルフホスト型サーバー）を使用する場合は </code>True<code>。クラウドAPI（OpenAI、Google等）は </code>False<code>。</li>
    <li>  </code>provider_name<code>: LLMプロバイダーを指定します。</li>
        <li>  ローカル: </code>ollama<code>, </code>lm-studio<code>, </code>openai<code>（OpenAI互換ローカルサーバー用）, </code>server<code>（セルフホストサーバー用）</li>
        <li>  API: </code>openai<code>, </code>google<code>, </code>deepseek<code>, </code>huggingface<code>, </code>togetherAI<code></li>
    <li>  </code>provider_model<code>: 選択したプロバイダー用のモデル名またはID（例：Ollamaなら </code>deepseekcoder:6.7b<code>、OpenAI APIなら </code>gpt-3.5-turbo<code>、TogetherAIなら </code>mistralai/Mixtral-8x7B-Instruct-v0.1<code>）</li>
    <li>  </code>provider_server_address<code>: LLMプロバイダーのアドレス</li>
        <li>  ローカル: 例 </code>http://127.0.0.1:11434<code>（Ollama）、</code>http://127.0.0.1:1234<code>（LM-Studio）</li>
        <li>  </code>server<code> プロバイダーの場合: セルフホストLLMサーバーのアドレス（例：</code>http://your_server_ip:3333<code>）</li>
        <li>  クラウドAPI（</code>is_local = False<code>）の場合：多くは無視されるか空欄でOK。APIエンドポイントはクライアントライブラリが管理します。</li>
    <li>  </code>agent_name<code>: AIアシスタントの名前（例：Friday）。音声認識トリガーワードとして使用。</li>
    <li>  </code>recover_last_session<code>: 前回セッションの状態を復元する場合は </code>True<code>、新規開始は </code>False<code></li>
    <li>  </code>save_session<code>: 現在のセッション状態を保存する場合は </code>True<code></li>
    <li>  </code>speak<code>: テキスト読み上げ音声出力を有効にする場合は </code>True<code></li>
    <li>  </code>listen<code>: 音声入力（CLIモードのみ）を有効にする場合は </code>True<code></li>
    <li>  </code>work_dir<code>: <strong>重要:</strong> AgenticSeekがファイルの読み書きを行うディレクトリ。<strong>このパスが有効かつアクセス可能であることを確認してください。</strong></li>
    <li>  </code>jarvis_personality<code>: "Jarvis風" のシステムプロンプトを使う場合は </code>True<code>（実験的）、標準プロンプトは </code>False<code></li>
    <li>  </code>languages<code>: カンマ区切りの言語リスト（例：</code>en, zh, fr<code>）。TTS音声選択（最初がデフォルト）やLLMルーターに利用。効率化のため、似すぎた言語や多すぎる言語は避けてください。</li>
<li>  <strong></code>[BROWSER]<code> セクション:</strong></li>
    <li>  </code>headless_browser<code>: ウィンドウを表示せず自動化ブラウザを実行する場合は </code>True<code>（ウェブインターフェースや非対話用途推奨）。ウィンドウを表示する場合は </code>False<code>（CLIモードやデバッグ用）。</li>
    <li>  </code>stealth_mode<code>: ブラウザ自動化の検出を難しくする機能を有効化する場合は </code>True<code>。anticaptcha等の拡張機能の手動インストールが必要な場合があります。</li></p><p>
</ul>このセクションではサポートされているLLMプロバイダータイプをまとめています。</code>config.ini<code> で設定してください。</p><p><strong>ローカルプロバイダー（自身のハードウェア上で実行）:</strong></p><p>| </code>config.ini<code>内のプロバイダー名 | </code>is_local<code> | 説明                                                                         | セットアップセクション                                                   |
|-------------------------------|------------|------------------------------------------------------------------------------|--------------------------------------------------------------------------|
| </code>ollama<code>                      | </code>True<code>     | OllamaでローカルLLMを提供                                                    | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">ローカル実行のセットアップ</a> |
| </code>lm-studio<code>                   | </code>True<code>     | LM-StudioでローカルLLMを提供                                                 | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">ローカル実行のセットアップ</a> |
| </code>openai<code>（ローカルサーバー用）| </code>True<code>     | OpenAI互換APIを公開するローカルサーバーへ接続（例：llama.cpp）               | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">ローカル実行のセットアップ</a> |
| </code>server<code>                      | </code>False<code>    | 他のマシンで動作するAgenticSeekセルフホストLLMサーバーへ接続                 | <a href="#setup-to-run-the-llm-on-your-own-server" target="_blank" rel="noopener noreferrer">独自サーバーでのセットアップ</a>      |</p><p><strong>APIプロバイダー（クラウドベース）:</strong></p><p>| </code>config.ini<code>内のプロバイダー名 | </code>is_local<code> | 説明                                             | セットアップセクション                     |
|-------------------------------|------------|--------------------------------------------------|--------------------------------------------|
| </code>openai<code>                      | </code>False<code>    | OpenAI公式API（例：GPT-3.5, GPT-4）利用         | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API利用セットアップ</a> |
| </code>google<code>                      | </code>False<code>    | Google GeminiモデルをAPI経由で利用               | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API利用セットアップ</a> |
| </code>deepseek<code>                    | </code>False<code>    | Deepseek公式API利用                             | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API利用セットアップ</a> |
| </code>huggingface<code>                 | </code>False<code>    | Hugging Face Inference API利用                   | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API利用セットアップ</a> |
| </code>togetherAI<code>                  | </code>False<code>    | TogetherAIのAPIで様々なオープンモデルを利用      | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API利用セットアップ</a> |</p><hr>
<h2>トラブルシューティング</h2></p><p>問題が発生した場合、このセクションがガイドとなります。</p><h1>既知の問題</h1></p><h2>ChromeDriverの問題</h2></p><p><strong>エラー例:</strong> </code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX<code></p><ul><li>  <strong>原因:</strong> インストール済みのChromeDriverのバージョンがGoogle Chromeブラウザのバージョンと互換性がありません。</li>
<li>  <strong>解決策:</strong></li>
    <li> <strong>Chromeバージョンの確認:</strong> Google Chromeを開き、</code>設定 > Chromeについて<code> でバージョン（例："Version 120.0.6099.110"）を確認。</li>
    <li> <strong>対応するChromeDriverをダウンロード:</strong></li>
        <li>  Chrome 115以降の場合: <a href="https://googlechromelabs.github.io/chrome-for-testing/" target="_blank" rel="noopener noreferrer">Chrome for Testing (CfT) JSON Endpoints</a>で「stable」チャンネルを探し、ご自身のOSに合ったChromeのメジャーバージョンに一致するChromeDriverをダウンロード。</li>
        <li>  旧バージョン（稀）: <a href="https://chromedriver.chromium.org/downloads" target="_blank" rel="noopener noreferrer">ChromeDriver - WebDriver for Chrome</a>ページを参照。</li>
        <li>  下記画像はCfTページの例です:</li>
            </ul><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="Download Chromedriver specific version from Chrome for Testing page">
    <ul><li> <strong>ChromeDriverのインストール:</strong></li>
        <li>  ダウンロードした </code>chromedriver<code>（Windowsの場合は </code>chromedriver.exe<code>）を、システムのPATH環境変数に含まれるディレクトリ（例：Linux/macOSは </code>/usr/local/bin<code>、WindowsはPATHに追加したカスタムスクリプトフォルダ等）に配置。</li>
        <li>  もしくは、</code>agenticSeek<code> プロジェクトのルートディレクトリに配置。</li>
        <li>  実行権限を付与（例：Linux/macOSは </code>chmod +x chromedriver<code>）。</li>
    <li> 詳細はインストールガイド内 <a href="#chromedriver-installation" target="_blank" rel="noopener noreferrer">ChromeDriver Installation</a> セクションを参照。</li></p><p></ul>このセクションが不完全な場合や他のChromeDriver問題が発生した場合、<a href="https://github.com/Fosowl/agenticSeek/issues" target="_blank" rel="noopener noreferrer">GitHub Issues</a> で既存の内容を検索、または新規Issueを作成してください。</p><p></code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113
Current browser version is 134.0.6998.89 with binary path<code></p><p>このエラーはブラウザとchromedriverのバージョンが一致していない場合に発生します。</p><p>以下から最新バージョンをダウンロードしてください：</p><p>https://developer.chrome.com/docs/chromedriver/downloads</p><p>Chrome バージョン115以降の場合はこちら：</p><p>https://googlechromelabs.github.io/chrome-for-testing/</p><p>ご自身のOSに合ったchromedriverバージョンをダウンロードしてください。</p><p><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text"></p><p>このセクションが不完全な場合はIssueを作成してください。</p><h2>connection adapters の問題</h2>
</code></pre>
Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'</code> (Note: port may vary)
<pre><code class="language-">
<ul><li>  <strong>原因:</strong> <code>lm-studio</code>（または同様のOpenAI互換ローカルサーバー）用に <code>config.ini</code> の <code>provider_server_address</code> に <code>http://</code> プレフィックスがない、またはポートが誤っています。</li>
<li>  <strong>解決策:</strong></li>
    <li>  アドレスが <code>http://</code> を含んでいることを確認。LM-Studioは通常 <code>http://127.0.0.1:1234</code> がデフォルトです。</li>
    <li>  <code>config.ini</code>の修正例：<code>provider_server_address = http://127.0.0.1:1234</code>（ご利用のLM-Studioサーバーのポートに合わせて修正）</li></p><p></ul><h2>SearxNG Base URL未指定</h2>
</code></pre>
raise ValueError("SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.")
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.<code>
</code>`<code></p><h2>FAQ</h2></p><p><strong>Q: 必要なハードウェアは？</strong>  </p><p>| モデルサイズ  | GPU  | コメント                                               |
|--------------|--------|-----------------------------------------------------------|
| 7B           | 8GB Vram | ⚠️ 推奨しません。パフォーマンスが悪く、幻覚も多く、プランナーエージェントはほぼ失敗します。 |
| 14B          | 12GB VRAM (例：RTX 3060) | ✅ 簡単なタスクには使用可能。ウェブブラウジングや計画タスクにはやや力不足。 |
| 32B          | 24GB以上VRAM (例：RTX 4090) | 🚀 ほとんどのタスクで成功。ただしタスクプランニングはやや苦手な場合あり。|
| 70B以上       | 48GB以上VRAM | 💪 優秀。高度な用途に推奨。|</p><p><strong>Q: エラーが出た場合は？</strong>  </p><p>ローカルが起動中（</code>ollama serve<code>）、</code>config.ini`がプロバイダーに一致、依存関係がインストール済みであることを確認。それでも解決しない場合はIssueを作成してください。</p><p><strong>Q: 本当に100％ローカル実行できる？</strong>  </p><p>Ollama、lm-studioまたはserverプロバイダー利用時は、音声認識・LLM・TTSモデルすべてローカル動作します。非ローカル（OpenAI等API）はオプションです。</p><p><strong>Q: ManusがあるのにAgenticSeekを使う理由は？</strong></p><p>Manusと異なり、AgenticSeekは外部システム依存を最小化し、より多くのコントロールやプライバシー、APIコスト回避を重視しています。</p><p><strong>Q: プロジェクトの運営者は？</strong></p><p>このプロジェクトは私と、オープンソースコミュニティの2人の友人（メンテナー兼コントリビューター）で開発しています。私たちはスタートアップや組織所属ではなく、情熱を持った個人の集まりです。</p><p>私の個人アカウント（https://x.com/Martin993886460）以外のAgenticSeek名義のXアカウントはなりすましです。</p><h2>貢献について</h2></p><p>AgenticSeekの開発にご協力いただける開発者を募集中です！オープンなIssueやディスカッションをご覧ください。</p><p><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">貢献ガイド</a></p><p><a href="https://www.star-history.com/#Fosowl/agenticSeek&Date" target="_blank" rel="noopener noreferrer"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&type=Date" alt="Star History Chart"></a></p><h2>メンテナー:</h2></p><p> > <a href="https://github.com/Fosowl" target="_blank" rel="noopener noreferrer">Fosowl</a> | パリ時間</p><p> > <a href="https://github.com/antoineVIVIES" target="_blank" rel="noopener noreferrer">antoineVIVIES</a> | 台北時間</p><p> > <a href="https://github.com/steveh8758" target="_blank" rel="noopener noreferrer">steveh8758</a> | 台北時間</p><h2>スペシャルサンクス:</h2></p><p> > <a href="https://github.com/tcsenpai" target="_blank" rel="noopener noreferrer">tcsenpai</a> および <a href="https://github.com/plitc" target="_blank" rel="noopener noreferrer">plitc</a> バックエンドのDocker化にご協力いただきました</p><h2>スポンサー:</h2></p><p>月額5ドル以上のスポンサー様（順不同）:
<ul><li><strong>tatra-labs</strong></li></p><p></ul>It appears that you have not provided the content of Part 4 of 4 for translation. Please paste the text you would like translated, and I will proceed as instructed.

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-16

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>