<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>agenticSeek - Read agenticSeek documentation in Simplified Chinese. This project has 18325 stars on GitHub.</title>
    <meta name="description" content="Read agenticSeek documentation in Simplified Chinese. This project has 18325 stars on GitHub.">
    <meta name="keywords" content="agenticSeek, Simplified Chinese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "agenticSeek",
  "description": "Read agenticSeek documentation in Simplified Chinese. This project has 18325 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "Fosowl"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 18325
  },
  "url": "https://OpenAiTx.github.io/projects/Fosowl/agenticSeek/README-zh-CN.html",
  "sameAs": "https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/Fosowl/agenticSeek" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    agenticSeek
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 18325 stars</span>
                <span class="language">Simplified Chinese</span>
                <span>by Fosowl</span>
            </div>
        </div>
        
        <div class="content">
            <h1>AgenticSeek：本地私有的 Manus 替代方案</h1></p><p><p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
<p>  English | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md" target="_blank" rel="noopener noreferrer">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md" target="_blank" rel="noopener noreferrer">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md" target="_blank" rel="noopener noreferrer">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md" target="_blank" rel="noopener noreferrer">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md" target="_blank" rel="noopener noreferrer">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md" target="_blank" rel="noopener noreferrer">Español</a></p><p><em>一个<strong>100% 本地化的 Manus AI 替代方案</strong>，此语音驱动的 AI 助手可自主浏览网页、编写代码、规划任务，所有数据都保存在您的设备上。为本地推理模型量身定制，完全在您的硬件上运行，确保数据隐私，无需依赖云端。</em></p><p><a href="https://fosowl.github.io/agenticSeek.html" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?label=Website&message=AgenticSeek&color=blue&style=flat-square" alt="访问 AgenticSeek"></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License"> <a href="https://discord.gg/8hGDaME3TC" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&logoColor=white" alt="Discord"></a> <a href="https://x.com/Martin993886460" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&label=Update%20%40Fosowl" alt="Twitter"></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars"></a></p><h3>为什么选择 AgenticSeek？</h3></p><ul><li>🔒 完全本地&私有 —— 所有内容在您的计算机上运行，无云端、无数据共享。您的文件、对话和搜索都保持私密。</li></p><p><li>🌐 智能网页浏览 —— AgenticSeek 能自主上网搜索、阅读、提取信息、填写网页表单，全程免手动操作。</li></p><p><li>💻 自主编程助手 —— 需要代码？它能编写、调试并运行 Python、C、Go、Java 等多种程序，无需人工干预。</li></p><p><li>🧠 智能代理选择 —— 您只需提问，它会自动选择最适合的 AI 代理处理任务，就像有一支专家团队随时待命。</li></p><p><li>📋 规划并执行复杂任务 —— 从行程规划到复杂项目，能将大任务拆分为步骤，利用多智能体高效完成。</li></p><p><li>🎙️ 语音驱动 —— 干净、快速、未来感十足的语音与语音转文字功能，让您像在科幻电影中那样与个人 AI 对话。（开发中）</li></p><p></ul><h3><strong>演示</strong></h3></p><blockquote><em>你能搜索 agenticSeek 项目，了解需要哪些技能，然后打开 CV_candidates.zip，告诉我哪个最匹配该项目吗</em></blockquote></p><p>https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</p><p>免责声明：该演示及所有出现的文件（如：CV_candidates.zip）均为虚构。我们不是公司，仅寻求开源贡献者而非候选人。</p><blockquote>🛠⚠️️ <strong>项目正在积极开发中</strong></blockquote></p><blockquote>🙏 本项目起初只是一个副业项目，没有明确的路线图和资金支持。它超出了我的预期并登上了 GitHub Trending。非常感谢您的贡献、反馈与耐心。</blockquote></p><h2>前置条件</h2></p><p>在开始之前，请确保已安装以下软件：</p><ul><li>  <strong>Git：</strong> 用于克隆仓库。<a href="https://git-scm.com/downloads" target="_blank" rel="noopener noreferrer">下载 Git</a></li>
<li>  <strong>Python 3.10.x：</strong> 强烈建议使用 Python 3.10.x 版本。其他版本可能会导致依赖错误。<a href="https://www.python.org/downloads/release/python-3100/" target="_blank" rel="noopener noreferrer">下载 Python 3.10</a>（请选择 3.10.x 版本）。</li>
<li>  <strong>Docker Engine & Docker Compose：</strong> 用于运行如 SearxNG 等捆绑服务。</li>
    <li>  安装 Docker Desktop（包含 Docker Compose V2）：<a href="https://docs.docker.com/desktop/install/windows-install/" target="_blank" rel="noopener noreferrer">Windows</a> | <a href="https://docs.docker.com/desktop/install/mac-install/" target="_blank" rel="noopener noreferrer">Mac</a> | <a href="https://docs.docker.com/desktop/install/linux-install/" target="_blank" rel="noopener noreferrer">Linux</a></li>
    <li>  或者在 Linux 上分别安装 Docker Engine 和 Docker Compose：<a href="https://docs.docker.com/engine/install/" target="_blank" rel="noopener noreferrer">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/" target="_blank" rel="noopener noreferrer">Docker Compose</a>（请确保安装 Compose V2，例如 <code>sudo apt-get install docker-compose-plugin</code>）。</li></p><p></ul><h3>1. <strong>克隆仓库并进行设置</strong></h3></p><pre><code class="language-sh">git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env</code></pre></p><h3>2. 修改 .env 文件内容</h3></p><pre><code class="language-sh">SEARXNG_BASE_URL="http://127.0.0.1:8080"
REDIS_BASE_URL="redis://redis:6379/0"
WORK_DIR="/Users/mlg/Documents/workspace_for_ai"
OLLAMA_PORT="11434"
LM_STUDIO_PORT="1234"
CUSTOM_ADDITIONAL_LLM_PORT="11435"
OPENAI_API_KEY='optional'
DEEPSEEK_API_KEY='optional'
OPENROUTER_API_KEY='optional'
TOGETHER_API_KEY='optional'
GOOGLE_API_KEY='optional'
ANTHROPIC_API_KEY='optional'</code></pre></p><p>根据需要用您自己的值更新 <code>.env</code> 文件：</p><ul><li><strong>SEARXNG_BASE_URL</strong>：保持不变</li>
<li><strong>REDIS_BASE_URL</strong>：保持不变</li>
<li><strong>WORK_DIR</strong>：本地机器上的工作目录路径。AgenticSeek 可以读取和操作这些文件。</li>
<li><strong>OLLAMA_PORT</strong>：Ollama 服务端口号。</li>
<li><strong>LM_STUDIO_PORT</strong>：LM Studio 服务端口号。</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>：任何自定义 LLM 服务的端口号。</li></p><p></ul><strong>API Key 完全可选，针对选择本地运行 LLM 的用户。该项目的主要目标即为此。如果硬件足够请留空。</strong></p><h3>3. <strong>启动 Docker</strong></h3></p><p>确保您的系统已安装并运行 Docker。可用以下命令启动 Docker：</p><ul><li><strong>在 Linux/macOS 上：</strong></li>
    </ul>打开终端并运行：
    <pre><code class="language-sh">    sudo systemctl start docker
    ``<code>
    或者在应用程序菜单中启动 Docker Desktop（如已安装）。</p><ul><li><strong>在 Windows 上：</strong></li>
    </ul>从开始菜单启动 Docker Desktop。</p><p>可通过以下命令验证 Docker 是否运行：</code></pre>sh
docker info
<pre><code class="language-">如果显示有关 Docker 安装的信息，则说明运行正常。</p><p>本地提供商的汇总见下表 <a href="#list-of-local-providers" target="_blank" rel="noopener noreferrer">Local Providers</a>。</p><p>下一步：<a href="#start-services-and-run" target="_blank" rel="noopener noreferrer">本地运行 AgenticSeek</a></p><p><em>如遇问题，请参阅 <a href="#troubleshooting" target="_blank" rel="noopener noreferrer">故障排查</a> 部分。</em>
<em>如您的硬件无法本地运行 LLM，请参考 <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API 运行设置</a>。</em>
<em>如需详细 </code>config.ini<code> 配置说明，请参见 <a href="#config" target="_blank" rel="noopener noreferrer">Config Section</a>。</em></p><hr></p><h2>本地运行 LLM 设置</h2></p><p><strong>硬件要求：</strong></p><p>如需本地运行 LLM，需具备足够的硬件资源。最低需有可运行 Magistral、Qwen 或 Deepseek 14B 的 GPU。详细的模型/性能建议请参见 FAQ。</p><p><strong>设置本地提供商</strong></p><p>启动本地提供商，例如使用 ollama：
</code></pre>sh
ollama serve
<pre><code class="language-">
下方列出本地支持的提供商。</p><p><strong>更新 config.ini</strong></p><p>修改 config.ini，将 provider_name 设置为受支持的提供商，将 provider_model 设置为该提供商支持的 LLM。推荐推理模型如 <em>Magistral</em> 或 <em>Deepseek</em>。</p><p>所需硬件请参考 README 最后的 <strong>FAQ</strong>。
</code></pre>sh
[MAIN]
is_local = True # 是否本地运行，或使用远程提供商
provider_name = ollama # 或 lm-studio、openai 等
provider_model = deepseek-r1:14b # 选择适合硬件的模型
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # AI 名称
recover_last_session = True # 是否恢复上次会话
save_session = True # 是否记住当前会话
speak = False # 文本转语音
listen = False # 语音转文本，仅 CLI，实验性
jarvis_personality = False # 是否使用更“Jarvis”风格的个性（实验性）
languages = en zh # 支持的语言列表，TTS 默认使用第一个
[BROWSER]
headless_browser = True # 除非在主机 CLI 使用，否则保持不变
stealth_mode = True # 使用 undetected selenium 降低被浏览器检测的概率
<pre><code class="language-">
<strong>注意事项</strong>：</p><ul><li></code>config.ini<code> 文件格式不支持注释。</li>
</ul>请勿直接复制示例配置中的注释，否则会报错。请手动根据需求修改 </code>config.ini<code>，并去除所有注释。</p><ul><li>如使用 LM-studio 本地运行 LLM，不要将 provider_name 设置为 </code>openai<code>，请设为 </code>lm-studio<code>。</li></p><p><li>某些提供商（如 lm-studio）需要在 IP 前加 </code>http://<code>，如 </code>http://127.0.0.1:1234<code></li></p><p></ul><strong>本地提供商列表</strong></p><p>| 提供商    | 本地？ | 描述                                                    |
|-----------|--------|---------------------------------------------------------|
| ollama    | 是     | 通过 ollama 作为 LLM 提供商，轻松本地运行 LLM           |
| lm-studio | 是     | 使用 LM studio 本地运行 LLM（</code>provider_name<code> 设为 </code>lm-studio<code>）|
| openai    | 是     | 使用 openai 兼容 API（如 llama.cpp server）             |</p><p>下一步：<a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">启动服务并运行 AgenticSeek</a></p><p><em>如遇问题，请参阅 <a href="#troubleshooting" target="_blank" rel="noopener noreferrer">故障排查</a> 部分。</em>
<em>如您的硬件无法本地运行 LLM，请参考 <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API 运行设置</a>。</em>
<em>如需详细 </code>config.ini<code> 配置说明，请参见 <a href="#config" target="_blank" rel="noopener noreferrer">Config Section</a>。</em></p><h2>使用 API 运行设置</h2></p><p>此方式使用外部云端 LLM 提供商。您需要从所选服务获取 API key。</p><p><strong>1. 选择 API 提供商并获取 API Key：</strong></p><p>参见下方 <a href="#list-of-api-providers" target="_blank" rel="noopener noreferrer">API 提供商列表</a>。访问其官网注册并获得 API key。</p><p><strong>2. 将 API Key 设为环境变量：</strong></p><ul><li>  <strong>Linux/macOS:</strong></li>
    </ul>打开终端，使用 </code>export<code> 命令。建议添加到 shell 配置文件（如 </code>~/.bashrc<code>、</code>~/.zshrc<code>）以便持久生效。
    </code>`<code>sh
    export PROVIDER_API_KEY="your_api_key_here"
    # 将 PROVIDER_API_KEY 替换为具体变量名，如 OPENAI_API_KEY、GOOGLE_API_KEY
    </code>`<code>
    TogetherAI 示例：
    </code>`<code>sh
    export TOGETHER_API_KEY="xxxxxxxxxxxxxxxxxxxxxx"
    </code>`<code>
<ul><li>  <strong>Windows:</strong></li>
<li>  <strong>命令提示符（当前会话临时生效）：</strong></li>
    </ul></code>`<code>cmd
    set PROVIDER_API_KEY=your_api_key_here
    </code>`<code>
<ul><li>  <strong>PowerShell（当前会话临时生效）：</strong></li>
    </ul></code>`<code>powershell
    $env:PROVIDER_API_KEY="your_api_key_here"
    </code>`<code>
<ul><li>  <strong>永久生效：</strong> 在 Windows 搜索栏中搜索“环境变量”，点击“编辑系统环境变量”，然后点击“环境变量...”按钮。添加一个新的用户变量，名称为相应的变量名（如 </code>OPENAI_API_KEY<code>），值为你的密钥。</li></p><p></ul><em>（详见常见问题：<a href="#how-do-i-set-api-keys" target="_blank" rel="noopener noreferrer">如何设置 API 密钥？</a>）</em></p><p>
<strong>3. 更新 </code>config.ini<code>：</strong></code></pre>ini
[MAIN]
is_local = False
provider_name = openai # 或 google, deepseek, togetherAI, huggingface
provider_model = gpt-3.5-turbo # 或 gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 等
provider_server_address = # 当 is_local = False 时通常忽略或可留空，大多数 API 均如此
<h1>... 其他设置 ...</h1>
<pre><code class="language-"><em>警告：</em> 请确保 </code>config.ini<code> 的值中没有尾随空格。</p><p><strong>API 提供商列表</strong></p><p>| 提供商        | </code>provider_name<code> | 本地？ | 描述                                             | API 密钥链接（示例）                           |
|---------------|-----------------|--------|--------------------------------------------------|-----------------------------------------------|
| OpenAI        | </code>openai<code>        | 否     | 通过 OpenAI 的 API 使用 ChatGPT 模型。            | <a href="https://platform.openai.com/signup" target="_blank" rel="noopener noreferrer">platform.openai.com/signup</a> |
| Google Gemini | </code>google<code>        | 否     | 通过 Google AI Studio 使用 Google Gemini 模型。   | <a href="https://aistudio.google.com/keys" target="_blank" rel="noopener noreferrer">aistudio.google.com/keys</a> |
| Deepseek      | </code>deepseek<code>      | 否     | 通过 Deepseek 的 API 使用 Deepseek 模型。         | <a href="https://platform.deepseek.com" target="_blank" rel="noopener noreferrer">platform.deepseek.com</a> |
| Hugging Face  | </code>huggingface<code>   | 否     | 通过 Hugging Face Inference API 使用模型。        | <a href="https://huggingface.co/settings/tokens" target="_blank" rel="noopener noreferrer">huggingface.co/settings/tokens</a> |
| TogetherAI    | </code>togetherAI<code>    | 否     | 通过 TogetherAI API 使用多种开源模型。            | <a href="https://api.together.ai/settings/api-keys" target="_blank" rel="noopener noreferrer">api.together.ai/settings/api-keys</a> |</p><p><em>注意：</em>
<ul><li>  我们不建议在复杂网页浏览和任务规划场景下使用 </code>gpt-4o<code> 或其他 OpenAI 模型，因为当前的提示词优化主要面向 Deepseek 等模型。</li>
<li>  在编码/bash 任务中，Gemini 可能无法严格遵循为 Deepseek 优化的格式化提示，可能会出现问题。</li>
<li>  当 </code>is_local = False<code> 时，</code>config.ini<code> 中的 </code>provider_server_address<code> 一般不会被使用，因为各提供商库中通常已硬编码了 API 端点。</li></p><p></ul>下一步：<a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">启动服务并运行 AgenticSeek</a></p><p><em>如遇问题请参见 <strong>已知问题</strong> 部分</em></p><p><em>详细配置文件说明请参见 <strong>Config</strong> 部分。</em></p><hr></p><h2>启动服务并运行</h2></p><p>默认情况下，AgenticSeek 完全在 Docker 中运行。</p><p>启动所需服务。这将启动 docker-compose.yml 中的所有服务，包括：
   <ul><li>searxng</li>
   <li>redis（searxng 需要）</li>
   <li>前端</li>
   <li>后端（如使用 </code>full<code>）</li>
</ul></code></pre>sh
./start_services.sh full # MacOS
start ./start_services.cmd full # Window
<pre><code class="language-">
<strong>警告：</strong> 此步骤将下载并加载所有 Docker 镜像，可能需要长达 30 分钟。启动服务后，请等待后端服务完全运行（你应该在日志中看到 <strong>backend: "GET /health HTTP/1.1" 200 OK</strong>）再发送任何消息。首次运行时后端服务可能需要 5 分钟启动。</p><p>访问 </code>http://localhost:3000/<code>，你应该可以看到 Web 界面。</p><p><em>服务启动故障排查：</em> 如脚本启动失败，请确保 Docker Engine 已运行且 Docker Compose（V2，</code>docker compose<code>）已正确安装。检查终端输出的错误信息。参见 <a href="#faq-troubleshooting" target="_blank" rel="noopener noreferrer">常见问题：运行 AgenticSeek 或其脚本时报错怎么办？</a></p><p><strong>可选：</strong> 在主机上运行（CLI 模式）：</p><p>如需用 CLI 界面运行，需要在主机上安装依赖包：
</code></pre>sh
./install.sh
./install.bat # windows
<pre><code class="language-">
启动服务：
</code></pre>sh
./start_services.sh # MacOS
start ./start_services.cmd # Window
<pre><code class="language-">
使用 CLI：</code>python3 cli.py<code></p><hr></p><h2>使用方法</h2></p><p>请确保服务已通过 </code>./start_services.sh full<code> 启动，并访问 </code>localhost:3000<code> 打开 Web 界面。</p><p>你还可以通过在配置中设置 </code>listen = True<code> 启用语音转文字功能，仅限 CLI 模式。</p><p>退出时，只需说或输入 </code>goodbye<code>。</p><p>以下是一些使用示例：</p><blockquote><em>用 python 制作一个贪吃蛇游戏！</em></blockquote></p><blockquote><em>在网上搜索法国雷恩（Rennes）排名前列的咖啡馆，并保存其中三家的名称和地址到 rennes_cafes.txt 文件。</em></blockquote></p><blockquote><em>写一个 Go 程序计算一个数的阶乘，将其保存为 workspace 目录下的 factorial.go</em></blockquote></p><blockquote><em>在 summer_pictures 文件夹中查找所有 JPG 文件，用今天的日期重命名，并将重命名后的文件列表保存到 photos_list.txt</em></blockquote></p><blockquote><em>在线搜索 2024 年流行的科幻电影，挑选三部今晚观看。将名单保存到 movie_night.txt。</em></blockquote></p><blockquote><em>在网上搜索 2025 年最新 AI 新闻文章，选择三篇，用 Python 脚本抓取它们的标题和摘要。将脚本保存为 news_scraper.py，摘要保存到 /home/projects 下的 ai_news.txt</em></blockquote></p><blockquote><em>周五，在网上搜索免费股票价格 API，用 supersuper7434567@gmail.com 注册账号，然后写一个 Python 脚本，利用该 API 获取特斯拉每天的股价，并将结果保存为 stock_prices.csv</em></blockquote></p><p><em>请注意，自动表单填写功能仍处于实验阶段，可能会失败。</em></p><p>
当你输入查询后，AgenticSeek 会为任务分配最佳代理。</p><p>由于目前为早期原型，代理路由系统可能不会始终根据你的查询分配最合适的代理。</p><p>因此，你应尽量明确表达需求，并说明 AI 应如何操作。例如，如果希望它进行网页搜索，不要说：</p><p></code>你知道哪些适合单人旅行的好国家吗？<code></p><p>而应这样问：</p><p></code>请进行网页搜索，找出最适合单人旅行的国家<code></p><hr></p><h2><strong>配置在你自己的服务器上运行 LLM</strong>  </h2></p><p>如果你有一台高性能电脑或服务器，希望从笔记本远程使用它，可以选择用我们的自定义 llm server 在远程服务器上运行 LLM。</p><p>在将运行 AI 模型的“服务器”上，获取 IP 地址
</code></pre>sh
ip a | grep "inet " | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # 本地 IP
curl https://ipinfo.io/ip # 公网 IP
<pre><code class="language-">
注意：Windows 或 macOS 请分别用 ipconfig 或 ifconfig 查询 IP 地址。</p><p>克隆仓库并进入 </code>server/<code> 文件夹。
</code></pre>sh
git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
<pre><code class="language-">
安装服务器端依赖：
</code></pre>sh
pip3 install -r requirements.txt
<pre><code class="language-">
运行服务器脚本。
</code></pre>sh
python3 app.py --provider ollama --port 3333
<pre><code class="language-">
你可以选择用 </code>ollama<code> 或 </code>llamacpp<code> 作为 LLM 服务。</p><p>现在在你的个人电脑上：</p><p>修改 </code>config.ini<code>，将 </code>provider_name<code> 设为 </code>server<code>，</code>provider_model<code> 设为 </code>deepseek-r1:xxb<code>。
把 </code>provider_server_address<code> 设置为运行模型机器的 IP 地址。
</code></pre>sh
[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
<pre><code class="language-"></p><p>下一步：<a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">启动服务并运行 AgenticSeek</a>  </p><hr></p><h2>语音转文字</h2></p><p>警告：语音转文字目前仅支持 CLI 模式。</p><p>请注意，语音转文字目前仅支持英文。</p><p>语音转文字功能默认关闭。要启用，请在 config.ini 文件中设置 listen 选项为 True：
</code></pre>
listen = True
<pre><code class="language-">
启用后，语音转文字功能会在你说出触发关键词（即代理名称）后开始处理输入。你可以通过修改 <em>config.ini</em> 文件中的 </code>agent_name<code> 值来自定义代理名称：
</code></pre>
agent_name = Friday
<pre><code class="language-">
为了获得最佳识别效果，我们建议使用常见的英文名字作为代理名称，如 "John" 或 "Emma"。</p><p>当你看到转录文本开始出现时，大声说出代理的名字以唤醒它（例如，“Friday”）。</p><p>请清晰地表达你的请求。</p><p>在请求结束时，用确认短语作为信号提示系统继续。确认短语示例包括：</code></pre>
"do it", "go ahead", "execute", "run", "start", "thanks", "would ya", "please", "okay?", "proceed", "continue", "go on", "do that", "go it", "do you understand?"
<pre><code class="language-">
<h2>配置</h2></p><p>配置示例:</code></pre>
[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # Ollama 示例；LM-Studio 请用 http://127.0.0.1:1234
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False</p><p>jarvis_personality = False
languages = en zh # 用于TTS及可能的路由的语言列表。
[BROWSER]
headless_browser = False
stealth_mode = False
<pre><code class="language-">
<strong></code>config.ini<code> 配置项说明</strong>:</p><ul><li>  <strong></code>[MAIN]<code> 部分:</strong></li>
    <li>  </code>is_local<code>: 若使用本地LLM服务（Ollama、LM-Studio、本地OpenAI兼容服务器）或自托管服务器选项，设为 </code>True<code>。若使用云端API（OpenAI、Google等），设为 </code>False<code>。</li>
    <li>  </code>provider_name<code>: 指定LLM服务提供商。</li>
        <li>  本地选项：</code>ollama<code>、</code>lm-studio<code>、</code>openai<code>（本地OpenAI兼容服务器）、</code>server<code>（自托管服务器）。</li>
        <li>  API选项：</code>openai<code>、</code>google<code>、</code>deepseek<code>、</code>huggingface<code>、</code>togetherAI<code>。</li>
    <li>  </code>provider_model<code>: 选定服务商的具体模型名称或ID（如 Ollama 的 </code>deepseekcoder:6.7b<code>，OpenAI API 的 </code>gpt-3.5-turbo<code>，TogetherAI 的 </code>mistralai/Mixtral-8x7B-Instruct-v0.1<code>）。</li>
    <li>  </code>provider_server_address<code>: 你的LLM服务提供商地址。</li>
        <li>  本地服务示例：Ollama 用 </code>http://127.0.0.1:11434<code>，LM-Studio 用 </code>http://127.0.0.1:1234<code>。</li>
        <li>  </code>server<code> 类型：自托管LLM服务器地址（如 </code>http://your_server_ip:3333<code>）。</li>
        <li>  云端API（</code>is_local = False<code>）：通常忽略或留空，因为API端点通常由客户端库处理。</li>
    <li>  </code>agent_name<code>: AI助手名称（如 Friday）。在启用语音转文本时用作唤醒词。</li>
    <li>  </code>recover_last_session<code>: 设为 </code>True<code> 时尝试恢复上次会话状态，设为 </code>False<code> 时重新开始。</li>
    <li>  </code>save_session<code>: 设为 </code>True<code> 保存当前会话以便恢复，否则为 </code>False<code>。</li>
    <li>  </code>speak<code>: 设为 </code>True<code> 启用文字转语音输出，设为 </code>False<code> 关闭。</li>
    <li>  </code>listen<code>: 设为 </code>True<code> 启用语音转文本输入（仅CLI模式），设为 </code>False<code> 关闭。</li>
    <li>  </code>work_dir<code>: <strong>重要：</strong> AgenticSeek 读写文件的目录。<strong>请确保该路径在你的系统中有效且可访问。</strong></li>
    <li>  </code>jarvis_personality<code>: 设为 </code>True<code> 使用更“Jarvis风格”的系统提示（实验性），设为 </code>False<code> 使用标准提示。</li>
    <li>  </code>languages<code>: 逗号分隔的语言列表（如 </code>en, zh, fr<code>）。用于TTS语音选择（默认第一项），也可辅助LLM路由。为提高效率，请勿设置过多或过于相似的语言。</li>
<li>  <strong></code>[BROWSER]<code> 部分:</strong></li>
    <li>  </code>headless_browser<code>: 设为 </code>True<code> 以无界面方式运行自动化浏览器（推荐用于网页界面或非交互场景）；设为 </code>False<code> 显示浏览器窗口（适合CLI模式或调试）。</li>
    <li>  </code>stealth_mode<code>: 设为 </code>True<code> 启用反检测措施，使浏览器自动化更难被检测。可能需要手动安装诸如 anticaptcha 等浏览器扩展。</li></p><p></ul>本节总结了支持的LLM服务类型。请在 </code>config.ini<code> 中进行配置。</p><p><strong>本地服务（在你自己的硬件上运行）:</strong></p><p>| </code>config.ini<code> 配置名称          | </code>is_local<code> | 描述                                                                         | 配置章节                                                        |
|-------------------------------|------------|------------------------------------------------------------------------------|------------------------------------------------------------------|
| </code>ollama<code>                      | </code>True<code>     | 使用 Ollama 提供本地LLM服务。                                                | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">本地LLM运行配置</a> |
| </code>lm-studio<code>                   | </code>True<code>     | 使用 LM-Studio 提供本地LLM服务。                                             | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">本地LLM运行配置</a> |
| </code>openai<code> (本地服务器)         | </code>True<code>     | 连接本地OpenAI兼容API服务器（如 llama.cpp）。                                 | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">本地LLM运行配置</a> |
| </code>server<code>                      | </code>False<code>    | 连接运行在其他机器上的 AgenticSeek 自托管LLM服务器。                         | <a href="#setup-to-run-the-llm-on-your-own-server" target="_blank" rel="noopener noreferrer">自托管LLM服务器配置</a>   |</p><p><strong>API服务（云端）:</strong></p><p>| </code>config.ini<code> 配置名称          | </code>is_local<code> | 描述                                       | 配置章节                                        |
|-------------------------------|------------|---------------------------------------------|-------------------------------------------------|
| </code>openai<code>                      | </code>False<code>    | 使用OpenAI官方API（如 GPT-3.5、GPT-4）。    | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API运行配置</a>         |
| </code>google<code>                      | </code>False<code>    | 通过API使用Google Gemini模型。              | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API运行配置</a>         |
| </code>deepseek<code>                    | </code>False<code>    | 使用Deepseek官方API。                       | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API运行配置</a>         |
| </code>huggingface<code>                 | </code>False<code>    | 使用 Hugging Face 推理API。                 | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API运行配置</a>         |
| </code>togetherAI<code>                  | </code>False<code>    | 使用 TogetherAI 的多种开源模型API。         | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API运行配置</a>         |</p><hr>
<h2>故障排查</h2></p><p>遇到问题时，本节将为你提供指导。</p><h1>已知问题</h1></p><h2>ChromeDriver 问题</h2></p><p><strong>错误示例:</strong> </code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX<code></p><ul><li>  <strong>原因:</strong> 你安装的 ChromeDriver 版本与 Google Chrome 浏览器版本不兼容。</li>
<li>  <strong>解决办法:</strong></li>
    <li> <strong>检查 Chrome 版本:</strong> 打开 Google Chrome，进入 </code>设置 > 关于 Chrome<code> 查看版本号（如 "Version 120.0.6099.110"）。</li>
    <li> <strong>下载匹配的 ChromeDriver:</strong></li>
        <li>  Chrome 115及以上版本：访问 <a href="https://googlechromelabs.github.io/chrome-for-testing/" target="_blank" rel="noopener noreferrer">Chrome for Testing (CfT) JSON Endpoints</a>。找到 “stable” 渠道，下载与你的Chrome主版本号对应的ChromeDriver。</li>
        <li>  旧版本（较少见）：可在 <a href="https://chromedriver.chromium.org/downloads" target="_blank" rel="noopener noreferrer">ChromeDriver - WebDriver for Chrome</a> 页面查找。</li>
        <li>  下图为 CfT 页面示例：</li>
            </ul><img src="./media/chromedriver_readme.png" alt="从Chrome for Testing页面下载特定版本Chromedriver">
    <ul><li> <strong>安装 ChromeDriver:</strong></li>
        <li>  确保下载的 </code>chromedriver<code>（Windows 下为 </code>chromedriver.exe<code>）放在系统PATH环境变量指定的目录下（如 Linux/macOS的 </code>/usr/local/bin<code>，或Windows下已加入PATH的脚本文件夹）。</li>
        <li>  或将其放在 </code>agenticSeek<code> 项目的根目录下。</li>
        <li>  确保驱动为可执行文件（Linux/macOS下可用 </code>chmod +x chromedriver<code>）。</li>
    <li> 更多信息请参考主安装指南的 <a href="#chromedriver-installation" target="_blank" rel="noopener noreferrer">ChromeDriver 安装</a> 部分。</li></p><p></ul>如果本节内容不完整或遇到其他ChromeDriver问题，请搜索现有 <a href="https://github.com/Fosowl/agenticSeek/issues" target="_blank" rel="noopener noreferrer">GitHub Issues</a> 或新建Issue反馈。</p><p></code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113
Current browser version is 134.0.6998.89 with binary path<code></p><p>如浏览器与chromedriver版本不匹配，会出现此类问题。</p><p>你需要前往以下链接下载最新版：</p><p>https://developer.chrome.com/docs/chromedriver/downloads</p><p>如使用的是 Chrome 115及以上版本，请访问：</p><p>https://googlechromelabs.github.io/chrome-for-testing/</p><p>并下载与你操作系统匹配的chromedriver版本。</p><p><img src="./media/chromedriver_readme.png" alt="alt text"></p><p>如本节内容不完整请提交Issue。</p><h2>连接适配器问题</h2>
</code></pre>
Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'</code> (注意：端口可能不同)
<pre><code class="language-">
<ul><li>  <strong>原因:</strong> <code>config.ini</code> 中 <code>lm-studio</code>（或其他本地OpenAI兼容服务器）的 <code>provider_server_address</code> 缺少 <code>http://</code> 前缀或指向了错误的端口。</li>
<li>  <strong>解决办法:</strong></li>
    <li>  确保地址包含 <code>http://</code>。LM-Studio 通常默认为 <code>http://127.0.0.1:1234</code>。</li>
    <li>  正确的 <code>config.ini</code> 配置：<code>provider_server_address = http://127.0.0.1:1234</code>（或你实际的LM-Studio服务器端口）。</li></p><p></ul><h2>未提供 SearxNG 基础URL</h2>
</code></pre>
raise ValueError("SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.")
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.<code>
</code>`<code></p><h2>常见问题</h2></p><p><strong>Q: 我需要什么硬件？</strong>  </p><p>| 模型规模  | GPU  | 说明                                                |
|-----------|--------|------------------------------------------------------|
| 7B        | 8GB 显存 | ⚠️ 不推荐。性能差，易产生幻觉，规划型Agent可能失败。 |
| 14B       | 12GB 显存（如RTX 3060） | ✅ 可用于简单任务。网页浏览和计划任务可能有困难。|
| 32B       | 24GB+ 显存（如RTX 4090） | 🚀 大部分任务表现良好，但复杂规划仍有挑战。    |
| 70B+      | 48GB+ 显存 | 💪 优秀，推荐用于高阶场景。                       |</p><p><strong>Q: 出现错误怎么办？</strong>  </p><p>确保本地服务已启动（如执行 </code>ollama serve<code>），</code>config.ini` 配置与你的服务商一致，且依赖项已安装。如仍有问题欢迎提交Issue反馈。</p><p><strong>Q: 真能100%本地运行吗？</strong>  </p><p>是的。配合 Ollama、lm-studio 或 server 服务，所有语音转文本、LLM与TTS模型都可本地运行。非本地选项（如OpenAI等API）为可选。</p><p><strong>Q: 我有 Manus，为什么还要用 AgenticSeek？</strong></p><p>AgenticSeek 以不依赖外部系统为设计重点，给予你更多控制权、隐私和避免API费用。</p><p><strong>Q: 项目背后是谁？</strong></p><p>本项目由我和两位朋友共同发起与维护，均来自GitHub开源社区。我们只是热爱技术的个人，并非创业公司或任何组织成员。</p><p>除我的个人账号（https://x.com/Martin993886460）外，任何自称AgenticSeek的X账号都是冒充。</p><h2>参与贡献</h2></p><p>欢迎开发者参与改进AgenticSeek！请查看开放Issue或讨论区。</p><p><a href="./docs/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">贡献指南</a></p><p><a href="https://www.star-history.com/#Fosowl/agenticSeek&Date" target="_blank" rel="noopener noreferrer"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&type=Date" alt="Star History Chart"></a></p><h2>维护者:</h2></p><p> > <a href="https://github.com/Fosowl" target="_blank" rel="noopener noreferrer">Fosowl</a> | 巴黎时间 </p><p> > <a href="https://github.com/antoineVIVIES" target="_blank" rel="noopener noreferrer">antoineVIVIES</a> | 台北时间 </p><p> > <a href="https://github.com/steveh8758" target="_blank" rel="noopener noreferrer">steveh8758</a> | 台北时间 </p><h2>特别感谢:</h2></p><p> > <a href="https://github.com/tcsenpai" target="_blank" rel="noopener noreferrer">tcsenpai</a> 和 <a href="https://github.com/plitc" target="_blank" rel="noopener noreferrer">plitc</a> 协助后端docker化</p><h2>赞助者:</h2></p><p>每月赞助5美元及以上将在此处展示：
<ul><li><strong>tatra-labs</strong></li></p><p></ul>Certainly! Please provide the content of Part 4 of 4 for translation.

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-16

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>