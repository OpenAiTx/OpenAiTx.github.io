<!DOCTYPE html>
<html lang="tr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>agenticSeek - Read agenticSeek documentation in Turkish. This project has 18325 stars on GitHub.</title>
    <meta name="description" content="Read agenticSeek documentation in Turkish. This project has 18325 stars on GitHub.">
    <meta name="keywords" content="agenticSeek, Turkish, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "agenticSeek",
  "description": "Read agenticSeek documentation in Turkish. This project has 18325 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "Fosowl"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 18325
  },
  "url": "https://OpenAiTx.github.io/projects/Fosowl/agenticSeek/README-tr.html",
  "sameAs": "https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/Fosowl/agenticSeek" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    agenticSeek
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 18325 stars</span>
                <span class="language">Turkish</span>
                <span>by Fosowl</span>
            </div>
        </div>
        
        <div class="content">
            <h1>AgenticSeek: Özel, Yerel Manus Alternatifi.</h1></p><p><p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
<p>  English | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md" target="_blank" rel="noopener noreferrer">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md" target="_blank" rel="noopener noreferrer">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md" target="_blank" rel="noopener noreferrer">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md" target="_blank" rel="noopener noreferrer">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md" target="_blank" rel="noopener noreferrer">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md" target="_blank" rel="noopener noreferrer">Español</a></p><p><em>%100 yerel Manus AI alternatifidir. Bu sesli AI asistanı, tüm verilerinizi cihazınızda tutarak internette özerk olarak gezinebilir, kod yazabilir ve görevleri planlayabilir. Yerel muhakeme modelleri için özelleştirilmiş olup, tamamen kendi donanımınızda çalışır ve tam gizlilik ile sıfır bulut bağımlılığı sağlar.</em></p><p><a href="https://fosowl.github.io/agenticSeek.html" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?label=Website&message=AgenticSeek&color=blue&style=flat-square" alt="AgenticSeek'i Ziyaret Et"></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="Lisans"> <a href="https://discord.gg/8hGDaME3TC" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&logoColor=white" alt="Discord"></a> <a href="https://x.com/Martin993886460" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&label=Update%20%40Fosowl" alt="Twitter"></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars"></a></p><h3>Neden AgenticSeek?</h3></p><ul><li>🔒 Tamamen Yerel ve Özel - Her şey kendi bilgisayarınızda çalışır — bulut yok, veri paylaşımı yok. Dosyalarınız, konuşmalarınız ve aramalarınız gizli kalır.</li></p><p><li>🌐 Akıllı Web Tarama - AgenticSeek, internette kendi başına gezinebilir — arama yapar, okur, bilgi çıkarır, web formlarını doldurur — tamamen eller serbest.</li></p><p><li>💻 Özerk Kodlama Asistanı - Kod mu lazım? Python, C, Go, Java ve daha fazlasında program yazabilir, hata ayıklayabilir ve çalıştırabilir — tamamen gözetimsiz.</li></p><p><li>🧠 Akıllı Ajan Seçimi - Siz sorarsınız, o işi için en iyi ajanı otomatik olarak bulur. Uzman bir ekip her an yardıma hazır gibi.</li></p><p><li>📋 Karmaşık Görevleri Planlar ve Uygular - Seyahat planlamadan karmaşık projelere — büyük görevleri adımlara böler ve birden fazla AI ajanı ile işi bitirir.</li></p><p><li>🎙️ Sesli - Temiz, hızlı ve fütüristik sesli yanıt ve konuşmadan metne özelliği ile bir bilim kurgu filmindeki kişisel AI'nızla konuşuyormuş gibi olursunuz. (Geliştiriliyor)</li></p><p></ul><h3><strong>Demo</strong></h3></p><blockquote><em>AgenticSeek projesini arayabilir misin, hangi yeteneklerin gerektiğini öğrenip, sonra CV_candidates.zip dosyasını açıp projeye en uygun olanları bana söyleyebilir misin?</em></blockquote></p><p>https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</p><p>Açıklama: Bu demo ve görünen tüm dosyalar (örn: CV_candidates.zip) tamamen kurgusaldır. Bir şirket değiliz, aday değil açık kaynak katkıcıları arıyoruz.</p><blockquote>🛠⚠️️ <strong>Aktif Olarak Geliştiriliyor</strong></blockquote></p><blockquote>🙏 Bu proje bir yan proje olarak başladı ve hiçbir yol haritası ya da fonlaması yok. GitHub Trending'de yer alacak kadar büyüdü. Katkılarınız, geri bildiriminiz ve sabrınız için minnettarız.</blockquote></p><h2>Ön Koşullar</h2></p><p>Başlamadan önce, aşağıdaki yazılımların kurulu olduğundan emin olun:</p><ul><li>  <strong>Git:</strong> Depoyu klonlamak için. <a href="https://git-scm.com/downloads" target="_blank" rel="noopener noreferrer">Git İndir</a></li>
<li>  <strong>Python 3.10.x:</strong> Python 3.10.x sürümünü kullanmanız şiddetle tavsiye edilir. Diğer sürümlerde bağımlılık hatası yaşanabilir. <a href="https://www.python.org/downloads/release/python-3100/" target="_blank" rel="noopener noreferrer">Python 3.10 İndir</a> (3.10.x sürümünü seçin).</li>
<li>  <strong>Docker Engine & Docker Compose:</strong> SearxNG gibi paket hizmetleri çalıştırmak için.</li>
    <li>  Docker Desktop'u yükleyin (Docker Compose V2 dahildir): <a href="https://docs.docker.com/desktop/install/windows-install/" target="_blank" rel="noopener noreferrer">Windows</a> | <a href="https://docs.docker.com/desktop/install/mac-install/" target="_blank" rel="noopener noreferrer">Mac</a> | <a href="https://docs.docker.com/desktop/install/linux-install/" target="_blank" rel="noopener noreferrer">Linux</a></li>
    <li>  Alternatif olarak Linux'ta Docker Engine ve Docker Compose'u ayrı ayrı yükleyin: <a href="https://docs.docker.com/engine/install/" target="_blank" rel="noopener noreferrer">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/" target="_blank" rel="noopener noreferrer">Docker Compose</a> (Compose V2 yüklediğinizden emin olun, örn. <code>sudo apt-get install docker-compose-plugin</code>).</li></p><p></ul><h3>1. <strong>Depoyu klonlayın ve kurulumu başlatın</strong></h3></p><pre><code class="language-sh">git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env</code></pre></p><h3>2. .env dosyasının içeriğini değiştirin</h3></p><pre><code class="language-sh">SEARXNG_BASE_URL="http://127.0.0.1:8080"
REDIS_BASE_URL="redis://redis:6379/0"
WORK_DIR="/Users/mlg/Documents/workspace_for_ai"
OLLAMA_PORT="11434"
LM_STUDIO_PORT="1234"
CUSTOM_ADDITIONAL_LLM_PORT="11435"
OPENAI_API_KEY='opsiyonel'
DEEPSEEK_API_KEY='opsiyonel'
OPENROUTER_API_KEY='opsiyonel'
TOGETHER_API_KEY='opsiyonel'
GOOGLE_API_KEY='opsiyonel'
ANTHROPIC_API_KEY='opsiyonel'</code></pre></p><p>Gerekirse <code>.env</code> dosyasındaki değerleri kendinize göre güncelleyin:</p><ul><li><strong>SEARXNG_BASE_URL</strong>: Değiştirmeyin </li>
<li><strong>REDIS_BASE_URL</strong>: Değiştirmeyin </li>
<li><strong>WORK_DIR</strong>: Yerel makinenizdeki çalışma dizininizin yolu. AgenticSeek bu dizindeki dosyaları okuyabilir ve onlarla etkileşime geçebilir.</li>
<li><strong>OLLAMA_PORT</strong>: Ollama servisi için port numarası.</li>
<li><strong>LM_STUDIO_PORT</strong>: LM Studio servisi için port numarası.</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>: Herhangi bir ek özel LLM servisi için port.</li></p><p></ul><strong>API Anahtarları, LLM'i yerel olarak çalıştırmayı seçen kullanıcılar için tamamen isteğe bağlıdır. Bu projenin birincil amacı budur. Yeterli donanımınız varsa boş bırakabilirsiniz.</strong></p><h3>3. <strong>Docker'ı Başlatın</strong></h3></p><p>Sisteminizde Docker'ın kurulu ve çalışır olduğundan emin olun. Aşağıdaki komutlarla Docker'ı başlatabilirsiniz:</p><ul><li><strong>Linux/macOS'ta:</strong>  </li>
    </ul>Bir terminal açın ve şunu çalıştırın:
    <pre><code class="language-sh">    sudo systemctl start docker
    ``<code>
    Veya uygulamalar menüsünden Docker Desktop'u başlatın.</p><ul><li><strong>Windows'ta:</strong>  </li>
    </ul>Başlat menüsünden Docker Desktop'u başlatın.</p><p>Docker'ın çalıştığını doğrulamak için şunu çalıştırın:</code></pre>sh
docker info
<pre><code class="language-">Docker kurulumu hakkında bilgi görüyorsanız, doğru şekilde çalışıyor demektir.</p><p>Aşağıdaki <a href="#list-of-local-providers" target="_blank" rel="noopener noreferrer">Yerel Sağlayıcılar Tablosu</a>'na göz atın.</p><p>Sonraki adım: <a href="#start-services-and-run" target="_blank" rel="noopener noreferrer">AgenticSeek'i Yerel Olarak Çalıştırın</a></p><p><em>Sorun yaşıyorsanız <a href="#troubleshooting" target="_blank" rel="noopener noreferrer">Sorun Giderme</a> bölümüne bakın.</em>
<em>Donanımınız LLM'leri yerel olarak çalıştıramıyorsa, <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API ile çalıştırma kurulumu</a> bölümüne bakın.</em>
<em>Detaylı </code>config.ini<code> açıklamaları için <a href="#config" target="_blank" rel="noopener noreferrer">Yapılandırma Bölümü</a> bölümüne bakın.</em></p><hr></p><h2>LLM'i kendi bilgisayarınızda yerel çalıştırma kurulumu</h2></p><p><strong>Donanım Gereksinimleri:</strong></p><p>LLM'leri yerel olarak çalıştırmak için yeterli donanıma ihtiyacınız var. En azından Magistral, Qwen veya Deepseek 14B çalıştırabilen bir GPU gereklidir. Detaylı model/performance önerileri için SSS'ye bakın.</p><p><strong>Yerel sağlayıcınızı başlatın</strong>  </p><p>Örneğin ollama ile yerel sağlayıcınızı başlatın:
</code></pre>sh
ollama serve
<pre><code class="language-">
Aşağıda desteklenen yerel sağlayıcıların listesine bakın.</p><p><strong>config.ini dosyasını güncelleyin</strong></p><p>config.ini dosyasını düzenleyerek provider_name alanını desteklenen bir sağlayıcı ile ve provider_model alanını sağlayıcınızın desteklediği bir LLM ile değiştirin. <em>Magistral</em> veya <em>Deepseek</em> gibi muhakeme modellerini öneririz.</p><p>Gerekli donanım için README'nin sonundaki <strong>SSS</strong>'ye bakın.
</code></pre>sh
[MAIN]
is_local = True # Yerel mi yoksa uzaktan mı çalıştırıyorsunuz.
provider_name = ollama # veya lm-studio, openai, vb..
provider_model = deepseek-r1:14b # Donanımınıza uygun bir model seçin
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # AI'nızın adı
recover_last_session = True # Önceki oturumu kurtarıp kurtarmayacağı
save_session = True # Geçerli oturumu hatırlayıp hatırlamayacağı
speak = False # Metinden sese
listen = False # Sesten metne, sadece CLI için, deneysel
jarvis_personality = False # Daha "Jarvis" benzeri bir kişilik kullanılıp kullanılmayacağı (deneysel)
languages = en zh # Diller listesi, Metinden Sese ilk dili varsayılan olarak kullanır
[BROWSER]
headless_browser = True # CLI kullanmıyorsanız değiştirmeyin.
stealth_mode = True # Tespit edilmemiş selenium kullanarak tarayıcı tespitini azaltır
<pre><code class="language-">
<strong>Uyarı</strong>:</p><ul><li></code>config.ini<code> dosya formatı yorum satırlarını desteklemez. </li>
</ul>Örnek yapılandırmayı doğrudan kopyalayıp yapıştırmayın, yorum satırları hata verebilir. Bunun yerine istediğiniz ayarlarla </code>config.ini<code> dosyasını elle düzenleyin ve yorum satırı eklemeyin.</p><ul><li>Eğer LLM'leri çalıştırmak için LM-studio kullanıyorsanız provider_name'i </code>openai<code> olarak AYARLAMAYIN. </code>lm-studio<code> olarak ayarlayın.</li></p><p><li>Bazı sağlayıcılar (örn: lm-studio), IP'nin önünde </code>http://<code> olmasını ister. Örneğin </code>http://127.0.0.1:1234<code></li></p><p></ul><strong>Yerel sağlayıcılar listesi</strong></p><p>| Sağlayıcı  | Yerel? | Açıklama                                               |
|-----------|--------|--------------------------------------------------------|
| ollama    | Evet   | Ollama ile kolayca yerel LLM çalıştırın                |
| lm-studio | Evet   | LM studio ile yerel LLM çalıştırın (</code>provider_name<code>i </code>lm-studio<code> olarak ayarlayın)|
| openai    | Evet   | OpenAI uyumlu API kullanın (örn: llama.cpp server)     |</p><p>Sonraki adım: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">Servisleri Başlatın ve AgenticSeek'i çalıştırın</a>  </p><p><em>Sorun yaşıyorsanız <a href="#troubleshooting" target="_blank" rel="noopener noreferrer">Sorun Giderme</a> bölümüne bakın.</em>
<em>Donanımınız LLM'leri yerel olarak çalıştıramıyorsa, <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API ile çalıştırma kurulumu</a> bölümüne bakın.</em>
<em>Detaylı </code>config.ini<code> açıklamaları için <a href="#config" target="_blank" rel="noopener noreferrer">Yapılandırma Bölümü</a> bölümüne bakın.</em></p><h2>API ile çalıştırma kurulumu</h2></p><p>Bu kurulum, harici, bulut tabanlı LLM sağlayıcılarını kullanır. Seçtiğiniz servisten bir API anahtarı almanız gerekir.</p><p><strong>1. Bir API Sağlayıcı Seçin ve API Anahtarı Alın:</strong></p><p>Aşağıdaki <a href="#list-of-api-providers" target="_blank" rel="noopener noreferrer">API Sağlayıcıları Listesi</a>'ne bakın. Web sitelerini ziyaret ederek kaydolun ve API anahtarı alın.</p><p><strong>2. API Anahtarınızı Ortam Değişkeni Olarak Ayarlayın:</strong></p><ul><li>  <strong>Linux/macOS:</strong></li>
    </ul>Terminalinizi açın ve </code>export<code> komutunu kullanın. Kalıcılık için bunu kabuk profil dosyanıza (örn: </code>~/.bashrc<code>, </code>~/.zshrc<code>) eklemeniz en iyisidir.
    </code>`<code>sh
    export PROVIDER_API_KEY="api_anahtarınız_buraya" 
    # PROVIDER_API_KEY yerine ilgili değişken adını yazın, örn: OPENAI_API_KEY, GOOGLE_API_KEY
    </code>`<code>
    TogetherAI örneği:
    </code>`<code>sh
    export TOGETHER_API_KEY="xxxxxxxxxxxxxxxxxxxxxx"
    </code>`<code>
<ul><li>  <strong>Windows:</strong></li>
<li>  <strong>Komut İstemi (Geçici, mevcut oturum için):</strong></li>
    </ul></code>`<code>cmd
    set PROVIDER_API_KEY=api_anahtarınız_buraya
    </code>`<code>
<ul><li>  <strong>PowerShell (Geçici, mevcut oturum için):</strong></li>
    </ul></code>`<code>powershell
    $env:PROVIDER_API_KEY="api_anahtarınız_buraya"
    </code>`<code>
<ul><li>  <strong>Kalıcı Olarak:</strong> Windows arama çubuğunda "environment variables" (çevre değişkenleri) arayın, "Sistem ortam değişkenlerini düzenle" seçeneğine tıklayın, ardından "Ortam Değişkenleri..." butonuna tıklayın. Uygun isimle (örn. </code>OPENAI_API_KEY<code>) ve anahtarınız değer olarak yeni bir Kullanıcı değişkeni ekleyin.</li></p><p></ul><em>(Daha fazla bilgi için SSS: <a href="#how-do-i-set-api-keys" target="_blank" rel="noopener noreferrer">API anahtarlarını nasıl ayarlayabilirim?</a> bölümüne bakınız).</em></p><p><strong>3. </code>config.ini<code> Dosyasını Güncelleyin:</strong></code></pre>ini
[MAIN]
is_local = False
provider_name = openai # Veya google, deepseek, togetherAI, huggingface
provider_model = gpt-3.5-turbo # Veya gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 vb.
provider_server_address = # Genellikle is_local = False olduğunda çoğu API için göz ardı edilir veya boş bırakılabilir
<h1>... diğer ayarlar ...</h1>
<pre><code class="language-"><em>Uyarı:</em> </code>config.ini<code> dosyasındaki değerlerin sonunda boşluk bırakmadığınızdan emin olun.</p><p><strong>API Sağlayıcıları Listesi</strong></p><p>| Sağlayıcı     | </code>provider_name<code> | Yerel? | Açıklama                                       | API Anahtar Bağlantısı (Örnekler)                     |
|---------------|-----------------|--------|------------------------------------------------|-------------------------------------------------------|
| OpenAI        | </code>openai<code>        | Hayır  | OpenAI'nin API'si ile ChatGPT modellerini kullanır. | <a href="https://platform.openai.com/signup" target="_blank" rel="noopener noreferrer">platform.openai.com/signup</a> |
| Google Gemini | </code>google<code>        | Hayır  | Google Gemini modellerini Google AI Studio ile kullanır. | <a href="https://aistudio.google.com/keys" target="_blank" rel="noopener noreferrer">aistudio.google.com/keys</a> |
| Deepseek      | </code>deepseek<code>      | Hayır  | Deepseek modellerini kendi API'leri ile kullanır. | <a href="https://platform.deepseek.com" target="_blank" rel="noopener noreferrer">platform.deepseek.com</a> |
| Hugging Face  | </code>huggingface<code>   | Hayır  | Hugging Face Inference API'den modeller kullanır. | <a href="https://huggingface.co/settings/tokens" target="_blank" rel="noopener noreferrer">huggingface.co/settings/tokens</a> |
| TogetherAI    | </code>togetherAI<code>    | Hayır  | TogetherAI API ile çeşitli açık kaynak modelleri kullanır. | <a href="https://api.together.ai/settings/api-keys" target="_blank" rel="noopener noreferrer">api.together.ai/settings/api-keys</a> |</p><p><em>Not:</em>
<ul><li>  Karmaşık web arama ve görev planlama için mevcut istem optimizasyonları Deepseek gibi modellere yönelik olduğundan, </code>gpt-4o<code> veya diğer OpenAI modellerini kullanmanızı önermiyoruz.</li>
<li>  Kodlama/bash görevlerinde Gemini ile, Deepseek için optimize edilmiş biçimlendirme istemlerini her zaman kesin olarak takip etmeyebileceği için sorun yaşanabilir.</li>
<li>  </code>config.ini<code> dosyasındaki </code>provider_server_address<code> ayarı, </code>is_local = False<code> olduğunda genellikle kullanılmaz; çünkü API uç noktası ilgili sağlayıcının kütüphanesinde sabit kodlanmıştır.</li></p><p></ul>Sonraki adım: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">Servisleri başlatın ve AgenticSeek'i çalıştırın</a></p><p><em>Sorun yaşıyorsanız <strong>Bilinen sorunlar</strong> bölümüne bakınız.</em></p><p><em>Ayrıntılı yapılandırma dosyası açıklaması için <strong>Config</strong> bölümüne bakınız.</em></p><hr></p><h2>Servisleri Başlatın ve Çalıştırın</h2></p><p>Varsayılan olarak AgenticSeek tamamen docker içinde çalışır.</p><p>Gerekli servisleri başlatın. Bu, docker-compose.yml dosyasından tüm servisleri başlatır; şunlar dahil:
    <ul><li>searxng</li>
    <li>redis (searxng tarafından gereklidir)</li>
    <li>frontend</li>
    <li>backend (eğer </code>full<code> kullanıyorsanız)</li>
</ul></code></pre>sh
./start_services.sh full # MacOS
start ./start_services.cmd full # Windows
<pre><code class="language-">
<strong>Uyarı:</strong> Bu adım tüm Docker imajlarını indirecek ve yükleyecektir, bu işlem 30 dakikaya kadar sürebilir. Servisleri başlattıktan sonra, herhangi bir mesaj göndermeden önce lütfen backend servisi tamamen başlatılana kadar bekleyin (günlüklerde <strong>backend: "GET /health HTTP/1.1" 200 OK</strong> mesajını görmelisiniz). Backend servisleri ilk çalıştırmada 5 dakika kadar sürebilir.</p><p></code>http://localhost:3000/<code> adresine gidin; web arayüzünü göreceksiniz.</p><p><em>Servis başlatma sorun giderme:</em> Eğer bu scriptler başarısız olursa, Docker Engine'in çalıştığından ve Docker Compose'un (V2, </code>docker compose<code>) doğru şekilde kurulu olduğundan emin olun. Hata mesajları için terminaldeki çıktıyı kontrol edin. <a href="#faq-troubleshooting" target="_blank" rel="noopener noreferrer">SSS: AgenticSeek veya scriptleri çalıştırırken hata alıyorum, ne yapmalıyım?</a> bölümüne bakınız.</p><p><strong>Opsiyonel:</strong> Ana makinede çalıştır (CLI modu):</p><p>CLI arayüzü ile çalıştırmak için paketi ana makinenize kurmanız gerekir:
</code></pre>sh
./install.sh
./install.bat # windows
<pre><code class="language-">
Servisleri başlatın:
</code></pre>sh
./start_services.sh # MacOS
start ./start_services.cmd # Windows
<pre><code class="language-">
CLI kullanın: </code>python3 cli.py<code></p><hr></p><h2>Kullanım</h2></p><p>Servislerin </code>./start_services.sh full<code> ile çalıştığından emin olun ve web arayüzü için </code>localhost:3000<code> adresine gidin.</p><p>Ayrıca config dosyasında </code>listen = True<code> olarak ayarlayarak konuşmadan yazıya (speech to text) özelliğini kullanabilirsiniz. Sadece CLI modu için geçerlidir.</p><p>Çıkmak için sadece </code>goodbye<code> yazmanız veya söylemeniz yeterlidir.</p><p>Bazı örnek kullanım şekilleri:</p><blockquote><em>Python'da bir yılan oyunu yap!</em></blockquote></p><blockquote><em>Fransa, Rennes'teki en iyi kafeleri web'de ara ve üç tanesinin adresleriyle birlikte rennes_cafes.txt dosyasına kaydet.</em></blockquote></p><blockquote><em>Bir sayının faktoriyelini hesaplayan bir Go programı yaz, factorial.go olarak çalışma alanına kaydet</em></blockquote></p><blockquote><em>summer_pictures klasörümdeki tüm JPG dosyalarını ara, bugünün tarihiyle yeniden adlandır ve yeniden adlandırılan dosyaların listesini photos_list.txt'ye kaydet</em></blockquote></p><blockquote><em>2024'ten popüler bilim kurgu filmlerini çevrimiçi ara, bu gece izlemek için üç tane seç. Listeyi movie_night.txt dosyasına kaydet.</em></blockquote></p><blockquote><em>2025'ten en son AI haber makalelerini web'de ara, üç tane seç ve başlıklarını ve özetlerini kazıyacak bir Python scripti yaz. Scripti news_scraper.py olarak, özetleri ise /home/projects klasöründe ai_news.txt olarak kaydet</em></blockquote></p><blockquote><em>Cuma günü, web'de ücretsiz bir hisse senedi fiyat API'si ara, supersuper7434567@gmail.com ile kayıt ol ve ardından API'yi kullanarak Tesla'nın günlük fiyatlarını çeken bir Python scripti yaz, sonuçları stock_prices.csv dosyasına kaydet.</em></blockquote></p><p><em>Form doldurma yeteneklerinin hâlâ deneysel olduğunu ve başarısız olabileceğini unutmayın.</em></p><p>
Sorgunuzu yazdıktan sonra, AgenticSeek göreve en uygun ajanı atayacaktır.</p><p>Bu erken prototipte, ajan yönlendirme sistemi sorgunuza göre her zaman doğru ajanı tahsis edemeyebilir.</p><p>Bu nedenle, ne istediğinizi ve AI'nın nasıl ilerlemesi gerektiğini çok açık bir şekilde belirtmelisiniz; örneğin bir web araması yapmasını istiyorsanız, şunu demeyin:</p><p></code>Yalnız seyahat için iyi ülkeleri biliyor musun?<code></p><p>Bunun yerine şunu sorun:</p><p></code>Bir web araması yap ve yalnız seyahat için en iyi ülkeleri bul<code></p><hr></p><h2><strong>LLM'i kendi sunucunuzda çalıştıracak şekilde kurulum</strong>  </h2></p><p>Güçlü bir bilgisayarınız veya kullanabileceğiniz bir sunucunuz varsa, fakat ona dizüstü bilgisayarınızdan erişmek istiyorsanız, özel llm sunucumuzu kullanarak LLM'i uzak bir sunucuda çalıştırabilirsiniz.</p><p>AI modelini çalıştıracak olan "sunucunuzda" ip adresini alın
</code></pre>sh
ip a | grep "inet " | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # yerel ip
curl https://ipinfo.io/ip # genel ip
<pre><code class="language-">
Not: Windows veya macOS için ip adresini bulmak için sırasıyla ipconfig veya ifconfig kullanın.</p><p>Depoyu klonlayın ve </code>server/<code> klasörüne girin.</p><p></code></pre>sh
git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
<pre><code class="language-">
Sunucuya özel gereksinimleri kurun:
</code></pre>sh
pip3 install -r requirements.txt
<pre><code class="language-">
Sunucu scriptini çalıştırın.
</code></pre>sh
python3 app.py --provider ollama --port 3333
<pre><code class="language-">
</code>ollama<code> ve </code>llamacpp<code> arasında LLM servisi olarak seçim yapabilirsiniz.</p><p>
Şimdi kişisel bilgisayarınızda:</p><p></code>config.ini<code> dosyasını değiştirerek </code>provider_name<code> değerini </code>server<code>, </code>provider_model<code> değerini ise </code>deepseek-r1:xxb<code> olarak ayarlayın.
</code>provider_server_address<code> değerini, modeli çalıştıracak makinenin ip adresi olarak ayarlayın.
</code></pre>sh
[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
<pre><code class="language-"></p><p>Sonraki adım: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">Servisleri başlatın ve AgenticSeek'i çalıştırın</a>  </p><hr></p><h2>Konuşmadan Yazıya (Speech to Text)</h2></p><p>Uyarı: konuşmadan yazıya özelliği şu anda sadece CLI modunda çalışır.</p><p>Lütfen şu anda konuşmadan yazıya özelliğinin yalnızca İngilizce olarak çalıştığını unutmayın.</p><p>Konuşmadan yazıya işlevselliği varsayılan olarak devre dışıdır. Bunu etkinleştirmek için config.ini dosyasında listen seçeneğini True olarak ayarlayın:
</code></pre>
listen = True
<pre><code class="language-">
Etkinleştirildiğinde, konuşmadan yazıya özelliği girişinizi işlemeye başlamadan önce tetikleyici bir anahtar kelimeyi, yani ajan adını dinler. Ajanın adını, <em>config.ini</em> dosyasındaki </code>agent_name<code> değerini güncelleyerek özelleştirebilirsiniz:
</code></pre>
agent_name = Friday
<pre><code class="language-">
En iyi tanıma için, temsilci adı olarak "John" veya "Emma" gibi yaygın bir İngilizce isim kullanılmasını öneriyoruz.</p><p>Transkript görünmeye başladığında, temsilcinin adını yüksek sesle söyleyerek onu uyandırın (ör. "Friday").</p><p>Sorgunuzu net bir şekilde konuşun.</p><p>Talebinizi sistemin devam etmesini işaret eden bir onay ifadesiyle bitirin. Onay ifadelerine örnekler:</code></pre>
"do it", "go ahead", "execute", "run", "start", "thanks", "would ya", "please", "okay?", "proceed", "continue", "go on", "do that", "go it", "do you understand?"
<pre><code class="language-">
<h2>Konfig</h2></p><p>Örnek konfig:</code></pre>
[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # Ollama için örnek; LM-Studio için http://127.0.0.1:1234 kullanın
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False</p><p>jarvis_personality = False
languages = en zh # TTS ve potansiyel yönlendirme için diller listesi.
[BROWSER]
headless_browser = False
stealth_mode = False
<pre><code class="language-">
<strong></code>config.ini<code> Ayarlarının Açıklaması</strong>:</p><ul><li>  <strong></code>[MAIN]<code> Bölümü:</strong></li>
    <li>  </code>is_local<code>: Yerel bir LLM sağlayıcı (Ollama, LM-Studio, yerel OpenAI-uyumlu sunucu) veya kendi barındırdığınız sunucu seçeneği kullanıyorsanız </code>True<code>. Bulut tabanlı bir API (OpenAI, Google, vb.) kullanıyorsanız </code>False<code>.</li>
    <li>  </code>provider_name<code>: LLM sağlayıcısını belirtir.</li>
        <li>  Yerel seçenekler: </code>ollama<code>, </code>lm-studio<code>, </code>openai<code> (yerel OpenAI uyumlu sunucular için), </code>server<code> (kendi barındırılan sunucu kurulumu için).</li>
        <li>  API seçenekleri: </code>openai<code>, </code>google<code>, </code>deepseek<code>, </code>huggingface<code>, </code>togetherAI<code>.</li>
    <li>  </code>provider_model<code>: Seçilen sağlayıcı için belirli model adı veya kimliği (örn. Ollama için </code>deepseekcoder:6.7b<code>, OpenAI API için </code>gpt-3.5-turbo<code>, TogetherAI için </code>mistralai/Mixtral-8x7B-Instruct-v0.1<code>).</li>
    <li>  </code>provider_server_address<code>: LLM sağlayıcınızın adresi.</li>
        <li>  Yerel sağlayıcılar için: örn. Ollama için </code>http://127.0.0.1:11434<code>, LM-Studio için </code>http://127.0.0.1:1234<code>.</li>
        <li>  </code>server<code> sağlayıcı tipi için: Kendi barındırdığınız LLM sunucunuzun adresi (örn. </code>http://your_server_ip:3333<code>).</li>
        <li>  Bulut API'leri (</code>is_local = False<code>): Genellikle yok sayılır ya da boş bırakılabilir, çünkü API uç noktası genellikle istemci kütüphanesi tarafından yönetilir.</li>
    <li>  </code>agent_name<code>: Yapay zeka asistanının adı (örn. Friday). Konuşmadan yazıya tetikleme kelimesi olarak kullanılır.</li>
    <li>  </code>recover_last_session<code>: Önceki oturumun durumunu geri yüklemeye çalışmak için </code>True<code>, yeni başlamak için </code>False<code>.</li>
    <li>  </code>save_session<code>: Gelecekte kurtarmak için mevcut oturumun durumunu kaydetmek için </code>True<code>, aksi takdirde </code>False<code>.</li>
    <li>  </code>speak<code>: Metinden konuşmaya sesli çıktı için </code>True<code>, devre dışı bırakmak için </code>False<code>.</li>
    <li>  </code>listen<code>: Konuşmadan yazıya sesli giriş (yalnızca CLI modu) için </code>True<code>, devre dışı bırakmak için </code>False<code>.</li>
    <li>  </code>work_dir<code>: <strong>Kritik:</strong> AgenticSeek'in dosya okuyup/yazacağı dizin. <strong>Bu yolun sisteminizde geçerli ve erişilebilir olduğundan emin olun.</strong></li>
    <li>  </code>jarvis_personality<code>: Daha "Jarvis-benzeri" bir sistem istemi için </code>True<code> (deneysel), standart istem için </code>False<code>.</li>
    <li>  </code>languages<code>: Virgülle ayrılmış diller listesi (örn. </code>en, zh, fr<code>). TTS ses seçimi için kullanılır (ilki varsayılan olur) ve LLM yönlendiriciye yardımcı olabilir. Yönlendirici verimliliği için çok fazla veya çok benzer dil eklemekten kaçının.</li>
<li>  <strong></code>[BROWSER]<code> Bölümü:</strong></li>
    <li>  </code>headless_browser<code>: Otomatikleştirilmiş tarayıcıyı görünür bir pencere olmadan çalıştırmak için </code>True<code> (web arayüzü veya etkileşimsiz kullanım için önerilir). Tarayıcı penceresini göstermek için </code>False<code> (CLI modu veya hata ayıklama için yararlı).</li>
    <li>  </code>stealth_mode<code>: Tarayıcı otomasyonunun algılanmasını zorlaştıracak önlemleri etkinleştirmek için </code>True<code>. Anticaptcha gibi tarayıcı eklentilerinin manuel olarak yüklenmesini gerektirebilir.</li></p><p>
</ul>Bu bölüm, desteklenen LLM sağlayıcı tiplerini özetler. Bunları </code>config.ini<code> dosyasında yapılandırın.</p><p><strong>Yerel Sağlayıcılar (Kendi Donanımınızda Çalıştırılır):</strong></p><p>| </code>config.ini<code>de Sağlayıcı Adı | </code>is_local<code> | Açıklama                                                                | Kurulum Bölümü                                                        |
|------------------------------|------------|-------------------------------------------------------------------------|-----------------------------------------------------------------------|
| </code>ollama<code>                     | </code>True<code>     | Yerel LLM'leri sunmak için Ollama'yı kullanır.                          | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">Yerel LLM çalıştırma kurulumu</a> |
| </code>lm-studio<code>                  | </code>True<code>     | Yerel LLM'leri sunmak için LM-Studio'yu kullanır.                       | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">Yerel LLM çalıştırma kurulumu</a> |
| </code>openai<code> (yerel sunucu için) | </code>True<code>     | OpenAI uyumlu API sunan yerel bir sunucuya bağlanır (örn. llama.cpp).   | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">Yerel LLM çalıştırma kurulumu</a> |
| </code>server<code>                     | </code>False<code>    | Başka bir makinede çalışan AgenticSeek kendi barındırılan LLM sunucusuna bağlanır. | <a href="#setup-to-run-the-llm-on-your-own-server" target="_blank" rel="noopener noreferrer">LLM'i kendi sunucunuzda çalıştırma kurulumu</a> |</p><p><strong>API Sağlayıcılar (Bulut Tabanlı):</strong></p><p>| </code>config.ini<code>de Sağlayıcı Adı | </code>is_local<code> | Açıklama                                         | Kurulum Bölümü                                     |
|------------------------------|------------|--------------------------------------------------|----------------------------------------------------|
| </code>openai<code>                     | </code>False<code>    | OpenAI'nin resmi API'sini kullanır (örn. GPT-3.5, GPT-4). | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API ile çalışma kurulumu</a> |
| </code>google<code>                     | </code>False<code>    | API üzerinden Google'ın Gemini modellerini kullanır. | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API ile çalışma kurulumu</a> |
| </code>deepseek<code>                   | </code>False<code>    | Deepseek'in resmi API'sini kullanır.             | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API ile çalışma kurulumu</a> |
| </code>huggingface<code>                | </code>False<code>    | Hugging Face Inference API'sini kullanır.        | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API ile çalışma kurulumu</a> |
| </code>togetherAI<code>                 | </code>False<code>    | Çeşitli açık modeller için TogetherAI API'sini kullanır. | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API ile çalışma kurulumu</a> |</p><hr>
<h2>Sorun Giderme</h2></p><p>Herhangi bir sorunla karşılaşırsanız, bu bölüm size rehberlik edecektir.</p><h1>Bilinen Sorunlar</h1></p><h2>ChromeDriver Sorunları</h2></p><p><strong>Hata Örneği:</strong> </code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX<code></p><ul><li>  <strong>Neden:</strong> Yüklü ChromeDriver sürümünüz, Google Chrome tarayıcınızın sürümüyle uyumlu değil.</li>
<li>  <strong>Çözüm:</strong></li>
    <li> <strong>Chrome Sürümünü Kontrol Edin:</strong> Google Chrome'u açın, </code>Ayarlar > Chrome Hakkında<code> bölümüne gidin ve sürümünüzü bulun (örn. "Sürüm 120.0.6099.110").</li>
    <li> <strong>Eşleşen ChromeDriver'ı İndirin:</strong></li>
        <li>  Chrome 115 ve üzeri sürümler için: <a href="https://googlechromelabs.github.io/chrome-for-testing/" target="_blank" rel="noopener noreferrer">Chrome for Testing (CfT) JSON Endpoints</a> adresine gidin. "Stable" kanalını bulun ve Chrome'unuzun ana sürümüyle eşleşen ChromeDriver'ı işletim sisteminize uygun olarak indirin.</li>
        <li>  Eski sürümler (daha az yaygın): <a href="https://chromedriver.chromium.org/downloads" target="_blank" rel="noopener noreferrer">ChromeDriver - WebDriver for Chrome</a> sayfasında bulabilirsiniz.</li>
        <li>  Aşağıdaki görsel CfT sayfasından bir örneği göstermektedir:</li>
            </ul><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="Chrome for Testing sayfasından belirli sürüm Chromedriver indirin">
    <ul><li> <strong>ChromeDriver'ı Kurun:</strong></li>
        <li>  İndirilen </code>chromedriver<code> dosyasının (Windows'ta </code>chromedriver.exe<code>) sisteminizin PATH ortam değişkeninde listelenen bir dizinde (örn. Linux/macOS için </code>/usr/local/bin<code> veya Windows'ta PATH'e eklenmiş bir özel komut dosyası klasörü) olduğundan emin olun.</li>
        <li>  Alternatif olarak, bunu </code>agenticSeek<code> projesinin kök dizinine yerleştirin.</li>
        <li>  Sürücünün çalıştırılabilir olduğundan emin olun (örn. Linux/macOS için </code>chmod +x chromedriver<code>).</li>
    <li> Daha fazla ayrıntı için ana Kurulum rehberindeki <a href="#chromedriver-installation" target="_blank" rel="noopener noreferrer">ChromeDriver Kurulumu</a> bölümüne bakın.</li></p><p></ul>Bu bölüm eksikse veya başka ChromeDriver sorunlarıyla karşılaşırsanız, lütfen mevcut <a href="https://github.com/Fosowl/agenticSeek/issues" target="_blank" rel="noopener noreferrer">GitHub Sorunları</a> arasında arama yapın veya yeni bir tane açın.</p><p></code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113
Current browser version is 134.0.6998.89 with binary path<code></p><p>Bu, tarayıcınız ile chromedriver sürümünüz arasında bir uyumsuzluk varsa oluşur.</p><p>En son sürümü indirmek için şuraya gidin:</p><p>https://developer.chrome.com/docs/chromedriver/downloads</p><p>Chrome'un 115 veya üzeri bir sürümünü kullanıyorsanız şuraya gidin:</p><p>https://googlechromelabs.github.io/chrome-for-testing/</p><p>Ve işletim sisteminize uygun chromedriver sürümünü indirin.</p><p><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text"></p><p>Bu bölüm eksikse lütfen bir sorun bildirin.</p><h2> bağlantı adaptörleri Sorunları</h2>
</code></pre>
Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'</code> (Not: port değişebilir)
<pre><code class="language-">
<ul><li>  <strong>Neden:</strong> <code>lm-studio</code> (veya benzer diğer yerel OpenAI uyumlu sunucular) için <code>config.ini</code> dosyasındaki <code>provider_server_address</code>, <code>http://</code> öneki olmadan girilmiş veya yanlış porta yönlendirilmiş.</li>
<li>  <strong>Çözüm:</strong></li>
    <li>  Adresin <code>http://</code> içerdiğinden emin olun. LM-Studio genellikle <code>http://127.0.0.1:1234</code> ile varsayılan gelir.</li>
    <li>  Doğru <code>config.ini</code>: <code>provider_server_address = http://127.0.0.1:1234</code> (veya gerçek LM-Studio sunucu portunuz).</li></p><p></ul><h2>SearxNG Temel URL Sağlanmadı</h2>
</code></pre>
raise ValueError("SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.")
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.<code>
</code>`<code></p><h2>SSS</h2></p><p><strong>S: Hangi donanım gereklidir?</strong>  </p><p>| Model Boyutu | GPU  | Yorum                                               |
|--------------|------|-----------------------------------------------------|
| 7B           | 8GB Vram | ⚠️ Tavsiye edilmez. Performansı düşük, sık sık halüsinasyon yapar ve planlayıcı ajanlar muhtemelen başarısız olur. |
| 14B          | 12 GB VRAM (örn. RTX 3060) | ✅ Basit görevler için kullanılabilir. Web tarama ve planlama görevlerinde zorlanabilir. |
| 32B          | 24+ GB VRAM (örn. RTX 4090) | 🚀 Çoğu görevde başarılı, yine de görev planlamada zorlanabilir |
| 70B+         | 48+ GB Vram | 💪 Mükemmel. Gelişmiş kullanım senaryoları için önerilir. |</p><p><strong>S: Hata alıyorum, ne yapmalıyım?</strong>  </p><p>Yerel çalışıyor mu kontrol edin (</code>ollama serve<code>), </code>config.ini` dosyanız sağlayıcınızla uyumlu mu ve bağımlılıklar yüklü mü emin olun. Hiçbiri işe yaramazsa bir sorun bildirmekten çekinmeyin.</p><p><strong>S: Gerçekten %100 yerel çalışabilir mi?</strong>  </p><p>Evet, Ollama, lm-studio veya server sağlayıcılarla, tüm konuşmadan yazıya, LLM ve metinden konuşmaya modelleri yerel olarak çalışır. Yerel olmayan seçenekler (OpenAI veya diğer API'ler) isteğe bağlıdır.</p><p><strong>S: Zaten Manus varken neden AgenticSeek kullanmalıyım?</strong></p><p>Manus'un aksine AgenticSeek, harici sistemlerden bağımsızlığı ön planda tutar; size daha fazla kontrol, gizlilik ve API maliyetlerinden kaçınma imkanı sunar.</p><p><strong>S: Projenin arkasında kim var?</strong></p><p>Proje tarafımdan başlatıldı, ayrıca iki arkadaşım GitHub'daki açık kaynak topluluğundan katkıcı ve sürdürücü olarak yer alıyor. Sadece tutkulu bir grup bireyiz, bir startup veya herhangi bir kuruluşla ilişkili değiliz.</p><p>Kişisel hesabım (https://x.com/Martin993886460) dışındaki herhangi bir AgenticSeek hesabı X üzerinde sahteciliktir.</p><h2>Katkıda Bulunun</h2></p><p>AgenticSeek'i geliştirmek için geliştiricilere ihtiyacımız var! Açık sorunları veya tartışmaları inceleyin.</p><p><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">Katkı rehberi</a></p><p><a href="https://www.star-history.com/#Fosowl/agenticSeek&Date" target="_blank" rel="noopener noreferrer"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&type=Date" alt="Star History Chart"></a></p><h2>Sürdürücüler:</h2></p><p> > <a href="https://github.com/Fosowl" target="_blank" rel="noopener noreferrer">Fosowl</a> | Paris Saati </p><p> > <a href="https://github.com/antoineVIVIES" target="_blank" rel="noopener noreferrer">antoineVIVIES</a> | Taipei Saati </p><p> > <a href="https://github.com/steveh8758" target="_blank" rel="noopener noreferrer">steveh8758</a> | Taipei Saati </p><h2>Özel Teşekkürler:</h2></p><p> > <a href="https://github.com/tcsenpai" target="_blank" rel="noopener noreferrer">tcsenpai</a> ve <a href="https://github.com/plitc" target="_blank" rel="noopener noreferrer">plitc</a> arka uç dockerizasyonuna yardımcı oldukları için</p><h2>Sponsorlar:</h2></p><p>Aylık 5$ veya daha fazla sponsorlar burada yer alır:
<ul><li><strong>tatra-labs</strong></li></p><p></ul>Sure! Please provide the content of Part 4 of 4 that you would like to have translated.

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-16

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>