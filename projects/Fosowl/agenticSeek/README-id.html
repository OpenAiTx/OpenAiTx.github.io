<!DOCTYPE html>
<html lang="id">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>agenticSeek - Read agenticSeek documentation in Indonesian. This project has 18325 stars on GitHub.</title>
    <meta name="description" content="Read agenticSeek documentation in Indonesian. This project has 18325 stars on GitHub.">
    <meta name="keywords" content="agenticSeek, Indonesian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "agenticSeek",
  "description": "Read agenticSeek documentation in Indonesian. This project has 18325 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "Fosowl"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 18325
  },
  "url": "https://OpenAiTx.github.io/projects/Fosowl/agenticSeek/README-id.html",
  "sameAs": "https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/Fosowl/agenticSeek" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    agenticSeek
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 18325 stars</span>
                <span class="language">Indonesian</span>
                <span>by Fosowl</span>
            </div>
        </div>
        
        <div class="content">
            <h1>AgenticSeek: Alternatif Manus Privat, Lokal.</h1></p><p><p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
<p>  English | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md" target="_blank" rel="noopener noreferrer">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md" target="_blank" rel="noopener noreferrer">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md" target="_blank" rel="noopener noreferrer">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md" target="_blank" rel="noopener noreferrer">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md" target="_blank" rel="noopener noreferrer">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md" target="_blank" rel="noopener noreferrer">Español</a></p><p><em>Sebagai <strong>alternatif Manus AI 100% lokal</strong>, asisten AI berbasis suara ini secara otomatis menjelajah web, menulis kode, dan merencanakan tugas sambil menjaga seluruh data tetap di perangkat Anda. Disesuaikan untuk model reasoning lokal, berjalan sepenuhnya di perangkat keras Anda, memastikan privasi total dan tanpa ketergantungan cloud.</em></p><p><a href="https://fosowl.github.io/agenticSeek.html" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?label=Website&message=AgenticSeek&color=blue&style=flat-square" alt="Kunjungi AgenticSeek"></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="Lisensi"> <a href="https://discord.gg/8hGDaME3TC" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&logoColor=white" alt="Discord"></a> <a href="https://x.com/Martin993886460" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&label=Update%20%40Fosowl" alt="Twitter"></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars"></a></p><h3>Mengapa AgenticSeek?</h3></p><ul><li>🔒 Sepenuhnya Lokal & Privat - Semua berjalan di mesin Anda — tanpa cloud, tanpa berbagi data. File, percakapan, dan pencarian Anda tetap privat.</li></p><p><li>🌐 Penjelajahan Web Cerdas - AgenticSeek dapat menjelajah internet secara mandiri — mencari, membaca, ekstrak info, mengisi formulir web — semua tanpa tangan.</li></p><p><li>💻 Asisten Koding Otonom - Butuh kode? Dapat menulis, debug, dan menjalankan program dalam Python, C, Go, Java, dan lainnya — semua tanpa pengawasan.</li></p><p><li>🧠 Pemilihan Agen Cerdas - Anda bertanya, ia menentukan agen terbaik secara otomatis. Seperti memiliki tim ahli siap membantu.</li></p><p><li>📋 Merencanakan & Mengeksekusi Tugas Kompleks - Dari perencanaan perjalanan hingga proyek rumit — dapat membagi tugas besar menjadi langkah-langkah dan menyelesaikannya dengan banyak agen AI.</li></p><p><li>🎙️ Berbasis Suara - Fitur suara dan konversi suara ke teks yang bersih, cepat, futuristik, memungkinkan Anda berbicara layaknya AI pribadi dari film sci-fi. (Sedang dikembangkan)</li></p><p></ul><h3><strong>Demo</strong></h3></p><blockquote><em>Bisakah kamu mencari proyek agenticSeek, pelajari skill yang dibutuhkan, lalu buka CV_candidates.zip dan beritahu saya mana yang paling cocok dengan proyek tersebut</em></blockquote></p><p>https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</p><p>Disclaimer: Demo ini, termasuk semua file yang muncul (misal: CV_candidates.zip), sepenuhnya fiktif. Kami bukan perusahaan, kami mencari kontributor open-source bukan kandidat.</p><blockquote>🛠⚠️️ <strong>Masih Dalam Pengembangan Aktif</strong></blockquote></p><blockquote>🙏 Proyek ini dimulai sebagai sampingan dan tidak memiliki roadmap maupun pendanaan. Proyek ini berkembang jauh melebihi ekspektasi hingga muncul di GitHub Trending. Kontribusi, umpan balik, dan kesabaran sangat dihargai.</blockquote></p><h2>Prasyarat</h2></p><p>Sebelum memulai, pastikan Anda telah menginstal software berikut:</p><ul><li>  <strong>Git:</strong> Untuk cloning repository. <a href="https://git-scm.com/downloads" target="_blank" rel="noopener noreferrer">Download Git</a></li>
<li>  <strong>Python 3.10.x:</strong> Sangat disarankan menggunakan Python versi 3.10.x. Versi lain bisa menyebabkan error dependensi. <a href="https://www.python.org/downloads/release/python-3100/" target="_blank" rel="noopener noreferrer">Download Python 3.10</a> (pilih versi 3.10.x).</li>
<li>  <strong>Docker Engine & Docker Compose:</strong> Untuk menjalankan layanan seperti SearxNG.</li>
    <li>  Instal Docker Desktop (termasuk Docker Compose V2): <a href="https://docs.docker.com/desktop/install/windows-install/" target="_blank" rel="noopener noreferrer">Windows</a> | <a href="https://docs.docker.com/desktop/install/mac-install/" target="_blank" rel="noopener noreferrer">Mac</a> | <a href="https://docs.docker.com/desktop/install/linux-install/" target="_blank" rel="noopener noreferrer">Linux</a></li>
    <li>  Atau, instal Docker Engine dan Docker Compose secara terpisah di Linux: <a href="https://docs.docker.com/engine/install/" target="_blank" rel="noopener noreferrer">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/" target="_blank" rel="noopener noreferrer">Docker Compose</a> (pastikan Compose V2, misal <code>sudo apt-get install docker-compose-plugin</code>).</li></p><p></ul><h3>1. <strong>Clone repository dan setup</strong></h3></p><pre><code class="language-sh">git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env</code></pre></p><h3>2. Ubah isi file .env</h3></p><pre><code class="language-sh">SEARXNG_BASE_URL="http://127.0.0.1:8080"
REDIS_BASE_URL="redis://redis:6379/0"
WORK_DIR="/Users/mlg/Documents/workspace_for_ai"
OLLAMA_PORT="11434"
LM_STUDIO_PORT="1234"
CUSTOM_ADDITIONAL_LLM_PORT="11435"
OPENAI_API_KEY='optional'
DEEPSEEK_API_KEY='optional'
OPENROUTER_API_KEY='optional'
TOGETHER_API_KEY='optional'
GOOGLE_API_KEY='optional'
ANTHROPIC_API_KEY='optional'</code></pre></p><p>Perbarui file <code>.env</code> dengan nilai Anda sendiri sesuai kebutuhan:</p><ul><li><strong>SEARXNG_BASE_URL</strong>: Biarkan tanpa perubahan </li>
<li><strong>REDIS_BASE_URL</strong>: Biarkan tanpa perubahan </li>
<li><strong>WORK_DIR</strong>: Path direktori kerja di mesin lokal Anda. AgenticSeek dapat membaca dan berinteraksi dengan file di sini.</li>
<li><strong>OLLAMA_PORT</strong>: Nomor port untuk layanan Ollama.</li>
<li><strong>LM_STUDIO_PORT</strong>: Nomor port untuk layanan LM Studio.</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>: Port untuk layanan LLM kustom tambahan.</li></p><p></ul><strong>API Key sepenuhnya opsional bagi pengguna yang memilih menjalankan LLM secara lokal. Ini adalah tujuan utama proyek ini. Biarkan kosong jika perangkat keras Anda memadai</strong></p><h3>3. <strong>Mulai Docker</strong></h3></p><p>Pastikan Docker terinstal dan berjalan di sistem Anda. Mulai Docker dengan perintah berikut:</p><ul><li><strong>Di Linux/macOS:</strong>  </li>
    </ul>Buka terminal dan jalankan:
    <pre><code class="language-sh">    sudo systemctl start docker
    ``<code>
    Atau buka Docker Desktop dari menu aplikasi jika sudah terinstal.</p><ul><li><strong>Di Windows:</strong>  </li>
    </ul>Mulai Docker Desktop dari Start menu.</p><p>Anda bisa memverifikasi Docker sudah berjalan dengan menjalankan:</code></pre>sh
docker info
<pre><code class="language-">Jika Anda melihat informasi instalasi Docker, berarti Docker sudah berjalan dengan benar.</p><p>Lihat tabel <a href="#list-of-local-providers" target="_blank" rel="noopener noreferrer">Penyedia Lokal</a> di bawah untuk ringkasan.</p><p>Langkah selanjutnya: <a href="#start-services-and-run" target="_blank" rel="noopener noreferrer">Jalankan AgenticSeek secara lokal</a></p><p><em>Lihat bagian <a href="#troubleshooting" target="_blank" rel="noopener noreferrer">Troubleshooting</a> jika mengalami masalah.</em>
<em>Jika perangkat keras Anda tidak bisa menjalankan LLM lokal, lihat <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">Setup untuk menjalankan dengan API</a>.</em>
<em>Penjelasan detail </code>config.ini<code> lihat di <a href="#config" target="_blank" rel="noopener noreferrer">Config Section</a>.</em></p><hr></p><h2>Setup untuk menjalankan LLM secara lokal di mesin Anda</h2></p><p><strong>Kebutuhan Hardware:</strong></p><p>Untuk menjalankan LLM lokal, Anda butuh perangkat keras yang memadai. Minimal diperlukan GPU yang mampu menjalankan Magistral, Qwen atau Deepseek 14B. Lihat FAQ untuk rekomendasi model/kinerja secara detail.</p><p><strong>Setup penyedia lokal Anda</strong>  </p><p>Jalankan penyedia lokal Anda, misal dengan ollama:
</code></pre>sh
ollama serve
<pre><code class="language-">
Lihat di bawah untuk daftar penyedia lokal yang didukung.</p><p><strong>Perbarui config.ini</strong></p><p>Ubah file config.ini untuk mengatur provider_name ke penyedia yang didukung dan provider_model ke LLM yang didukung oleh penyedia Anda. Kami merekomendasikan model reasoning seperti <em>Magistral</em> atau <em>Deepseek</em>.</p><p>Lihat <strong>FAQ</strong> di akhir README untuk kebutuhan hardware.
</code></pre>sh
[MAIN]
is_local = True # Apakah Anda menjalankan secara lokal atau dengan penyedia remote.
provider_name = ollama # atau lm-studio, openai, dll..
provider_model = deepseek-r1:14b # pilih model sesuai hardware Anda
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # nama AI Anda
recover_last_session = True # apakah ingin memulihkan sesi sebelumnya
save_session = True # apakah ingin menyimpan sesi saat ini
speak = False # text to speech
listen = False # Speech to text, hanya untuk CLI, eksperimental
jarvis_personality = False # Apakah menggunakan personality seperti "Jarvis" (eksperimental)
languages = en zh # Daftar bahasa, Text to speech default ke bahasa pertama
[BROWSER]
headless_browser = True # biarkan tanpa perubahan kecuali menggunakan CLI di host.
stealth_mode = True # Gunakan selenium tidak terdeteksi untuk mengurangi deteksi browser
<pre><code class="language-">
<strong>Peringatan</strong>:</p><ul><li>Format file </code>config.ini<code> tidak mendukung komentar. </li>
</ul>Jangan copy-paste contoh konfigurasi secara langsung, karena komentar akan menyebabkan error. Ubah secara manual file </code>config.ini<code> dengan setting yang diinginkan, tanpa komentar.</p><ul><li>Jangan <em>PERNAH</em> set provider_name ke </code>openai<code> jika menggunakan LM-studio untuk menjalankan LLM. Set ke </code>lm-studio<code>.</li></p><p><li>Beberapa penyedia (misal: lm-studio) mengharuskan </code>http://<code> di depan IP. Contoh </code>http://127.0.0.1:1234<code></li></p><p></ul><strong>Daftar penyedia lokal</strong></p><p>| Provider  | Lokal? | Deskripsi                                               |
|-----------|--------|---------------------------------------------------------|
| ollama    | Ya     | Jalankan LLM lokal dengan mudah menggunakan ollama       |
| lm-studio | Ya     | Jalankan LLM lokal dengan LM studio (set </code>provider_name<code> ke </code>lm-studio<code>)|
| openai    | Ya     | Gunakan API kompatibel openai (misal: llama.cpp server)  |</p><p>Langkah selanjutnya: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">Mulai layanan dan jalankan AgenticSeek</a>  </p><p><em>Lihat bagian <a href="#troubleshooting" target="_blank" rel="noopener noreferrer">Troubleshooting</a> jika Anda mengalami masalah.</em>
<em>Jika perangkat keras Anda tidak dapat menjalankan LLM lokal, lihat <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">Setup untuk menjalankan dengan API</a>.</em>
<em>Penjelasan detail </code>config.ini<code> lihat di <a href="#config" target="_blank" rel="noopener noreferrer">Config Section</a>.</em></p><h2>Setup untuk menjalankan dengan API</h2></p><p>Setup ini menggunakan penyedia LLM cloud eksternal. Anda perlu API key dari layanan pilihan Anda.</p><p><strong>1. Pilih Penyedia API dan Dapatkan API Key:</strong></p><p>Lihat <a href="#list-of-api-providers" target="_blank" rel="noopener noreferrer">Daftar Penyedia API</a> di bawah. Kunjungi situs web mereka untuk mendaftar dan mendapatkan API key.</p><p><strong>2. Set API Key Anda sebagai Environment Variable:</strong></p><ul><li>  <strong>Linux/macOS:</strong></li>
    </ul>Buka terminal dan gunakan perintah </code>export<code>. Sebaiknya tambahkan ke file profil shell Anda (misal, </code>~/.bashrc<code>, </code>~/.zshrc<code>) untuk permanen.
    </code>`<code>sh
    export PROVIDER_API_KEY="your_api_key_here" 
    # Ganti PROVIDER_API_KEY dengan nama variabel spesifik, misal OPENAI_API_KEY, GOOGLE_API_KEY
    </code>`<code>
    Contoh untuk TogetherAI:
    </code>`<code>sh
    export TOGETHER_API_KEY="xxxxxxxxxxxxxxxxxxxxxx"
    </code>`<code>
<ul><li>  <strong>Windows:</strong></li>
<li>  <strong>Command Prompt (Sementara untuk sesi saat ini):</strong></li>
    </ul></code>`<code>cmd
    set PROVIDER_API_KEY=your_api_key_here
    </code>`<code>
<ul><li>  <strong>PowerShell (Sementara untuk sesi saat ini):</strong></li>
    </ul></code>`<code>powershell
    $env:PROVIDER_API_KEY="your_api_key_here"
    </code>`<code>
<ul><li>  <strong>Permanen:</strong> Cari "environment variables" di bilah pencarian Windows, klik "Edit the system environment variables," lalu klik tombol "Environment Variables...". Tambahkan variabel User baru dengan nama yang sesuai (misal, </code>OPENAI_API_KEY<code>) dan masukkan key Anda sebagai nilainya.</li></p><p></ul><em>(Lihat FAQ: <a href="#how-do-i-set-api-keys" target="_blank" rel="noopener noreferrer">Bagaimana cara mengatur API keys?</a> untuk detail lebih lanjut).</em></p><p>
<strong>3. Perbarui </code>config.ini<code>:</strong></code></pre>ini
[MAIN]
is_local = False
provider_name = openai # Atau google, deepseek, togetherAI, huggingface
provider_model = gpt-3.5-turbo # Atau gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 dll.
provider_server_address = # Biasanya diabaikan atau dikosongkan ketika is_local = False untuk kebanyakan API
<h1>... pengaturan lain ...</h1>
<pre><code class="language-"><em>Peringatan:</em> Pastikan tidak ada spasi di akhir nilai dalam </code>config.ini<code>.</p><p><strong>Daftar Penyedia API</strong></p><p>| Penyedia     | </code>provider_name<code> | Lokal? | Deskripsi                                         | Link API Key (Contoh)                        |
|--------------|-----------------|--------|---------------------------------------------------|----------------------------------------------|
| OpenAI       | </code>openai<code>        | Tidak  | Gunakan model ChatGPT melalui API OpenAI.         | <a href="https://platform.openai.com/signup" target="_blank" rel="noopener noreferrer">platform.openai.com/signup</a> |
| Google Gemini| </code>google<code>        | Tidak  | Gunakan model Google Gemini melalui Google AI Studio. | <a href="https://aistudio.google.com/keys" target="_blank" rel="noopener noreferrer">aistudio.google.com/keys</a> |
| Deepseek     | </code>deepseek<code>      | Tidak  | Gunakan model Deepseek melalui API mereka.        | <a href="https://platform.deepseek.com" target="_blank" rel="noopener noreferrer">platform.deepseek.com</a> |
| Hugging Face | </code>huggingface<code>   | Tidak  | Gunakan model dari Hugging Face Inference API.    | <a href="https://huggingface.co/settings/tokens" target="_blank" rel="noopener noreferrer">huggingface.co/settings/tokens</a> |
| TogetherAI   | </code>togetherAI<code>    | Tidak  | Gunakan berbagai model open-source melalui TogetherAI API.| <a href="https://api.together.ai/settings/api-keys" target="_blank" rel="noopener noreferrer">api.together.ai/settings/api-keys</a> |</p><p><em>Catatan:</em>
<ul><li>  Kami menyarankan untuk tidak menggunakan </code>gpt-4o<code> atau model OpenAI lain untuk penelusuran web kompleks dan perencanaan tugas karena optimasi prompt saat ini difokuskan pada model seperti Deepseek.</li>
<li>  Tugas coding/bash mungkin mengalami masalah dengan Gemini, karena model ini mungkin tidak selalu mengikuti format prompt yang telah dioptimalkan untuk Deepseek.</li>
<li>  </code>provider_server_address<code> pada </code>config.ini<code> umumnya tidak digunakan ketika </code>is_local = False<code> karena endpoint API biasanya sudah tertanam di library masing-masing penyedia.</li></p><p></ul>Langkah berikutnya: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">Mulai layanan dan jalankan AgenticSeek</a></p><p><em>Lihat bagian <strong>Known issues</strong> jika Anda mengalami masalah</em></p><p><em>Lihat bagian <strong>Config</strong> untuk penjelasan detail file konfigurasi.</em></p><hr></p><h2>Mulai layanan dan Jalankan</h2></p><p>Secara default AgenticSeek dijalankan sepenuhnya dalam docker.</p><p>Mulai layanan yang dibutuhkan. Ini akan menjalankan semua layanan dari docker-compose.yml, termasuk:
    <ul><li>searxng</li>
    <li>redis (dibutuhkan oleh searxng)</li>
    <li>frontend</li>
    <li>backend (jika menggunakan </code>full<code>)</li>
</ul></code></pre>sh
./start_services.sh full # MacOS
start ./start_services.cmd full # Window
<pre><code class="language-">
<strong>Peringatan:</strong> Langkah ini akan mengunduh dan memuat semua image Docker, yang mungkin memerlukan waktu hingga 30 menit. Setelah layanan dijalankan, harap tunggu hingga layanan backend benar-benar berjalan (Anda akan melihat <strong>backend: "GET /health HTTP/1.1" 200 OK</strong> di log) sebelum mengirim pesan apapun. Layanan backend mungkin memerlukan waktu 5 menit untuk mulai pada kali pertama.</p><p>Buka </code>http://localhost:3000/<code> dan Anda akan melihat antarmuka web.</p><p><em>Pemecahan masalah saat memulai layanan:</em> Jika skrip ini gagal, pastikan Docker Engine sedang berjalan dan Docker Compose (V2, </code>docker compose<code>) telah terinstal dengan benar. Periksa output di terminal untuk pesan error. Lihat <a href="#faq-troubleshooting" target="_blank" rel="noopener noreferrer">FAQ: Help! Saya mendapat error saat menjalankan AgenticSeek atau skripnya.</a></p><p><strong>Opsional:</strong> Menjalankan di host (mode CLI):</p><p>Untuk menjalankan dengan antarmuka CLI Anda harus menginstal paket di host:
</code></pre>sh
./install.sh
./install.bat # windows
<pre><code class="language-">
Mulai layanan:
</code></pre>sh
./start_services.sh # MacOS
start ./start_services.cmd # Window
<pre><code class="language-">
Gunakan CLI: </code>python3 cli.py<code></p><hr></p><h2>Penggunaan</h2></p><p>Pastikan layanan telah berjalan dengan </code>./start_services.sh full<code> dan buka </code>localhost:3000<code> untuk antarmuka web.</p><p>Anda juga dapat menggunakan speech to text dengan mengatur </code>listen = True<code> di konfigurasi. Hanya untuk mode CLI.</p><p>Untuk keluar, cukup ucapkan/ketik </code>goodbye<code>.</p><p>Berikut beberapa contoh penggunaan:</p><blockquote><em>Buat game ular dalam python!</em></blockquote></p><blockquote><em>Cari di web kafe terbaik di Rennes, Prancis, dan simpan daftar tiga dengan alamatnya di rennes_cafes.txt.</em></blockquote></p><blockquote><em>Tulis program Go untuk menghitung faktorial sebuah angka, simpan sebagai factorial.go di workspace Anda</em></blockquote></p><blockquote><em>Cari di folder summer_pictures saya untuk semua file JPG, ubah nama dengan tanggal hari ini, dan simpan daftar file yang diganti namanya di photos_list.txt</em></blockquote></p><blockquote><em>Cari online film sci-fi populer dari 2024 dan pilih tiga untuk ditonton malam ini. Simpan daftarnya di movie_night.txt.</em></blockquote></p><blockquote><em>Cari di web artikel berita AI terbaru dari 2025, pilih tiga, dan tulis skrip Python untuk mengambil judul dan ringkasannya. Simpan skrip sebagai news_scraper.py dan ringkasannya di ai_news.txt di /home/projects</em></blockquote></p><blockquote><em>Jumat, cari di web API harga saham gratis, daftar dengan supersuper7434567@gmail.com lalu tulis skrip Python untuk mengambil harga harian Tesla menggunakan API tersebut, dan simpan hasilnya di stock_prices.csv</em></blockquote></p><p><em>Perlu diperhatikan bahwa kemampuan pengisian formulir masih bersifat eksperimental dan mungkin gagal.</em></p><p>Setelah Anda mengetikkan pertanyaan, AgenticSeek akan memilih agent terbaik untuk tugas tersebut.</p><p>Karena ini adalah prototipe awal, sistem routing agent mungkin tidak selalu memilih agent yang tepat berdasarkan permintaan Anda.</p><p>Oleh karena itu, Anda harus sangat eksplisit tentang apa yang Anda inginkan dan bagaimana AI dapat melanjutkan. Misalnya jika Anda ingin melakukan pencarian web, jangan katakan:</p><p></code>Apakah kamu tahu beberapa negara yang bagus untuk solo-travel?<code></p><p>Sebaliknya, mintalah:</p><p></code>Lakukan pencarian web dan cari tahu negara mana yang terbaik untuk solo-travel<code></p><hr></p><h2><strong>Pengaturan untuk menjalankan LLM di server Anda sendiri</strong>  </h2></p><p>Jika Anda memiliki komputer atau server yang cukup kuat, tetapi ingin menggunakannya dari laptop, Anda dapat menjalankan LLM di server remote menggunakan server llm khusus kami.</p><p>Di "server" yang akan menjalankan model AI, dapatkan alamat ip-nya
</code></pre>sh
ip a | grep "inet " | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # ip lokal
curl https://ipinfo.io/ip # ip publik
<pre><code class="language-">
Catatan: Untuk Windows atau macOS, gunakan ipconfig atau ifconfig untuk menemukan alamat IP.</p><p>Clone repository dan masuk ke folder </code>server/<code>.</p><p></code></pre>sh
git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
<pre><code class="language-">
Install kebutuhan khusus server:
</code></pre>sh
pip3 install -r requirements.txt
<pre><code class="language-">
Jalankan skrip server.
</code></pre>sh
python3 app.py --provider ollama --port 3333
<pre><code class="language-">
Anda dapat memilih antara menggunakan </code>ollama<code> dan </code>llamacpp<code> sebagai layanan LLM.</p><p>
Sekarang di komputer pribadi Anda:</p><p>Ubah file </code>config.ini<code> untuk mengatur </code>provider_name<code> ke </code>server<code> dan </code>provider_model<code> ke </code>deepseek-r1:xxb<code>.
Set </code>provider_server_address<code> ke alamat ip mesin yang akan menjalankan model.
</code></pre>sh
[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
<pre><code class="language-"></p><p>Langkah berikutnya: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">Mulai layanan dan jalankan AgenticSeek</a>  </p><hr></p><h2>Speech to Text</h2></p><p>Peringatan: speech to text saat ini hanya berfungsi di mode CLI.</p><p>Perlu diperhatikan saat ini speech to text hanya berfungsi dalam bahasa Inggris.</p><p>Fitur speech-to-text dinonaktifkan secara default. Untuk mengaktifkannya, atur opsi listen menjadi True di file config.ini:
</code></pre>
listen = True
<pre><code class="language-">
Saat diaktifkan, fitur speech-to-text akan mendengarkan kata kunci pemicu, yaitu nama agent, sebelum mulai memproses input Anda. Anda dapat menyesuaikan nama agent dengan memperbarui nilai </code>agent_name<code> di file <em>config.ini</em>:
agent_name = Friday</code></pre></p><p>Untuk pengenalan optimal, kami merekomendasikan menggunakan nama umum dalam bahasa Inggris seperti "John" atau "Emma" sebagai nama agen.</p><p>Setelah Anda melihat transkrip mulai muncul, ucapkan nama agen dengan keras untuk membangunkannya (mis., "Friday").</p><p>Ucapkan pertanyaan Anda dengan jelas.</p><p>Akhiri permintaan Anda dengan frasa konfirmasi untuk memberi sinyal sistem untuk melanjutkan. Contoh frasa konfirmasi meliputi:
<pre><code class="language-">"do it", "go ahead", "execute", "run", "start", "thanks", "would ya", "please", "okay?", "proceed", "continue", "go on", "do that", "go it", "do you understand?"</code></pre></p><h2>Konfigurasi</h2></p><p>Contoh konfigurasi:
<pre><code class="language-">[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # Contoh untuk Ollama; gunakan http://127.0.0.1:1234 untuk LM-Studio
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False</p><p>jarvis_personality = False
languages = en zh # Daftar bahasa untuk TTS dan kemungkinan routing.
[BROWSER]
headless_browser = False
stealth_mode = False</code></pre></p><p><strong>Penjelasan Pengaturan </code>config.ini<code>:</strong></p><ul><li>  <strong>Bagian </code>[MAIN]<code>:</strong></li>
    <li>  </code>is_local<code>: </code>True<code> jika menggunakan penyedia LLM lokal (Ollama, LM-Studio, server OpenAI-kompatibel lokal) atau opsi server self-hosted. </code>False<code> jika menggunakan API berbasis cloud (OpenAI, Google, dll).</li>
    <li>  </code>provider_name<code>: Menentukan penyedia LLM.</li>
        <li>  Opsi lokal: </code>ollama<code>, </code>lm-studio<code>, </code>openai<code> (untuk server OpenAI-kompatibel lokal), </code>server<code> (untuk setup server self-hosted).</li>
        <li>  Opsi API: </code>openai<code>, </code>google<code>, </code>deepseek<code>, </code>huggingface<code>, </code>togetherAI<code>.</li>
    <li>  </code>provider_model<code>: Nama model spesifik atau ID untuk penyedia yang dipilih (mis. </code>deepseekcoder:6.7b<code> untuk Ollama, </code>gpt-3.5-turbo<code> untuk API OpenAI, </code>mistralai/Mixtral-8x7B-Instruct-v0.1<code> untuk TogetherAI).</li>
    <li>  </code>provider_server_address<code>: Alamat dari penyedia LLM Anda.</li>
        <li>  Untuk penyedia lokal: mis. </code>http://127.0.0.1:11434<code> untuk Ollama, </code>http://127.0.0.1:1234<code> untuk LM-Studio.</li>
        <li>  Untuk tipe penyedia </code>server<code>: Alamat server LLM self-hosted Anda (mis., </code>http://your_server_ip:3333<code>).</li>
        <li>  Untuk API cloud (</code>is_local = False<code>): Ini sering diabaikan atau bisa dibiarkan kosong, karena endpoint API biasanya ditangani oleh library klien.</li>
    <li>  </code>agent_name<code>: Nama asisten AI (mis., Friday). Digunakan sebagai kata pemicu untuk speech-to-text jika diaktifkan.</li>
    <li>  </code>recover_last_session<code>: </code>True<code> untuk mencoba memulihkan status sesi sebelumnya, </code>False<code> untuk memulai dari awal.</li>
    <li>  </code>save_session<code>: </code>True<code> untuk menyimpan status sesi saat ini untuk pemulihan potensial, </code>False<code> jika tidak.</li>
    <li>  </code>speak<code>: </code>True<code> untuk mengaktifkan output suara text-to-speech, </code>False<code> untuk menonaktifkan.</li>
    <li>  </code>listen<code>: </code>True<code> untuk mengaktifkan input suara speech-to-text (hanya mode CLI), </code>False<code> untuk menonaktifkan.</li>
    <li>  </code>work_dir<code>: <strong>Penting:</strong> Direktori tempat AgenticSeek akan membaca/menulis file. <strong>Pastikan path ini valid dan dapat diakses di sistem Anda.</strong></li>
    <li>  </code>jarvis_personality<code>: </code>True<code> untuk menggunakan prompt sistem bergaya "Jarvis" (eksperimental), </code>False<code> untuk prompt standar.</li>
    <li>  </code>languages<code>: Daftar bahasa yang dipisahkan koma (mis., </code>en, zh, fr<code>). Digunakan untuk pemilihan suara TTS (default ke yang pertama) dan dapat membantu router LLM. Hindari terlalu banyak atau bahasa yang sangat mirip demi efisiensi router.</li>
<li>  <strong>Bagian </code>[BROWSER]<code>:</strong></li>
    <li>  </code>headless_browser<code>: </code>True<code> untuk menjalankan browser otomatis tanpa jendela terlihat (direkomendasikan untuk antarmuka web atau penggunaan non-interaktif). </code>False<code> untuk menampilkan jendela browser (berguna untuk mode CLI atau debugging).</li>
    <li>  </code>stealth_mode<code>: </code>True<code> untuk mengaktifkan langkah-langkah agar otomatisasi browser lebih sulit terdeteksi. Mungkin memerlukan instalasi ekstensi browser secara manual seperti anticaptcha.</li></p><p>
</ul>Bagian ini merangkum tipe penyedia LLM yang didukung. Konfigurasikan di </code>config.ini<code>.</p><p><strong>Penyedia Lokal (Jalankan di Perangkat Anda Sendiri):</strong></p><p>| Nama Penyedia di </code>config.ini<code> | </code>is_local<code> | Deskripsi                                                                  | Bagian Setup                                                     |
|-------------------------------|------------|---------------------------------------------------------------------------|------------------------------------------------------------------|
| </code>ollama<code>                      | </code>True<code>     | Gunakan Ollama untuk melayani LLM lokal.                                   | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">Setup untuk menjalankan LLM secara lokal</a> |
| </code>lm-studio<code>                   | </code>True<code>     | Gunakan LM-Studio untuk melayani LLM lokal.                                | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">Setup untuk menjalankan LLM secara lokal</a> |
| </code>openai<code> (untuk server lokal) | </code>True<code>     | Koneksi ke server lokal yang menyediakan API OpenAI-kompatibel (mis., llama.cpp). | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">Setup untuk menjalankan LLM secara lokal</a> |
| </code>server<code>                      | </code>False<code>    | Koneksi ke server LLM AgenticSeek self-hosted yang berjalan di mesin lain. | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-the-llm-on-your-own-server" target="_blank" rel="noopener noreferrer">Setup untuk menjalankan LLM di server Anda sendiri</a> |</p><p><strong>Penyedia API (Berbasis Cloud):</strong></p><p>| Nama Penyedia di </code>config.ini<code> | </code>is_local<code> | Deskripsi                                      | Bagian Setup                                         |
|-------------------------------|------------|------------------------------------------------|------------------------------------------------------|
| </code>openai<code>                      | </code>False<code>    | Gunakan API resmi OpenAI (mis., GPT-3.5, GPT-4). | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">Setup untuk menjalankan dengan API</a> |
| </code>google<code>                      | </code>False<code>    | Gunakan model Gemini Google via API.            | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">Setup untuk menjalankan dengan API</a> |
| </code>deepseek<code>                    | </code>False<code>    | Gunakan API resmi Deepseek.                     | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">Setup untuk menjalankan dengan API</a> |
| </code>huggingface<code>                 | </code>False<code>    | Gunakan Hugging Face Inference API.             | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">Setup untuk menjalankan dengan API</a> |
| </code>togetherAI<code>                  | </code>False<code>    | Gunakan API TogetherAI untuk berbagai model open.| <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">Setup untuk menjalankan dengan API</a> |</p><hr>
<h2>Pemecahan Masalah</h2></p><p>Jika Anda mengalami masalah, bagian ini menyediakan panduan.</p><h1>Masalah Dikenal</h1></p><h2>Masalah ChromeDriver</h2></p><p><strong>Contoh Error:</strong> </code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX<code></p><ul><li>  <strong>Penyebab:</strong> Versi ChromeDriver yang Anda instal tidak kompatibel dengan versi browser Google Chrome Anda.</li>
<li>  <strong>Solusi:</strong></li>
    <li> <strong>Cek Versi Chrome:</strong> Buka Google Chrome, pergi ke </code>Settings > About Chrome<code> untuk menemukan versi Anda (mis., "Version 120.0.6099.110").</li>
    <li> <strong>Unduh ChromeDriver yang Cocok:</strong></li>
        <li>  Untuk Chrome versi 115 ke atas: Buka <a href="https://googlechromelabs.github.io/chrome-for-testing/" target="_blank" rel="noopener noreferrer">Chrome for Testing (CfT) JSON Endpoints</a>. Temukan channel "stable" dan unduh ChromeDriver untuk OS Anda yang sesuai dengan versi mayor Chrome Anda.</li>
        <li>  Untuk versi lebih lama (jarang): Anda bisa menemukannya di halaman <a href="https://chromedriver.chromium.org/downloads" target="_blank" rel="noopener noreferrer">ChromeDriver - WebDriver for Chrome</a>.</li>
        <li>  Gambar di bawah menunjukkan contoh dari halaman CfT:</li>
            </ul><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="Unduh versi spesifik Chromedriver dari halaman Chrome for Testing">
    <ul><li> <strong>Instal ChromeDriver:</strong></li>
        <li>  Pastikan file </code>chromedriver<code> yang diunduh (atau </code>chromedriver.exe<code> di Windows) diletakkan di direktori yang terdaftar di variabel lingkungan PATH sistem Anda (mis., </code>/usr/local/bin<code> di Linux/macOS, atau folder skrip khusus yang ditambahkan ke PATH di Windows).</li>
        <li>  Atau, letakkan di direktori root proyek </code>agenticSeek<code>.</li>
        <li>  Pastikan driver dapat dieksekusi (mis., </code>chmod +x chromedriver<code> di Linux/macOS).</li>
    <li> Lihat bagian <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#chromedriver-installation" target="_blank" rel="noopener noreferrer">Instalasi ChromeDriver</a> di panduan Instalasi utama untuk detail lebih lanjut.</li></p><p></ul>Jika bagian ini tidak lengkap atau Anda mengalami masalah ChromeDriver lainnya, silakan cari <a href="https://github.com/Fosowl/agenticSeek/issues" target="_blank" rel="noopener noreferrer">GitHub Issues</a> yang sudah ada atau ajukan yang baru.</p><p></code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113
Current browser version is 134.0.6998.89 with binary path<code></p><p>Ini terjadi jika ada ketidakcocokan antara versi browser dan chromedriver Anda.</p><p>Anda perlu mengunjungi tautan berikut untuk mengunduh versi terbaru:</p><p>https://developer.chrome.com/docs/chromedriver/downloads</p><p>Jika Anda menggunakan Chrome versi 115 atau lebih baru, kunjungi:</p><p>https://googlechromelabs.github.io/chrome-for-testing/</p><p>Dan unduh versi chromedriver yang sesuai dengan OS Anda.</p><p><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text"></p><p>Jika bagian ini tidak lengkap, silakan ajukan issue.</p><h2>Masalah connection adapters</h2></p><pre><code class="language-">Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'</code> (Catatan: port bisa berbeda)</code></pre></p><ul><li>  <strong>Penyebab:</strong> <code>provider_server_address</code> di <code>config.ini</code> untuk <code>lm-studio</code> (atau server OpenAI-kompatibel lokal sejenis) tidak memiliki awalan <code>http://</code> atau menunjuk ke port yang salah.</li>
<li>  <strong>Solusi:</strong></li>
    <li>  Pastikan alamat sudah termasuk <code>http://</code>. LM-Studio biasanya default ke <code>http://127.0.0.1:1234</code>.</li>
    <li>  Perbaiki <code>config.ini</code>: <code>provider_server_address = http://127.0.0.1:1234</code> (atau port server LM-Studio Anda yang sebenarnya).</li></p><p></ul><h2>SearxNG Base URL Tidak Diberikan</h2></p><pre><code class="language-">raise ValueError("SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.")
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.<code></code></pre></p><h2>FAQ</h2></p><p><strong>T: Perangkat keras apa yang saya butuhkan?</strong>  </p><p>| Ukuran Model | GPU           | Komentar                                                                                   |
|--------------|---------------|-------------------------------------------------------------------------------------------|
| 7B           | 8GB Vram      | ⚠️ Tidak direkomendasikan. Performa buruk, sering halusinasi, dan agen planner kemungkinan gagal. |
| 14B          | 12 GB VRAM (mis. RTX 3060) | ✅ Dapat digunakan untuk tugas sederhana. Mungkin kesulitan untuk browsing web dan tugas perencanaan. |
| 32B          | 24+ GB VRAM (mis. RTX 4090) | 🚀 Berhasil untuk sebagian besar tugas, mungkin masih kesulitan untuk perencanaan tugas |
| 70B+         | 48+ GB Vram   | 💪 Sangat baik. Direkomendasikan untuk kasus penggunaan lanjutan. |</p><p><strong>T: Saya mendapatkan error, apa yang harus saya lakukan?</strong>  </p><p>Pastikan lokal sudah berjalan (</code>ollama serve<code>), </code>config.ini` Anda sesuai dengan penyedia Anda, dan dependensi terinstal. Jika tidak ada yang berhasil silakan ajukan issue.</p><p><strong>T: Apakah benar-benar bisa berjalan 100% lokal?</strong>  </p><p>Ya, dengan penyedia Ollama, lm-studio atau server, semua speech to text, LLM dan text to speech model berjalan secara lokal. Opsi non-lokal (OpenAI atau API lainnya) bersifat opsional.</p><p><strong>T: Mengapa saya harus menggunakan AgenticSeek padahal saya punya Manus?</strong></p><p>Berbeda dengan Manus, AgenticSeek mengutamakan kemandirian dari sistem eksternal, memberi Anda lebih banyak kontrol, privasi dan menghindari biaya API.</p><p><strong>T: Siapa di balik proyek ini?</strong></p><p>Proyek ini dibuat oleh saya, bersama dua teman yang menjadi maintainer dan kontributor dari komunitas open-source di GitHub. Kami hanyalah sekelompok individu yang antusias, bukan startup atau terafiliasi dengan organisasi manapun.</p><p>Setiap akun AgenticSeek di X selain akun pribadi saya (https://x.com/Martin993886460) adalah akun peniru.</p><h2>Berkontribusi</h2></p><p>Kami mencari developer untuk meningkatkan AgenticSeek! Lihat issue terbuka atau diskusi.</p><p><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">Panduan Kontribusi</a></p><p><a href="https://www.star-history.com/#Fosowl/agenticSeek&Date" target="_blank" rel="noopener noreferrer"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&type=Date" alt="Star History Chart"></a></p><h2>Maintainer:</h2></p><p> > <a href="https://github.com/Fosowl" target="_blank" rel="noopener noreferrer">Fosowl</a> | Waktu Paris </p><p> > <a href="https://github.com/antoineVIVIES" target="_blank" rel="noopener noreferrer">antoineVIVIES</a> | Waktu Taipei </p><p> > <a href="https://github.com/steveh8758" target="_blank" rel="noopener noreferrer">steveh8758</a> | Waktu Taipei </p><h2>Ucapan Terima Kasih Khusus:</h2></p><p> > <a href="https://github.com/tcsenpai" target="_blank" rel="noopener noreferrer">tcsenpai</a> dan <a href="https://github.com/plitc" target="_blank" rel="noopener noreferrer">plitc</a> untuk bantuan dockerisasi backend</p><h2>Sponsor:</h2></p><p>Sponsor bulanan 5$ atau lebih tampil di sini:
<ul><li><strong>tatra-labs</strong></li>
</ul>Certainly! However, it appears that you haven't provided the content of Part 4 of 4 to be translated. Please provide the text of the technical document (Part 4), and I will translate it into Indonesian while preserving the original Markdown format and adjusting the relative paths as requested.

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-16

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>