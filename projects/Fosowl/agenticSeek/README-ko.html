<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>agenticSeek - Read agenticSeek documentation in Korean. This project has 18325 stars on GitHub.</title>
    <meta name="description" content="Read agenticSeek documentation in Korean. This project has 18325 stars on GitHub.">
    <meta name="keywords" content="agenticSeek, Korean, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "agenticSeek",
  "description": "Read agenticSeek documentation in Korean. This project has 18325 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "Fosowl"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 18325
  },
  "url": "https://OpenAiTx.github.io/projects/Fosowl/agenticSeek/README-ko.html",
  "sameAs": "https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/Fosowl/agenticSeek" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    agenticSeek
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 18325 stars</span>
                <span class="language">Korean</span>
                <span>by Fosowl</span>
            </div>
        </div>
        
        <div class="content">
            <h1>AgenticSeek: 프라이빗, 로컬 Manus 대안</h1></p><p><p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
<p>  English | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md" target="_blank" rel="noopener noreferrer">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md" target="_blank" rel="noopener noreferrer">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md" target="_blank" rel="noopener noreferrer">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md" target="_blank" rel="noopener noreferrer">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md" target="_blank" rel="noopener noreferrer">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md" target="_blank" rel="noopener noreferrer">Español</a></p><p><em> <strong>Manus AI의 100% 로컬 대안</strong>인 이 음성 인식 AI 어시스턴트는 웹을 자동으로 탐색하고, 코드를 작성하며, 작업을 계획합니다. 모든 데이터는 사용자의 장치에만 보관됩니다. 로컬 추론 모델에 최적화되어 있으며, 모든 기능이 완전히 사용자의 하드웨어에서 실행되어 완전한 프라이버시와 클라우드 의존도 0%를 보장합니다.</em></p><p><a href="https://fosowl.github.io/agenticSeek.html" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?label=Website&message=AgenticSeek&color=blue&style=flat-square" alt="Visit AgenticSeek"></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License"> <a href="https://discord.gg/8hGDaME3TC" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&logoColor=white" alt="Discord"></a> <a href="https://x.com/Martin993886460" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&label=Update%20%40Fosowl" alt="Twitter"></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars"></a></p><h3>왜 AgenticSeek인가?</h3></p><ul><li>🔒 완전 로컬 & 프라이빗 - 모든 것이 사용자의 컴퓨터에서 실행됩니다. 클라우드, 데이터 공유 없음. 파일, 대화, 검색 모두 프라이빗하게 유지됩니다.</li></p><p><li>🌐 스마트 웹 브라우징 - AgenticSeek은 스스로 인터넷을 검색, 읽기, 정보 추출, 웹 폼 작성 등 완전 자동으로 수행합니다.</li></p><p><li>💻 자율 코딩 어시스턴트 - 코드가 필요하신가요? Python, C, Go, Java 등 다양한 언어로 프로그램을 작성, 디버깅, 실행까지 스스로 합니다.</li></p><p><li>🧠 스마트 에이전트 선택 - 사용자가 요청하면, 작업에 최적화된 에이전트를 자동으로 선정합니다. 전문가 팀이 대기 중인 느낌을 경험하세요.</li></p><p><li>📋 복잡한 작업의 계획 및 실행 - 여행 계획부터 복잡한 프로젝트까지, 대형 작업을 단계별로 분할하고 여러 AI 에이전트를 활용해 완수합니다.</li></p><p><li>🎙️ 음성 지원 - 빠르고 미래지향적인 음성 및 음성-텍스트 변환으로, 마치 SF 영화 속 개인 AI와 대화하듯 사용할 수 있습니다. (개발 중)</li></p><p></ul><h3><strong>데모</strong></h3></p><blockquote><em>agenticSeek 프로젝트를 검색하고, 필요한 기술을 파악한 후, CV_candidates.zip을 열고, 프로젝트와 가장 잘 맞는 후보를 알려줘</em></blockquote></p><p>https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</p><p>면책 조항: 이 데모에 등장하는 모든 파일(예: CV_candidates.zip)은 모두 허구입니다. 우리는 기업이 아니며, 지원자가 아닌 오픈소스 기여자를 찾고 있습니다.</p><blockquote>🛠⚠️️ <strong>현재 활발히 개발 중</strong></blockquote></p><blockquote>🙏 이 프로젝트는 사이드 프로젝트로 시작되어 로드맵과 자금이 전혀 없습니다. GitHub Trending에 오르며 예상보다 훨씬 성장했습니다. 기여, 피드백, 그리고 인내에 깊이 감사드립니다.</blockquote></p><h2>사전 준비 사항</h2></p><p>시작하기 전에 다음 소프트웨어가 설치되어 있는지 확인하세요:</p><ul><li>  <strong>Git:</strong> 저장소 클론용. <a href="https://git-scm.com/downloads" target="_blank" rel="noopener noreferrer">Git 다운로드</a></li>
<li>  <strong>Python 3.10.x:</strong> Python 3.10.x 버전 사용을 강력 권장합니다. 다른 버전은 의존성 오류가 발생할 수 있습니다. <a href="https://www.python.org/downloads/release/python-3100/" target="_blank" rel="noopener noreferrer">Python 3.10 다운로드</a> (3.10.x 버전 선택).</li>
<li>  <strong>Docker Engine & Docker Compose:</strong> SearxNG 등 번들 서비스 실행용.</li>
    <li>  Docker Desktop(Compose V2 포함) 설치: <a href="https://docs.docker.com/desktop/install/windows-install/" target="_blank" rel="noopener noreferrer">Windows</a> | <a href="https://docs.docker.com/desktop/install/mac-install/" target="_blank" rel="noopener noreferrer">Mac</a> | <a href="https://docs.docker.com/desktop/install/linux-install/" target="_blank" rel="noopener noreferrer">Linux</a></li>
    <li>  또는 리눅스에서 Docker Engine과 Docker Compose 개별 설치: <a href="https://docs.docker.com/engine/install/" target="_blank" rel="noopener noreferrer">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/" target="_blank" rel="noopener noreferrer">Docker Compose</a> (Compose V2 설치 필요, 예: <code>sudo apt-get install docker-compose-plugin</code>).</li></p><p></ul><h3>1. <strong>저장소 클론 및 설정</strong></h3></p><pre><code class="language-sh">git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env</code></pre></p><h3>2. .env 파일 내용 변경</h3></p><pre><code class="language-sh">SEARXNG_BASE_URL="http://127.0.0.1:8080"
REDIS_BASE_URL="redis://redis:6379/0"
WORK_DIR="/Users/mlg/Documents/workspace_for_ai"
OLLAMA_PORT="11434"
LM_STUDIO_PORT="1234"
CUSTOM_ADDITIONAL_LLM_PORT="11435"
OPENAI_API_KEY='optional'
DEEPSEEK_API_KEY='optional'
OPENROUTER_API_KEY='optional'
TOGETHER_API_KEY='optional'
GOOGLE_API_KEY='optional'
ANTHROPIC_API_KEY='optional'</code></pre></p><p>필요에 따라 <code>.env</code> 파일을 본인 환경에 맞게 수정하세요:</p><ul><li><strong>SEARXNG_BASE_URL</strong>: 변경 없이 유지</li>
<li><strong>REDIS_BASE_URL</strong>: 변경 없이 유지</li>
<li><strong>WORK_DIR</strong>: 로컬 PC의 작업 디렉터리 경로. AgenticSeek이 이 파일에 접근 및 상호작용할 수 있습니다.</li>
<li><strong>OLLAMA_PORT</strong>: Ollama 서비스 포트 번호</li>
<li><strong>LM_STUDIO_PORT</strong>: LM Studio 서비스 포트 번호</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>: 추가 커스텀 LLM 서비스 포트</li></p><p></ul><strong>API Key는 로컬에서 LLM을 실행하는 사용자의 경우 완전히 선택 사항입니다. 이 프로젝트의 주요 목적이기도 합니다. 하드웨어가 충분하다면 비워 두세요.</strong></p><h3>3. <strong>Docker 시작</strong></h3></p><p>시스템에 Docker가 설치되어 실행 중인지 확인하세요. 다음 명령어로 Docker를 시작할 수 있습니다:</p><ul><li><strong>Linux/macOS:</strong>  </li>
    </ul>터미널에서 아래를 실행:
    <pre><code class="language-sh">    sudo systemctl start docker
    ``<code>
    또는 Docker Desktop이 설치되어 있다면 애플리케이션 메뉴에서 실행하세요.</p><ul><li><strong>Windows:</strong>  </li>
    </ul>시작 메뉴에서 Docker Desktop을 실행하세요.</p><p>Docker가 정상 실행 중인지 아래로 확인:</code></pre>sh
docker info
<pre><code class="language-">Docker 설치 정보가 보이면 정상적으로 실행 중입니다.</p><p>아래 <a href="#list-of-local-providers" target="_blank" rel="noopener noreferrer">로컬 제공자 목록</a> 표를 참고하세요.</p><p>다음 단계: <a href="#start-services-and-run" target="_blank" rel="noopener noreferrer">AgenticSeek 로컬 실행</a></p><p><em>문제가 있을 경우 <a href="#troubleshooting" target="_blank" rel="noopener noreferrer">문제 해결</a> 섹션을 참고하세요.</em>
<em>로컬에서 LLM 실행이 어렵다면 <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API로 실행 설정</a>을 참고하세요.</em>
<em>자세한 </code>config.ini<code> 설명은 <a href="#config" target="_blank" rel="noopener noreferrer">설정 섹션</a>을 참고하세요.</em></p><hr></p><h2>내 PC에서 LLM 로컬 실행 설정</h2></p><p><strong>하드웨어 요구사항:</strong></p><p>LLM을 로컬에서 실행하려면 충분한 하드웨어가 필요합니다. 최소한 Magistral, Qwen 또는 Deepseek 14B를 실행할 수 있는 GPU가 필요합니다. 자세한 모델/성능 권장사항은 FAQ를 참고하세요.</p><p><strong>로컬 제공자 설정</strong>  </p><p>예시로 ollama로 로컬 제공자를 시작합니다:
</code></pre>sh
ollama serve
<pre><code class="language-">
아래에서 지원되는 로컬 제공자 목록을 확인하세요.</p><p><strong>config.ini 업데이트</strong></p><p>config.ini 파일에서 provider_name을 지원되는 제공자로, provider_model을 해당 제공자가 지원하는 LLM으로 설정하세요. <em>Magistral</em> 또는 <em>Deepseek</em> 등 추론 모델을 권장합니다.</p><p>필요 하드웨어는 README 마지막의 <strong>FAQ</strong>를 참고하세요.
</code></pre>sh
[MAIN]
is_local = True # 로컬 또는 원격 제공자 사용 여부
provider_name = ollama # 또는 lm-studio, openai 등
provider_model = deepseek-r1:14b # 하드웨어에 맞는 모델 선택
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # AI의 이름
recover_last_session = True # 이전 세션 복구 여부
save_session = True # 현재 세션 저장 여부
speak = False # 텍스트 음성 변환
listen = False # 음성 인식, CLI 전용, 실험적
jarvis_personality = False # "Jarvis" 스타일 성격 사용 여부(실험적)
languages = en zh # 지원 언어 목록, 텍스트 음성 변환은 첫 번째 언어로 기본 설정
[BROWSER]
headless_browser = True # CLI 사용 시에만 변경, 그 외는 유지
stealth_mode = True # 탐지 우회를 위한 undetected selenium 사용
<pre><code class="language-">
<strong>경고</strong>:</p><ul><li></code>config.ini<code> 파일 형식은 주석을 지원하지 않습니다. </li>
</ul>예시 설정을 복사-붙여넣기 하지 마세요. 주석이 포함되면 오류가 발생합니다. 원하는 설정만 직접 입력해 수정하세요.</p><ul><li>LM-studio로 LLM을 실행할 경우 provider_name을 </code>openai<code>로 설정하지 마세요. 반드시 </code>lm-studio<code>로 설정하세요.</li></p><p><li>일부 제공자(예: lm-studio)는 IP 앞에 </code>http://<code>가 필요합니다. 예시: </code>http://127.0.0.1:1234<code></li></p><p></ul><strong>로컬 제공자 목록</strong></p><p>| 제공자     | 로컬 지원 | 설명                                                    |
|-----------|--------|---------------------------------------------------------|
| ollama    | 예     | ollama를 LLM 제공자로 사용하여 쉽게 로컬에서 실행         |
| lm-studio | 예     | LM studio를 통해 로컬 LLM 실행 (</code>provider_name<code>을 </code>lm-studio<code>로 설정)|
| openai    | 예     | openai 호환 API 사용 (예: llama.cpp 서버)                |</p><p>다음 단계: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">서비스 시작 및 AgenticSeek 실행</a>  </p><p><em>문제가 있을 경우 <a href="#troubleshooting" target="_blank" rel="noopener noreferrer">문제 해결</a> 섹션을 참고하세요.</em>
<em>로컬에서 LLM 실행이 어렵다면 <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API로 실행 설정</a>을 참고하세요.</em>
<em>자세한 </code>config.ini<code> 설명은 <a href="#config" target="_blank" rel="noopener noreferrer">설정 섹션</a>을 참고하세요.</em></p><h2>API로 실행 설정</h2></p><p>이 설정은 외부 클라우드 기반 LLM 제공자를 사용합니다. 원하는 서비스의 API 키가 필요합니다.</p><p><strong>1. API 제공자 선택 및 API 키 발급:</strong></p><p>아래 <a href="#list-of-api-providers" target="_blank" rel="noopener noreferrer">API 제공자 목록</a>을 참고하여 웹사이트에서 회원가입 후 API 키를 발급받으세요.</p><p><strong>2. API 키를 환경 변수로 설정:</strong></p><ul><li>  <strong>Linux/macOS:</strong></li>
    </ul>터미널을 열고 </code>export<code> 명령을 사용하세요. 영구 적용을 위해 셸 프로필 파일(예: </code>~/.bashrc<code>, </code>~/.zshrc<code>)에 추가하는 것이 좋습니다.
    </code>`<code>sh
    export PROVIDER_API_KEY="your_api_key_here" 
    # PROVIDER_API_KEY를 실제 변수명(예: OPENAI_API_KEY, GOOGLE_API_KEY)으로 변경하세요.
    </code>`<code>
    TogetherAI 예시:
    </code>`<code>sh
    export TOGETHER_API_KEY="xxxxxxxxxxxxxxxxxxxxxx"
    </code>`<code>
<ul><li>  <strong>Windows:</strong></li>
<li>  <strong>명령 프롬프트(현재 세션에서 임시로 설정):</strong></li>
    </ul></code>`<code>cmd
    set PROVIDER_API_KEY=your_api_key_here
    </code>`<code>
<ul><li>  <strong>PowerShell(현재 세션에서 임시로 설정):</strong></li>
    </ul></code>`<code>powershell
    $env:PROVIDER_API_KEY="your_api_key_here"
    </code>`<code>
<ul><li>  <strong>영구적으로 설정:</strong> Windows 검색창에서 "환경 변수"를 검색한 뒤, "시스템 환경 변수 편집"을 클릭하고, "환경 변수..." 버튼을 누릅니다. 적절한 이름(예: </code>OPENAI_API_KEY<code>)과 값으로 새로운 사용자 변수를 추가하세요.</li></p><p></ul><em>(자세한 내용은 FAQ: <a href="#how-do-i-set-api-keys" target="_blank" rel="noopener noreferrer">API 키는 어떻게 설정하나요?</a> 참고)</em></p><p>
<strong>3. </code>config.ini<code> 업데이트:</strong></code></pre>ini
[MAIN]
is_local = False
provider_name = openai # 또는 google, deepseek, togetherAI, huggingface
provider_model = gpt-3.5-turbo # 또는 gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 등
provider_server_address = # 대부분의 API에서 is_local = False일 때 일반적으로 무시되거나 비워둘 수 있음
<h1>... 기타 설정 ...</h1>
<pre><code class="language-"><em>경고:</em> </code>config.ini<code> 값에 공백(띄어쓰기)이 뒤따르지 않도록 하세요.</p><p><strong>API 제공자 목록</strong></p><p>| 제공자        | </code>provider_name<code> | 로컬? | 설명                                               | API 키 링크(예시)                             |
|---------------|-----------------|-------|----------------------------------------------------|-----------------------------------------------|
| OpenAI        | </code>openai<code>        | 아니오| OpenAI의 API를 통해 ChatGPT 모델 사용                | <a href="https://platform.openai.com/signup" target="_blank" rel="noopener noreferrer">platform.openai.com/signup</a> |
| Google Gemini | </code>google<code>        | 아니오| Google AI Studio를 통해 Google Gemini 모델 사용      | <a href="https://aistudio.google.com/keys" target="_blank" rel="noopener noreferrer">aistudio.google.com/keys</a> |
| Deepseek      | </code>deepseek<code>      | 아니오| Deepseek API를 통해 Deepseek 모델 사용               | <a href="https://platform.deepseek.com" target="_blank" rel="noopener noreferrer">platform.deepseek.com</a> |
| Hugging Face  | </code>huggingface<code>   | 아니오| Hugging Face Inference API의 모델 사용               | <a href="https://huggingface.co/settings/tokens" target="_blank" rel="noopener noreferrer">huggingface.co/settings/tokens</a> |
| TogetherAI    | </code>togetherAI<code>    | 아니오| TogetherAI API를 통해 다양한 오픈소스 모델 사용       | <a href="https://api.together.ai/settings/api-keys" target="_blank" rel="noopener noreferrer">api.together.ai/settings/api-keys</a> |</p><p><em>참고:</em>
<ul><li>  복잡한 웹 브라우징 및 작업 계획에는 </code>gpt-4o<code> 또는 기타 OpenAI 모델 사용을 권장하지 않습니다. 현재 프롬프트 최적화는 Deepseek와 같은 모델에 맞춰져 있습니다.</li>
<li>  코딩/bash 작업은 Gemini에서 프롬프트 포맷팅을 엄격히 따르지 않아 문제가 발생할 수 있습니다.</li>
<li>  </code>config.ini<code>의 </code>provider_server_address<code>는 </code>is_local = False<code>일 때는 일반적으로 사용되지 않으며, 각 제공자 라이브러리에서 API 엔드포인트가 하드코딩되어 있습니다.</li></p><p></ul>다음 단계: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">서비스 시작 및 AgenticSeek 실행</a></p><p><em>문제가 발생하면 <strong>Known issues</strong>(알려진 문제) 섹션을 참고하세요.</em></p><p><em>자세한 설정 파일 설명은 <strong>Config</strong> 섹션을 참고하세요.</em></p><hr></p><h2>서비스 시작 및 실행</h2></p><p>기본적으로 AgenticSeek는 도커(docker)에서 완전히 실행됩니다.</p><p>필요한 서비스를 시작하세요. 이는 docker-compose.yml의 모든 서비스를 시작합니다. 포함된 서비스:
    <ul><li>searxng</li>
    <li>redis (searxng에서 필요)</li>
    <li>frontend</li>
    <li>backend(</code>full<code> 사용 시)</li>
</ul></code></pre>sh
./start_services.sh full # MacOS
start ./start_services.cmd full # Window
<pre><code class="language-">
<strong>경고:</strong> 이 단계는 모든 도커 이미지를 다운로드 및 로드합니다. 최대 30분이 소요될 수 있습니다. 서비스를 시작한 후, 백엔드 서비스가 완전히 실행될 때까지 기다리세요(로그에서 <strong>backend: "GET /health HTTP/1.1" 200 OK</strong> 메시지를 확인할 수 있음). 백엔드 서비스는 첫 실행 시 5분 정도 소요될 수 있습니다.</p><p></code>http://localhost:3000/<code>에 접속하면 웹 인터페이스가 나타납니다.</p><p><em>서비스 시작 문제 해결:</em> 스크립트가 실패하면 Docker Engine이 실행 중인지, Docker Compose(V2, </code>docker compose<code>)가 올바르게 설치되어 있는지 확인하세요. 터미널의 출력 오류 메시지를 확인하세요. <a href="#faq-troubleshooting" target="_blank" rel="noopener noreferrer">FAQ: AgenticSeek 또는 스크립트 실행 시 오류가 발생합니다.</a> 참고</p><p><strong>선택 사항:</strong> 호스트에서 실행(CLI 모드):</p><p>CLI 인터페이스로 실행하려면 패키지를 호스트에 설치해야 합니다.
</code></pre>sh
./install.sh
./install.bat # windows
<pre><code class="language-">
서비스 시작:
</code></pre>sh
./start_services.sh # MacOS
start ./start_services.cmd # Window
<pre><code class="language-">
CLI 사용: </code>python3 cli.py<code></p><hr></p><h2>사용법</h2></p><p></code>./start_services.sh full<code>로 서비스가 정상적으로 실행 중인지 확인하고, 웹 인터페이스는 </code>localhost:3000<code>에서 접속하세요.</p><p>CLI 모드에서 </code>listen = True<code>로 설정하면 음성 인식(speech to text)도 사용할 수 있습니다.</p><p>종료하려면 </code>goodbye<code>라고 말하거나 입력하면 됩니다.</p><p>사용 예시는 다음과 같습니다:</p><blockquote><em>파이썬으로 뱀 게임을 만들어줘!</em></blockquote></p><blockquote><em>프랑스 렌(Rennes)의 인기 카페를 웹에서 검색해서, 3곳의 주소와 함께 rennes_cafes.txt에 저장해줘.</em></blockquote></p><blockquote><em>숫자의 팩토리얼을 계산하는 Go 프로그램을 작성해서, 작업 공간에 factorial.go로 저장해줘.</em></blockquote></p><blockquote><em>내 summer_pictures 폴더의 모든 JPG 파일을 찾아, 오늘 날짜로 파일명을 변경하고, 변경된 파일 목록을 photos_list.txt에 저장해줘.</em></blockquote></p><blockquote><em>2024년의 인기 공상과학 영화를 온라인에서 검색해서, 오늘 밤 볼 영화 3편을 고르고 movie_night.txt에 저장해줘.</em></blockquote></p><blockquote><em>2025년 최신 AI 뉴스 기사를 웹에서 검색해 3건을 골라, 제목과 요약을 스크랩하는 파이썬 스크립트를 작성해줘. 스크립트는 news_scraper.py, 요약은 ai_news.txt에 /home/projects에 저장해줘.</em></blockquote></p><blockquote><em>금요일에 무료 주가 API를 찾아 supersuper7434567@gmail.com으로 가입하고, 해당 API로 테슬라의 일일 주가를 가져오는 파이썬 스크립트를 작성해 stock_prices.csv에 저장해줘.</em></blockquote></p><p><em>양식 자동 입력(Form filling)은 아직 실험적 기능이며 실패할 수 있습니다.</em></p><p>
질문을 입력하면 AgenticSeek가 해당 작업에 가장 적합한 에이전트를 할당합니다.</p><p>초기 프로토타입이기 때문에, 에이전트 라우팅 시스템이 항상 올바른 에이전트를 할당하지 않을 수 있습니다.</p><p>따라서 원하는 바와 AI가 어떻게 진행해야 하는지 명확히 지시하는 것이 좋습니다. 예를 들어, 웹 검색을 원한다면 다음과 같이 하지 마세요:</p><p></code>혼자 여행하기 좋은 나라 알아?<code></p><p>대신 다음과 같이 요청하세요:</p><p></code>웹 검색을 해서 혼자 여행하기 좋은 나라를 찾아줘<code></p><hr></p><h2><strong>자체 서버에서 LLM 실행 설정</strong>  </h2></p><p>강력한 컴퓨터나 서버가 있고, 이를 랩탑 등에서 원격으로 사용하고 싶다면 커스텀 llm 서버를 이용해 원격 서버에서 LLM을 실행할 수 있습니다.</p><p>AI 모델을 실행할 "서버"에서 ip 주소를 확인하세요.
</code></pre>sh
ip a | grep "inet " | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # 로컬 IP
curl https://ipinfo.io/ip # 공인 IP
<pre><code class="language-">
참고: Windows 또는 macOS에서는 각각 ipconfig 또는 ifconfig를 사용하여 IP를 확인하세요.</p><p>저장소를 클론하고 </code>server/<code> 폴더로 진입합니다.</p><p></code></pre>sh
git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
<pre><code class="language-">
서버 전용 requirements를 설치하세요:
</code></pre>sh
pip3 install -r requirements.txt
<pre><code class="language-">
서버 스크립트를 실행하세요.
</code></pre>sh
python3 app.py --provider ollama --port 3333
<pre><code class="language-">
LLM 서비스로 </code>ollama<code>와 </code>llamacpp<code> 중에서 선택할 수 있습니다.</p><p>
이제 개인 컴퓨터에서:</p><p></code>config.ini<code> 파일에서 </code>provider_name<code>을 </code>server<code>로, </code>provider_model<code>을 </code>deepseek-r1:xxb<code>로 설정하세요.
</code>provider_server_address<code>는 모델을 실행할 머신의 IP 주소로 지정하세요.
</code></pre>sh
[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
<pre><code class="language-"></p><p>다음 단계: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">서비스 시작 및 AgenticSeek 실행</a>  </p><hr></p><h2>음성 인식(Speech to Text)</h2></p><p>경고: 현재 음성 인식은 CLI 모드에서만 동작합니다.</p><p>현재 영어로만 음성 인식이 가능합니다.</p><p>음성 인식 기능은 기본적으로 비활성화되어 있습니다. 활성화하려면 config.ini 파일에서 listen 옵션을 True로 설정하세요:
</code></pre>
listen = True
<pre><code class="language-">
활성화되면, 음성 인식 기능은 입력 처리 전에 트리거 키워드(에이전트 이름)를 듣습니다. 에이전트 이름은 <em>config.ini</em> 파일의 </code>agent_name<code> 값을 변경하여 맞춤 설정할 수 있습니다:
</code></pre>
agent_name = Friday
<pre><code class="language-">
최적의 인식률을 위해 에이전트 이름으로 "John"이나 "Emma"와 같은 일반적인 영어 이름 사용을 권장합니다.</p><p>전사(Transcript)가 나타나기 시작하면 에이전트의 이름(예: "Friday")을 소리 내어 불러 깨우세요.</p><p>질문을 명확하게 말하세요.</p><p>요청을 마칠 때 시스템이 진행하도록 신호를 주는 확인 문구로 끝내세요. 확인 문구 예시는 다음과 같습니다:</code></pre>
"do it", "go ahead", "execute", "run", "start", "thanks", "would ya", "please", "okay?", "proceed", "continue", "go on", "do that", "go it", "do you understand?"
<pre><code class="language-">
<h2>Config</h2></p><p>예시 config:</code></pre>
[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # Ollama 예시; LM-Studio는 http://127.0.0.1:1234 사용
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False</p><p>jarvis_personality = False
languages = en zh # TTS 및 라우팅에 사용할 언어 목록.
[BROWSER]
headless_browser = False
stealth_mode = False
<pre><code class="language-">
<strong></code>config.ini<code> 설정 설명</strong>:</p><ul><li>  <strong></code>[MAIN]<code> 섹션:</strong></li>
    <li>  </code>is_local<code>: 로컬 LLM 제공자(Ollama, LM-Studio, 로컬 OpenAI 호환 서버)나 자체 호스팅 서버를 사용할 때 </code>True<code>. 클라우드 기반 API(OpenAI, Google 등) 사용 시 </code>False<code>.</li>
    <li>  </code>provider_name<code>: LLM 제공자 지정.</li>
        <li>  로컬 옵션: </code>ollama<code>, </code>lm-studio<code>, </code>openai<code>(로컬 OpenAI 호환 서버용), </code>server<code>(자체 호스팅 서버).</li>
        <li>  API 옵션: </code>openai<code>, </code>google<code>, </code>deepseek<code>, </code>huggingface<code>, </code>togetherAI<code>.</li>
    <li>  </code>provider_model<code>: 선택한 제공자의 특정 모델명 또는 ID(예: Ollama의 </code>deepseekcoder:6.7b<code>, OpenAI API의 </code>gpt-3.5-turbo<code>, TogetherAI의 </code>mistralai/Mixtral-8x7B-Instruct-v0.1<code>).</li>
    <li>  </code>provider_server_address<code>: LLM 제공자의 주소.</li>
        <li>  로컬 제공자: 예를 들어 Ollama는 </code>http://127.0.0.1:11434<code>, LM-Studio는 </code>http://127.0.0.1:1234<code> 등.</li>
        <li>  </code>server<code> 제공자 유형: 자체 호스팅 LLM 서버 주소(예: </code>http://your_server_ip:3333<code>).</li>
        <li>  클라우드 API(</code>is_local = False<code>): 보통 무시되거나 비워둘 수 있음. API 엔드포인트는 클라이언트 라이브러리에서 처리함.</li>
    <li>  </code>agent_name<code>: AI 비서의 이름(예: Friday). 음성 인식 트리거 단어로 사용됨.</li>
    <li>  </code>recover_last_session<code>: 이전 세션 상태 복원을 시도하려면 </code>True<code>, 새로 시작하려면 </code>False<code>.</li>
    <li>  </code>save_session<code>: 세션 복구를 위해 현재 세션 상태 저장은 </code>True<code>, 아니면 </code>False<code>.</li>
    <li>  </code>speak<code>: 음성 출력(TTS) 활성화는 </code>True<code>, 비활성화는 </code>False<code>.</li>
    <li>  </code>listen<code>: 음성 입력(STT, CLI 모드 전용) 활성화는 </code>True<code>, 비활성화는 </code>False<code>.</li>
    <li>  </code>work_dir<code>: <strong>중요:</strong> AgenticSeek가 파일을 읽고 쓰는 디렉터리. <strong>해당 경로가 유효하고 접근 가능한지 확인하세요.</strong></li>
    <li>  </code>jarvis_personality<code>: 보다 "Jarvis 스타일" 시스템 프롬프트 사용은 </code>True<code>(실험적), 표준 프롬프트는 </code>False<code>.</li>
    <li>  </code>languages<code>: 쉼표로 구분된 언어 목록(예: </code>en, zh, fr<code>). TTS 음성 선택(기본은 첫 번째 언어)과 LLM 라우터 보조에 사용됨. 라우터 효율성을 위해 너무 많거나 유사한 언어는 피하세요.</li>
<li>  <strong></code>[BROWSER]<code> 섹션:</strong></li>
    <li>  </code>headless_browser<code>: 브라우저 창 없이 자동화 브라우저 실행은 </code>True<code>(웹 인터페이스/비대화형 사용 권장), 브라우저 창 표시(CLI 모드/디버깅에 유용)는 </code>False<code>.</li>
    <li>  </code>stealth_mode<code>: 브라우저 자동화 탐지 방지를 위한 조치 활성화는 </code>True<code>. anticaptcha 등 브라우저 확장 수동 설치 필요할 수 있음.</li></p><p>
</ul>이 섹션은 지원되는 LLM 제공자 유형을 요약합니다. </code>config.ini<code>에서 설정하세요.</p><p><strong>로컬 제공자(자체 하드웨어에서 실행):</strong></p><p>| </code>config.ini<code>의 Provider Name | </code>is_local<code> | 설명                                                                 | 설치 섹션                                                        |
|-------------------------------|------------|---------------------------------------------------------------------|------------------------------------------------------------------|
| </code>ollama<code>                      | </code>True<code>     | Ollama를 사용해 로컬 LLM 서비스.                                    | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">로컬 LLM 실행 설정</a> |
| </code>lm-studio<code>                   | </code>True<code>     | LM-Studio를 사용해 로컬 LLM 서비스.                                 | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">로컬 LLM 실행 설정</a> |
| </code>openai<code> (로컬 서버용)        | </code>True<code>     | OpenAI 호환 API를 노출하는 로컬 서버 연결(예: llama.cpp).           | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">로컬 LLM 실행 설정</a> |
| </code>server<code>                      | </code>False<code>    | 다른 머신에서 실행 중인 AgenticSeek 자체 호스팅 LLM 서버 연결.      | <a href="#setup-to-run-the-llm-on-your-own-server" target="_blank" rel="noopener noreferrer">자체 서버에서 LLM 실행 설정</a> |</p><p><strong>API 제공자(클라우드 기반):</strong></p><p>| </code>config.ini<code>의 Provider Name | </code>is_local<code> | 설명                                          | 설치 섹션                                     |
|-------------------------------|------------|-----------------------------------------------|-----------------------------------------------|
| </code>openai<code>                      | </code>False<code>    | OpenAI 공식 API 사용(예: GPT-3.5, GPT-4).     | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API로 실행 설정</a>   |
| </code>google<code>                      | </code>False<code>    | Google Gemini 모델 API 사용.                  | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API로 실행 설정</a>   |
| </code>deepseek<code>                    | </code>False<code>    | Deepseek 공식 API 사용.                       | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API로 실행 설정</a>   |
| </code>huggingface<code>                 | </code>False<code>    | Hugging Face 추론 API 사용.                   | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API로 실행 설정</a>   |
| </code>togetherAI<code>                  | </code>False<code>    | 다양한 오픈 모델용 TogetherAI API 사용.       | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API로 실행 설정</a>   |</p><hr>
<h2>문제 해결</h2></p><p>문제가 발생하면 이 섹션에서 안내를 제공합니다.</p><h1>알려진 문제</h1></p><h2>ChromeDriver 문제</h2></p><p><strong>오류 예시:</strong> </code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX<code></p><ul><li>  <strong>원인:</strong> 설치된 ChromeDriver 버전이 Google Chrome 브라우저 버전과 호환되지 않습니다.</li>
<li>  <strong>해결 방법:</strong></li>
    <li> <strong>Chrome 버전 확인:</strong> Google Chrome을 열고 </code>설정 > Chrome 정보<code>에서 버전 확인(예: "Version 120.0.6099.110").</li>
    <li> <strong>일치하는 ChromeDriver 다운로드:</strong></li>
        <li>  Chrome 115 이상: <a href="https://googlechromelabs.github.io/chrome-for-testing/" target="_blank" rel="noopener noreferrer">Chrome for Testing (CfT) JSON Endpoints</a>에서 "stable" 채널을 찾아 OS에 맞는 Chrome의 주요 버전에 일치하는 ChromeDriver를 다운로드합니다.</li>
        <li>  이전 버전(드물게 사용): <a href="https://chromedriver.chromium.org/downloads" target="_blank" rel="noopener noreferrer">ChromeDriver - WebDriver for Chrome</a> 페이지에서 찾을 수 있습니다.</li>
        <li>  아래 이미지는 CfT 페이지 예시입니다:</li>
            </ul><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="Download Chromedriver specific version from Chrome for Testing page">
    <ul><li> <strong>ChromeDriver 설치:</strong></li>
        <li>  다운로드한 </code>chromedriver<code>(Windows는 </code>chromedriver.exe<code>)를 시스템 PATH 환경 변수에 포함된 디렉터리에 배치(예: Linux/macOS는 </code>/usr/local/bin<code>, Windows는 PATH에 추가한 커스텀 스크립트 폴더).</li>
        <li>  또는 </code>agenticSeek<code> 프로젝트 루트 디렉터리에 위치시켜도 됩니다.</li>
        <li>  드라이버가 실행 가능해야 합니다(Linux/macOS는 </code>chmod +x chromedriver<code>).</li>
    <li> 자세한 내용은 설치 가이드의 <a href="#chromedriver-installation" target="_blank" rel="noopener noreferrer">ChromeDriver 설치</a> 섹션을 참조하세요.</li></p><p></ul>이 섹션이 미완성이거나 추가 ChromeDriver 문제가 있으면 <a href="https://github.com/Fosowl/agenticSeek/issues" target="_blank" rel="noopener noreferrer">GitHub Issues</a>에서 검색하거나 새 이슈를 등록하세요.</p><p></code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113
Current browser version is 134.0.6998.89 with binary path<code></p><p>브라우저와 chromedriver 버전이 일치하지 않을 때 발생합니다.</p><p>최신 버전 다운로드는 아래 링크에서 가능합니다:</p><p>https://developer.chrome.com/docs/chromedriver/downloads</p><p>Chrome 115 이상을 사용 중이면 다음으로 이동하세요:</p><p>https://googlechromelabs.github.io/chrome-for-testing/</p><p>운영체제에 맞는 chromedriver 버전을 다운로드하세요.</p><p><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text"></p><p>이 섹션이 미완성이라면 이슈를 등록해주세요.</p><h2> connection adapters 문제</h2>
</code></pre>
Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'</code> (포트는 다를 수 있음)
<pre><code class="language-">
<ul><li>  <strong>원인:</strong> <code>lm-studio</code>(또는 유사 로컬 OpenAI 호환 서버)의 <code>config.ini</code>의 <code>provider_server_address</code>에 <code>http://</code> 접두사가 없거나 잘못된 포트로 지정됨.</li>
<li>  <strong>해결 방법:</strong></li>
    <li>  주소에 반드시 <code>http://</code>가 포함되어야 합니다. LM-Studio는 보통 <code>http://127.0.0.1:1234</code>가 기본입니다.</li>
    <li>  <code>config.ini</code>를 수정: <code>provider_server_address = http://127.0.0.1:1234</code>(또는 실제 LM-Studio 서버 포트).</li></p><p></ul><h2>SearxNG Base URL 미제공</h2>
</code></pre>
raise ValueError("SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.")
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.<code>
</code>`<code></p><h2>FAQ</h2></p><p><strong>Q: 어떤 하드웨어가 필요합니까?</strong>  </p><p>| 모델 크기  | GPU  | 설명                                               |
|-----------|--------|---------------------------------------------------|
| 7B        | 8GB Vram | ⚠️ 비추천. 성능 저하, 환각 빈번, 플래너 에이전트 실패 가능성 높음. |
| 14B        | 12 GB VRAM (예: RTX 3060) | ✅ 단순 작업에는 사용 가능. 웹 브라우징, 플래닝 작업엔 어려울 수 있음. |
| 32B        | 24+ GB VRAM (예: RTX 4090) | 🚀 대부분 작업 성공, 작업 계획에는 아직 어려움 있을 수 있음 |
| 70B+        | 48+ GB Vram | 💪 우수. 고급 사용 사례에 추천.               |</p><p><strong>Q: 오류가 발생하면 어떻게 합니까?</strong>  </p><p>로컬이 실행 중인지(</code>ollama serve<code>), </code>config.ini`가 제공자와 일치하는지, 의존성이 설치되어 있는지 확인하세요. 모두 해결되지 않으면 이슈를 등록하세요.</p><p><strong>Q: 정말 100% 로컬 실행이 가능한가요?</strong>  </p><p>Ollama, lm-studio, server 제공자 사용 시 음성 인식, LLM, 음성 합성 모두 로컬에서 실행됩니다. 비로컬 옵션(OpenAI 등 API)은 선택사항입니다.</p><p><strong>Q: 이미 Manus가 있는데 왜 AgenticSeek을 써야 하나요?</strong></p><p>Manus와 달리 AgenticSeek은 외부 시스템에 대한 의존도를 줄여 더 많은 제어권, 프라이버시, API 비용 회피를 제공합니다.</p><p><strong>Q: 프로젝트의 개발자는 누구입니까?</strong></p><p>본 프로젝트는 저와 두 명의 친구(오픈소스 커뮤니티의 기여자, 유지보수자)가 함께 만들었습니다. 우리는 스타트업이나 조직 소속이 아닌, 열정적인 개인들입니다.</p><p>X(트위터)에서 AgenticSeek 명의의 계정은 제 개인 계정(https://x.com/Martin993886460) 외엔 모두 사칭입니다.</p><h2>기여</h2></p><p>AgenticSeek 개선에 기여할 개발자를 찾고 있습니다! 오픈 이슈나 토론을 확인하세요.</p><p><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">기여 가이드</a></p><p><a href="https://www.star-history.com/#Fosowl/agenticSeek&Date" target="_blank" rel="noopener noreferrer"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&type=Date" alt="Star History Chart"></a></p><h2>Maintainers:</h2></p><p> > <a href="https://github.com/Fosowl" target="_blank" rel="noopener noreferrer">Fosowl</a> | 파리 시간 </p><p> > <a href="https://github.com/antoineVIVIES" target="_blank" rel="noopener noreferrer">antoineVIVIES</a> | 타이베이 시간 </p><p> > <a href="https://github.com/steveh8758" target="_blank" rel="noopener noreferrer">steveh8758</a> | 타이베이 시간 </p><h2>Special Thanks:</h2></p><p> > <a href="https://github.com/tcsenpai" target="_blank" rel="noopener noreferrer">tcsenpai</a> 및 <a href="https://github.com/plitc" target="_blank" rel="noopener noreferrer">plitc</a> - 백엔드 도커화 지원</p><h2>Sponsors:</h2></p><p>월 5달러 이상 후원자는 여기에 표시됩니다:
<ul><li><strong>tatra-labs</strong></li>
</ul>Certainly! Please provide the content of Part 4 of 4 that you would like translated.

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-16

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>