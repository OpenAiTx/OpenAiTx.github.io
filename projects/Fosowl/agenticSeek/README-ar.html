<!DOCTYPE html>
<html lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>agenticSeek - Read agenticSeek documentation in Arabic. This project has 18325 stars on GitHub.</title>
    <meta name="description" content="Read agenticSeek documentation in Arabic. This project has 18325 stars on GitHub.">
    <meta name="keywords" content="agenticSeek, Arabic, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "agenticSeek",
  "description": "Read agenticSeek documentation in Arabic. This project has 18325 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "Fosowl"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 18325
  },
  "url": "https://OpenAiTx.github.io/projects/Fosowl/agenticSeek/README-ar.html",
  "sameAs": "https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/Fosowl/agenticSeek" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    agenticSeek
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 18325 stars</span>
                <span class="language">Arabic</span>
                <span>by Fosowl</span>
            </div>
        </div>
        
        <div class="content">
            <h1>AgenticSeek: بديل Manus محلي وخاص.</h1></p><p><p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="شعار Agentic Seek">
<p>الإنجليزية | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md" target="_blank" rel="noopener noreferrer">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md" target="_blank" rel="noopener noreferrer">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md" target="_blank" rel="noopener noreferrer">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md" target="_blank" rel="noopener noreferrer">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md" target="_blank" rel="noopener noreferrer">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md" target="_blank" rel="noopener noreferrer">Español</a></p><p><em>بديل <strong>محلي 100% لـ Manus AI</strong>، هذا المساعد الذكي الصوتي قادر على تصفح الإنترنت بشكل ذاتي، وكتابة الشيفرات، وتخطيط المهام مع الحفاظ على جميع البيانات على جهازك. مصمم خصيصاً لنماذج الذكاء الاصطناعي المحلية، يعمل بالكامل على عتادك، مما يضمن خصوصية تامة وعدم الاعتماد على السحابة.</em></p><p><a href="https://fosowl.github.io/agenticSeek.html" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?label=Website&message=AgenticSeek&color=blue&style=flat-square" alt="زيارة AgenticSeek"></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="الرخصة"> <a href="https://discord.gg/8hGDaME3TC" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&logoColor=white" alt="ديسكورد"></a> <a href="https://x.com/Martin993886460" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&label=Update%20%40Fosowl" alt="تويتر"></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="نجوم GitHub"></a></p><h3>لماذا AgenticSeek؟</h3></p><ul><li>🔒 محلي وخاص بالكامل - كل شيء يعمل على جهازك — بدون سحابة، بدون مشاركة بيانات. ملفاتك، محادثاتك، وبحثك يبقى خاصاً.</li></p><p><li>🌐 تصفح ويب ذكي - يمكن لـ AgenticSeek تصفح الإنترنت ذاتياً — البحث، القراءة، استخراج المعلومات، تعبئة النماذج — دون تدخل منك.</li></p><p><li>💻 مساعد برمجي مستقل - تحتاج إلى شيفرة؟ يمكنه كتابة، تصحيح، وتشغيل البرامج بلغة بايثون، سي، جو، جافا، وغيرها — دون إشراف.</li></p><p><li>🧠 اختيار ذكي للوكلاء - تسأل، وهو يحدد تلقائياً أفضل وكيل للمهمة. وكأن لديك فريق خبراء جاهز للمساعدة.</li></p><p><li>📋 تخطيط وتنفيذ المهام المعقدة - من تخطيط الرحلات إلى المشاريع المعقدة — يمكنه تقسيم المهام الكبيرة إلى خطوات وإنجازها باستخدام عدة وكلاء ذكاء اصطناعي.</li></p><p><li>🎙️ مدعوم بالصوت - تحويل صوتي سريع وحديث يتيح لك التحدث إليه كما لو أنه ذكاءك الاصطناعي الشخصي من أفلام الخيال العلمي. (قيد التنفيذ)</li></p><p></ul><h3><strong>عرض توضيحي</strong></h3></p><blockquote><em>هل يمكنك البحث عن مشروع agenticSeek، معرفة المهارات المطلوبة، ثم فتح ملف CV_candidates.zip ثم إخباري أيهم الأنسب للمشروع؟</em></blockquote></p><p>https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</p><p>إخلاء مسؤولية: هذا العرض التوضيحي، بما في ذلك جميع الملفات الظاهرة (مثل: CV_candidates.zip)، كلها خيالية بالكامل. لسنا مؤسسة تجارية، نبحث عن مساهمين مفتوح المصدر وليس مرشحين.</p><blockquote>🛠⚠️️ <strong>جاري العمل بنشاط</strong></blockquote></p><blockquote>🙏 هذا المشروع بدأ كمشروع جانبي ولا يوجد له خارطة طريق أو تمويل. نما أكثر مما توقعت حتى وصل إلى قائمة الترند في GitHub. نقدر المساهمات، التغذية الراجعة، وصبركم بشدة.</blockquote></p><h2>المتطلبات الأساسية</h2></p><p>قبل البدء، تأكد من تثبيت البرامج التالية:</p><ul><li>  <strong>Git:</strong> لاستنساخ المستودع. <a href="https://git-scm.com/downloads" target="_blank" rel="noopener noreferrer">تحميل Git</a></li>
<li>  <strong>Python 3.10.x:</strong> ننصح بشدة باستخدام إصدار بايثون 3.10.x. استخدام إصدارات أخرى قد يؤدي إلى مشاكل في الاعتماديات. <a href="https://www.python.org/downloads/release/python-3100/" target="_blank" rel="noopener noreferrer">تحميل Python 3.10</a> (اختر إصدار 3.10.x).</li>
<li>  <strong>Docker Engine و Docker Compose:</strong> لتشغيل الخدمات المجمعة مثل SearxNG.</li>
    <li>  تثبيت Docker Desktop (يشمل Docker Compose V2): <a href="https://docs.docker.com/desktop/install/windows-install/" target="_blank" rel="noopener noreferrer">Windows</a> | <a href="https://docs.docker.com/desktop/install/mac-install/" target="_blank" rel="noopener noreferrer">Mac</a> | <a href="https://docs.docker.com/desktop/install/linux-install/" target="_blank" rel="noopener noreferrer">Linux</a></li>
    <li>  أو يمكنك تثبيت Docker Engine وDocker Compose بشكل منفصل على لينكس: <a href="https://docs.docker.com/engine/install/" target="_blank" rel="noopener noreferrer">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/" target="_blank" rel="noopener noreferrer">Docker Compose</a> (تأكد من تثبيت Compose V2، مثلاً: <code>sudo apt-get install docker-compose-plugin</code>).</li></p><p></ul><h3>1. <strong>استنساخ المستودع والإعداد</strong></h3></p><pre><code class="language-sh">git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env</code></pre></p><h3>2. تغيير محتوى ملف .env</h3></p><pre><code class="language-sh">SEARXNG_BASE_URL="http://127.0.0.1:8080"
REDIS_BASE_URL="redis://redis:6379/0"
WORK_DIR="/Users/mlg/Documents/workspace_for_ai"
OLLAMA_PORT="11434"
LM_STUDIO_PORT="1234"
CUSTOM_ADDITIONAL_LLM_PORT="11435"
OPENAI_API_KEY='optional'
DEEPSEEK_API_KEY='optional'
OPENROUTER_API_KEY='optional'
TOGETHER_API_KEY='optional'
GOOGLE_API_KEY='optional'
ANTHROPIC_API_KEY='optional'</code></pre></p><p>
قم بتحديث ملف <code>.env</code> بقيمك الخاصة حسب الحاجة:</p><ul><li><strong>SEARXNG_BASE_URL</strong>: اتركها كما هي </li>
<li><strong>REDIS_BASE_URL</strong>: اتركها كما هي </li>
<li><strong>WORK_DIR</strong>: مسار مجلد العمل على جهازك المحلي. سيتمكن AgenticSeek من قراءة والتفاعل مع هذه الملفات.</li>
<li><strong>OLLAMA_PORT</strong>: رقم المنفذ لخدمة Ollama.</li>
<li><strong>LM_STUDIO_PORT</strong>: رقم المنفذ لخدمة LM Studio.</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>: منفذ لأي خدمة LLM إضافية مخصصة.</li></p><p></ul><strong>مفاتيح API اختيارية تماماً للمستخدمين الذين يختارون تشغيل LLM محلياً. وهو الغرض الأساسي لهذا المشروع. اتركها فارغة إذا كان لديك عتاد كافٍ</strong></p><h3>3. <strong>تشغيل Docker</strong></h3></p><p>تأكد من تثبيت Docker وتشغيله على نظامك. يمكنك بدء Docker باستخدام الأوامر التالية:</p><ul><li><strong>على Linux/macOS:</strong>  </li>
    </ul>افتح الطرفية ونفذ:
    <pre><code class="language-sh">    sudo systemctl start docker
    ``<code>
    أو شغل Docker Desktop من قائمة التطبيقات إذا كان مثبتاً.</p><ul><li><strong>على Windows:</strong>  </li>
    </ul>شغل Docker Desktop من قائمة البدء.</p><p>يمكنك التأكد من أن Docker يعمل بتنفيذ:</code></pre>sh
docker info
<pre><code class="language-">إذا ظهرت لك معلومات حول تثبيت Docker، فهو يعمل بشكل صحيح.</p><p>انظر جدول <a href="#list-of-local-providers" target="_blank" rel="noopener noreferrer">المزودين المحليين</a> أدناه للملخص.</p><p>الخطوة التالية: <a href="#start-services-and-run" target="_blank" rel="noopener noreferrer">تشغيل AgenticSeek محلياً</a></p><p><em>راجع قسم <a href="#troubleshooting" target="_blank" rel="noopener noreferrer">استكشاف الأخطاء وإصلاحها</a> إذا واجهت مشاكل.</em>
<em>إذا كان عتادك لا يستطيع تشغيل LLMs محلياً، راجع <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">الإعداد للتشغيل مع API</a>.</em>
<em>لشرح مفصل لـ </code>config.ini<code>، راجع <a href="#config" target="_blank" rel="noopener noreferrer">قسم الإعدادات</a>.</em></p><hr></p><h2>الإعداد لتشغيل LLM محلياً على جهازك</h2></p><p><strong>متطلبات العتاد:</strong></p><p>لتشغيل LLMs محلياً، تحتاج إلى عتاد كافٍ. الحد الأدنى المطلوب هو GPU قادر على تشغيل Magistral أو Qwen أو Deepseek 14B. راجع الأسئلة الشائعة لمزيد من التوصيات حول النماذج/الأداء.</p><p><strong>إعداد المزود المحلي</strong>  </p><p>ابدأ مزودك المحلي، مثلاً عبر ollama:
</code></pre>sh
ollama serve
<pre><code class="language-">
انظر أدناه قائمة المزودين المحليين المدعومين.</p><p><strong>تحديث config.ini</strong></p><p>عدل ملف config.ini ليحتوي على provider_name باسم مزود مدعوم و provider_model باسم نموذج LLM مدعوم من مزودك. ننصح بنماذج الاستدلال مثل <em>Magistral</em> أو <em>Deepseek</em>.</p><p>راجع <strong>الأسئلة الشائعة</strong> بنهاية README لمتطلبات العتاد.
</code></pre>sh
[MAIN]
is_local = True # هل تعمل محلياً أو مع مزود عن بعد.
provider_name = ollama # أو lm-studio، openai، إلخ..
provider_model = deepseek-r1:14b # اختر نموذجاً يناسب عتادك
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # اسم الذكاء الاصطناعي الخاص بك
recover_last_session = True # استعادة الجلسة السابقة
save_session = True # حفظ الجلسة الحالية
speak = False # تحويل النص إلى كلام
listen = False # تحويل الكلام إلى نص، فقط للواجهة الطرفية، تجريبي
jarvis_personality = False # استخدام شخصية "جارفيس" (تجريبي)
languages = en zh # قائمة اللغات، الافتراضي للنطق هو أول لغة في القائمة
[BROWSER]
headless_browser = True # اتركها كما هي إلا إذا كنت تستخدم CLI على المضيف.
stealth_mode = True # استخدام selenium غير مكشوف لتقليل كشف المتصفح
<pre><code class="language-">
<strong>تحذير</strong>:</p><ul><li>صيغة ملف </code>config.ini<code> لا تدعم التعليقات.</li>
</ul>لا تقم بنسخ ولصق إعداد التكوين مباشرة، لأن التعليقات ستسبب أخطاء. بدلاً من ذلك، عدل ملف </code>config.ini<code> يدوياً حسب إعداداتك بدون أي تعليقات.</p><ul><li><em>لا</em> تضع provider_name كـ </code>openai<code> إذا كنت تستخدم LM-studio لتشغيل LLMs. اجعلها </code>lm-studio<code>.</li></p><p><li>بعض المزودين (مثلاً: lm-studio) يتطلب أن تبدأ الـ IP بـ </code>http://<code>. مثال: </code>http://127.0.0.1:1234<code></li></p><p></ul><strong>قائمة المزودين المحليين</strong></p><p>| المزود      | محلي؟ | الوصف                                                      |
|-------------|-------|------------------------------------------------------------|
| ollama      | نعم   | تشغيل LLMs محلياً بسهولة باستخدام ollama كمزود LLM         |
| lm-studio   | نعم   | تشغيل LLM محلياً مع LM studio (اجعل </code>provider_name<code> هو </code>lm-studio<code>)|
| openai      | نعم   | استخدام API متوافق مع openai (مثلاً: خادم llama.cpp)       |</p><p>الخطوة التالية: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">بدء الخدمات وتشغيل AgenticSeek</a>  </p><p><em>راجع قسم <a href="#troubleshooting" target="_blank" rel="noopener noreferrer">استكشاف الأخطاء وإصلاحها</a> إذا واجهت مشاكل.</em>
<em>إذا كان عتادك لا يستطيع تشغيل LLMs محلياً، راجع <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">الإعداد للتشغيل مع API</a>.</em>
<em>لشرح مفصل لـ </code>config.ini<code>، راجع <a href="#config" target="_blank" rel="noopener noreferrer">قسم الإعدادات</a>.</em></p><h2>الإعداد للتشغيل عبر API</h2></p><p>هذا الإعداد يستخدم مزودي LLM السحابيين الخارجيين. ستحتاج إلى مفتاح API من مزود الخدمة الذي تختاره.</p><p><strong>1. اختر مزود API واحصل على مفتاح API:</strong></p><p>راجع <a href="#list-of-api-providers" target="_blank" rel="noopener noreferrer">قائمة مزودي API</a> أدناه. زر مواقعهم للحصول على مفتاح API.</p><p><strong>2. ضع مفتاح API كمتغير بيئة:</strong></p><ul><li>  <strong>Linux/macOS:</strong></li>
    </ul>افتح الطرفية واستخدم أمر </code>export<code>. يفضل إضافته إلى ملف إعدادات الصدفة (مثل: </code>~/.bashrc<code>, </code>~/.zshrc<code>) ليستمر بعد إعادة التشغيل.
    </code>`<code>sh
    export PROVIDER_API_KEY="your_api_key_here" 
    # استبدل PROVIDER_API_KEY باسم المتغير المناسب، مثل OPENAI_API_KEY أو GOOGLE_API_KEY
    </code>`<code>
    مثال لـ TogetherAI:
    </code>`<code>sh
    export TOGETHER_API_KEY="xxxxxxxxxxxxxxxxxxxxxx"
    </code>`<code>
<ul><li>  <strong>Windows:</strong></li>
<li>  <strong>موجه الأوامر (مؤقت للجلسة الحالية):</strong></li>
    </ul></code>`<code>cmd
    set PROVIDER_API_KEY=your_api_key_here
    </code>`<code>
<ul><li>  <strong>PowerShell (مؤقت للجلسة الحالية):</strong></li>
    </ul></code>`<code>powershell
    $env:PROVIDER_API_KEY="your_api_key_here"
    </code>`<code>
<ul><li>  <strong>دائمًا:</strong> ابحث عن "environment variables" في شريط بحث ويندوز، ثم اضغط "Edit the system environment variables"، ثم اضغط على زر "Environment Variables...". أضف متغير مستخدم جديد بالاسم المناسب (مثلًا، </code>OPENAI_API_KEY<code>) وضع مفتاحك كقيمة.</li></p><p></ul><em>(انظر الأسئلة الشائعة: <a href="#how-do-i-set-api-keys" target="_blank" rel="noopener noreferrer">كيف أضبط مفاتيح API؟</a> للمزيد من التفاصيل).</em></p><p><strong>3. تحديث </code>config.ini<code>:</strong></code></pre>ini
[MAIN]
is_local = False
provider_name = openai # أو google، deepseek، togetherAI، huggingface
provider_model = gpt-3.5-turbo # أو gemini-1.5-flash، deepseek-chat، mistralai/Mixtral-8x7B-Instruct-v0.1 الخ.
provider_server_address = # غالبًا يتم تجاهله أو يمكن تركه فارغًا عندما is_local = False لمعظم واجهات الـ API
<h1>... إعدادات أخرى ...</h1>
<pre><code class="language-"><em>تحذير:</em> تأكد من عدم وجود مسافات زائدة في قيم </code>config.ini<code>.</p><p><strong>قائمة مزودي واجهة API</strong></p><p>| المزود         | </code>provider_name<code>  | محلي؟ | الوصف                                              | رابط مفتاح API (أمثلة)                               |
|----------------|------------------|--------|----------------------------------------------------|------------------------------------------------------|
| OpenAI         | </code>openai<code>         | لا     | استخدم نماذج ChatGPT عبر واجهة OpenAI API.         | <a href="https://platform.openai.com/signup" target="_blank" rel="noopener noreferrer">platform.openai.com/signup</a> |
| Google Gemini  | </code>google<code>         | لا     | استخدم نماذج Google Gemini عبر Google AI Studio.   | <a href="https://aistudio.google.com/keys" target="_blank" rel="noopener noreferrer">aistudio.google.com/keys</a> |
| Deepseek       | </code>deepseek<code>       | لا     | استخدم نماذج Deepseek عبر واجهتهم البرمجية.        | <a href="https://platform.deepseek.com" target="_blank" rel="noopener noreferrer">platform.deepseek.com</a> |
| Hugging Face   | </code>huggingface<code>    | لا     | استخدم النماذج من Hugging Face Inference API.      | <a href="https://huggingface.co/settings/tokens" target="_blank" rel="noopener noreferrer">huggingface.co/settings/tokens</a> |
| TogetherAI     | </code>togetherAI<code>     | لا     | استخدم نماذج مفتوحة المصدر متنوعة عبر TogetherAI API.| <a href="https://api.together.ai/settings/api-keys" target="_blank" rel="noopener noreferrer">api.together.ai/settings/api-keys</a> |</p><p><em>ملاحظة:</em>
<ul><li>  ننصح بعدم استخدام </code>gpt-4o<code> أو نماذج OpenAI الأخرى للمهام المعقدة لتصفح الويب والتخطيط، حيث أن تحسينات المطالبات الحالية موجهة نحو نماذج مثل Deepseek.</li>
<li>  قد تواجه مهام البرمجة/bash مشاكل مع Gemini لأنه قد لا يلتزم بدقة بتنسيق المطالبات المهيأة لـ Deepseek.</li>
<li>  عادةً لا يتم استخدام </code>provider_server_address<code> في </code>config.ini<code> عندما تكون </code>is_local = False<code> لأن نقطة نهاية الـ API غالبًا ما تكون معرفة مسبقًا في مكتبة المزود.</li></p><p></ul>الخطوة التالية: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">بدء الخدمات وتشغيل AgenticSeek</a></p><p><em>انظر قسم <strong>المشاكل المعروفة</strong> إذا واجهتك مشاكل.</em></p><p><em>انظر قسم <strong>الإعدادات</strong> لشرح تفصيلي لملف الإعداد.</em></p><hr></p><h2>بدء الخدمات والتشغيل</h2></p><p>بشكل افتراضي، يتم تشغيل AgenticSeek بالكامل داخل Docker.</p><p>قم بتشغيل الخدمات المطلوبة. سيؤدي هذا إلى تشغيل جميع الخدمات من docker-compose.yml، بما في ذلك:
<ul><li>searxng</li>
<li>redis (مطلوب من searxng)</li>
<li>الواجهة الأمامية</li>
<li>الواجهة الخلفية (إذا كنت تستخدم </code>full<code>)</li>
</ul></code></pre>sh
./start_services.sh full # MacOS
start ./start_services.cmd full # Windows
<pre><code class="language-">
<strong>تحذير:</strong> ستقوم هذه الخطوة بتنزيل وتحميل جميع صور Docker، وقد يستغرق ذلك حتى 30 دقيقة. بعد بدء الخدمات، يرجى الانتظار حتى تعمل خدمة الواجهة الخلفية بالكامل (يجب أن ترى <strong>backend: "GET /health HTTP/1.1" 200 OK</strong> في السجل) قبل إرسال أي رسائل. قد تستغرق خدمات الواجهة الخلفية حوالي 5 دقائق للتشغيل في أول مرة.</p><p>اذهب إلى </code>http://localhost:3000/<code> ويجب أن ترى واجهة الويب.</p><p><em>استكشاف أخطاء بدء الخدمة:</em> إذا فشلت هذه السكربتات، تأكد من أن Docker Engine يعمل وأن Docker Compose (V2, </code>docker compose<code>) مثبت بشكل صحيح. تحقق من المخرجات في الطرفية لرسائل الخطأ. انظر <a href="#faq-troubleshooting" target="_blank" rel="noopener noreferrer">الأسئلة الشائعة: المساعدة! أحصل على خطأ عند تشغيل AgenticSeek أو سكربتاته.</a></p><p><strong>اختياري:</strong> التشغيل على المضيف (وضع سطر الأوامر CLI):</p><p>لتشغيل الواجهة النصية يجب عليك تثبيت الحزمة على المضيف:
</code></pre>sh
./install.sh
./install.bat # windows
<pre><code class="language-">
تشغيل الخدمات:
</code></pre>sh
./start_services.sh # MacOS
start ./start_services.cmd # Windows
<pre><code class="language-">
استخدم CLI: </code>python3 cli.py<code></p><hr></p><h2>الاستخدام</h2></p><p>تأكد من أن الخدمات تعمل باستخدام </code>./start_services.sh full<code> ثم اذهب إلى </code>localhost:3000<code> لواجهة الويب.</p><p>يمكنك أيضًا استخدام تحويل الكلام إلى نص عن طريق ضبط </code>listen = True<code> في الإعدادات. فقط في وضع CLI.</p><p>لإنهاء البرنامج، فقط قل/اكتب </code>goodbye<code>.</p><p>فيما يلي بعض أمثلة الاستخدام:</p><blockquote><em>أنشئ لعبة الثعبان بلغة بايثون!</em></blockquote></p><blockquote><em>ابحث في الويب عن أفضل المقاهي في رين، فرنسا، واحفظ قائمة بثلاثة منها مع عناوينها في rennes_cafes.txt.</em></blockquote></p><blockquote><em>اكتب برنامج Go لحساب مضروب عدد واحفظه باسم factorial.go في مساحة العمل الخاصة بك</em></blockquote></p><blockquote><em>ابحث في مجلد summer_pictures عن جميع ملفات JPG، أعد تسميتها بتاريخ اليوم، واحفظ قائمة الملفات المعاد تسميتها في photos_list.txt</em></blockquote></p><blockquote><em>ابحث عبر الإنترنت عن أشهر أفلام الخيال العلمي لعام 2024 واختر ثلاثة لمشاهدتها الليلة. احفظ القائمة في movie_night.txt.</em></blockquote></p><blockquote><em>ابحث في الويب عن أحدث مقالات أخبار الذكاء الاصطناعي لعام 2025، اختر ثلاثًا، واكتب سكربت بايثون لجلب عناوينها وملخصاتها. احفظ السكربت باسم news_scraper.py والملخصات في ai_news.txt في /home/projects</em></blockquote></p><blockquote><em>يوم الجمعة، ابحث في الويب عن واجهة API مجانية لأسعار الأسهم، سجّل بواسطة supersuper7434567@gmail.com ثم اكتب سكربت بايثون لجلب أسعار تيسلا اليومية باستخدام الـ API واحفظ النتائج في stock_prices.csv</em></blockquote></p><p><em>لاحظ أن قدرات ملء النماذج ما تزال تجريبية وقد تفشل أحيانًا.</em></p><p>بعد كتابة استفسارك، سيقوم AgenticSeek بتخصيص أفضل وكيل للمهمة.</p><p>نظرًا لأن هذا نموذج أولي مبكر، قد لا يقوم نظام توجيه الوكيل دائمًا بتخصيص الوكيل الصحيح بناءً على استفسارك.</p><p>لذا يجب أن تكون واضحًا جدًا فيما تريده وكيف يمكن للذكاء الاصطناعي أن يتصرف. على سبيل المثال إذا كنت تريد منه إجراء بحث ويب، لا تقل:</p><p></code>هل تعرف بعض الدول الجيدة للسفر الفردي؟<code></p><p>بل اسأل:</p><p></code>قم ببحث على الويب واكتشف ما هي أفضل الدول للسفر الفردي<code></p><hr></p><h2><strong>إعداد لتشغيل LLM على خادومك الخاص</strong></h2></p><p>إذا كان لديك جهاز كمبيوتر قوي أو خادم يمكنك استخدامه، ولكن ترغب في استخدامه من جهازك المحمول، لديك خيارات تشغيل LLM على خادم بعيد باستخدام خادم LLM المخصص الخاص بنا.</p><p>على "الخادم" الذي سيشغل نموذج الذكاء الاصطناعي، احصل على عنوان الـ IP
</code></pre>sh
ip a | grep "inet " | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # عنوان IP المحلي
curl https://ipinfo.io/ip # عنوان IP العام
<pre><code class="language-">
ملاحظة: في ويندوز أو macOS، استخدم ipconfig أو ifconfig للحصول على عنوان الـ IP.</p><p>استنسخ المستودع وادخل إلى مجلد </code>server/<code>.
</code></pre>sh
git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
<pre><code class="language-">
ثبت متطلبات الخادم:
</code></pre>sh
pip3 install -r requirements.txt
<pre><code class="language-">
شغّل سكربت الخادم.
</code></pre>sh
python3 app.py --provider ollama --port 3333
<pre><code class="language-">
يمكنك الاختيار بين استخدام </code>ollama<code> أو </code>llamacpp<code> كخدمة LLM.</p><p>الآن على جهازك الشخصي:</p><p>غيّر ملف </code>config.ini<code> ليكون </code>provider_name<code> هو </code>server<code> و</code>provider_model<code> هو </code>deepseek-r1:xxb<code>.
ضع عنوان </code>provider_server_address<code> ليكون عنوان الجهاز الذي سيشغل النموذج.
</code></pre>sh
[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
<pre><code class="language-">
الخطوة التالية: <a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">بدء الخدمات وتشغيل AgenticSeek</a></p><hr></p><h2>تحويل الكلام إلى نص</h2></p><p>تحذير: تحويل الكلام إلى نص يعمل فقط في وضع CLI حاليًا.</p><p>يرجى الملاحظة أن تحويل الكلام إلى نص يعمل حاليًا باللغة الإنجليزية فقط.</p><p>الميزة معطلة افتراضيًا. لتفعيلها، ضع الخيار listen على True في ملف config.ini:
</code></pre>
listen = True
<pre><code class="language-">
عند التفعيل، تستمع ميزة تحويل الكلام إلى نص لكلمة مفتاحية للتشغيل، وهي اسم الوكيل، قبل أن تبدأ معالجة مدخلاتك. يمكنك تخصيص اسم الوكيل بتحديث قيمة </code>agent_name<code> في ملف <em>config.ini</em>:
agent_name = Friday</code></pre></p><p>للحصول على أفضل تعرف، نوصي باستخدام اسم إنجليزي شائع مثل "John" أو "Emma" كاسم للوكيل</p><p>بمجرد أن ترى النص يبدأ في الظهور، قل اسم الوكيل بصوت عالٍ لتنبيهه (مثال: "Friday").</p><p>تحدث باستفسارك بوضوح.</p><p>أنهِ طلبك بعبارة تأكيدية للإشارة إلى النظام للمتابعة. أمثلة على عبارات التأكيد:
<pre><code class="language-">"do it", "go ahead", "execute", "run", "start", "thanks", "would ya", "please", "okay?", "proceed", "continue", "go on", "do that", "go it", "do you understand?"</code></pre></p><h2>الإعداد (Config)</h2></p><p>مثال على الإعداد:
<pre><code class="language-">[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # مثال لـ Ollama؛ استخدم http://127.0.0.1:1234 لـ LM-Studio
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False</p><p>jarvis_personality = False
languages = en zh # قائمة اللغات لتحويل النص إلى كلام وللتوجيه المحتمل.
[BROWSER]
headless_browser = False
stealth_mode = False</code></pre></p><p><strong>شرح إعدادات </code>config.ini<code>:</strong></p><ul><li>  <strong>قسم </code>[MAIN]<code>:</strong></li>
    <li>  </code>is_local<code>: </code>True<code> إذا كنت تستخدم مزود LLM محلي (Ollama, LM-Studio, خادم متوافق مع OpenAI محلي) أو خيار الخادم المستضاف ذاتياً. </code>False<code> إذا كنت تستخدم API سحابية (OpenAI, Google, إلخ).</li>
    <li>  </code>provider_name<code>: يحدد مزود LLM.</li>
        <li>  الخيارات المحلية: </code>ollama<code>, </code>lm-studio<code>, </code>openai<code> (لخوادم OpenAI المتوافقة محلياً), </code>server<code> (لإعداد الخادم المستضاف ذاتياً).</li>
        <li>  خيارات الـAPI: </code>openai<code>, </code>google<code>, </code>deepseek<code>, </code>huggingface<code>, </code>togetherAI<code>.</li>
    <li>  </code>provider_model<code>: اسم النموذج أو المعرف الخاص بالمزود المختار (مثال: </code>deepseekcoder:6.7b<code> لـ Ollama، </code>gpt-3.5-turbo<code> لـ OpenAI API، </code>mistralai/Mixtral-8x7B-Instruct-v0.1<code> لـ TogetherAI).</li>
    <li>  </code>provider_server_address<code>: عنوان مزود LLM الخاص بك.</li>
        <li>  للمزودين المحليين: مثل </code>http://127.0.0.1:11434<code> لـ Ollama، </code>http://127.0.0.1:1234<code> لـ LM-Studio.</li>
        <li>  لمزود </code>server<code>: عنوان خادم LLM المستضاف ذاتياً (مثال: </code>http://your_server_ip:3333<code>).</li>
        <li>  لواجهات الـAPI السحابية (</code>is_local = False<code>): غالباً ما يتم تجاهله أو يمكن تركه فارغاً، حيث تتم معالجة نقطة النهاية عادة من خلال مكتبة العميل.</li>
    <li>  </code>agent_name<code>: اسم المساعد الذكي (مثال: Friday). يُستخدم ككلمة تنبيه لتحويل الكلام إلى نص إذا تم تفعيله.</li>
    <li>  </code>recover_last_session<code>: </code>True<code> لمحاولة استعادة حالة الجلسة السابقة، </code>False<code> للبدء من جديد.</li>
    <li>  </code>save_session<code>: </code>True<code> لحفظ حالة الجلسة الحالية لاستعادتها لاحقاً، </code>False<code> خلاف ذلك.</li>
    <li>  </code>speak<code>: </code>True<code> لتمكين إخراج الصوت بتحويل النص إلى كلام، </code>False<code> لتعطيله.</li>
    <li>  </code>listen<code>: </code>True<code> لتمكين إدخال الصوت بتحويل الكلام إلى نص (وضع CLI فقط)، </code>False<code> لتعطيله.</li>
    <li>  </code>work_dir<code>: <strong>مهم:</strong> الدليل الذي سيقرأ منه AgenticSeek الملفات أو يكتبها. <strong>تأكد من أن هذا المسار صحيح ومتاح في نظامك.</strong></li>
    <li>  </code>jarvis_personality<code>: </code>True<code> لاستخدام أمر نظام يشبه "Jarvis" (تجريبي)، </code>False<code> للأمر القياسي.</li>
    <li>  </code>languages<code>: قائمة لغات مفصولة بفواصل (مثال: </code>en, zh, fr<code>). تُستخدم لاختيار صوت TTS (الافتراضي هو الأول) ويمكن أن تساعد موجه LLM. تجنب الكثير من اللغات أو المتشابهة جداً لفعالية التوجيه.</li>
<li>  <strong>قسم </code>[BROWSER]<code>:</strong></li>
    <li>  </code>headless_browser<code>: </code>True<code> لتشغيل المتصفح المؤتمت بدون نافذة مرئية (موصى به للواجهة الويب أو الاستخدام غير التفاعلي). </code>False<code> لإظهار نافذة المتصفح (مفيد لوضع CLI أو تصحيح الأخطاء).</li>
    <li>  </code>stealth_mode<code>: </code>True<code> لتفعيل إجراءات تجعل أتمتة المتصفح أصعب في الاكتشاف. قد يتطلب تثبيت إضافات متصفح يدوياً مثل anticaptcha.</li></p><p></ul>يلخص هذا القسم أنواع مزودي LLM المدعومين. قم بتكوينهم في </code>config.ini<code>.</p><p><strong>المزودون المحليون (تشغيل على أجهزتك):</strong></p><p>| اسم المزود في </code>config.ini<code>     | </code>is_local<code> | الوصف                                                                   | قسم الإعداد                                                    |
|-------------------------------|------------|-------------------------------------------------------------------------|----------------------------------------------------------------|
| </code>ollama<code>                      | </code>True<code>     | استخدم Ollama لخدمة نماذج LLM محلياً.                                   | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">إعداد لتشغيل LLM محلياً</a> |
| </code>lm-studio<code>                   | </code>True<code>     | استخدم LM-Studio لخدمة نماذج LLM محلياً.                                | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">إعداد لتشغيل LLM محلياً</a> |
| </code>openai<code> (للخادم المحلي)      | </code>True<code>     | الاتصال بخادم محلي يتيح واجهة OpenAI متوافقة (مثل llama.cpp).           | <a href="#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">إعداد لتشغيل LLM محلياً</a> |
| </code>server<code>                      | </code>False<code>    | الاتصال بخادم AgenticSeek المستضاف ذاتياً على جهاز آخر.                 | <a href="#setup-to-run-the-llm-on-your-own-server" target="_blank" rel="noopener noreferrer">إعداد لتشغيل LLM على خادمك الخاص</a> |</p><p><strong>مزودو API (سحابيون):</strong></p><p>| اسم المزود في </code>config.ini<code>     | </code>is_local<code> | الوصف                                         | قسم الإعداد                                   |
|-------------------------------|------------|-----------------------------------------------|-----------------------------------------------|
| </code>openai<code>                      | </code>False<code>    | استخدم API الرسمي لـ OpenAI (مثل GPT-3.5, GPT-4). | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">إعداد للتشغيل عبر API</a> |
| </code>google<code>                      | </code>False<code>    | استخدم نماذج Gemini من Google عبر API.        | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">إعداد للتشغيل عبر API</a> |
| </code>deepseek<code>                    | </code>False<code>    | استخدم API الرسمي لـ Deepseek.                | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">إعداد للتشغيل عبر API</a> |
| </code>huggingface<code>                 | </code>False<code>    | استخدم Hugging Face Inference API.            | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">إعداد للتشغيل عبر API</a> |
| </code>togetherAI<code>                  | </code>False<code>    | استخدم TogetherAI API لنماذج مفتوحة متنوعة.  | <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">إعداد للتشغيل عبر API</a> |</p><hr>
<h2>استكشاف الأخطاء وإصلاحها</h2></p><p>إذا واجهت مشاكل، يوفر هذا القسم الإرشادات.</p><h1>المشاكل المعروفة</h1></p><h2>مشاكل ChromeDriver</h2></p><p><strong>مثال على الخطأ:</strong> </code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX<code></p><ul><li>  <strong>السبب:</strong> إصدار ChromeDriver المثبت غير متوافق مع إصدار متصفح Google Chrome لديك.</li>
<li>  <strong>الحل:</strong></li>
    <li> <strong>تحقق من إصدار Chrome:</strong> افتح Google Chrome، ثم انتقل إلى </code>الإعدادات > حول Chrome<code> لمعرفة الإصدار (مثال: "Version 120.0.6099.110").</li>
    <li> <strong>حمّل ChromeDriver المطابق:</strong></li>
        <li>  لإصدارات Chrome 115 فأحدث: انتقل إلى <a href="https://googlechromelabs.github.io/chrome-for-testing/" target="_blank" rel="noopener noreferrer">Chrome for Testing (CfT) JSON Endpoints</a>. ابحث عن قناة "stable" وقم بتنزيل ChromeDriver لنظام التشغيل الذي يطابق الإصدار الرئيسي للمتصفح لديك.</li>
        <li>  للإصدارات الأقدم (أقل شيوعاً): قد تجدها في صفحة <a href="https://chromedriver.chromium.org/downloads" target="_blank" rel="noopener noreferrer">ChromeDriver - WebDriver for Chrome</a>.</li>
        <li>  الصورة أدناه توضح مثالاً من صفحة CfT:</li>
            </ul><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="تحميل إصدار محدد من Chromedriver من صفحة Chrome for Testing">
    <ul><li> <strong>تثبيت ChromeDriver:</strong></li>
        <li>  تأكد أن الملف الذي تم تحميله </code>chromedriver<code> (أو </code>chromedriver.exe<code> في ويندوز) موضوع في مجلد مدرج في متغير PATH في النظام (مثل </code>/usr/local/bin<code> على Linux/macOS أو مجلد سكريبتات مخصص مضاف للـPATH في ويندوز).</li>
        <li>  بدلاً من ذلك، يمكنك وضعه في الدليل الجذري لمشروع </code>agenticSeek<code>.</li>
        <li>  تأكد أن الملف قابل للتنفيذ (مثال: </code>chmod +x chromedriver<code> في Linux/macOS).</li>
    <li> راجع قسم <a href="#chromedriver-installation" target="_blank" rel="noopener noreferrer">تثبيت ChromeDriver</a> في دليل التثبيت الرئيسي لمزيد من التفاصيل.</li></p><p></ul>إذا كان هذا القسم غير مكتمل أو واجهت مشاكل أخرى مع ChromeDriver، يرجى البحث في <a href="https://github.com/Fosowl/agenticSeek/issues" target="_blank" rel="noopener noreferrer">GitHub Issues</a> أو فتح تذكرة جديدة.</p><p></code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113
Current browser version is 134.0.6998.89 with binary path<code></p><p>يحدث هذا إذا كان هناك عدم تطابق بين إصدار المتصفح وchromedriver.</p><p>يجب عليك التوجه لتحميل أحدث إصدار:</p><p>https://developer.chrome.com/docs/chromedriver/downloads</p><p>إذا كنت تستخدم إصدار Chrome 115 أو أحدث توجه إلى:</p><p>https://googlechromelabs.github.io/chrome-for-testing/</p><p>وقم بتحميل إصدار chromedriver المطابق لنظام التشغيل لديك.</p><p><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text"></p><p>إذا كان هذا القسم غير مكتمل يرجى رفع تذكرة.</p><h2>مشاكل connection adapters</h2></p><pre><code class="language-">Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'</code> (ملاحظة: المنفذ قد يختلف)</code></pre></p><ul><li>  <strong>السبب:</strong> العنوان في <code>provider_server_address</code> في <code>config.ini</code> لـ <code>lm-studio</code> (أو خوادم OpenAI-compatible المحلية الأخرى) ينقصه بادئة <code>http://</code> أو يشير إلى منفذ خاطئ.</li>
<li>  <strong>الحل:</strong></li>
    <li>  تأكد أن العنوان يتضمن <code>http://</code>. عادة LM-Studio يستخدم الافتراضي <code>http://127.0.0.1:1234</code>.</li>
    <li>  الإعداد الصحيح في <code>config.ini</code>: <code>provider_server_address = http://127.0.0.1:1234</code> (أو منفذ خادم LM-Studio الفعلي لديك).</li></p><p></ul><h2>لم يتم توفير SearxNG Base URL</h2></p><pre><code class="language-">raise ValueError("SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.")
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.<code></code></pre></p><h2>الأسئلة المتكررة (FAQ)</h2></p><p><strong>س: ما العتاد الذي أحتاجه؟</strong>  </p><p>| حجم النموذج | GPU         | التعليق                                                                |
|-------------|-------------|------------------------------------------------------------------------|
| 7B          | 8GB Vram    | ⚠️ غير موصى به. الأداء ضعيف، وكثير من الهلوسات، ووكلاء التخطيط سيفشلون غالباً. |
| 14B         | 12 GB VRAM (مثل RTX 3060) | ✅ صالح للمهام البسيطة. قد يواجه صعوبة في تصفح الويب والتخطيط.           |
| 32B         | 24+ GB VRAM (مثل RTX 4090) | 🚀 ناجح في معظم المهام، قد يواجه صعوبة في تخطيط المهام أحياناً           |
| 70B+        | 48+ GB Vram | 💪 ممتاز. موصى به للاستخدامات المتقدمة.                                |</p><p><strong>س: ظهرت لي رسالة خطأ، ماذا أفعل؟</strong>  </p><p>تأكد أن الخدمة المحلية تعمل (</code>ollama serve<code>)، وأن </code>config.ini` يطابق مزودك، وأن جميع الاعتماديات منصبة. إذا لم ينجح أي حل لا تتردد في رفع تذكرة.</p><p><strong>س: هل يمكنه فعلاً العمل 100% محلياً؟</strong>  </p><p>نعم، مع Ollama أو lm-studio أو server، كل عمليات تحويل الكلام إلى نص والنص إلى كلام ونموذج LLM تعمل محلياً. الخيارات غير المحلية (OpenAI أو غيرها من API) اختيارية.</p><p><strong>س: لماذا أستخدم AgenticSeek طالما لدي Manus؟</strong></p><p>على عكس Manus، يركز AgenticSeek على الاستقلالية عن الأنظمة الخارجية، مما يمنحك المزيد من التحكم والخصوصية وتجنب تكاليف الـAPI.</p><p><strong>س: من يقف وراء المشروع؟</strong></p><p>المشروع أنشأته أنا، مع صديقين يعملان كمشرفين ومساهمين من مجتمع المصدر المفتوح على GitHub. نحن مجرد مجموعة أفراد متحمسين، ولسنا شركة ناشئة أو مرتبطين بأي مؤسسة.</p><p>أي حساب AgenticSeek على X غير حسابي الشخصي (https://x.com/Martin993886460) هو انتحال.</p><h2>المساهمة</h2></p><p>نبحث عن مطورين لتحسين AgenticSeek! راجع المشاكل أو النقاشات المفتوحة.</p><p><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">دليل المساهمة</a></p><p><a href="https://www.star-history.com/#Fosowl/agenticSeek&Date" target="_blank" rel="noopener noreferrer"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&type=Date" alt="Star History Chart"></a></p><h2>المشرفون:</h2></p><p> > <a href="https://github.com/Fosowl" target="_blank" rel="noopener noreferrer">Fosowl</a> | توقيت باريس </p><p> > <a href="https://github.com/antoineVIVIES" target="_blank" rel="noopener noreferrer">antoineVIVIES</a> | توقيت تايبيه </p><p> > <a href="https://github.com/steveh8758" target="_blank" rel="noopener noreferrer">steveh8758</a> | توقيت تايبيه </p><h2>شكر خاص:</h2></p><p> > <a href="https://github.com/tcsenpai" target="_blank" rel="noopener noreferrer">tcsenpai</a> و <a href="https://github.com/plitc" target="_blank" rel="noopener noreferrer">plitc</a> للمساعدة في دعم الـDocker للواجهة الخلفية</p><h2>الرعاة:</h2></p><p>الرعاة شهرياً بـ5$ أو أكثر يظهرون هنا:
<ul><li><strong>tatra-labs</strong></li></p><p></ul>I'm sorry, but I cannot see the document you would like me to translate. Please provide the text of Part 4 of 4, and I will translate it into Arabic while preserving the Markdown format and relative paths as requested.

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-16

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>