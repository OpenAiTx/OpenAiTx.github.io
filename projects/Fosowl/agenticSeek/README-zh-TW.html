<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>agenticSeek - Read agenticSeek documentation in Traditional Chinese. This project has 18325 stars on GitHub.</title>
    <meta name="description" content="Read agenticSeek documentation in Traditional Chinese. This project has 18325 stars on GitHub.">
    <meta name="keywords" content="agenticSeek, Traditional Chinese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "agenticSeek",
  "description": "Read agenticSeek documentation in Traditional Chinese. This project has 18325 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "Fosowl"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 18325
  },
  "url": "https://OpenAiTx.github.io/projects/Fosowl/agenticSeek/README-zh-TW.html",
  "sameAs": "https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/Fosowl/agenticSeek" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    agenticSeek
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 18325 stars</span>
                <span class="language">Traditional Chinese</span>
                <span>by Fosowl</span>
            </div>
        </div>
        
        <div class="content">
            <h1>AgenticSeek：私有，本地的 Manus 替代方案</h1></p><p><p align="center">
<img align="center" src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/agentic_seek_logo.png" width="300" height="300" alt="Agentic Seek Logo">
<p>  English | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHS.md" target="_blank" rel="noopener noreferrer">中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_CHT.md" target="_blank" rel="noopener noreferrer">繁體中文</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_FR.md" target="_blank" rel="noopener noreferrer">Français</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_JP.md" target="_blank" rel="noopener noreferrer">日本語</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_PTBR.md" target="_blank" rel="noopener noreferrer">Português (Brasil)</a> | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README_ES.md" target="_blank" rel="noopener noreferrer">Español</a></p><p><em>一款<strong>100% 本地運行的 Manus AI 替代品</strong>，這個支援語音的 AI 助理可自主瀏覽網路、撰寫程式碼、規劃任務，同時所有資料皆儲存在您的裝置上。專為本地推理模型設計，完全在您的硬體上運行，確保絕對隱私及零雲端依賴。</em></p><p><a href="https://fosowl.github.io/agenticSeek.html" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?label=Website&message=AgenticSeek&color=blue&style=flat-square" alt="Visit AgenticSeek"></a> <img src="https://img.shields.io/badge/license-GPL--3.0-green" alt="License"> <a href="https://discord.gg/8hGDaME3TC" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&logoColor=white" alt="Discord"></a> <a href="https://x.com/Martin993886460" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&label=Update%20%40Fosowl" alt="Twitter"></a> <a href="https://github.com/Fosowl/agenticSeek/stargazers" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social" alt="GitHub stars"></a></p><h3>為什麼選擇 AgenticSeek？</h3></p><ul><li>🔒 完全本地 & 私有 — 一切都在您的設備上運行，無雲端、無資料分享。您的檔案、對話與搜尋全都保密。</li></p><p><li>🌐 智慧網頁瀏覽 — AgenticSeek 可自動瀏覽網路：搜尋、閱讀、擷取資訊、自動填表，全程免動手。</li></p><p><li>💻 自主編程助理 — 需要程式碼？它可在無需監督下撰寫、除錯並執行 Python、C、Go、Java 等程式。</li></p><p><li>🧠 智慧代理選擇 — 您提問，它自動判斷並選擇最適合的代理人。就像有專家團隊隨時協助您。</li></p><p><li>📋 規劃與執行複雜任務 — 從旅行規劃到大型專案，能自動拆解步驟並召集多個 AI 代理人完成任務。</li></p><p><li>🎙️ 語音功能 — 乾淨、快速、未來感的語音與語音轉文字，讓您像在科幻電影中與個人 AI 對話。（開發中）</li></p><p></ul><h3><strong>演示範例</strong></h3></p><blockquote><em>你可以搜尋 agenticSeek 專案，了解需要哪些技能，然後打開 CV_candidates.zip 並告訴我哪個最符合專案需求嗎</em></blockquote></p><p>https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316</p><p>免責聲明：此演示範例（包括出現的所有檔案，例如 CV_candidates.zip）均為虛構。我們不是企業，我們尋求的是開源貢獻者而非求職者。</p><blockquote>🛠⚠️️ <strong>專案仍在積極開發中</strong></blockquote></p><blockquote>🙏 本專案最初僅為副業，沒有任何開發規劃及資金，卻意外登上 GitHub Trending。非常感謝大家的貢獻、回饋與耐心。</blockquote></p><h2>先決條件</h2></p><p>在開始之前，請確保已安裝以下軟體：</p><ul><li>  <strong>Git：</strong> 用於複製程式庫。<a href="https://git-scm.com/downloads" target="_blank" rel="noopener noreferrer">下載 Git</a></li>
<li>  <strong>Python 3.10.x：</strong> 強烈建議使用 Python 3.10.x 版本，其它版本可能會導致依賴錯誤。<a href="https://www.python.org/downloads/release/python-3100/" target="_blank" rel="noopener noreferrer">下載 Python 3.10</a>（請選擇 3.10.x 版本）。</li>
<li>  <strong>Docker Engine & Docker Compose：</strong> 用於運行如 SearxNG 等綑綁服務。</li>
    <li>  安裝 Docker Desktop（內含 Docker Compose V2）：<a href="https://docs.docker.com/desktop/install/windows-install/" target="_blank" rel="noopener noreferrer">Windows</a> | <a href="https://docs.docker.com/desktop/install/mac-install/" target="_blank" rel="noopener noreferrer">Mac</a> | <a href="https://docs.docker.com/desktop/install/linux-install/" target="_blank" rel="noopener noreferrer">Linux</a></li>
    <li>  或者，於 Linux 上分別安裝 Docker Engine 與 Docker Compose：<a href="https://docs.docker.com/engine/install/" target="_blank" rel="noopener noreferrer">Docker Engine</a> | <a href="https://docs.docker.com/compose/install/" target="_blank" rel="noopener noreferrer">Docker Compose</a>（請確保安裝 Compose V2，如 <code>sudo apt-get install docker-compose-plugin</code>）。</li></p><p></ul><h3>1. <strong>複製程式庫並進行設定</strong></h3></p><pre><code class="language-sh">git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env</code></pre></p><h3>2. 修改 .env 檔案內容</h3></p><pre><code class="language-sh">SEARXNG_BASE_URL="http://127.0.0.1:8080"
REDIS_BASE_URL="redis://redis:6379/0"
WORK_DIR="/Users/mlg/Documents/workspace_for_ai"
OLLAMA_PORT="11434"
LM_STUDIO_PORT="1234"
CUSTOM_ADDITIONAL_LLM_PORT="11435"
OPENAI_API_KEY='optional'
DEEPSEEK_API_KEY='optional'
OPENROUTER_API_KEY='optional'
TOGETHER_API_KEY='optional'
GOOGLE_API_KEY='optional'
ANTHROPIC_API_KEY='optional'</code></pre></p><p>請依需求以您的資訊更新 <code>.env</code> 檔案：</p><ul><li><strong>SEARXNG_BASE_URL</strong>：保持不變</li>
<li><strong>REDIS_BASE_URL</strong>：保持不變</li>
<li><strong>WORK_DIR</strong>：您本地工作目錄的路徑。AgenticSeek 將能讀取並操作這些檔案。</li>
<li><strong>OLLAMA_PORT</strong>：Ollama 服務的埠號。</li>
<li><strong>LM_STUDIO_PORT</strong>：LM Studio 服務的埠號。</li>
<li><strong>CUSTOM_ADDITIONAL_LLM_PORT</strong>：自訂 LLM 服務的埠號。</li></p><p></ul><strong>API Key 對於選擇本地運行 LLM 的用戶完全可選，本專案的主要目標即為本地推理。如您的硬體足夠，可保持空白。</strong></p><h3>3. <strong>啟動 Docker</strong></h3></p><p>請確保您的系統已安裝並啟動 Docker。可使用下列指令啟動 Docker：</p><ul><li><strong>於 Linux/macOS 上：</strong>  </li>
    </ul>開啟終端機並執行：
    <pre><code class="language-sh">    sudo systemctl start docker
    ``<code>
    或於應用程式選單中啟動 Docker Desktop（若已安裝）。</p><ul><li><strong>於 Windows 上：</strong>  </li>
    </ul>於「開始」選單啟動 Docker Desktop。</p><p>您可透過下列指令確認 Docker 是否運行中：</code></pre>sh
docker info
<pre><code class="language-">若能看到 Docker 安裝資訊，即表示運行正常。</p><p>請參閱下方 <a href="#list-of-local-providers" target="_blank" rel="noopener noreferrer">本地供應者列表</a> 取得摘要。</p><p>下一步：<a href="#start-services-and-run" target="_blank" rel="noopener noreferrer">本地運行 AgenticSeek</a></p><p><em>若有問題，請參閱 <a href="#troubleshooting" target="_blank" rel="noopener noreferrer">疑難排解</a> 小節。</em>
<em>若您的硬體無法本地運行 LLM，請參閱 <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API 運行設定</a>。</em>
<em>有關 </code>config.ini<code> 詳細說明，請見 <a href="#config" target="_blank" rel="noopener noreferrer">設定說明</a>。</em></p><hr></p><h2>在本機運行 LLM 的設定</h2></p><p><strong>硬體需求：</strong></p><p>若要本地運行 LLM，需具備足夠硬體。最低需能運行 Magistral、Qwen 或 Deepseek 14B 的 GPU。詳細模型/效能建議請參見 FAQ。</p><p><strong>設定本地供應者</strong>  </p><p>啟動您的本地供應者，例如用 ollama：
</code></pre>sh
ollama serve
<pre><code class="language-">
下方列出所有受支援的本地供應者。</p><p><strong>更新 config.ini</strong></p><p>修改 config.ini 檔案，將 provider_name 設為受支援的供應者，provider_model 設為該供應者支援的 LLM。我們推薦如 <em>Magistral</em> 或 <em>Deepseek</em> 等推理模型。</p><p>有關硬體需求請參見本文件結尾的 <strong>FAQ</strong>。
</code></pre>sh
[MAIN]
is_local = True # 無論是本地還是遠端運行
provider_name = ollama # 或 lm-studio、openai 等
provider_model = deepseek-r1:14b # 選擇適合您硬體的模型
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # 您的 AI 名稱
recover_last_session = True # 是否恢復上次工作階段
save_session = True # 是否記住目前工作階段
speak = False # 文字轉語音
listen = False # 語音轉文字，僅限 CLI，實驗性
jarvis_personality = False # 是否啟用更像 "Jarvis" 的個性（實驗性）
languages = en zh # 支援的語言列表，語音合成將預設第一個語言
[BROWSER]
headless_browser = True # 除非於主機 CLI 運行，否則保持不變
stealth_mode = True # 使用 undetected selenium 降低瀏覽器偵測
<pre><code class="language-">
<strong>注意：</strong></p><ul><li></code>config.ini<code> 檔案格式不支援註解。</li>
</ul>請勿直接複製貼上範例設定，註解將導致錯誤。請手動編輯 </code>config.ini<code>，移除所有註解後再保存。</p><ul><li>若使用 LM-studio 運行 LLM，請<em>勿</em>將 provider_name 設為 </code>openai<code>，而要設為 </code>lm-studio<code>。</li></p><p><li>某些供應者（如 lm-studio）要求 IP 前需加上 </code>http://<code>，例如：</code>http://127.0.0.1:1234<code></li></p><p></ul><strong>本地供應者列表</strong></p><p>| 供應者    | 本地？ | 說明                                                         |
|-----------|--------|-------------------------------------------------------------|
| ollama    | 是     | 使用 ollama 作為 LLM 供應者，本地輕鬆運行 LLM                |
| lm-studio | 是     | 使用 LM studio 本地運行 LLM（</code>provider_name<code> 設為 </code>lm-studio<code>）|
| openai    | 是     | 使用 openai 相容 API（如 llama.cpp server）                   |</p><p>下一步：<a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">啟動服務並運行 AgenticSeek</a>  </p><p><em>若有問題，請參閱 <a href="#troubleshooting" target="_blank" rel="noopener noreferrer">疑難排解</a> 小節。</em>
<em>若您的硬體無法本地運行 LLM，請參閱 <a href="#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API 運行設定</a>。</em>
<em>有關 </code>config.ini<code> 詳細說明，請見 <a href="#config" target="_blank" rel="noopener noreferrer">設定說明</a>。</em></p><h2>使用 API 運行的設定</h2></p><p>此方式採用外部雲端 LLM 供應者。您需從所選服務取得 API 金鑰。</p><p><strong>1. 選擇 API 供應者並取得 API 金鑰：</strong></p><p>請參閱下方 <a href="#list-of-api-providers" target="_blank" rel="noopener noreferrer">API 供應者列表</a>。造訪相關網站註冊並取得 API 金鑰。</p><p><strong>2. 將 API 金鑰設為環境變數：</strong></p><ul><li>  <strong>Linux/macOS：</strong></li>
    </ul>開啟終端機，使用 </code>export<code> 指令。建議將其加入 shell 的設定檔（如 </code>~/.bashrc<code>、</code>~/.zshrc<code>），以便永久生效。
    </code>`<code>sh
    export PROVIDER_API_KEY="your_api_key_here" 
    # 請將 PROVIDER_API_KEY 替換為具體變數名稱，如 OPENAI_API_KEY、GOOGLE_API_KEY
    </code>`<code>
    TogetherAI 範例：
    </code>`<code>sh
    export TOGETHER_API_KEY="xxxxxxxxxxxxxxxxxxxxxx"
    </code>`<code>
<ul><li>  <strong>Windows：</strong></li>
<li>  <strong>命令提示字元（僅限目前工作階段暫時設定）：</strong></li>
    </ul></code>`<code>cmd
    set PROVIDER_API_KEY=your_api_key_here
    </code>`<code>
<ul><li>  <strong>PowerShell（僅限目前工作階段暫時設定）：</strong></li>
    </ul></code>`<code>powershell
    $env:PROVIDER_API_KEY="your_api_key_here"
    </code>`<code>
<ul><li>  <strong>永久設定：</strong> 在 Windows 搜尋列輸入「環境變數」，點擊「編輯系統環境變數」，再點選「環境變數...」按鈕。新增一個使用者變數，名稱（例如 </code>OPENAI_API_KEY<code>）和你的金鑰作為值。</li></p><p></ul><em>（詳見常見問題：<a href="#how-do-i-set-api-keys" target="_blank" rel="noopener noreferrer">如何設定 API 金鑰？</a>）</em></p><p><strong>3. 更新 </code>config.ini<code>:</strong></code></pre>ini
[MAIN]
is_local = False
provider_name = openai # 或 google、deepseek、togetherAI、huggingface
provider_model = gpt-3.5-turbo # 或 gemini-1.5-flash、deepseek-chat、mistralai/Mixtral-8x7B-Instruct-v0.1 等
provider_server_address = # 當 is_local = False 時，通常可忽略或留白，適用於大多數 API
<h1>... 其他設定 ...</h1>
<pre><code class="language-"><em>警告：</em> 請確保 </code>config.ini<code> 的值末尾沒有空格。</p><p><strong>API 提供商列表</strong></p><p>| 提供商        | </code>provider_name<code>   | 本地？ | 說明                                               | API 金鑰連結（範例）                                |
|--------------|-------------------|--------|----------------------------------------------------|------------------------------------------------------|
| OpenAI       | </code>openai<code>          | 否     | 透過 OpenAI API 使用 ChatGPT 模型。                 | <a href="https://platform.openai.com/signup" target="_blank" rel="noopener noreferrer">platform.openai.com/signup</a> |
| Google Gemini| </code>google<code>          | 否     | 透過 Google AI Studio 使用 Google Gemini 模型。     | <a href="https://aistudio.google.com/keys" target="_blank" rel="noopener noreferrer">aistudio.google.com/keys</a>     |
| Deepseek     | </code>deepseek<code>        | 否     | 透過他們的 API 使用 Deepseek 模型。                 | <a href="https://platform.deepseek.com" target="_blank" rel="noopener noreferrer">platform.deepseek.com</a>           |
| Hugging Face | </code>huggingface<code>     | 否     | 透過 Hugging Face Inference API 使用模型。          | <a href="https://huggingface.co/settings/tokens" target="_blank" rel="noopener noreferrer">huggingface.co/settings/tokens</a> |
| TogetherAI   | </code>togetherAI<code>      | 否     | 透過 TogetherAI API 使用多種開源模型。              | <a href="https://api.together.ai/settings/api-keys" target="_blank" rel="noopener noreferrer">api.together.ai/settings/api-keys</a> |</p><p><em>注意：</em>
<ul><li>  建議不要在複雜的網頁瀏覽和任務規劃中使用 </code>gpt-4o<code> 或其他 OpenAI 模型，目前提示詞最佳化主要針對 Deepseek 等模型。</li>
<li>  使用 Gemini 進行程式碼/bash 任務可能會遇到問題，因為其格式化回應不一定嚴格遵循針對 Deepseek 最佳化的提示。</li>
<li>  當 </code>is_local = False<code> 時，</code>config.ini<code> 的 </code>provider_server_address<code> 一般不需要設定，API 端點通常已在各自的提供商函式庫中硬編碼。</li></p><p></ul>下一步：<a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">啟動服務並運行 AgenticSeek</a></p><p><em>如果遇到問題，請參閱 <strong>已知問題</strong> 章節</em></p><p><em>完整的設定檔說明，請參閱 <strong>Config</strong> 章節。</em></p><hr></p><h2>啟動服務並運行</h2></p><p>預設情況下，AgenticSeek 完全在 docker 中運行。</p><p>啟動所需服務。這會從 docker-compose.yml 啟動所有服務，包括：
    <ul><li>searxng</li>
    <li>redis（searxng 所需）</li>
    <li>frontend</li>
    <li>backend（若使用 </code>full<code>）</li>
</ul></code></pre>sh
./start_services.sh full # MacOS
start ./start_services.cmd full # Window
<pre><code class="language-">
<strong>警告：</strong> 此步驟將下載並載入所有 Docker 映像檔，可能需要高達 30 分鐘。啟動服務後，請等到 backend 服務完全運行（你應該會在日誌中看到 <strong>backend: "GET /health HTTP/1.1" 200 OK</strong>）再發送任何訊息。backend 服務初次啟動可能需要 5 分鐘。</p><p>打開 </code>http://localhost:3000/<code>，你應該會看到網頁介面。</p><p><em>服務啟動故障排除：</em> 如果這些腳本執行失敗，請確保 Docker Engine 已啟動，且 Docker Compose（V2，</code>docker compose<code>）已正確安裝。請檢查終端機輸出以獲取錯誤訊息。詳見 <a href="#faq-troubleshooting" target="_blank" rel="noopener noreferrer">常見問題：執行 AgenticSeek 或其腳本時出錯怎麼辦？</a></p><p><strong>可選：</strong> 在主機運行（CLI 模式）：</p><p>若要使用 CLI 介面，必須在主機安裝套件：
</code></pre>sh
./install.sh
./install.bat # windows
<pre><code class="language-">
啟動服務：
</code></pre>sh
./start_services.sh # MacOS
start ./start_services.cmd # Window
<pre><code class="language-">
使用 CLI：</code>python3 cli.py<code></p><hr></p><h2>使用方式</h2></p><p>請確保服務已經使用 </code>./start_services.sh full<code> 啟動，並前往 </code>localhost:3000<code> 使用網頁介面。</p><p>你也可以在設定檔中將 </code>listen = True<code> 來啟用語音轉文字（僅 CLI 模式）。</p><p>要離開，只需說/輸入 </code>goodbye<code>。</p><p>以下是一些使用範例：</p><blockquote><em>用 python 做一個貪食蛇遊戲！</em></blockquote></p><blockquote><em>搜尋網路上法國雷恩（Rennes）最棒的咖啡館，並將三家含地址保存於 rennes_cafes.txt。</em></blockquote></p><blockquote><em>寫一個 Go 程式來計算一個數的階乘，並儲存為 factorial.go 於你的工作目錄</em></blockquote></p><blockquote><em>搜尋我的 summer_pictures 資料夾內所有 JPG 檔案，將它們以今天日期重新命名，並將重新命名的檔案列表儲存於 photos_list.txt</em></blockquote></p><blockquote><em>線上搜尋 2024 年熱門科幻電影，挑三部今晚要看。將片單儲存於 movie_night.txt。</em></blockquote></p><blockquote><em>搜尋 2025 年最新 AI 新聞文章，選三篇，寫一個 Python 程式抓取其標題與摘要。將程式碼保存為 news_scraper.py，摘要存於 /home/projects 的 ai_news.txt</em></blockquote></p><blockquote><em>週五，搜尋網路免費股票價格 API，使用 supersuper7434567@gmail.com 註冊，再寫一支 Python 腳本每天用 API 取得特斯拉股價，結果存於 stock_prices.csv</em></blockquote></p><p><em>請注意，表單自動填寫功能仍屬實驗性，可能會失敗。</em></p><p>當你輸入查詢後，AgenticSeek 會分配最佳代理來執行該任務。</p><p>由於這是早期原型，代理分流系統根據查詢分配的代理可能不是最合適的。</p><p>因此，請儘量明確說明你要做什麼，以及 AI 應該如何操作。例如，如果你想讓它進行網路搜尋，請不要這樣說：</p><p></code>你知道哪些國家適合單獨旅行嗎？<code></p><p>而要這樣問：</p><p></code>請搜尋網路並找出最適合單獨旅行的國家<code></p><hr></p><h2><strong>設定在自己的伺服器上運行 LLM</strong>  </h2></p><p>如果你有一台強大的電腦或伺服器想要運行模型，但又想從筆電遠端使用，你可以透過自訂的 llm server 在遠端伺服器運行 LLM。</p><p>在將要運行 AI 模型的「伺服器」上，獲取 IP 位址
</code></pre>sh
ip a | grep "inet " | grep -v 127.0.0.1 | awk '{print $2}' | cut -d/ -f1 # 本機 ip
curl https://ipinfo.io/ip # 公網 ip
<pre><code class="language-">
注意：Windows 或 macOS 請分別使用 ipconfig 或 ifconfig 查詢 IP 位址。</p><p>複製專案並進入 </code>server/<code> 資料夾。
</code></pre>sh
git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
<pre><code class="language-">
安裝伺服器專用套件：
</code></pre>sh
pip3 install -r requirements.txt
<pre><code class="language-">
執行伺服器腳本。
</code></pre>sh
python3 app.py --provider ollama --port 3333
<pre><code class="language-">
你可以選擇使用 </code>ollama<code> 或 </code>llamacpp<code> 作為 LLM 服務。</p><p>現在在你的個人電腦上：</p><p>修改 </code>config.ini<code> 檔案，將 </code>provider_name<code> 設為 </code>server<code>，</code>provider_model<code> 設為 </code>deepseek-r1:xxb<code>。
把 </code>provider_server_address<code> 設成運行模型機器的 IP 位址。
</code></pre>sh
[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = x.x.x.x:3333
<pre><code class="language-">
下一步：<a href="#Start-services-and-Run" target="_blank" rel="noopener noreferrer">啟動服務並運行 AgenticSeek</a></p><hr></p><h2>語音轉文字</h2></p><p>警告：目前語音轉文字僅支援 CLI 模式。</p><p>請注意，目前語音轉文字僅支援英文。</p><p>語音轉文字功能預設為關閉。若要啟用，請在 config.ini 檔案中將 listen 選項設為 True：
</code></pre>
listen = True
<pre><code class="language-">
啟用後，語音轉文字會在你說出觸發關鍵字（即代理名稱）後開始接收輸入。你可以在 <em>config.ini</em> 檔案中修改 </code>agent_name<code> 來自訂代理名稱：
</code></pre>
agent_name = Friday
<pre><code class="language-">
為了最佳辨識效果，我們建議使用常見的英文名字作為 agent 名稱，例如 "John" 或 "Emma"</p><p>當你看到逐字稿開始出現時，請大聲說出 agent 的名字來喚醒它（例如："Friday"）。</p><p>清楚地說出你的查詢內容。</p><p>請在請求結尾使用確認語句，讓系統知道可以繼續執行。確認語句的範例包括：</code></pre>
"do it", "go ahead", "execute", "run", "start", "thanks", "would ya", "please", "okay?", "proceed", "continue", "go on", "do that", "go it", "do you understand?"
<pre><code class="language-">
<h2>設定檔 Config</h2></p><p>設定範例：</code></pre>
[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # Ollama 範例；LM-Studio 請用 http://127.0.0.1:1234
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False</p><p>jarvis_personality = False
languages = en zh # TTS 及路由語言清單
[BROWSER]
headless_browser = False
stealth_mode = False
<pre><code class="language-">
<strong></code>config.ini<code> 設定說明</strong>：</p><ul><li>  <strong></code>[MAIN]<code> 區段:</strong></li>
    <li>  </code>is_local<code>：如果使用本地 LLM 供應商（Ollama、LM-Studio、本地 OpenAI 相容伺服器）或自架伺服器，請設為 </code>True<code>。若使用雲端 API（OpenAI、Google 等）請設為 </code>False<code>。</li>
    <li>  </code>provider_name<code>：指定 LLM 供應商名稱。</li>
        <li>  本地選項：</code>ollama<code>、</code>lm-studio<code>、</code>openai<code>（本地 OpenAI 相容伺服器）、</code>server<code>（自架伺服器）。</li>
        <li>  API 選項：</code>openai<code>、</code>google<code>、</code>deepseek<code>、</code>huggingface<code>、</code>togetherAI<code>。</li>
    <li>  </code>provider_model<code>：所選供應商的具體模型名稱或 ID（如 Ollama 的 </code>deepseekcoder:6.7b<code>，OpenAI API 的 </code>gpt-3.5-turbo<code>，TogetherAI 的 </code>mistralai/Mixtral-8x7B-Instruct-v0.1<code>）。</li>
    <li>  </code>provider_server_address<code>：LLM 供應商伺服器位址。</li>
        <li>  本地供應商範例：Ollama 請用 </code>http://127.0.0.1:11434<code>，LM-Studio 請用 </code>http://127.0.0.1:1234<code>。</li>
        <li>  </code>server<code> 類型：填寫自架 LLM 伺服器地址（如 </code>http://your_server_ip:3333<code>）。</li>
        <li>  雲端 API（</code>is_local = False<code>）：此欄多半可忽略，API 端點通常由客戶端處理。</li>
    <li>  </code>agent_name<code>：AI 助手名稱（如 Friday）。啟用語音辨識時用作觸發詞。</li>
    <li>  </code>recover_last_session<code>：設為 </code>True<code> 則嘗試回復前次狀態，</code>False<code> 則重新開始。</li>
    <li>  </code>save_session<code>：設為 </code>True<code> 則儲存目前會話以便回復，否則為 </code>False<code>。</li>
    <li>  </code>speak<code>：設為 </code>True<code> 開啟文字轉語音輸出，否則關閉。</li>
    <li>  </code>listen<code>：設為 </code>True<code> 開啟語音辨識輸入（僅限 CLI 模式），否則關閉。</li>
    <li>  </code>work_dir<code>：<strong>重要：</strong> AgenticSeek 讀寫檔案的目錄。<strong>請確保此路徑在你的系統上有效且可存取。</strong></li>
    <li>  </code>jarvis_personality<code>：</code>True<code> 使用更像 Jarvis 的提示詞（實驗性），</code>False<code> 則為標準提示。</li>
    <li>  </code>languages<code>：逗號分隔的語言清單（如 </code>en, zh, fr<code>）。TTS 語音選擇（預設第一個），也可協助 LLM 路由。路由效率建議避免太多或太相似語言。</li>
<li>  <strong></code>[BROWSER]<code> 區段:</strong></li>
    <li>  </code>headless_browser<code>：設為 </code>True<code> 則無視窗運行自動化瀏覽器（推薦於網頁介面或非互動用途）。</code>False<code> 則顯示瀏覽器視窗（適用於 CLI 模式或除錯）。</li>
    <li>  </code>stealth_mode<code>：</code>True<code> 啟用反偵測瀏覽器自動化，可能需手動安裝如 anticaptcha 等瀏覽器擴充套件。</li></p><p></ul>本段落總結支援的 LLM 供應商類型。請於 </code>config.ini<code> 設定。</p><p><strong>本地供應商（在你自己的硬體執行）：</strong></p><p>| </code>config.ini<code> 供應商名稱       | </code>is_local<code> | 說明                                                                   | 相關設定章節                                                                    |
|-------------------------------|------------|------------------------------------------------------------------------|--------------------------------------------------------------------------------|
| </code>ollama<code>                      | </code>True<code>     | 使用 Ollama 服務本地 LLM。                                             | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">本地執行 LLM 設定</a> |
| </code>lm-studio<code>                   | </code>True<code>     | 使用 LM-Studio 服務本地 LLM。                                          | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">本地執行 LLM 設定</a> |
| </code>openai<code>（本地伺服器）        | </code>True<code>     | 連接本地 OpenAI 相容 API 伺服器（如 llama.cpp）。                      | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-for-running-llm-locally-on-your-machine" target="_blank" rel="noopener noreferrer">本地執行 LLM 設定</a> |
| </code>server<code>                      | </code>False<code>    | 連接運行於其他主機的 AgenticSeek 自架 LLM 伺服器。                     | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-the-llm-on-your-own-server" target="_blank" rel="noopener noreferrer">自架伺服器 LLM 設定</a> |</p><p><strong>API 供應商（雲端）：</strong></p><p>| </code>config.ini<code> 供應商名稱       | </code>is_local<code> | 說明                                            | 相關設定章節                                                                |
|-------------------------------|------------|-------------------------------------------------|----------------------------------------------------------------------------|
| </code>openai<code>                      | </code>False<code>    | 使用 OpenAI 官方 API（如 GPT-3.5、GPT-4）。      | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API 運行設定</a> |
| </code>google<code>                      | </code>False<code>    | 使用 Google 的 Gemini 模型 API。                | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API 運行設定</a> |
| </code>deepseek<code>                    | </code>False<code>    | 使用 Deepseek 官方 API。                        | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API 運行設定</a> |
| </code>huggingface<code>                 | </code>False<code>    | 使用 Hugging Face 推論 API。                    | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API 運行設定</a> |
| </code>togetherAI<code>                  | </code>False<code>    | 使用 TogetherAI API 支援多種開放模型。           | <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#setup-to-run-with-an-api" target="_blank" rel="noopener noreferrer">API 運行設定</a> |</p><hr>
<h2>疑難排解</h2></p><p>如遇問題請參考本節說明。</p><h1>已知問題</h1></p><h2>ChromeDriver 問題</h2></p><p><strong>錯誤範例：</strong> </code>SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version XXX<code></p><ul><li>  <strong>原因：</strong> 你安裝的 ChromeDriver 版本與 Google Chrome 瀏覽器版本不相容。</li>
<li>  <strong>解決方式：</strong></li>
    <li> <strong>檢查 Chrome 版本：</strong> 開啟 Google Chrome，至 </code>設定 > 關於 Chrome<code> 查詢版本（如 "版本 120.0.6099.110"）。</li>
    <li> <strong>下載對應的 ChromeDriver：</strong></li>
        <li>  Chrome 115 版以上：至 <a href="https://googlechromelabs.github.io/chrome-for-testing/" target="_blank" rel="noopener noreferrer">Chrome for Testing (CfT) JSON Endpoints</a> 查詢 "stable" 頻道，下載對應你作業系統與 Chrome 主版本的 ChromeDriver。</li>
        <li>  舊版（較少見）：可至 <a href="https://chromedriver.chromium.org/downloads" target="_blank" rel="noopener noreferrer">ChromeDriver - WebDriver for Chrome</a> 尋找。</li>
        <li>  下圖為 CfT 頁面範例：</li>
            </ul><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="從 Chrome for Testing 頁面下載指定版本 Chromedriver">
    <ul><li> <strong>安裝 ChromeDriver：</strong></li>
        <li>  請將下載的 </code>chromedriver<code>（Windows 為 </code>chromedriver.exe<code>）放到系統 PATH 目錄（如 Linux/macOS 的 </code>/usr/local/bin<code>，或 Windows 的自訂腳本資料夾）。</li>
        <li>  或直接放在 </code>agenticSeek<code> 專案根目錄。</li>
        <li>  確保驅動程式具有執行權限（如 Linux/macOS 執行 </code>chmod +x chromedriver<code>）。</li>
    <li> 詳細請參考主安裝指南內 <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/#chromedriver-installation" target="_blank" rel="noopener noreferrer">ChromeDriver 安裝說明</a>。</li></p><p></ul>若本節說明不足或遇到其他 ChromeDriver 問題，請搜尋 <a href="https://github.com/Fosowl/agenticSeek/issues" target="_blank" rel="noopener noreferrer">GitHub Issues</a> 或提出新問題。</p><p></code>Exception: Failed to initialize browser: Message: session not created: This version of ChromeDriver only supports Chrome version 113
Current browser version is 134.0.6998.89 with binary path<code></p><p>當你的瀏覽器與 chromedriver 版本不符時會發生此錯誤。</p><p>你需要前往下載最新版本：</p><p>https://developer.chrome.com/docs/chromedriver/downloads</p><p>若你使用 Chrome 115 以上，請前往：</p><p>https://googlechromelabs.github.io/chrome-for-testing/</p><p>下載與你作業系統相符的 chromedriver 版本。</p><p><img src="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/media/chromedriver_readme.png" alt="alt text"></p><p>如本節說明不足請提出 issue。</p><h2> connection adapters 問題</h2>
</code></pre>
Exception: Provider lm-studio failed: HTTP request failed: No connection adapters were found for '127.0.0.1:1234/v1/chat/completions'</code> (注意：port 可能不同)
<pre><code class="language-">
<ul><li>  <strong>原因：</strong> <code>config.ini</code> 內 <code>lm-studio</code>（或其他本地 OpenAI 相容伺服器）的 <code>provider_server_address</code> 缺少 <code>http://</code> 前綴或連到錯誤的埠號。</li>
<li>  <strong>解決方式：</strong></li>
    <li>  請確保地址包含 <code>http://</code>。LM-Studio 預設為 <code>http://127.0.0.1:1234</code>。</li>
    <li>  正確設定 <code>config.ini</code>：<code>provider_server_address = http://127.0.0.1:1234</code>（或你的實際伺服器埠號）。</li></p><p></ul><h2>未提供 SearxNG Base URL</h2>
</code></pre>
raise ValueError("SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.")
ValueError: SearxNG base URL must be provided either as an argument or via the SEARXNG_BASE_URL environment variable.<code>
</code>`<code></p><h2>常見問題 FAQ</h2></p><p><strong>Q: 我需要什麼硬體？</strong>  </p><p>| 模型大小   | GPU          | 說明                                               |
|-----------|--------------|----------------------------------------------------|
| 7B        | 8GB Vram     | ⚠️ 不建議。效能不佳，易產生幻覺，規劃型 agent 可能失敗。|
| 14B       | 12GB Vram (如 RTX 3060) | ✅ 簡單任務可用。瀏覽網頁與規劃可能吃力。          |
| 32B       | 24GB 以上 Vram (如 RTX 4090) | 🚀 大多數任務可成功，規劃型任務仍有挑戰。       |
| 70B+      | 48GB 以上 Vram | 💪 極佳。推薦進階使用情境。                         |</p><p><strong>Q: 出現錯誤怎麼辦？</strong>  </p><p>請確認本地服務（</code>ollama serve<code>）正常，</code>config.ini` 與供應商相符，且相關依賴已安裝。如皆無效歡迎提出 issue。</p><p><strong>Q: 能否 100% 本地執行？</strong>  </p><p>可以，使用 Ollama、lm-studio 或 server 供應商時，語音辨識、LLM、文字轉語音皆於本地運行。非本地（OpenAI 等 API）選項為可選。</p><p><strong>Q: 已有 Manus，為什麼還要用 AgenticSeek？</strong></p><p>AgenticSeek 強調對外部系統的獨立性，讓你有更多控制權、隱私保障且避免 API 成本。</p><p><strong>Q: 專案是由誰維護？</strong></p><p>專案由我本人與兩位在 GitHub 開源社群活躍的朋友共同維護。我們只是熱愛開發的個人，並非新創公司或組織成員。</p><p>除了我的個人帳號（https://x.com/Martin993886460）以外，任何 AgenticSeek 在 X 上的帳戶皆為冒名。</p><h2>貢獻</h2></p><p>我們歡迎開發者參與改進 AgenticSeek！請參考 open issues 或討論區。</p><p><a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/docs/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer">貢獻指南</a></p><p><a href="https://www.star-history.com/#Fosowl/agenticSeek&Date" target="_blank" rel="noopener noreferrer"><img src="https://api.star-history.com/svg?repos=Fosowl/agenticSeek&type=Date" alt="Star History Chart"></a></p><h2>維護者：</h2></p><p> > <a href="https://github.com/Fosowl" target="_blank" rel="noopener noreferrer">Fosowl</a> | 巴黎時間 </p><p> > <a href="https://github.com/antoineVIVIES" target="_blank" rel="noopener noreferrer">antoineVIVIES</a> | 台北時間 </p><p> > <a href="https://github.com/steveh8758" target="_blank" rel="noopener noreferrer">steveh8758</a> | 台北時間 </p><h2>特別感謝：</h2></p><p> > <a href="https://github.com/tcsenpai" target="_blank" rel="noopener noreferrer">tcsenpai</a> 和 <a href="https://github.com/plitc" target="_blank" rel="noopener noreferrer">plitc</a> 協助後端 Docker 化</p><h2>贊助者：</h2></p><p>每月贊助 5 美元或以上會顯示於此：
<ul><li><strong>tatra-labs</strong></li></p><p></ul>Sorry, but I need the content of Part 4 of 4 in order to translate it. Please provide the text you want translated.

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-06-16

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Fosowl/agenticSeek/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>