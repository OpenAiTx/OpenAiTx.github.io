<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch-accelerated - Una libreria leggera progettata per accelerare il processo di addestramento dei modelli PyTorch, offrendo un ciclo di training minimale ma estensibile, abbastanza flessibile da gestire la maggior parte dei casi d’uso e capace di sfruttare diverse opzioni hardware senza richiedere modifiche al codice. Documentazione: https://pytorch-accelerated.readthedocs.io/en/latest/</title>
    <meta name="description" content="Una libreria leggera progettata per accelerare il processo di addestramento dei modelli PyTorch, offrendo un ciclo di training minimale ma estensibile, abbastanza flessibile da gestire la maggior parte dei casi d’uso e capace di sfruttare diverse opzioni hardware senza richiedere modifiche al codice. Documentazione: https://pytorch-accelerated.readthedocs.io/en/latest/">
    <meta name="keywords" content="pytorch-accelerated, Italian, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "pytorch-accelerated",
  "description": "Una libreria leggera progettata per accelerare il processo di addestramento dei modelli PyTorch, offrendo un ciclo di training minimale ma estensibile, abbastanza flessibile da gestire la maggior parte dei casi d’uso e capace di sfruttare diverse opzioni hardware senza richiedere modifiche al codice. Documentazione: https://pytorch-accelerated.readthedocs.io/en/latest/",
  "author": {
    "@type": "Person",
    "name": "Chris-hughes10"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 193
  },
  "url": "https://OpenAiTx.github.io/projects/Chris-hughes10/pytorch-accelerated/README-it.html",
  "sameAs": "https://raw.githubusercontent.com/Chris-hughes10/pytorch-accelerated/main/README.md",
  "datePublished": "2026-02-28",
  "dateModified": "2026-02-28"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/Chris-hughes10/pytorch-accelerated" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    pytorch-accelerated
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 193 stars</span>
                <span class="language">Italian</span>
                <span>by Chris-hughes10</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Lingua</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=en">English</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ja">日本語</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ko">한국어</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=hi">हिन्दी</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=th">ไทย</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=fr">Français</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=de">Deutsch</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=es">Español</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=it">Italiano</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ru">Русский</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=pt">Português</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=pl">Polski</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ar">العربية</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=fa">فارسی</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=tr">Türkçe</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=vi">Tiếng Việt</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=id">Bahasa Indonesia</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=as">অসমীয়া</
      </div>
    </div>
  </details>
</div></p><h1>pytorch-accelerated</h1></p><p><code>pytorch-accelerated</code> è una libreria leggera progettata per accelerare il processo di addestramento dei modelli PyTorch
 fornendo un ciclo di addestramento minimale ma estensibile - racchiuso in un unico oggetto <code>Trainer</code> -
che è sufficientemente flessibile per gestire la maggior parte dei casi d'uso, e in grado di sfruttare diverse opzioni hardware
 senza necessità di modifiche al codice.
 
<code>pytorch-accelerated</code> offre un set di funzionalità essenziale e pone grande enfasi su <strong>semplicità</strong> e <strong>trasparenza</strong>,
per consentire agli utenti di capire esattamente cosa sta succedendo sotto il cofano, ma senza dover scrivere e mantenere loro stessi il boilerplate!
   
Le caratteristiche principali sono:
<ul><li>Un ciclo di addestramento semplice e contenuto, ma facilmente personalizzabile, che dovrebbe funzionare subito nei casi più semplici;</li>
 </ul>il comportamento può essere personalizzato tramite ereditarietà e/o callback.
<ul><li>Gestisce il posizionamento dei dispositivi, la mixed-precision, l'integrazione DeepSpeed, il training multi-GPU e distribuito senza modifiche al codice.</li>
<li>Utilizza componenti PyTorch puri, senza modifiche o wrapper aggiuntivi, e si integra facilmente</li>
 </ul>con altre librerie popolari come <a href="https://github.com/rwightman/pytorch-image-models" target="_blank" rel="noopener noreferrer">timm</a>,
 <a href="https://huggingface.co/transformers/" target="_blank" rel="noopener noreferrer">transformers</a> e <a href="https://torchmetrics.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">torchmetrics</a>.
<ul><li>Una piccola e snella API assicura una curva di apprendimento minima per gli utenti PyTorch già esistenti.</li></p><p></ul>È stato fatto un grande sforzo per garantire che ogni parte della libreria - sia i componenti interni che quelli esterni - sia il più chiara e semplice possibile,
rendendo facile la personalizzazione, il debug e la comprensione di ciò che accade dietro le quinte ad ogni passo; la maggior parte del
comportamento del trainer è contenuto in una singola classe!
Nello spirito di Python, nulla è nascosto e tutto è accessibile.</p><p><code>pytorch-accelerated</code> è orgogliosamente e trasparentemente costruito sopra
<a href="https://github.com/huggingface/accelerate" target="_blank" rel="noopener noreferrer">Hugging Face Accelerate</a>, che si occupa
dello spostamento dei dati tra i dispositivi e dell'avvio delle configurazioni di addestramento. Quando si personalizza il trainer o si avvia
l'addestramento, si consiglia agli utenti di consultare la <a href="https://huggingface.co/docs/accelerate/" target="_blank" rel="noopener noreferrer">documentazione di Accelerate</a>
per comprendere tutte le opzioni disponibili; Accelerate fornisce funzioni comode per operazioni come il raggruppamento dei tensori
e il clipping dei gradienti, il cui utilizzo può essere visto nella cartella <code>pytorch-accelerated</code>
<a href="https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples" target="_blank" rel="noopener noreferrer">esempi</a>!</p><p>Per saperne di più sulle motivazioni che stanno dietro questa libreria, insieme a una guida dettagliata per iniziare, dai un'occhiata a <a href="https://medium.com/@chris.p.hughes10/introducing-pytorch-accelerated-6ba99530608c?source=friends_link&sk=868c2d2ec5229fdea42877c0bf82b968" target="_blank" rel="noopener noreferrer">questo post sul blog</a>.</p><h2>Installazione</h2></p><p><code>pytorch-accelerated</code> può essere installato tramite pip usando il seguente comando:
<pre><code class="language-">pip install pytorch-accelerated</code></pre></p><p>Per rendere il pacchetto il più snello possibile, i pacchetti necessari per eseguire gli esempi non sono inclusi di default. Per includere questi pacchetti, puoi usare il seguente comando:
<pre><code class="language-">pip install pytorch-accelerated[examples]</code></pre></p><h2>Guida rapida</h2></p><p>Per iniziare, importa e utilizza semplicemente il <code>Trainer</code> di pytorch-accelerated, come mostrato nel seguente esempio,
e poi avvia l’addestramento utilizzando la 
<a href="https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script" target="_blank" rel="noopener noreferrer">accelerate CLI</a>
descritta di seguito.</p><pre><code class="language-python"># examples/core/train_mnist.py
import os</p><p>from torch import nn, optim
from torch.utils.data import random_split
from torchvision import transforms
from torchvision.datasets import MNIST</p><p>from pytorch_accelerated import Trainer</p><p>class MNISTModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.main = nn.Sequential(
            nn.Linear(in_features=784, out_features=128),
            nn.ReLU(),
            nn.Linear(in_features=128, out_features=64),
            nn.ReLU(),
            nn.Linear(in_features=64, out_features=10),
        )</p><p>    def forward(self, input):
        return self.main(input.view(input.shape[0], -1))</p><p>def main():
    dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())
    train_dataset, validation_dataset, test_dataset = random_split(dataset, [50000, 5000, 5000])
    model = MNISTModel()
    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
    loss_func = nn.CrossEntropyLoss()</p><p>    trainer = Trainer(
            model,
            loss_func=loss_func,
            optimizer=optimizer,
    )</p><p>    trainer.train(
        train_dataset=train_dataset,
        eval_dataset=validation_dataset,
        num_epochs=8,
        per_device_batch_size=32,
    )</p><p>    trainer.evaluate(
        dataset=test_dataset,
        per_device_batch_size=64,
    )
    
if __name__ == "__main__":
    main()</code></pre>
Per avviare l'addestramento utilizzando la <a href="https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script" target="_blank" rel="noopener noreferrer">accelerate CLI</a>
, sulla/le tua/e macchina/e, esegui:</p><p><code> accelerate config --config_file accelerate_config.yaml</code></p><p>e rispondi alle domande poste. Questo genererà un file di configurazione che verrà utilizzato per impostare correttamente le opzioni predefinite durante</p><p><code>accelerate launch --config_file accelerate_config.yaml train.py [--training-args]</code></p><p><em>Nota</em>: L'utilizzo della <a href="https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script" target="_blank" rel="noopener noreferrer">accelerate CLI</a> è completamente opzionale, l'addestramento può anche essere avviato nel modo consueto usando:</p><p><code>python train.py</code> / <code>python -m torch.distributed ...</code></p><p>a seconda della configurazione della tua infrastruttura, per utenti che desiderano mantenere un controllo più dettagliato 
sul comando di avvio.</p><p>Esempi di addestramento più complessi possono essere visti nella cartella degli esempi 
<a href="https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples" target="_blank" rel="noopener noreferrer">qui</a>. </p><p>In alternativa, se preferisci prima comprendere i concetti fondamentali, questi si trovano nella <a href="https://pytorch-accelerated.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">documentazione</a>.</p><h2>Utilizzo</h2></p><h3>A chi è rivolto pytorch-accelerated?</h3></p><ul><li>Utenti che hanno familiarità con PyTorch ma vorrebbero evitare di scrivere il boilerplate del ciclo di addestramento comune</li>
</ul>per concentrarsi sulle parti interessanti del ciclo di training.
<ul><li>Utenti che apprezzano, e sono a loro agio, nel selezionare e creare i propri modelli, funzioni di perdita, ottimizzatori e dataset.</li>
<li>Utenti che valorizzano un set di funzionalità semplice e snello, dove il comportamento è facile da debug, comprendere e motivare!</li></p><p></ul><h3>Quando non dovrei usare pytorch-accelerated?</h3></p><ul><li>Se stai cercando una soluzione end-to-end, che comprenda tutto dal caricamento dati all'inferenza,</li>
  </ul>che ti aiuti a selezionare un modello, ottimizzatore o funzione di perdita, probabilmente sarai più adatto a
  <a href="https://github.com/fastai/fastai" target="_blank" rel="noopener noreferrer">fastai</a>. <code>pytorch-accelerated</code> si concentra solo sul processo di addestramento, con tutte le altre
  problematiche lasciate alla responsabilità dell'utente.
<ul><li>Se vorresti scrivere l'intero ciclo di addestramento tu stesso, solo senza tutte le difficoltà di gestione dei dispositivi, </li>
</ul>probabilmente ti troverai meglio usando direttamente <a href="https://github.com/huggingface/accelerate" target="_blank" rel="noopener noreferrer">Accelerate</a>! Anche se
è possibile personalizzare ogni parte del <code>Trainer</code>, il ciclo di addestramento è fondamentalmente suddiviso in numerose</p><p>diversi metodi che dovresti sovrascrivere. Ma, prima di andare, scrivere quei cicli <code>for</code> è davvero così importante 
da giustificare il ricominciare <em>da capo</em> un'altra volta 😉.
<ul><li>Se stai lavorando su un caso d'uso personalizzato, altamente complesso, che non si adatta agli schemi dei soliti cicli di addestramento</li>
</ul>e vuoi ottenere ogni minimo incremento di performance sull'hardware scelto, probabilmente la soluzione migliore è restare
 con il PyTorch “vanilla”; qualsiasi API ad alto livello diventa un sovraccarico in casi altamente specializzati!</p><h2>Ringraziamenti</h2></p><p>Molti aspetti del design e delle funzionalità di <code>pytorch-accelerated</code> sono stati fortemente ispirati da numerose eccellenti 
librerie e framework come <a href="https://github.com/fastai/fastai" target="_blank" rel="noopener noreferrer">fastai</a>, <a href="https://github.com/rwightman/pytorch-image-models" target="_blank" rel="noopener noreferrer">timm</a>, 
<a href="https://github.com/PyTorchLightning/pytorch-lightning" target="_blank" rel="noopener noreferrer">PyTorch-lightning</a> e <a href="https://github.com/huggingface/accelerate" target="_blank" rel="noopener noreferrer">Hugging Face Accelerate</a>. Ognuno di questi strumenti 
ha avuto un impatto enorme sia su questa libreria che sulla comunità del machine learning, e la loro influenza non può essere 
sottolineata abbastanza!</p><p><code>pytorch-accelerated</code> ha preso solo ispirazione da questi strumenti, e tutte le funzionalità incluse sono state implementate
 da zero in modo da avvantaggiare questa libreria. Le uniche eccezioni sono alcuni degli script nella cartella 
 <a href="https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples" target="_blank" rel="noopener noreferrer">examples</a>
 in cui sono state prese e modificate risorse esistenti per mostrare le funzionalità di <code>pytorch-accelerated</code>;
 questi casi sono chiaramente segnalati, con riconoscimento dato agli autori originali.
 </p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-02-28

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Chris-hughes10/pytorch-accelerated/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-02-28 
    </div>
    
</body>
</html>