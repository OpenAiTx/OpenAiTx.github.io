<!DOCTYPE html>
<html lang="nl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch-accelerated - Een lichte bibliotheek ontworpen om het trainen van PyTorch-modellen te versnellen door een minimale, maar uitbreidbare trainingslus te bieden die flexibel genoeg is voor de meeste toepassingen en verschillende hardware-opties kan benutten zonder dat codewijzigingen nodig zijn. Documentatie: https://pytorch-accelerated.readthedocs.io/en/latest/</title>
    <meta name="description" content="Een lichte bibliotheek ontworpen om het trainen van PyTorch-modellen te versnellen door een minimale, maar uitbreidbare trainingslus te bieden die flexibel genoeg is voor de meeste toepassingen en verschillende hardware-opties kan benutten zonder dat codewijzigingen nodig zijn. Documentatie: https://pytorch-accelerated.readthedocs.io/en/latest/">
    <meta name="keywords" content="pytorch-accelerated, Dutch, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "pytorch-accelerated",
  "description": "Een lichte bibliotheek ontworpen om het trainen van PyTorch-modellen te versnellen door een minimale, maar uitbreidbare trainingslus te bieden die flexibel genoeg is voor de meeste toepassingen en verschillende hardware-opties kan benutten zonder dat codewijzigingen nodig zijn. Documentatie: https://pytorch-accelerated.readthedocs.io/en/latest/",
  "author": {
    "@type": "Person",
    "name": "Chris-hughes10"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 193
  },
  "url": "https://OpenAiTx.github.io/projects/Chris-hughes10/pytorch-accelerated/README-nl.html",
  "sameAs": "https://raw.githubusercontent.com/Chris-hughes10/pytorch-accelerated/main/README.md",
  "datePublished": "2026-02-28",
  "dateModified": "2026-02-28"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/Chris-hughes10/pytorch-accelerated" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    pytorch-accelerated
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 193 stars</span>
                <span class="language">Dutch</span>
                <span>by Chris-hughes10</span>
            </div>
        </div>
        
        <div class="content">
            <p>
<div align="right">
  <details>
    <summary >🌐 Taal</summary>
    <div>
      <div align="center">
        <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=en">Engels</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=zh-CN">简体中文</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=zh-TW">繁體中文</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ja">Japans</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ko">Koreaans</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=hi">Hindi</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=th">Thais</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=fr">Frans</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=de">Duits</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=es">Spaans</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=it">Italiaans</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ru">Russisch</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=pt">Portugees</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=nl">Nederlands</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=pl">Pools</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=ar">Arabisch</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=fa">Perzisch</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=tr">Turks</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=vi">Vietnamees</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=id">Indonesisch</a>
        | <a href="https://openaitx.github.io/view.html?user=Chris-hughes10&project=pytorch-accelerated&lang=as">অসমীয়া</
      </div>
    </div>
  </details>
</div></p><h1>pytorch-accelerated</h1></p><p><code>pytorch-accelerated</code> is een lichte bibliotheek ontworpen om het trainen van PyTorch-modellen te versnellen
 door een minimale, maar uitbreidbare trainingslus te bieden - verpakt in één <code>Trainer</code>
object - die flexibel genoeg is om de meeste gebruikssituaties aan te kunnen, en in staat is om verschillende hardware
opties te gebruiken zonder dat er codewijzigingen nodig zijn.
 
<code>pytorch-accelerated</code> biedt een gestroomlijnd functieset en legt een grote nadruk op <strong>eenvoud</strong> en <strong>transparantie</strong>,
om gebruikers in staat te stellen precies te begrijpen wat er onder de motorkap gebeurt, maar zonder dat ze zelf de boilerplate hoeven te schrijven en onderhouden!
   
De belangrijkste kenmerken zijn:
<ul><li>Een eenvoudige en overzichtelijke, maar gemakkelijk aanpasbare trainingslus, die direct uit de doos zou moeten werken in eenvoudige gevallen;</li>
 </ul>het gedrag kan worden aangepast met behulp van overerving en/of callbacks.
<ul><li>Regelt apparaatplaatsing, mixed-precision, DeepSpeed-integratie, multi-GPU en gedistribueerde training zonder codewijzigingen.</li>
<li>Gebruikt pure PyTorch-componenten, zonder extra aanpassingen of wrappers, en werkt eenvoudig samen</li>
 </ul>met andere populaire libraries zoals <a href="https://github.com/rwightman/pytorch-image-models" target="_blank" rel="noopener noreferrer">timm</a>, 
 <a href="https://huggingface.co/transformers/" target="_blank" rel="noopener noreferrer">transformers</a> en <a href="https://torchmetrics.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">torchmetrics</a>.
<ul><li>Een kleine, gestroomlijnde API zorgt ervoor dat er een minimale leercurve is voor bestaande PyTorch-gebruikers.</li></p><p></ul>Er is veel moeite gedaan om ervoor te zorgen dat elk deel van de library - zowel interne als externe componenten - zo duidelijk en eenvoudig mogelijk is, 
waardoor het gemakkelijk is om aan te passen, te debuggen en precies te begrijpen wat er achter de schermen gebeurt bij elke stap; het grootste deel van het 
gedrag van de trainer zit in een enkele klasse!
In de geest van Python wordt niets verborgen en is alles toegankelijk.</p><p><code>pytorch-accelerated</code> is trots en transparant gebouwd bovenop 
<a href="https://github.com/huggingface/accelerate" target="_blank" rel="noopener noreferrer">Hugging Face Accelerate</a>, dat verantwoordelijk is voor de 
verplaatsing van data tussen apparaten en het starten van trainingsconfiguraties. Bij het aanpassen van de trainer, of het starten van
training, worden gebruikers aangemoedigd om de <a href="https://huggingface.co/docs/accelerate/" target="_blank" rel="noopener noreferrer">Accelerate documentatie</a> 
te raadplegen om alle beschikbare opties te begrijpen; Accelerate biedt handige functies voor operaties zoals het verzamelen van tensors 
en gradient clipping, waarvan het gebruik te zien is in de <code>pytorch-accelerated</code> 
<a href="https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples" target="_blank" rel="noopener noreferrer">voorbeelden</a> map!</p><p>Om meer te weten te komen over de motivaties achter deze library, samen met een gedetailleerde introductiegids, bekijk <a href="https://medium.com/@chris.p.hughes10/introducing-pytorch-accelerated-6ba99530608c?source=friends_link&sk=868c2d2ec5229fdea42877c0bf82b968" target="_blank" rel="noopener noreferrer">deze blogpost</a>.</p><h2>Installatie</h2></p><p><code>pytorch-accelerated</code> kan worden geïnstalleerd via pip met het volgende commando:
<pre><code class="language-">pip install pytorch-accelerated</code></pre>
Om het pakket zo slank mogelijk te houden, zijn de pakketten die nodig zijn om de voorbeelden uit te voeren niet standaard inbegrepen. Om deze pakketten toe te voegen, kunt u de volgende opdracht gebruiken:</p><pre><code class="language-">pip install pytorch-accelerated[examples]</code></pre></p><h2>Snelstart</h2></p><p>Om aan de slag te gaan, importeer en gebruik je eenvoudig de pytorch-accelerated <code>Trainer</code>, zoals getoond in het volgende fragment,
en start vervolgens de training met de 
<a href="https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script" target="_blank" rel="noopener noreferrer">accelerate CLI</a>
zoals hieronder beschreven.</p><pre><code class="language-python"># examples/core/train_mnist.py
import os</p><p>from torch import nn, optim
from torch.utils.data import random_split
from torchvision import transforms
from torchvision.datasets import MNIST</p><p>from pytorch_accelerated import Trainer</p><p>class MNISTModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.main = nn.Sequential(
            nn.Linear(in_features=784, out_features=128),
            nn.ReLU(),
            nn.Linear(in_features=128, out_features=64),
            nn.ReLU(),
            nn.Linear(in_features=64, out_features=10),
        )</p><p>    def forward(self, input):
        return self.main(input.view(input.shape[0], -1))</p><p>def main():
    dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())
    train_dataset, validation_dataset, test_dataset = random_split(dataset, [50000, 5000, 5000])
    model = MNISTModel()
    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
    loss_func = nn.CrossEntropyLoss()</p><p>    trainer = Trainer(
            model,
            loss_func=loss_func,
            optimizer=optimizer,
    )</p><p>    trainer.train(
        train_dataset=train_dataset,
        eval_dataset=validation_dataset,
        num_epochs=8,
        per_device_batch_size=32,
    )</p><p>    trainer.evaluate(
        dataset=test_dataset,
        per_device_batch_size=64,
    )
    
if __name__ == "__main__":
    main()</code></pre></p><p>Om training te starten met behulp van de <a href="https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script" target="_blank" rel="noopener noreferrer">accelerate CLI</a>
, voer op je machine(s) het volgende uit:</p><p><code> accelerate config --config_file accelerate_config.yaml</code></p><p>en beantwoord de gestelde vragen. Dit genereert een configuratiebestand dat gebruikt zal worden om de standaardopties correct in te stellen bij</p><p><code>accelerate launch --config_file accelerate_config.yaml train.py [--training-args]</code></p><p><em>Opmerking</em>: Het gebruik van de <a href="https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script" target="_blank" rel="noopener noreferrer">accelerate CLI</a> is volledig optioneel, training kan ook op de gebruikelijke manier worden gestart met:</p><p><code>python train.py</code> / <code>python -m torch.distributed ...</code></p><p>afhankelijk van je infrastructuurconfiguratie, voor gebruikers die graag meer gedetailleerde controle willen 
over het startcommando.</p><p>Meer complexe trainingsvoorbeelden zijn te vinden in de examples-map 
<a href="https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples" target="_blank" rel="noopener noreferrer">hier</a>. </p><p>Als je liever eerst de kernconcepten wilt begrijpen, kun je deze vinden in de <a href="https://pytorch-accelerated.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">documentatie</a>.</p><h2>Gebruik</h2></p><h3>Voor wie is pytorch-accelerated bedoeld?</h3></p><ul><li>Gebruikers die bekend zijn met PyTorch maar het schrijven van de standaard trainingsloop-boilerplate willen vermijden</li>
</ul>om zich te kunnen richten op de interessante delen van de trainingsloop.
<ul><li>Gebruikers die graag hun eigen modellen, verliesfuncties, optimalisatoren en datasets kiezen en samenstellen.</li>
<li>Gebruikers die waarde hechten aan een eenvoudige en gestroomlijnde feature set, waarbij het gedrag makkelijk te debuggen, te begrijpen en te doorgronden is!</li></p><p></ul><h3>Wanneer kun je pytorch-accelerated beter niet gebruiken?</h3></p><ul><li>Als je op zoek bent naar een end-to-end oplossing, van het laden van data tot inferentie,</li>
  </ul>die je helpt bij het kiezen van een model, optimizer of verliesfunctie, ben je waarschijnlijk beter af met
  <a href="https://github.com/fastai/fastai" target="_blank" rel="noopener noreferrer">fastai</a>. <code>pytorch-accelerated</code> richt zich alleen op het trainingsproces, waarbij alle andere
  aspecten aan de gebruiker worden overgelaten.
<ul><li>Als je graag zelf de volledige trainingsloop wilt schrijven, maar zonder al het device-management gedoe, </li>
</ul>ben je waarschijnlijk het beste af met <a href="https://github.com/huggingface/accelerate" target="_blank" rel="noopener noreferrer">Accelerate</a> direct! Hoewel het
mogelijk is om elk onderdeel van de <code>Trainer</code> aan te passen, wordt de trainingsloop in de basis opgedeeld in een aantal 
verschillende methoden die je zou moeten overschrijven. Maar voordat je vertrekt, is het schrijven van die <code>for</code>-lussen echt belangrijk genoeg om <em>weer</em> helemaal opnieuw te beginnen 😉.
<ul><li>Als je werkt aan een aangepaste, zeer complexe use-case die niet past binnen de patronen van de gebruikelijke trainingslussen en je wilt elk beetje prestatie uit je gekozen hardware halen, kun je waarschijnlijk het beste bij vanilla PyTorch blijven; elke high-level API wordt een overhead in sterk gespecialiseerde gevallen!</li></p><p>
</ul><h2>Dankbetuigingen</h2></p><p>Veel aspecten achter het ontwerp en de functies van <code>pytorch-accelerated</code> zijn sterk geïnspireerd door een aantal uitstekende bibliotheken en frameworks zoals <a href="https://github.com/fastai/fastai" target="_blank" rel="noopener noreferrer">fastai</a>, <a href="https://github.com/rwightman/pytorch-image-models" target="_blank" rel="noopener noreferrer">timm</a>, <a href="https://github.com/PyTorchLightning/pytorch-lightning" target="_blank" rel="noopener noreferrer">PyTorch-lightning</a> en <a href="https://github.com/huggingface/accelerate" target="_blank" rel="noopener noreferrer">Hugging Face Accelerate</a>. Elk van deze tools heeft een enorme impact gehad op zowel deze bibliotheek als de machine learning community, en hun invloed kan niet genoeg worden benadrukt!</p><p><code>pytorch-accelerated</code> heeft alleen inspiratie uit deze tools gehaald, en alle functionaliteit is volledig opnieuw geïmplementeerd op een manier die voordelig is voor deze bibliotheek. De enige uitzonderingen hierop zijn sommige scripts in de map <a href="https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples" target="_blank" rel="noopener noreferrer">examples</a> waarin bestaande resources zijn gebruikt en aangepast om de mogelijkheden van <code>pytorch-accelerated</code> te demonstreren; deze gevallen zijn duidelijk gemarkeerd, met erkenning aan de oorspronkelijke auteurs.</p><p>
---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-02-28

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Chris-hughes10/pytorch-accelerated/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-02-28 
    </div>
    
</body>
</html>