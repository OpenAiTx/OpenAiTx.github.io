<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>pytorch-accelerated - Une biblioth&#232;que l&#233;g&#232;re con&#231;ue pour acc&#233;l&#233;rer le processus d&#39;entra&#238;nement des mod&#232;les PyTorch en fournissant une boucle d&#39;entra&#238;nement minimale mais extensible, suffisamment flexible pour g&#233;rer la majorit&#233; des cas d&#39;utilisation, et capable d&#39;utiliser diff&#233;rentes options mat&#233;rielles sans n&#233;cessiter de modifications de code. Docs : https://pytorch-accelerated.readthedocs.io/en/latest/</title>
    <meta name="description" content="Une biblioth&#232;que l&#233;g&#232;re con&#231;ue pour acc&#233;l&#233;rer le processus d&#39;entra&#238;nement des mod&#232;les PyTorch en fournissant une boucle d&#39;entra&#238;nement minimale mais extensible, suffisamment flexible pour g&#233;rer la majorit&#233; des cas d&#39;utilisation, et capable d&#39;utiliser diff&#233;rentes options mat&#233;rielles sans n&#233;cessiter de modifications de code. Docs : https://pytorch-accelerated.readthedocs.io/en/latest/">
    <meta name="keywords" content="pytorch-accelerated, French, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "pytorch-accelerated",
  "description": "Une bibliothèque légère conçue pour accélérer le processus d'entraînement des modèles PyTorch en fournissant une boucle d'entraînement minimale mais extensible, suffisamment flexible pour gérer la majorité des cas d'utilisation, et capable d'utiliser différentes options matérielles sans nécessiter de modifications de code. Docs : https://pytorch-accelerated.readthedocs.io/en/latest/",
  "author": {
    "@type": "Person",
    "name": "Chris-hughes10"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 192
  },
  "url": "https://OpenAiTx.github.io/projects/Chris-hughes10/pytorch-accelerated/README-fr.html",
  "sameAs": "https://raw.githubusercontent.com/Chris-hughes10/pytorch-accelerated/main/README.md",
  "datePublished": "2026-02-23",
  "dateModified": "2026-02-23"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/Chris-hughes10/pytorch-accelerated" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    pytorch-accelerated
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 192 stars</span>
                <span class="language">French</span>
                <span>by Chris-hughes10</span>
            </div>
        </div>
        
        <div class="content">
            <h1>pytorch-accelerated</h1></p><p><code>pytorch-accelerated</code> est une bibliothèque légère conçue pour accélérer le processus d'entraînement des modèles PyTorch  
en fournissant une boucle d'entraînement minimale, mais extensible - encapsulée dans un seul objet <code>Trainer</code>  
qui est suffisamment flexible pour gérer la majorité des cas d'utilisation, et capable d'utiliser différentes options matérielles  
sans nécessiter de modification du code.  </p><p><code>pytorch-accelerated</code> offre un ensemble de fonctionnalités simplifié, et met un fort accent sur la <strong>simplicité</strong> et la <strong>transparence</strong>,  
pour permettre aux utilisateurs de comprendre exactement ce qui se passe sous le capot, sans avoir à écrire et maintenir eux-mêmes le code standard !  </p><p>Les principales fonctionnalités sont :  
<ul><li>Une boucle d'entraînement simple et contenue, mais facilement personnalisable, qui devrait fonctionner immédiatement dans des cas simples ;  </li>
  </ul>le comportement peut être personnalisé via l'héritage et/ou les callbacks.  
<ul><li>Gère le placement sur les dispositifs, la précision mixte, l'intégration DeepSpeed, le multi-GPU et l'entraînement distribué sans modification du code.  </li>
<li>Utilise des composants purement PyTorch, sans modifications ou wrappers supplémentaires, et interopère facilement  </li>
  </ul>avec d'autres bibliothèques populaires telles que <a href="https://github.com/rwightman/pytorch-image-models" target="_blank" rel="noopener noreferrer">timm</a>,  
  <a href="https://huggingface.co/transformers/" target="_blank" rel="noopener noreferrer">transformers</a> et <a href="https://torchmetrics.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">torchmetrics</a>.  
<ul><li>Une API petite et épurée garantit une courbe d'apprentissage minimale pour les utilisateurs existants de PyTorch.  </li></p><p></ul>Un effort important a été fait pour garantir que chaque partie de la bibliothèque - composants internes et externes - soit aussi claire et simple que possible,  
ce qui facilite la personnalisation, le débogage et la compréhension exacte de ce qui se passe en coulisses à chaque étape ; la majeure partie du  
comportement du trainer est contenue dans une seule classe !  
Dans l’esprit de Python, rien n’est caché et tout est accessible.  </p><p><code>pytorch-accelerated</code> est fièrement et transparent construit sur  
<a href="https://github.com/huggingface/accelerate" target="_blank" rel="noopener noreferrer">Hugging Face Accelerate</a>, qui est responsable du  
transfert des données entre les dispositifs et du lancement des configurations d'entraînement. Lors de la personnalisation du trainer, ou du lancement  
de l'entraînement, il est conseillé aux utilisateurs de consulter la <a href="https://huggingface.co/docs/accelerate/" target="_blank" rel="noopener noreferrer">documentation d’Accelerate</a>  
pour comprendre toutes les options disponibles ; Accelerate fournit des fonctions pratiques pour des opérations telles que la collecte des tenseurs  
et la coupure des gradients, dont l’utilisation peut être vue dans le dossier  
<a href="https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples" target="_blank" rel="noopener noreferrer">exemples</a> de <code>pytorch-accelerated</code> !  </p><p>Pour en savoir plus sur les motivations derrière cette bibliothèque, ainsi qu’un guide détaillé de démarrage, consultez <a href="https://medium.com/@chris.p.hughes10/introducing-pytorch-accelerated-6ba99530608c?source=friends_link&sk=868c2d2ec5229fdea42877c0bf82b968" target="_blank" rel="noopener noreferrer">cet article de blog</a>.  </p><h2>Installation  </h2></p><p><code>pytorch-accelerated</code> peut être installé depuis pip avec la commande suivante :
<pre><code class="language-">pip install pytorch-accelerated</code></pre></p><p>Pour rendre le package aussi léger que possible, les packages nécessaires pour exécuter les exemples ne sont pas inclus par défaut. Pour inclure ces packages, vous pouvez utiliser la commande suivante :
<pre><code class="language-">pip install pytorch-accelerated[examples]</code></pre></p><h2>Démarrage rapide</h2></p><p>Pour commencer, importez simplement et utilisez le <code>Trainer</code> accéléré par pytorch, comme démontré dans l'extrait suivant,
puis lancez l'entraînement en utilisant la 
<a href="https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script" target="_blank" rel="noopener noreferrer">CLI accelerate</a>
décrite ci-dessous.</p><pre><code class="language-python"># examples/core/train_mnist.py
import os</p><p>from torch import nn, optim
from torch.utils.data import random_split
from torchvision import transforms
from torchvision.datasets import MNIST</p><p>from pytorch_accelerated import Trainer</p><p>class MNISTModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.main = nn.Sequential(
            nn.Linear(in_features=784, out_features=128),
            nn.ReLU(),
            nn.Linear(in_features=128, out_features=64),
            nn.ReLU(),
            nn.Linear(in_features=64, out_features=10),
        )</p><p>    def forward(self, input):
        return self.main(input.view(input.shape[0], -1))</p><p>def main():
    dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())
    train_dataset, validation_dataset, test_dataset = random_split(dataset, [50000, 5000, 5000])
    model = MNISTModel()
    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
    loss_func = nn.CrossEntropyLoss()</p><p>    trainer = Trainer(
            model,
            loss_func=loss_func,
            optimizer=optimizer,
    )</p><p>    trainer.train(
        train_dataset=train_dataset,
        eval_dataset=validation_dataset,
        num_epochs=8,
        per_device_batch_size=32,
    )</p><p>    trainer.evaluate(
        dataset=test_dataset,
        per_device_batch_size=64,
    )
    
if __name__ == "__main__":
    main()</code></pre>
Pour lancer l'entraînement en utilisant le <a href="https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script" target="_blank" rel="noopener noreferrer">CLI accelerate</a>
, sur votre(s) machine(s), exécutez :</p><p><code> accelerate config --config_file accelerate_config.yaml</code></p><p>et répondez aux questions posées. Cela générera un fichier de configuration qui sera utilisé pour définir correctement les options par défaut lors de l'exécution de</p><p><code>accelerate launch --config_file accelerate_config.yaml train.py [--training-args]</code></p><p><em>Note</em> : L'utilisation du <a href="https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script" target="_blank" rel="noopener noreferrer">CLI accelerate</a> est totalement optionnelle, l'entraînement peut également être lancé de la manière habituelle via :</p><p><code>python train.py</code> / <code>python -m torch.distributed ...</code></p><p>selon la configuration de votre infrastructure, pour les utilisateurs qui souhaitent garder un contrôle plus précis
sur la commande de lancement.</p><p>Des exemples d'entraînement plus complexes sont disponibles dans le dossier examples
<a href="https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples" target="_blank" rel="noopener noreferrer">ici</a>.</p><p>Alternativement, si vous préférez comprendre d'abord les concepts de base, vous pouvez les trouver dans la <a href="https://pytorch-accelerated.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">documentation</a>.</p><h2>Utilisation</h2></p><h3>À qui s'adresse pytorch-accelerated ?</h3></p><ul><li>Aux utilisateurs familiers avec PyTorch mais qui souhaitent éviter d'écrire la structure standard de la boucle d'entraînement</li>
</ul>pour se concentrer sur les parties intéressantes de la boucle d'entraînement.
<ul><li>Aux utilisateurs qui aiment, et sont à l'aise avec, la sélection et la création de leurs propres modèles, fonctions de perte, optimiseurs et ensembles de données.</li>
<li>Aux utilisateurs qui apprécient un ensemble de fonctionnalités simple et épuré, où le comportement est facile à déboguer, comprendre et analyser !</li></p><p></ul><h3>Quand ne devrais-je pas utiliser pytorch-accelerated ?</h3></p><ul><li>Si vous cherchez une solution complète, couvrant tout depuis le chargement des données jusqu'à l'inférence,</li>
  </ul>qui vous aide à sélectionner un modèle, un optimiseur ou une fonction de perte, vous seriez probablement mieux servi par
  <a href="https://github.com/fastai/fastai" target="_blank" rel="noopener noreferrer">fastai</a>. <code>pytorch-accelerated</code> se concentre uniquement sur le processus d'entraînement, toutes les autres
  préoccupations restant de la responsabilité de l'utilisateur.
<ul><li>Si vous souhaitez écrire vous-même toute la boucle d'entraînement, simplement sans toutes les complications liées à la gestion des appareils,</li>
</ul>vous seriez probablement mieux servi en utilisant directement <a href="https://github.com/huggingface/accelerate" target="_blank" rel="noopener noreferrer">Accelerate</a> ! Bien qu'il
soit possible de personnaliser chaque partie du <code>Trainer</code>, la boucle d'entraînement est fondamentalement découpée en un certain nombre de</p><p>différentes méthodes que vous devrez surcharger. Mais, avant de partir, est-ce que l'écriture de ces boucles <code>for</code> est vraiment assez importante  
pour justifier de repartir de zéro <em>encore</em> 😉.  
<ul><li>Si vous travaillez sur un cas d'utilisation personnalisé, très complexe, qui ne correspond pas aux schémas habituels des boucles d'entraînement  </li>
</ul>et que vous souhaitez exploiter chaque dernier bit de performance sur votre matériel choisi, il est probablement préférable de rester  
avec PyTorch vanilla ; toute API de haut niveau devient une surcharge dans les cas hautement spécialisés !  </p><h2>Remerciements  </h2></p><p>De nombreux aspects derrière la conception et les fonctionnalités de <code>pytorch-accelerated</code> ont été grandement inspirés par un certain nombre d'excellentes  
bibliothèques et frameworks tels que <a href="https://github.com/fastai/fastai" target="_blank" rel="noopener noreferrer">fastai</a>, <a href="https://github.com/rwightman/pytorch-image-models" target="_blank" rel="noopener noreferrer">timm</a>,  
<a href="https://github.com/PyTorchLightning/pytorch-lightning" target="_blank" rel="noopener noreferrer">PyTorch-lightning</a> et <a href="https://github.com/huggingface/accelerate" target="_blank" rel="noopener noreferrer">Hugging Face Accelerate</a>. Chacun de ces outils  
a eu un impact énorme à la fois sur cette bibliothèque et sur la communauté de l'apprentissage automatique, et leur influence ne peut  
être assez soulignée !  </p><p><code>pytorch-accelerated</code> s'est inspiré uniquement de ces outils, et toute la fonctionnalité contenue a été implémentée  
à partir de zéro de manière à bénéficier à cette bibliothèque. Les seules exceptions sont certains scripts dans le  
<a href="https://github.com/Chris-hughes10/pytorch-accelerated/tree/main/examples" target="_blank" rel="noopener noreferrer">dossier examples</a>  
dans lesquels des ressources existantes ont été prises et modifiées afin de présenter les fonctionnalités de <code>pytorch-accelerated</code> ;  
ces cas sont clairement indiqués, avec une reconnaissance donnée aux auteurs originaux.  </p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2026-02-23

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Chris-hughes10/pytorch-accelerated/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2026-02-23 
    </div>
    
</body>
</html>