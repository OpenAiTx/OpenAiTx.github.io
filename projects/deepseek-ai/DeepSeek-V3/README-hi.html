<!DOCTYPE html>
<html lang="hi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DeepSeek-V3 - Read DeepSeek-V3 documentation in Hindi. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read DeepSeek-V3 documentation in Hindi. This project has 0 stars on GitHub.">
    <meta name="keywords" content="DeepSeek-V3, Hindi, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "DeepSeek-V3",
  "description": "Read DeepSeek-V3 documentation in Hindi. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "deepseek-ai"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/deepseek-ai/DeepSeek-V3/README-hi.html",
  "sameAs": "https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/master/README.md",
  "datePublished": "2025-07-24",
  "dateModified": "2025-07-24"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/deepseek-ai/DeepSeek-V3" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    DeepSeek-V3
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Hindi</span>
                <span>by deepseek-ai</span>
            </div>
        </div>
        
        <div class="content">
            <p><!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable html -->
<!-- markdownlint-disable no-duplicate-header --></p><p><div align="center">
  <img src="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true" width="60%" alt="DeepSeek-V3" />
</div>
<hr>
<div align="center" style="line-height: 1;">
  <a href="https://www.deepseek.com/"><img alt="Homepage"
    src="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true"/></a>
  <a href="https://chat.deepseek.com/"><img alt="Chat"
    src="https://img.shields.io/badge/🤖%20Chat-DeepSeek%20V3-536af5?color=536af5&logoColor=white"/></a>
  <a href="https://huggingface.co/deepseek-ai"><img alt="Hugging Face"
    src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white"/></a>
  <br>
  <a href="https://discord.gg/Tc7c45Zzu5"><img alt="Discord"
    src="https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da"/></a>
  <a href="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true"><img alt="Wechat"
    src="https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white"/></a>
  <a href="https://twitter.com/deepseek_ai"><img alt="Twitter Follow"
    src="https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white"/></a>
  <br>
  <a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-CODE"><img alt="Code License"
    src="https://img.shields.io/badge/Code_License-MIT-f5de53?&color=f5de53"/></a>
  <a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-MODEL"><img alt="Model License"
    src="https://img.shields.io/badge/Model_License-Model_Agreement-f5de53?&color=f5de53"/></a>
  <br>
  <a href="https://arxiv.org/pdf/2412.19437"><b>Paper Link</b>👁️</a>
</div></p><h2>सामग्री सूची</h2></p><ul><li><a href="#1-introduction" target="_blank" rel="noopener noreferrer">परिचय</a></li>
<li><a href="#2-model-summary" target="_blank" rel="noopener noreferrer">मॉडल सारांश</a></li>
<li><a href="#3-model-downloads" target="_blank" rel="noopener noreferrer">मॉडल डाउनलोड</a></li>
<li><a href="#4-evaluation-results" target="_blank" rel="noopener noreferrer">मूल्यांकन परिणाम</a></li>
<li><a href="#5-chat-website--api-platform" target="_blank" rel="noopener noreferrer">चैट वेबसाइट और एपीआई प्लेटफॉर्म</a></li>
<li><a href="#6-how-to-run-locally" target="_blank" rel="noopener noreferrer">स्थानीय रूप से कैसे चलाएं</a></li>
<li><a href="#7-license" target="_blank" rel="noopener noreferrer">लाइसेंस</a></li>
<li><a href="#8-citation" target="_blank" rel="noopener noreferrer">संदर्भ</a></li>
<li><a href="#9-contact" target="_blank" rel="noopener noreferrer">संपर्क</a></li></p><p></ul><h2>1. परिचय</h2></p><p>हम प्रस्तुत करते हैं DeepSeek-V3, एक शक्तिशाली मिक्सचर-ऑफ-एक्सपर्ट्स (MoE) भाषा मॉडल जिसमें कुल 671B पैरामीटर्स हैं, जिनमें से प्रत्येक टोकन के लिए 37B सक्रिय होते हैं।  
कुशल अनुमान और लागत प्रभावी प्रशिक्षण प्राप्त करने के लिए, DeepSeek-V3 Multi-head Latent Attention (MLA) और DeepSeekMoE आर्किटेक्चर को अपनाता है, जिन्हें DeepSeek-V2 में पूरी तरह से मान्य किया गया था।  
साथ ही, DeepSeek-V3 लोड बैलेंसिंग के लिए एक सहायक-हानि-रहित रणनीति (auxiliary-loss-free strategy) की शुरुआत करता है और बेहतर प्रदर्शन के लिए मल्टी-टोकन प्रेडिक्शन प्रशिक्षण लक्ष्य निर्धारित करता है।  
हम DeepSeek-V3 को 14.8 ट्रिलियन विविध और उच्च गुणवत्ता वाले टोकन पर पूर्व-प्रशिक्षित करते हैं, इसके बाद सुपरवाइज्ड फाइन-ट्यूनिंग और रिइंफोर्समेंट लर्निंग चरण होते हैं, जिससे इसकी क्षमताओं का पूर्ण उपयोग किया जा सके।  
व्यापक मूल्यांकन से पता चलता है कि DeepSeek-V3 अन्य ओपन-सोर्स मॉडलों से बेहतर प्रदर्शन करता है और अग्रणी क्लोज्ड-सोर्स मॉडलों के समान प्रदर्शन प्राप्त करता है।  
अपने उत्कृष्ट प्रदर्शन के बावजूद, DeepSeek-V3 के पूर्ण प्रशिक्षण के लिए केवल 2.788M H800 GPU घंटे की आवश्यकता होती है।  
इसके अतिरिक्त, इसका प्रशिक्षण प्रक्रिया अत्यंत स्थिर है।  
पूरे प्रशिक्षण के दौरान, हमें कभी भी कोई अपरिवर्तनीय लॉस स्पाइक्स नहीं मिले और न ही कोई रोलबैक किया गया।  
<p align="center">
  <img width="80%" src="figures/benchmark.png">
</p></p><h2>2. मॉडल सारांश</h2></p><hr></p><p><strong>आर्किटेक्चर: अभिनव लोड बैलेंसिंग रणनीति और प्रशिक्षण उद्देश्य</strong></p><ul><li>DeepSeek-V2 की कुशल आर्किटेक्चर पर, हम लोड बैलेंसिंग के लिए सहायक-हानि-रहित रणनीति की शुरुआत करते हैं, जिससे लोड बैलेंसिंग को प्रोत्साहित करने से उत्पन्न प्रदर्शन गिरावट न्यूनतम होती है।</li>
<li>हम Multi-Token Prediction (MTP) उद्देश्य की जांच करते हैं और इसे मॉडल प्रदर्शन के लिए लाभकारी सिद्ध करते हैं।  </li>
    </ul>इसे अनुमान त्वरण (inference acceleration) के लिए speculative decoding में भी इस्तेमाल किया जा सकता है।  </p><hr></p><p><strong>पूर्व-प्रशिक्षण: अंतिम प्रशिक्षण दक्षता की ओर</strong></p><ul><li>हम FP8 मिश्रित सटीकता प्रशिक्षण ढांचा डिज़ाइन करते हैं, और पहली बार, अत्यंत बड़े पैमाने पर मॉडल पर FP8 प्रशिक्षण की व्यवहार्यता और प्रभावशीलता को मान्य करते हैं।  </li>
<li>एल्गोरिदम, फ्रेमवर्क और हार्डवेयर के सह-डिज़ाइन के माध्यम से, हम क्रॉस-नोड MoE प्रशिक्षण में संचार बाधा को पार करते हैं, लगभग पूर्ण गणना-संचार ओवरलैप प्राप्त करते हैं।  </li>
  </ul>यह हमारे प्रशिक्षण दक्षता को काफी बढ़ाता है और लागत को कम करता है, जिससे हम अतिरिक्त ओवरहेड के बिना मॉडल आकार को और बढ़ा सकते हैं।  
<ul><li>केवल 2.664M H800 GPU घंटे की किफायती लागत पर, हम 14.8T टोकन पर DeepSeek-V3 का पूर्व-प्रशिक्षण पूरा करते हैं, जिससे वर्तमान में सबसे मजबूत ओपन-सोर्स बेस मॉडल तैयार होता है। पूर्व-प्रशिक्षण के बाद के प्रशिक्षण चरणों के लिए केवल 0.1M GPU घंटे की आवश्यकता होती है।</li></p><p></ul>---</p><p><strong>पोस्ट-प्रशिक्षण: DeepSeek-R1 से ज्ञान आसवन (डिस्टिलेशन)</strong></p><ul><li>  हम एक अभिनव कार्यप्रणाली पेश करते हैं जिससे लंबी चेन-ऑफ-थॉट (CoT) मॉडल, विशेष रूप से DeepSeek R1 श्रृंखला के एक मॉडल से, मानक LLMs, विशेष रूप से DeepSeek-V3 में तर्क क्षमताओं का आसवन किया जाता है। हमारी पाइपलाइन R1 के सत्यापन और परावर्तन पैटर्न को DeepSeek-V3 में खूबसूरती से समाहित करती है और इसके तर्क प्रदर्शन में उल्लेखनीय सुधार करती है। साथ ही, हम DeepSeek-V3 के आउटपुट शैली और लंबाई को भी नियंत्रित रखते हैं।</li></p><p></ul>---</p><h2>3. मॉडल डाउनलोड</h2></p><p><div align="center"></p><p>| <strong>मॉडल</strong> | <strong>#कुल पैरामीटर्स</strong> | <strong>#सक्रिय पैरामीटर्स</strong> | <strong>संदर्भ लंबाई</strong> | <strong>डाउनलोड</strong> |
| :------------: | :------------: | :------------: | :------------: | :------------: |
| DeepSeek-V3-Base | 671B | 37B | 128K   | <a href="https://huggingface.co/deepseek-ai/DeepSeek-V3-Base" target="_blank" rel="noopener noreferrer">🤗 Hugging Face</a>   |
| DeepSeek-V3   | 671B | 37B |  128K   | <a href="https://huggingface.co/deepseek-ai/DeepSeek-V3" target="_blank" rel="noopener noreferrer">🤗 Hugging Face</a>   |</p><p></div></p><blockquote>[!NOTE]</blockquote>
<blockquote>Hugging Face पर DeepSeek-V3 मॉडलों का कुल आकार 685B है, जिसमें 671B मुख्य मॉडल वजन और 14B Multi-Token Prediction (MTP) मॉड्यूल वजन शामिल हैं।</blockquote></p><p>सर्वोत्तम प्रदर्शन और लचीलापन सुनिश्चित करने के लिए, हमने ओपन-सोर्स समुदायों और हार्डवेयर विक्रेताओं के साथ साझेदारी की है, ताकि मॉडल को स्थानीय रूप से चलाने के कई तरीके उपलब्ध कराए जा सकें। चरण-दर-चरण मार्गदर्शन के लिए, अनुभाग 6 देखें: <a href="#6-how-to-run-locally" target="_blank" rel="noopener noreferrer">स्थानीय रूप से कैसे चलाएं</a>।</p><p>डेवलपर्स के लिए, हम मुख्य मॉडल वजन और मल्टी-टोकन प्रेडिक्शन (MTP) मॉड्यूल के विवरण के लिए <a href="./README_WEIGHTS.md" target="_blank" rel="noopener noreferrer">README_WEIGHTS.md</a> देखने की सलाह देते हैं। कृपया ध्यान दें कि MTP समर्थन वर्तमान में समुदाय में सक्रिय विकास के अधीन है, और हम आपके योगदान व फीडबैक का स्वागत करते हैं।</p><h2>4. मूल्यांकन परिणाम</h2>
<h3>बेस मॉडल</h3>
#### मानक बेंचमार्क</p><p><div align="center"></p><p>|  | बेंचमार्क (मेट्रिक) | #शॉट्स | DeepSeek-V2 | Qwen2.5 72B | LLaMA3.1 405B | DeepSeek-V3 |
|---|-------------------|----------|--------|-------------|---------------|---------|
| | आर्किटेक्चर | - | MoE | Dense | Dense | MoE |
| | #सक्रिय पैरामीटर्स | - | 21B | 72B | 405B | 37B |
| | #कुल पैरामीटर्स | - | 236B | 72B | 405B | 671B |
| अंग्रेज़ी | Pile-test (BPB) | - | 0.606 | 0.638 | <strong>0.542</strong> | 0.548 |
| | BBH (EM) | 3-shot | 78.8 | 79.8 | 82.9 | <strong>87.5</strong> |
| | MMLU (सटीकता) | 5-shot | 78.4 | 85.0 | 84.4 | <strong>87.1</strong> |
| | MMLU-Redux (सटीकता) | 5-shot | 75.6 | 83.2 | 81.3 | <strong>86.2</strong> |
| | MMLU-Pro (सटीकता) | 5-shot | 51.4 | 58.3 | 52.8 | <strong>64.4</strong> |
| | DROP (F1) | 3-shot | 80.4 | 80.6 | 86.0 | <strong>89.0</strong> |
| | ARC-Easy (सटीकता) | 25-shot | 97.6 | 98.4 | 98.4 | <strong>98.9</strong> |
| | ARC-Challenge (सटीकता) | 25-shot | 92.2 | 94.5 | <strong>95.3</strong> | <strong>95.3</strong> |
| | HellaSwag (सटीकता) | 10-shot | 87.1 | 84.8 | <strong>89.2</strong> | 88.9 |
| | PIQA (सटीकता) | 0-shot | 83.9 | 82.6 | <strong>85.9</strong> | 84.7 |
| | WinoGrande (सटीकता) | 5-shot | <strong>86.3</strong> | 82.3 | 85.2 | 84.9 |
| | RACE-Middle (सटीकता) | 5-shot | 73.1 | 68.1 | <strong>74.2</strong> | 67.1 |
| | RACE-High (सटीकता) | 5-shot | 52.6 | 50.3 | <strong>56.8</strong> | 51.3 |
| | TriviaQA (EM) | 5-shot | 80.0 | 71.9 | 82.7 | <strong>82.9</strong> |
| | NaturalQuestions (EM) | 5-shot | 38.6 | 33.2 | <strong>41.5</strong> | 40.0 |
| | AGIEval (सटीकता) | 0-shot | 57.5 | 75.8 | 60.6 | <strong>79.6</strong> |
| कोड | HumanEval (Pass@1) | 0-shot | 43.3 | 53.0 | 54.9 | <strong>65.2</strong> |
| | MBPP (Pass@1) | 3-shot | 65.0 | 72.6 | 68.4 | <strong>75.4</strong> |
| | LiveCodeBench-Base (Pass@1) | 3-shot | 11.6 | 12.9 | 15.5 | <strong>19.4</strong> |
| | CRUXEval-I (सटीकता) | 2-shot | 52.5 | 59.1 | 58.5 | <strong>67.3</strong> |
| | CRUXEval-O (सटीकता) | 2-shot | 49.8 | 59.9 | 59.9 | <strong>69.8</strong> |
| गणित | GSM8K (EM) | 8-shot | 81.6 | 88.3 | 83.5 | <strong>89.3</strong> |
| | MATH (EM) | 4-shot | 43.4 | 54.4 | 49.0 | <strong>61.6</strong> |
| | MGSM (EM) | 8-shot | 63.6 | 76.2 | 69.9 | <strong>79.8</strong> |
| | CMath (EM) | 3-shot | 78.7 | 84.5 | 77.3 | <strong>90.7</strong> |
| चीनी | CLUEWSC (EM) | 5-shot | 82.0 | 82.5 | <strong>83.0</strong> | 82.7 |
| | C-Eval (सटीकता) | 5-shot | 81.4 | 89.2 | 72.5 | <strong>90.1</strong> |
| | CMMLU (सटीकता) | 5-shot | 84.0 | <strong>89.5</strong> | 73.7 | 88.8 |
| | CMRC (EM) | 1-shot | <strong>77.4</strong> | 75.8 | 76.0 | 76.3 |
| | C3 (सटीकता) | 0-shot | 77.4 | 76.7 | <strong>79.7</strong> | 78.6 |
| | CCPM (सटीकता) | 0-shot | <strong>93.0</strong> | 88.5 | 78.6 | 92.0 |
| बहुभाषी | MMMLU-non-English (सटीकता) | 5-shot | 64.0 | 74.8 | 73.8 | <strong>79.4</strong> |</p><p></div></p><blockquote>[!NOTE]</blockquote>
<blockquote>सर्वश्रेष्ठ परिणाम बोल्ड में दिखाए गए हैं। 0.3 से अधिक का अंतर न होने वाले स्कोर को एक ही स्तर का माना जाता है। DeepSeek-V3 अधिकांश बेंचमार्क पर सर्वश्रेष्ठ प्रदर्शन करता है, विशेष रूप से गणित और कोड कार्यों पर।</blockquote>
<blockquote>अधिक मूल्यांकन विवरण के लिए, कृपया हमारा पेपर देखें। </blockquote></p><p>#### संदर्भ विंडो
<p align="center">
  <img width="80%" src="figures/niah.png">
</p></p><p>`<code>Needle In A Haystack</code><code> (NIAH) परीक्षणों पर मूल्यांकन परिणाम। DeepSeek-V3 सभी संदर्भ विंडो लंबाई (context window lengths) में <strong>128K</strong> तक अच्छा प्रदर्शन करता है।</p><h3>चैट मॉडल</h3>
#### मानक बेंचमार्क (67B से बड़े मॉडल)
<div align="center"></p><p>| | <strong>बेंचमार्क (मेट्रिक)</strong> | <strong>DeepSeek V2-0506</strong> | <strong>DeepSeek V2.5-0905</strong> | <strong>Qwen2.5 72B-Inst.</strong> | <strong>Llama3.1 405B-Inst.</strong> | <strong>Claude-3.5-Sonnet-1022</strong> | <strong>GPT-4o 0513</strong> | <strong>DeepSeek V3</strong> |
|---|---------------------|---------------------|----------------------|---------------------|----------------------|---------------------------|----------------|----------------|
| | आर्किटेक्चर | MoE | MoE | Dense | Dense | - | - | MoE |
| | #सक्रिय पैरामीटर्स | 21B | 21B | 72B | 405B | - | - | 37B |
| | #कुल पैरामीटर्स | 236B | 236B | 72B | 405B | - | - | 671B |
| अंग्रेज़ी | MMLU (EM) | 78.2 | 80.6 | 85.3 | <strong>88.6</strong> | <strong>88.3</strong> | 87.2 | <strong>88.5</strong> |
| | MMLU-Redux (EM) | 77.9 | 80.3 | 85.6 | 86.2 | <strong>88.9</strong> | 88.0 | <strong>89.1</strong> |
| | MMLU-Pro (EM) | 58.5 | 66.2 | 71.6 | 73.3 | <strong>78.0</strong> | 72.6 | 75.9 |
| | DROP (3-shot F1) | 83.0 | 87.8 | 76.7 | 88.7 | 88.3 | 83.7 | <strong>91.6</strong> |
| | IF-Eval (Prompt Strict) | 57.7 | 80.6 | 84.1 | 86.0 | <strong>86.5</strong> | 84.3 | 86.1 |
| | GPQA-Diamond (Pass@1) | 35.3 | 41.3 | 49.0 | 51.1 | <strong>65.0</strong> | 49.9 | 59.1 |
| | SimpleQA (Correct) | 9.0 | 10.2 | 9.1 | 17.1 | 28.4 | <strong>38.2</strong> | 24.9 |
| | FRAMES (सटीकता) | 66.9 | 65.4 | 69.8 | 70.0 | 72.5 | <strong>80.5</strong> | 73.3 |
| | LongBench v2 (सटीकता) | 31.6 | 35.4 | 39.4 | 36.1 | 41.0 | 48.1 | <strong>48.7</strong> |
| कोड | HumanEval-Mul (Pass@1) | 69.3 | 77.4 | 77.3 | 77.2 | 81.7 | 80.5 | <strong>82.6</strong> |
| | LiveCodeBench (Pass@1-COT) | 18.8 | 29.2 | 31.1 | 28.4 | 36.3 | 33.4 | <strong>40.5</strong> |
| | LiveCodeBench (Pass@1) | 20.3 | 28.4 | 28.7 | 30.1 | 32.8 | 34.2 | <strong>37.6</strong> |
| | Codeforces (प्रतिशत) | 17.5 | 35.6 | 24.8 | 25.3 | 20.3 | 23.6 | <strong>51.6</strong> |
| | SWE Verified (Resolved) | - | 22.6 | 23.8 | 24.5 | <strong>50.8</strong> | 38.8 | 42.0 |
| | Aider-Edit (सटीकता) | 60.3 | 71.6 | 65.4 | 63.9 | <strong>84.2</strong> | 72.9 | 79.7 |
| | Aider-Polyglot (सटीकता) | - | 18.2 | 7.6 | 5.8 | 45.3 | 16.0 | <strong>49.6</strong> |
| गणित | AIME 2024 (Pass@1) | 4.6 | 16.7 | 23.3 | 23.3 | 16.0 | 9.3 | <strong>39.2</strong> |
| | MATH-500 (EM) | 56.3 | 74.7 | 80.0 | 73.8 | 78.3 | 74.6 | <strong>90.2</strong> |
| | CNMO 2024 (Pass@1) | 2.8 | 10.8 | 15.9 | 6.8 | 13.1 | 10.8 | <strong>43.2</strong> |
| चीनी | CLUEWSC (EM) | 89.9 | 90.4 | <strong>91.4</strong> | 84.7 | 85.4 | 87.9 | 90.9 |
| | C-Eval (EM) | 78.6 | 79.5 | 86.1 | 61.5 | 76.7 | 76.0 | <strong>86.5</strong> |
| | C-SimpleQA (सही) | 48.5 | 54.1 | 48.4 | 50.4 | 51.3 | 59.3 | <strong>64.8</strong> |</p><p></div></p><blockquote>[!NOTE]</blockquote>
<blockquote>सभी मॉडलों का मूल्यांकन एक कॉन्फ़िगरेशन में किया गया है जो आउटपुट लंबाई को 8K तक सीमित करता है। 1000 से कम सैंपल वाले बेंचमार्क को मजबूत अंतिम परिणाम प्राप्त करने के लिए कई बार विभिन्न तापमान सेटिंग्स के साथ परीक्षण किया जाता है। DeepSeek-V3 सबसे अच्छा प्रदर्शन करने वाला ओपन-सोर्स मॉडल है, और अग्रणी क्लोज्ड-सोर्स मॉडलों के मुकाबले भी प्रतिस्पर्धी प्रदर्शन दिखाता है।</blockquote></p><p>####  ओपन एंडेड जनरेशन मूल्यांकन</p><p><div align="center"></p><p>| मॉडल | Arena-Hard | AlpacaEval 2.0 |
|-------|------------|----------------|
| DeepSeek-V2.5-0905 | 76.2 | 50.5 |
| Qwen2.5-72B-Instruct | 81.2 | 49.1 |
| LLaMA-3.1 405B | 69.3 | 40.5 |
| GPT-4o-0513 | 80.4 | 51.1 |
| Claude-Sonnet-3.5-1022 | 85.2 | 52.0 |
| DeepSeek-V3 | <strong>85.5</strong> | <strong>70.0</strong> |</p><p></div></p><blockquote>[!NOTE]</blockquote>
<blockquote>अंग्रेज़ी ओपन-एंडेड संवाद मूल्यांकन। AlpacaEval 2.0 के लिए, हम मेट्रिक के रूप में लंबाई-नियंत्रित जीत दर (win rate) का उपयोग करते हैं।</blockquote></p><h2>5. चैट वेबसाइट और एपीआई प्लेटफॉर्म</h2>
आप DeepSeek-V3 के साथ DeepSeek की आधिकारिक वेबसाइट पर चैट कर सकते हैं: <a href="https://chat.deepseek.com/sign_in" target="_blank" rel="noopener noreferrer">chat.deepseek.com</a></p><p>हम DeepSeek प्लेटफॉर्म पर OpenAI-संगत एपीआई भी प्रदान करते हैं: <a href="https://platform.deepseek.com/" target="_blank" rel="noopener noreferrer">platform.deepseek.com</a></p><h2>6. स्थानीय रूप से कैसे चलाएं</h2></p><p>DeepSeek-V3 को निम्नलिखित हार्डवेयर और ओपन-सोर्स समुदाय सॉफ़्टवेयर का उपयोग करके स्थानीय रूप से तैनात किया जा सकता है:</p><ul><li><strong>DeepSeek-Infer डेमो</strong>: हम FP8 और BF16 अनुमान के लिए एक सरल और हल्का डेमो प्रदान करते हैं।</li>
<li><strong>SGLang</strong>: BF16 और FP8 दोनों अनुमान मोड में DeepSeek-V3 मॉडल का पूर्ण समर्थन करता है, मल्टी-टोकन प्रेडिक्शन <a href="https://github.com/sgl-project/sglang/issues/2591" target="_blank" rel="noopener noreferrer">जल्द आ रहा है</a>।</li>
<li><strong>LMDeploy</strong>: स्थानीय और क्लाउड तैनाती के लिए कुशल FP8 और BF16 अनुमान सक्षम करता है।</li>
<li><strong>TensorRT-LLM</strong>: वर्तमान में BF16 अनुमान और INT4/8 क्वांटाइजेशन का समर्थन करता है, FP8 समर्थन जल्द आ रहा है।</li>
<li><strong>vLLM</strong>: टेन्सर पैरेलिज़्म और पाइपलाइन पैरेलिज़्म के लिए FP8 और BF16 मोड के साथ DeepSeek-V3 मॉडल का समर्थन करता है।</li>
<li><strong>LightLLM</strong>: FP8 और BF16 के लिए कुशल सिंगल-नोड या मल्टी-नोड तैनाती का समर्थन करता है।</li>
<li><strong>AMD GPU</strong>: SGLang के माध्यम से BF16 और FP8 दोनों मोड में DeepSeek-V3 मॉडल को AMD GPU पर चलाने में सक्षम बनाता है।</li>
<li><strong>Huawei Ascend NPU</strong>: Huawei Ascend डिवाइसेज पर DeepSeek-V3 चलाने का समर्थन करता है।</li></p><p></ul>चूंकि हमारे फ्रेमवर्क में FP8 प्रशिक्षण मूल रूप से अपनाया गया है, हम केवल FP8 वेट्स प्रदान करते हैं। यदि आप प्रयोग के लिए BF16 वेट्स की आवश्यकता रखते हैं, तो आप प्रदान किए गए कन्वर्ज़न स्क्रिप्ट का उपयोग करके रूपांतरण कर सकते हैं।</p><p>यहाँ FP8 वेट्स को BF16 में बदलने का एक उदाहरण है:</p><pre><code class="language-shell">cd inference
python fp8_cast_bf16.py --input-fp8-hf-path /path/to/fp8_weights --output-bf16-hf-path /path/to/bf16_weights</code></pre></p><blockquote>[!NOTE]</blockquote>
<blockquote>Hugging Face का Transformers अभी सीधे समर्थित नहीं है।</blockquote></p><h3>6.1 DeepSeek-Infer डेमो के साथ अनुमान (केवल उदाहरण)</h3></p><p>#### सिस्टम आवश्यकताएँ</p><blockquote>[!NOTE] </blockquote>
<blockquote>केवल Linux और Python 3.10। Mac और Windows समर्थित नहीं हैं।</blockquote></p><p>डिपेंडेंसी:
</code>`<code>pip-requirements
torch==2.4.1
triton==3.0.0
transformers==4.46.3
safetensors==0.4.5
<pre><code class="language-">#### मॉडल वेट्स और डेमो कोड तैयारी</p><p>सबसे पहले, हमारे DeepSeek-V3 GitHub रिपॉजिटरी को क्लोन करें:
</code></pre>shell
git clone https://github.com/deepseek-ai/DeepSeek-V3.git
<pre><code class="language-">
</code>inference<code> फ़ोल्डर में जाएँ और </code>requirements.txt<code> में सूचीबद्ध डिपेंडेंसी इंस्टॉल करें। सबसे आसान तरीका है </code>conda<code> या </code>uv<code> जैसे पैकेज मैनेजर का उपयोग करके नया वर्चुअल एनवायरनमेंट बनाना और डिपेंडेंसी इंस्टॉल करना।
</code></pre>shell
cd DeepSeek-V3/inference
pip install -r requirements.txt
<pre><code class="language-">
मॉडल वेट्स Hugging Face से डाउनलोड करें, और उन्हें </code>/path/to/DeepSeek-V3<code> फ़ोल्डर में रखें।</p><p>#### मॉडल वेट्स कन्वर्ज़न</p><p>Hugging Face मॉडल वेट्स को विशिष्ट प्रारूप में बदलें:
</code></pre>shell
python convert.py --hf-ckpt-path /path/to/DeepSeek-V3 --save-path /path/to/DeepSeek-V3-Demo --n-experts 256 --model-parallel 16
<pre><code class="language-">
#### चलाएँ</p><p>फिर आप DeepSeek-V3 के साथ चैट कर सकते हैं:
</code></pre>shell
torchrun --nnodes 2 --nproc-per-node 8 --node-rank $RANK --master-addr $ADDR generate.py --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --interactive --temperature 0.7 --max-new-tokens 200
<pre><code class="language-">
या किसी दिए गए फ़ाइल पर बैच अनुमान करें:
</code></pre>shell
torchrun --nnodes 2 --nproc-per-node 8 --node-rank $RANK --master-addr $ADDR generate.py --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --input-file $FILE
<pre><code class="language-">
<h3>6.2 SGLang के साथ अनुमान (अनुशंसित)</h3></p><p><a href="https://github.com/sgl-project/sglang" target="_blank" rel="noopener noreferrer">SGLang</a> वर्तमान में <a href="https://lmsys.org/blog/2024-09-04-sglang-v0-3/#deepseek-multi-head-latent-attention-mla-throughput-optimizations" target="_blank" rel="noopener noreferrer">MLA अनुकूलन</a>, <a href="https://lmsys.org/blog/2024-12-04-sglang-v0-4/#data-parallelism-attention-for-deepseek-models" target="_blank" rel="noopener noreferrer">DP Attention</a>, FP8 (W8A8), FP8 KV Cache, और Torch Compile का समर्थन करता है, जिससे ओपन-सोर्स फ्रेमवर्क्स में अत्याधुनिक लेटेंसी और थ्रूपुट प्रदर्शन मिलता है।</p><p>विशेष रूप से, <a href="https://github.com/sgl-project/sglang/releases/tag/v0.4.1" target="_blank" rel="noopener noreferrer">SGLang v0.4.1</a> <strong>NVIDIA और AMD GPU</strong> दोनों पर DeepSeek-V3 चलाने का पूर्ण समर्थन करता है, जिससे यह एक अत्यंत बहुमुखी और मजबूत समाधान बनता है।</p><p>SGLang <a href="https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3#example-serving-with-2-h208" target="_blank" rel="noopener noreferrer">मल्टी-नोड टेन्सर पैरेलिज़्म</a> का भी समर्थन करता है, जिससे आप इस मॉडल को कई नेटवर्क-कनेक्टेड मशीनों पर चला सकते हैं।</p><p>मल्टी-टोकन प्रेडिक्शन (MTP) विकासाधीन है, और प्रगति को <a href="https://github.com/sgl-project/sglang/issues/2591" target="_blank" rel="noopener noreferrer">ऑप्टिमाइज़ेशन प्लान</a> में ट्रैक किया जा सकता है।</p><p>यहाँ SGLang टीम से लॉन्च निर्देश दिए गए हैं: https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3</p><h3>6.3 LMDeploy के साथ अनुमान (अनुशंसित)</h3>
<a href="https://github.com/InternLM/lmdeploy" target="_blank" rel="noopener noreferrer">LMDeploy</a>, एक लचीला और उच्च प्रदर्शन वाला अनुमान एवं सर्विंग फ्रेमवर्क, अब DeepSeek-V3 का समर्थन करता है। यह ऑफ़लाइन पाइपलाइन प्रोसेसिंग और ऑनलाइन तैनाती दोनों क्षमताएँ प्रदान करता है, और PyTorch-आधारित वर्कफ़्लो के साथ सहज एकीकरण करता है।</p><p>DeepSeek-V3 को LMDeploy के साथ चलाने के लिए चरण-दर-चरण निर्देशों के लिए, कृपया यहाँ देखें: https://github.com/InternLM/lmdeploy/issues/2960</p><h3>6.4 TRT-LLM के साथ अनुमान (अनुशंसित)</h3></p><p><a href="https://github.com/NVIDIA/TensorRT-LLM" target="_blank" rel="noopener noreferrer">TensorRT-LLM</a> अब DeepSeek-V3 मॉडल का समर्थन करता है, जिसमें BF16 और INT4/INT8 वेट-ओनली सटीकता विकल्प उपलब्ध हैं। FP8 का समर्थन विकासाधीन है और जल्द ही जारी किया जाएगा। आप DeepSeek-V3 समर्थन के लिए TRTLLM की कस्टम ब्रांच यहाँ देख सकते हैं: https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/deepseek_v3.</p><h3>6.5 vLLM के साथ अनुमान (अनुशंसित)</h3></p><p><a href="https://github.com/vllm-project/vllm" target="_blank" rel="noopener noreferrer">vLLM</a> v0.6.6 NVIDIA और AMD GPU दोनों पर FP8 और BF16 मोड के लिए DeepSeek-V3 अनुमान का समर्थन करता है। मानक तकनीकों के अलावा, vLLM _pipeline parallelism_ भी प्रदान करता है जिससे आप इस मॉडल को नेटवर्क से जुड़े कई मशीनों पर चला सकते हैं। विस्तृत मार्गदर्शन के लिए, कृपया <a href="https://docs.vllm.ai/en/latest/serving/distributed_serving.html" target="_blank" rel="noopener noreferrer">vLLM निर्देश</a> देखें। आप <a href="https://github.com/vllm-project/vllm/issues/11539" target="_blank" rel="noopener noreferrer">enhancement plan</a> को भी फॉलो कर सकते हैं।</p><h3>6.6 LightLLM के साथ अनुमान (अनुशंसित)</h3></p><p><a href="https://github.com/ModelTC/lightllm/tree/main" target="_blank" rel="noopener noreferrer">LightLLM</a> v1.0.1 DeepSeek-R1 (FP8/BF16) के लिए सिंगल-मशीन और मल्टी-मशीन टेन्सर पैरेलल तैनाती का समर्थन करता है और मिक्स्ड-प्रिसिजन तैनाती प्रदान करता है, साथ में अधिक क्वांटाइजेशन मोड लगातार एकीकृत किए जा रहे हैं। अधिक विवरण के लिए <a href="https://lightllm-en.readthedocs.io/en/latest/getting_started/quickstart.html" target="_blank" rel="noopener noreferrer">LightLLM निर्देश</a> देखें। साथ ही, LightLLM DeepSeek-V2 के लिए PD-disaggregation तैनाती प्रदान करता है, और DeepSeek-V3 के लिए PD-disaggregation विकासाधीन है।</p><h3>6.7 AMD GPU के साथ अनुशंसित अनुमान कार्यक्षमता</h3></p><p>AMD टीम के सहयोग से, हमने SGLang का उपयोग करते हुए AMD GPU के लिए Day-One समर्थन प्राप्त किया है, जिसमें FP8 और BF16 दोनों सटीकता के लिए पूरी संगतता है। विस्तृत मार्गदर्शन के लिए, कृपया <a href="#63-inference-with-lmdeploy-recommended" target="_blank" rel="noopener noreferrer">SGLang निर्देश</a> देखें।</p><h3>6.8 Huawei Ascend NPUs के साथ अनुशंसित अनुमान कार्यक्षमता</h3>
Huawei Ascend समुदाय के <a href="https://www.hiascend.com/en/software/mindie" target="_blank" rel="noopener noreferrer">MindIE</a> फ्रेमवर्क ने DeepSeek-V3 के BF16 संस्करण को सफलतापूर्वक अनुकूलित किया है। Ascend NPUs पर चरण-दर-चरण मार्गदर्शन के लिए, कृपया <a href="https://modelers.cn/models/MindIE/deepseekv3" target="_blank" rel="noopener noreferrer">यहाँ दिए गए निर्देश</a> का अनुसरण करें।</p><h2>7. लाइसेंस</h2>
यह कोड रिपॉजिटरी <a href="LICENSE-CODE" target="_blank" rel="noopener noreferrer">MIT लाइसेंस</a> के अंतर्गत लाइसेंस प्राप्त है। DeepSeek-V3 Base/Chat मॉडलों का उपयोग <a href="LICENSE-MODEL" target="_blank" rel="noopener noreferrer">मॉडल लाइसेंस</a> के अधीन है। DeepSeek-V3 श्रृंखला (Base और Chat सहित) व्यावसायिक उपयोग का समर्थन करती है।</p><h2>8. संदर्भ</code></pre></h2>
@misc{deepseekai2024deepseekv3technicalreport,
      title={DeepSeek-V3 Technical Report}, 
      author={DeepSeek-AI},
      year={2024},
      eprint={2412.19437},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.19437}, 
}
</code>``</p><h2>9. संपर्क</h2>
यदि आपके कोई प्रश्न हैं, तो कृपया एक issue दर्ज करें या हमसे संपर्क करें: <a href="service@deepseek.com" target="_blank" rel="noopener noreferrer">service@deepseek.com</a>

---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-07-24 
    </div>
    
</body>
</html>