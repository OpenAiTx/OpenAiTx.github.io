<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DeepSeek-V3 - Read DeepSeek-V3 documentation in Vietnamese. This project has 0 stars on GitHub.</title>
    <meta name="description" content="Read DeepSeek-V3 documentation in Vietnamese. This project has 0 stars on GitHub.">
    <meta name="keywords" content="DeepSeek-V3, Vietnamese, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "DeepSeek-V3",
  "description": "Read DeepSeek-V3 documentation in Vietnamese. This project has 0 stars on GitHub.",
  "author": {
    "@type": "Person",
    "name": "deepseek-ai"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 0
  },
  "url": "https://OpenAiTx.github.io/projects/deepseek-ai/DeepSeek-V3/README-vi.html",
  "sameAs": "https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/master/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/deepseek-ai/DeepSeek-V3" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    DeepSeek-V3
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 0 stars</span>
                <span class="language">Vietnamese</span>
                <span>by deepseek-ai</span>
            </div>
        </div>
        
        <div class="content">
            <p><!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable html -->
<!-- markdownlint-disable no-duplicate-header --></p><p><div align="center">
  <img src="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true" width="60%" alt="DeepSeek-V3" />
</div>
<hr>
<div align="center" style="line-height: 1;">
  <a href="https://www.deepseek.com/"><img alt="Homepage"
    src="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true"/></a>
  <a href="https://chat.deepseek.com/"><img alt="Chat"
    src="https://img.shields.io/badge/🤖%20Chat-DeepSeek%20V3-536af5?color=536af5&logoColor=white"/></a>
  <a href="https://huggingface.co/deepseek-ai"><img alt="Hugging Face"
    src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white"/></a>
  <br>
  <a href="https://discord.gg/Tc7c45Zzu5"><img alt="Discord"
    src="https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da"/></a>
  <a href="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true"><img alt="Wechat"
    src="https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white"/></a>
  <a href="https://twitter.com/deepseek_ai"><img alt="Twitter Follow"
    src="https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white"/></a>
  <br>
  <a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-CODE"><img alt="Code License"
    src="https://img.shields.io/badge/Code_License-MIT-f5de53?&color=f5de53"/></a>
  <a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-MODEL"><img alt="Model License"
    src="https://img.shields.io/badge/Model_License-Model_Agreement-f5de53?&color=f5de53"/></a>
  <br>
  <a href="https://arxiv.org/pdf/2412.19437"><b>Paper Link</b>👁️</a>
</div></p><h2>Mục lục</h2></p><ul><li><a href="#1-giới-thiệu" target="_blank" rel="noopener noreferrer">Giới thiệu</a></li>
<li><a href="#2-tóm-tắt-mô-hình" target="_blank" rel="noopener noreferrer">Tóm tắt mô hình</a></li>
<li><a href="#3-tải-xuống-mô-hình" target="_blank" rel="noopener noreferrer">Tải xuống mô hình</a></li>
<li><a href="#4-kết-quả-đánh-giá" target="_blank" rel="noopener noreferrer">Kết quả đánh giá</a></li>
<li><a href="#5-trang-web-chat--nền-tảng-api" target="_blank" rel="noopener noreferrer">Trang web Chat & Nền tảng API</a></li>
<li><a href="#6-chạy-cục-bộ" target="_blank" rel="noopener noreferrer">Chạy cục bộ</a></li>
<li><a href="#7-giấy-phép" target="_blank" rel="noopener noreferrer">Giấy phép</a></li>
<li><a href="#8-trích-dẫn" target="_blank" rel="noopener noreferrer">Trích dẫn</a></li>
<li><a href="#9-liên-hệ" target="_blank" rel="noopener noreferrer">Liên hệ</a></li></p><p>
</ul><h2>1. Giới thiệu</h2></p><p>Chúng tôi giới thiệu DeepSeek-V3, một mô hình ngôn ngữ Mixture-of-Experts (MoE) mạnh mẽ với tổng số 671 tỷ tham số, trong đó 37 tỷ tham số được kích hoạt cho mỗi token.  
Để đạt được suy luận hiệu quả và huấn luyện tiết kiệm chi phí, DeepSeek-V3 áp dụng kiến trúc Multi-head Latent Attention (MLA) và DeepSeekMoE, đã được xác thực kỹ lưỡng trong DeepSeek-V2.  
Hơn nữa, DeepSeek-V3 tiên phong với chiến lược cân bằng tải không cần auxiliary-loss và đặt mục tiêu huấn luyện dự đoán đa token (multi-token prediction) nhằm nâng cao hiệu suất.  
Chúng tôi huấn luyện sơ bộ DeepSeek-V3 trên 14,8 nghìn tỷ token đa dạng và chất lượng cao, sau đó tiến hành các giai đoạn Fine-Tuning Giám sát và Học tăng cường để khai thác tối đa khả năng của mô hình.  
Các đánh giá toàn diện cho thấy DeepSeek-V3 vượt trội hơn các mô hình mã nguồn mở khác và đạt hiệu năng tương đương với các mô hình mã nguồn đóng hàng đầu.  
Mặc dù đạt hiệu suất xuất sắc, DeepSeek-V3 chỉ cần 2,788 triệu giờ GPU H800 cho toàn bộ quá trình huấn luyện.  
Ngoài ra, quá trình huấn luyện của mô hình này rất ổn định.  
Trong suốt quá trình huấn luyện, chúng tôi không gặp phải bất kỳ sự cố mất mát không thể phục hồi nào hoặc phải rollback.  
<p align="center">
  <img width="80%" src="figures/benchmark.png">
</p></p><h2>2. Tóm tắt mô hình</h2></p><hr></p><p><strong>Kiến trúc: Chiến lược cân bằng tải và mục tiêu huấn luyện đột phá</strong></p><ul><li>Dựa trên kiến trúc hiệu quả của DeepSeek-V2, chúng tôi tiên phong với chiến lược cân bằng tải không cần auxiliary-loss, giúp giảm thiểu suy giảm hiệu suất phát sinh từ việc cân bằng tải.</li>
<li>Chúng tôi nghiên cứu mục tiêu Dự đoán Đa Token (Multi-Token Prediction - MTP) và chứng minh lợi ích của nó đối với hiệu suất mô hình.  </li>
    </ul>Nó cũng có thể được sử dụng cho quá trình suy luận gia tốc (speculative decoding).</p><hr></p><p><strong>Huấn luyện sơ bộ: Hướng tới hiệu quả tối ưu</strong></p><ul><li>Chúng tôi thiết kế khung huấn luyện hỗn hợp chính xác FP8 và lần đầu tiên xác thực tính khả thi cũng như hiệu quả của huấn luyện FP8 trên mô hình siêu lớn.  </li>
<li>Thông qua đồng thiết kế thuật toán, framework và phần cứng, chúng tôi vượt qua nút thắt cổ chai truyền thông trong huấn luyện MoE đa node, gần như đạt được sự chồng lấp hoàn toàn giữa tính toán và truyền thông.  </li>
  </ul>Điều này nâng cao hiệu quả huấn luyện và giảm chi phí, cho phép mở rộng quy mô mô hình mà không tăng thêm chi phí.  
<ul><li>Với chi phí chỉ 2,664 triệu giờ GPU H800, chúng tôi hoàn tất huấn luyện sơ bộ DeepSeek-V3 trên 14,8T token, tạo ra mô hình nền tảng mã nguồn mở mạnh nhất hiện nay. Các giai đoạn huấn luyện tiếp theo chỉ cần thêm 0,1 triệu giờ GPU.</li></p><p></ul>---</p><p><strong>Sau huấn luyện: Chưng cất tri thức từ DeepSeek-R1</strong></p><ul><li>Chúng tôi giới thiệu phương pháp sáng tạo để chưng cất khả năng suy luận từ mô hình Chain-of-Thought (CoT) chuỗi dài, cụ thể từ một trong các mô hình dòng DeepSeek R1, vào các LLM chuẩn, đặc biệt là DeepSeek-V3. Quy trình của chúng tôi tích hợp khéo léo các mẫu xác minh và phản chiếu của R1 vào DeepSeek-V3, cải thiện đáng kể hiệu suất suy luận. Đồng thời, chúng tôi cũng kiểm soát được phong cách và độ dài đầu ra của DeepSeek-V3.</li></p><p></ul>---</p><h2>3. Tải xuống mô hình</h2></p><p><div align="center"></p><p>| <strong>Mô hình</strong> | <strong>#Tổng tham số</strong> | <strong>#Tham số kích hoạt</strong> | <strong>Chiều dài ngữ cảnh</strong> | <strong>Tải xuống</strong> |
| :------------: | :------------: | :------------: | :------------: | :------------: |
| DeepSeek-V3-Base | 671B | 37B | 128K   | <a href="https://huggingface.co/deepseek-ai/DeepSeek-V3-Base" target="_blank" rel="noopener noreferrer">🤗 Hugging Face</a>   |
| DeepSeek-V3   | 671B | 37B |  128K   | <a href="https://huggingface.co/deepseek-ai/DeepSeek-V3" target="_blank" rel="noopener noreferrer">🤗 Hugging Face</a>   |</p><p></div></p><blockquote>[!CHÚ Ý]</blockquote>
<blockquote>Tổng dung lượng các mô hình DeepSeek-V3 trên Hugging Face là 685B, bao gồm 671B trọng số mô hình chính và 14B trọng số của Module Multi-Token Prediction (MTP).</blockquote></p><p>Để đảm bảo hiệu năng tối ưu và tính linh hoạt, chúng tôi hợp tác với các cộng đồng mã nguồn mở và nhà cung cấp phần cứng để cung cấp nhiều phương thức chạy mô hình cục bộ. Tham khảo hướng dẫn từng bước tại Mục 6: <a href="#6-chạy-cục-bộ" target="_blank" rel="noopener noreferrer">Chạy cục bộ</a>.</p><p>Dành cho các nhà phát triển muốn tìm hiểu sâu hơn, hãy khám phá <a href="./README_WEIGHTS.md" target="_blank" rel="noopener noreferrer">README_WEIGHTS.md</a> để biết chi tiết về trọng số Mô hình chính và các Module Multi-Token Prediction (MTP). Lưu ý rằng hỗ trợ MTP hiện đang được phát triển tích cực trong cộng đồng, và chúng tôi hoan nghênh đóng góp, phản hồi của bạn.</p><h2>4. Kết quả đánh giá</h2>
<h3>Mô hình nền tảng (Base Model)</h3>
#### Bộ benchmark tiêu chuẩn</p><p><div align="center"></p><p>
|  | Benchmark (Metric) | # Shots | DeepSeek-V2 | Qwen2.5 72B | LLaMA3.1 405B | DeepSeek-V3 |
|---|-------------------|----------|--------|-------------|---------------|---------|
| | Architecture | - | MoE | Dense | Dense | MoE |
| | # Activated Params | - | 21B | 72B | 405B | 37B |
| | # Total Params | - | 236B | 72B | 405B | 671B |
| English | Pile-test (BPB) | - | 0.606 | 0.638 | <strong>0.542</strong> | 0.548 |
| | BBH (EM) | 3-shot | 78.8 | 79.8 | 82.9 | <strong>87.5</strong> |
| | MMLU (Acc.) | 5-shot | 78.4 | 85.0 | 84.4 | <strong>87.1</strong> |
| | MMLU-Redux (Acc.) | 5-shot | 75.6 | 83.2 | 81.3 | <strong>86.2</strong> |
| | MMLU-Pro (Acc.) | 5-shot | 51.4 | 58.3 | 52.8 | <strong>64.4</strong> |
| | DROP (F1) | 3-shot | 80.4 | 80.6 | 86.0 | <strong>89.0</strong> |
| | ARC-Easy (Acc.) | 25-shot | 97.6 | 98.4 | 98.4 | <strong>98.9</strong> |
| | ARC-Challenge (Acc.) | 25-shot | 92.2 | 94.5 | <strong>95.3</strong> | <strong>95.3</strong> |
| | HellaSwag (Acc.) | 10-shot | 87.1 | 84.8 | <strong>89.2</strong> | 88.9 |
| | PIQA (Acc.) | 0-shot | 83.9 | 82.6 | <strong>85.9</strong> | 84.7 |
| | WinoGrande (Acc.) | 5-shot | <strong>86.3</strong> | 82.3 | 85.2 | 84.9 |
| | RACE-Middle (Acc.) | 5-shot | 73.1 | 68.1 | <strong>74.2</strong> | 67.1 |
| | RACE-High (Acc.) | 5-shot | 52.6 | 50.3 | <strong>56.8</strong> | 51.3 |
| | TriviaQA (EM) | 5-shot | 80.0 | 71.9 | 82.7 | <strong>82.9</strong> |
| | NaturalQuestions (EM) | 5-shot | 38.6 | 33.2 | <strong>41.5</strong> | 40.0 |
| | AGIEval (Acc.) | 0-shot | 57.5 | 75.8 | 60.6 | <strong>79.6</strong> |
| Code | HumanEval (Pass@1) | 0-shot | 43.3 | 53.0 | 54.9 | <strong>65.2</strong> |
| | MBPP (Pass@1) | 3-shot | 65.0 | 72.6 | 68.4 | <strong>75.4</strong> |
| | LiveCodeBench-Base (Pass@1) | 3-shot | 11.6 | 12.9 | 15.5 | <strong>19.4</strong> |
| | CRUXEval-I (Acc.) | 2-shot | 52.5 | 59.1 | 58.5 | <strong>67.3</strong> |
| | CRUXEval-O (Acc.) | 2-shot | 49.8 | 59.9 | 59.9 | <strong>69.8</strong> |
| Math | GSM8K (EM) | 8-shot | 81.6 | 88.3 | 83.5 | <strong>89.3</strong> |
| | MATH (EM) | 4-shot | 43.4 | 54.4 | 49.0 | <strong>61.6</strong> |
| | MGSM (EM) | 8-shot | 63.6 | 76.2 | 69.9 | <strong>79.8</strong> |
| | CMath (EM) | 3-shot | 78.7 | 84.5 | 77.3 | <strong>90.7</strong> |
| Chinese | CLUEWSC (EM) | 5-shot | 82.0 | 82.5 | <strong>83.0</strong> | 82.7 |
| | C-Eval (Acc.) | 5-shot | 81.4 | 89.2 | 72.5 | <strong>90.1</strong> |
| | CMMLU (Acc.) | 5-shot | 84.0 | <strong>89.5</strong> | 73.7 | 88.8 |
| | CMRC (EM) | 1-shot | <strong>77.4</strong> | 75.8 | 76.0 | 76.3 |
| | C3 (Acc.) | 0-shot | 77.4 | 76.7 | <strong>79.7</strong> | 78.6 |
| | CCPM (Acc.) | 0-shot | <strong>93.0</strong> | 88.5 | 78.6 | 92.0 |
| Multilingual | MMMLU-non-English (Acc.) | 5-shot | 64.0 | 74.8 | 73.8 | <strong>79.4</strong> |</p><p></div></p><blockquote>[!CHÚ Ý]</blockquote>
<blockquote>Kết quả tốt nhất được in đậm. Các điểm số có chênh lệch không vượt quá 0,3 được coi là cùng mức. DeepSeek-V3 đạt hiệu năng tốt nhất trên phần lớn benchmark, đặc biệt ở các bài toán toán học và lập trình.</blockquote>
<blockquote>Tham khảo bài báo của chúng tôi để biết chi tiết đánh giá. </blockquote></p><p>#### Cửa sổ ngữ cảnh
<p align="center">
  <img width="80%" src="figures/niah.png">
</p></p><p>Kết quả đánh giá trên các bài kiểm tra `<code>Needle In A Haystack</code><code> (NIAH). DeepSeek-V3 hoạt động tốt ở tất cả các chiều dài cửa sổ ngữ cảnh lên tới <strong>128K</strong>.</p><h3>Mô hình Chat</h3>
#### Bộ benchmark tiêu chuẩn (Các mô hình lớn hơn 67B)
<div align="center"></p><p>| | <strong>Benchmark (Metric)</strong> | <strong>DeepSeek V2-0506</strong> | <strong>DeepSeek V2.5-0905</strong> | <strong>Qwen2.5 72B-Inst.</strong> | <strong>Llama3.1 405B-Inst.</strong> | <strong>Claude-3.5-Sonnet-1022</strong> | <strong>GPT-4o 0513</strong> | <strong>DeepSeek V3</strong> |
|---|---------------------|---------------------|----------------------|---------------------|----------------------|---------------------------|----------------|----------------|
| | Architecture | MoE | MoE | Dense | Dense | - | - | MoE |
| | # Activated Params | 21B | 21B | 72B | 405B | - | - | 37B |
| | # Total Params | 236B | 236B | 72B | 405B | - | - | 671B |
| English | MMLU (EM) | 78.2 | 80.6 | 85.3 | <strong>88.6</strong> | <strong>88.3</strong> | 87.2 | <strong>88.5</strong> |
| | MMLU-Redux (EM) | 77.9 | 80.3 | 85.6 | 86.2 | <strong>88.9</strong> | 88.0 | <strong>89.1</strong> |
| | MMLU-Pro (EM) | 58.5 | 66.2 | 71.6 | 73.3 | <strong>78.0</strong> | 72.6 | 75.9 |
| | DROP (3-shot F1) | 83.0 | 87.8 | 76.7 | 88.7 | 88.3 | 83.7 | <strong>91.6</strong> |
| | IF-Eval (Prompt Strict) | 57.7 | 80.6 | 84.1 | 86.0 | <strong>86.5</strong> | 84.3 | 86.1 |
| | GPQA-Diamond (Pass@1) | 35.3 | 41.3 | 49.0 | 51.1 | <strong>65.0</strong> | 49.9 | 59.1 |
| | SimpleQA (Correct) | 9.0 | 10.2 | 9.1 | 17.1 | 28.4 | <strong>38.2</strong> | 24.9 |
| | FRAMES (Acc.) | 66.9 | 65.4 | 69.8 | 70.0 | 72.5 | <strong>80.5</strong> | 73.3 |
| | LongBench v2 (Acc.) | 31.6 | 35.4 | 39.4 | 36.1 | 41.0 | 48.1 | <strong>48.7</strong> |
| Code | HumanEval-Mul (Pass@1) | 69.3 | 77.4 | 77.3 | 77.2 | 81.7 | 80.5 | <strong>82.6</strong> |
| | LiveCodeBench (Pass@1-COT) | 18.8 | 29.2 | 31.1 | 28.4 | 36.3 | 33.4 | <strong>40.5</strong> |
| | LiveCodeBench (Pass@1) | 20.3 | 28.4 | 28.7 | 30.1 | 32.8 | 34.2 | <strong>37.6</strong> |
| | Codeforces (Percentile) | 17.5 | 35.6 | 24.8 | 25.3 | 20.3 | 23.6 | <strong>51.6</strong> |
| | SWE Verified (Resolved) | - | 22.6 | 23.8 | 24.5 | <strong>50.8</strong> | 38.8 | 42.0 |
| | Aider-Edit (Acc.) | 60.3 | 71.6 | 65.4 | 63.9 | <strong>84.2</strong> | 72.9 | 79.7 |
| | Aider-Polyglot (Acc.) | - | 18.2 | 7.6 | 5.8 | 45.3 | 16.0 | <strong>49.6</strong> |
| Math | AIME 2024 (Pass@1) | 4.6 | 16.7 | 23.3 | 23.3 | 16.0 | 9.3 | <strong>39.2</strong> |
| | MATH-500 (EM) | 56.3 | 74.7 | 80.0 | 73.8 | 78.3 | 74.6 | <strong>90.2</strong> |
| | CNMO 2024 (Pass@1) | 2.8 | 10.8 | 15.9 | 6.8 | 13.1 | 10.8 | <strong>43.2</strong> |
| Chinese | CLUEWSC (EM) | 89.9 | 90.4 | <strong>91.4</strong> | 84.7 | 85.4 | 87.9 | 90.9 |
| | C-Eval (EM) | 78.6 | 79.5 | 86.1 | 61.5 | 76.7 | 76.0 | <strong>86.5</strong> |
| | C-SimpleQA (Correct) | 48.5 | 54.1 | 48.4 | 50.4 | 51.3 | 59.3 | <strong>64.8</strong> |</p><p></div></p><blockquote>[!CHÚ Ý]</blockquote>
<blockquote>Tất cả các mô hình được đánh giá với cấu hình giới hạn độ dài đầu ra ở mức 8K. Các benchmark có ít hơn 1000 mẫu sẽ được kiểm tra nhiều lần với các giá trị temperature khác nhau để đảm bảo kết quả cuối cùng ổn định. DeepSeek-V3 là mô hình mã nguồn mở có hiệu năng tốt nhất, đồng thời cạnh tranh mạnh với các mô hình mã nguồn đóng hàng đầu.</blockquote></p><p>
#### Đánh giá sinh đầu ra mở</p><p><div align="center"></p><p>| Mô hình | Arena-Hard | AlpacaEval 2.0 |
|-------|------------|----------------|
| DeepSeek-V2.5-0905 | 76.2 | 50.5 |
| Qwen2.5-72B-Instruct | 81.2 | 49.1 |
| LLaMA-3.1 405B | 69.3 | 40.5 |
| GPT-4o-0513 | 80.4 | 51.1 |
| Claude-Sonnet-3.5-1022 | 85.2 | 52.0 |
| DeepSeek-V3 | <strong>85.5</strong> | <strong>70.0</strong> |</p><p></div></p><blockquote>[!CHÚ Ý]</blockquote>
<blockquote>Đánh giá hội thoại tiếng Anh mở. Với AlpacaEval 2.0, chúng tôi sử dụng tỉ lệ thắng kiểm soát độ dài làm tiêu chí.</blockquote></p><h2>5. Trang web Chat & Nền tảng API</h2>
Bạn có thể trò chuyện với DeepSeek-V3 trên trang web chính thức của DeepSeek: <a href="https://chat.deepseek.com/sign_in" target="_blank" rel="noopener noreferrer">chat.deepseek.com</a></p><p>Chúng tôi cũng cung cấp API tương thích OpenAI tại DeepSeek Platform: <a href="https://platform.deepseek.com/" target="_blank" rel="noopener noreferrer">platform.deepseek.com</a></p><h2>6. Chạy cục bộ</h2></p><p>DeepSeek-V3 có thể triển khai cục bộ với các phần cứng và phần mềm mã nguồn mở sau:</p><ul><li><strong>DeepSeek-Infer Demo</strong>: Cung cấp demo nhẹ cho suy luận FP8 và BF16.</li>
<li><strong>SGLang</strong>: Hỗ trợ đầy đủ mô hình DeepSeek-V3 ở cả hai chế độ suy luận BF16 và FP8, Multi-Token Prediction <a href="https://github.com/sgl-project/sglang/issues/2591" target="_blank" rel="noopener noreferrer">sắp ra mắt</a>.</li>
<li><strong>LMDeploy</strong>: Cho phép suy luận hiệu quả FP8 và BF16 cho triển khai cục bộ và đám mây.</li>
<li><strong>TensorRT-LLM</strong>: Hiện hỗ trợ suy luận BF16 và lượng tử hóa INT4/8, hỗ trợ FP8 sẽ ra mắt sớm.</li>
<li><strong>vLLM</strong>: Hỗ trợ mô hình DeepSeek-V3 với chế độ FP8 và BF16 cho song song tensor và song song pipeline.</li>
<li><strong>LightLLM</strong>: Hỗ trợ triển khai đơn node hoặc đa node hiệu quả cho FP8 và BF16.</li>
<li><strong>AMD GPU</strong>: Cho phép chạy mô hình DeepSeek-V3 trên GPU AMD qua SGLang ở cả chế độ BF16 và FP8.</li>
<li><strong>Huawei Ascend NPU</strong>: Hỗ trợ chạy DeepSeek-V3 trên thiết bị Huawei Ascend.</li></p><p></ul>Vì huấn luyện FP8 được áp dụng gốc trong framework của chúng tôi, chúng tôi chỉ cung cấp trọng số FP8. Nếu bạn cần trọng số BF16 để thử nghiệm, hãy dùng script chuyển đổi đi kèm.</p><p>Ví dụ chuyển đổi trọng số FP8 sang BF16:</p><pre><code class="language-shell">cd inference
python fp8_cast_bf16.py --input-fp8-hf-path /path/to/fp8_weights --output-bf16-hf-path /path/to/bf16_weights</code></pre></p><blockquote>[!CHÚ Ý]</blockquote>
<blockquote>Hugging Face Transformers chưa được hỗ trợ trực tiếp.</blockquote></p><h3>6.1 Suy luận với DeepSeek-Infer Demo (chỉ là ví dụ)</h3></p><p>#### Yêu cầu hệ thống</p><blockquote>[!CHÚ Ý] </blockquote>
<blockquote>Chỉ hỗ trợ Linux với Python 3.10. Không hỗ trợ Mac và Windows.</blockquote></p><p>Phụ thuộc:
</code>`<code>pip-requirements
torch==2.4.1
triton==3.0.0
transformers==4.46.3
safetensors==0.4.5
<pre><code class="language-">#### Chuẩn bị trọng số mô hình & mã demo</p><p>Đầu tiên, clone kho GitHub DeepSeek-V3 của chúng tôi:
</code></pre>shell
git clone https://github.com/deepseek-ai/DeepSeek-V3.git
<pre><code class="language-">
Di chuyển tới thư mục </code>inference<code> và cài đặt các phụ thuộc trong </code>requirements.txt<code>. Cách dễ nhất là dùng trình quản lý như </code>conda<code> hoặc </code>uv<code> để tạo môi trường ảo mới và cài đặt phụ thuộc.
</code></pre>shell
cd DeepSeek-V3/inference
pip install -r requirements.txt
<pre><code class="language-">
Tải trọng số mô hình từ Hugging Face và đặt vào thư mục </code>/path/to/DeepSeek-V3<code>.</p><p>#### Chuyển đổi trọng số mô hình</p><p>Chuyển đổi trọng số mô hình Hugging Face sang định dạng cụ thể:
</code></pre>shell
python convert.py --hf-ckpt-path /path/to/DeepSeek-V3 --save-path /path/to/DeepSeek-V3-Demo --n-experts 256 --model-parallel 16
<pre><code class="language-">
#### Chạy</p><p>Bây giờ bạn có thể chat với DeepSeek-V3:
</code></pre>shell
torchrun --nnodes 2 --nproc-per-node 8 --node-rank $RANK --master-addr $ADDR generate.py --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --interactive --temperature 0.7 --max-new-tokens 200
<pre><code class="language-">
Hoặc suy luận hàng loạt trên file cho trước:
</code></pre>shell
torchrun --nnodes 2 --nproc-per-node 8 --node-rank $RANK --master-addr $ADDR generate.py --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --input-file $FILE
<pre><code class="language-">
<h3>6.2 Suy luận với SGLang (khuyến nghị)</h3></p><p><a href="https://github.com/sgl-project/sglang" target="_blank" rel="noopener noreferrer">SGLang</a> hiện hỗ trợ <a href="https://lmsys.org/blog/2024-09-04-sglang-v0-3/#deepseek-multi-head-latent-attention-mla-throughput-optimizations" target="_blank" rel="noopener noreferrer">tối ưu hóa MLA</a>, <a href="https://lmsys.org/blog/2024-12-04-sglang-v0-4/#data-parallelism-attention-for-deepseek-models" target="_blank" rel="noopener noreferrer">DP Attention</a>, FP8 (W8A8), FP8 KV Cache, và Torch Compile, mang lại độ trễ và thông lượng hàng đầu trong số các framework mã nguồn mở.</p><p>Đặc biệt, <a href="https://github.com/sgl-project/sglang/releases/tag/v0.4.1" target="_blank" rel="noopener noreferrer">SGLang v0.4.1</a> hỗ trợ đầy đủ chạy DeepSeek-V3 trên cả <strong>GPU NVIDIA và AMD</strong>, giúp giải pháp này rất linh hoạt và mạnh mẽ.</p><p>SGLang còn hỗ trợ <a href="https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3#example-serving-with-2-h208" target="_blank" rel="noopener noreferrer">song song tensor đa node</a>, cho phép bạn chạy mô hình này trên nhiều máy kết nối mạng.</p><p>Multi-Token Prediction (MTP) đang được phát triển, theo dõi tiến độ tại <a href="https://github.com/sgl-project/sglang/issues/2591" target="_blank" rel="noopener noreferrer">kế hoạch tối ưu hóa</a>.</p><p>Hướng dẫn khởi chạy từ nhóm SGLang: https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3</p><h3>6.3 Suy luận với LMDeploy (khuyến nghị)</h3>
<a href="https://github.com/InternLM/lmdeploy" target="_blank" rel="noopener noreferrer">LMDeploy</a>, framework suy luận và phục vụ hiệu suất cao, linh hoạt dành cho mô hình ngôn ngữ lớn, hiện hỗ trợ DeepSeek-V3. Cung cấp cả xử lý pipeline ngoại tuyến và triển khai trực tuyến, tích hợp mượt mà với workflow dựa trên PyTorch.</p><p>Hướng dẫn chi tiết từng bước sử dụng LMDeploy với DeepSeek-V3 tại: https://github.com/InternLM/lmdeploy/issues/2960</p><h3>6.4 Suy luận với TRT-LLM (khuyến nghị)</h3></p><p><a href="https://github.com/NVIDIA/TensorRT-LLM" target="_blank" rel="noopener noreferrer">TensorRT-LLM</a> hiện hỗ trợ mô hình DeepSeek-V3, cung cấp các tùy chọn chính xác như BF16 và INT4/INT8 weight-only. Hỗ trợ FP8 đang được phát triển và sẽ phát hành sớm. Bạn có thể truy cập branch tùy chỉnh TRTLLM dành riêng cho DeepSeek-V3 tại: https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/deepseek_v3. </p><h3>6.5 Suy luận với vLLM (khuyến nghị)</h3></p><p><a href="https://github.com/vllm-project/vllm" target="_blank" rel="noopener noreferrer">vLLM</a> v0.6.6 hỗ trợ suy luận DeepSeek-V3 cho chế độ FP8 và BF16 trên cả GPU NVIDIA và AMD. Ngoài các kỹ thuật tiêu chuẩn, vLLM cung cấp _pipeline parallelism_ giúp chạy mô hình trên nhiều máy nối mạng. Xem hướng dẫn chi tiết tại <a href="https://docs.vllm.ai/en/latest/serving/distributed_serving.html" target="_blank" rel="noopener noreferrer">vLLM instructions</a>. Theo dõi <a href="https://github.com/vllm-project/vllm/issues/11539" target="_blank" rel="noopener noreferrer">kế hoạch mở rộng</a>.</p><h3>6.6 Suy luận với LightLLM (khuyến nghị)</h3></p><p><a href="https://github.com/ModelTC/lightllm/tree/main" target="_blank" rel="noopener noreferrer">LightLLM</a> v1.0.1 hỗ trợ triển khai song song tensor một máy và nhiều máy cho DeepSeek-R1 (FP8/BF16) và cung cấp triển khai hỗn hợp chính xác, với nhiều chế độ lượng tử hóa liên tục được tích hợp. Xem chi tiết tại <a href="https://lightllm-en.readthedocs.io/en/latest/getting_started/quickstart.html" target="_blank" rel="noopener noreferrer">LightLLM instructions</a>. Ngoài ra, LightLLM cung cấp triển khai PD-disaggregation cho DeepSeek-V2, và phiên bản cho DeepSeek-V3 đang được phát triển.</p><h3>6.7 Suy luận khuyến nghị với GPU AMD</h3></p><p>Hợp tác với đội ngũ AMD, chúng tôi đã đạt hỗ trợ Day-One cho GPU AMD sử dụng SGLang, tương thích đầy đủ cả FP8 và BF16. Xem hướng dẫn chi tiết tại <a href="#63-inference-with-lmdeploy-recommended" target="_blank" rel="noopener noreferrer">SGLang instructions</a>.</p><h3>6.8 Suy luận khuyến nghị với Huawei Ascend NPU</h3>
Framework <a href="https://www.hiascend.com/en/software/mindie" target="_blank" rel="noopener noreferrer">MindIE</a> từ cộng đồng Huawei Ascend đã thích ứng thành công phiên bản BF16 của DeepSeek-V3. Hướng dẫn từng bước cho Ascend NPUs tại <a href="https://modelers.cn/models/MindIE/deepseekv3" target="_blank" rel="noopener noreferrer">đây</a>.</p><h2>7. Giấy phép</h2>
Kho mã nguồn này được cấp phép theo <a href="LICENSE-CODE" target="_blank" rel="noopener noreferrer">Giấy phép MIT</a>. Việc sử dụng các mô hình DeepSeek-V3 Base/Chat tuân theo <a href="LICENSE-MODEL" target="_blank" rel="noopener noreferrer">Giấy phép Mô hình</a>. Dòng DeepSeek-V3 (bao gồm Base và Chat) hỗ trợ sử dụng thương mại.</p><h2>8. Trích dẫn</code></pre></h2>
@misc{deepseekai2024deepseekv3technicalreport,
      title={DeepSeek-V3 Technical Report}, 
      author={DeepSeek-AI},
      year={2024},
      eprint={2412.19437},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.19437}, 
}
</code>``</p><h2>9. Liên hệ</h2>
Nếu bạn có bất kỳ câu hỏi nào, vui lòng tạo issue hoặc liên hệ với chúng tôi qua <a href="service@deepseek.com" target="_blank" rel="noopener noreferrer">service@deepseek.com</a>.</p><p>
---

<a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Powered By OpenAiTx</a>

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/deepseek-ai/DeepSeek-V3/master/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>