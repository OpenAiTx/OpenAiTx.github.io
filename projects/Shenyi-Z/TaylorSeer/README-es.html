<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TaylorSeer - [ICCV2025] De la Reutilizaci&#243;n a la Predicci&#243;n: Acelerando Modelos de Difusi&#243;n con TaylorSeers</title>
    <meta name="description" content="[ICCV2025] De la Reutilizaci&#243;n a la Predicci&#243;n: Acelerando Modelos de Difusi&#243;n con TaylorSeers">
    <meta name="keywords" content="TaylorSeer, Spanish, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TaylorSeer",
  "description": "[ICCV2025] De la Reutilización a la Predicción: Acelerando Modelos de Difusión con TaylorSeers",
  "author": {
    "@type": "Person",
    "name": "Shenyi-Z"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 241
  },
  "url": "https://OpenAiTx.github.io/projects/Shenyi-Z/TaylorSeer/README-es.html",
  "sameAs": "https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/Shenyi-Z/TaylorSeer" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TaylorSeer
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 241 stars</span>
                <span class="language">Spanish</span>
                <span>by Shenyi-Z</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align=center>
  
<h1>[ICCV 2025] <em>TaylorSeer</em>: De Reutilizar a Predecir: Acelerando Modelos de Difusión con <em>TaylorSeers</em></h1></p><p><p>
<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>
<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>
</p></p><p></div></p><h2>🔥 Noticias</h2></p><ul><li><code>2025/06/26</code> 💥💥 ¡TaylorSeer tiene el honor de ser aceptado en ICCV 2025!</li></p><p><li><code>2025/05/03</code> 🚀🚀 Se lanza TaylorSeer para HiDream.</li></p><p><li><code>2025/03/30</code> 🚀🚀 Se lanza TaylorSeer para Wan2.1.</li></p><p><li><code>2025/03/30</code> 🚀🚀 Los scripts de inferencia Diffusers para TaylorSeers y los scripts xDiT aplicables para inferencia paralela multi-GPU han sido lanzados oficialmente.</li></p><p></ul><em> <code>2025/03/10</code> 🚀🚀 ¡Nuestro trabajo más reciente "De Reutilizar a Predecir: Acelerando Modelos de Difusión con TaylorSeers" ha sido publicado! Los códigos están disponibles en <a href="https://github.com/Shenyi-Z/TaylorSeer" target="_blank" rel="noopener noreferrer">TaylorSeer</a>! TaylorSeer soporta compresión sin pérdidas a una tasa de 4.99x en FLUX.1-dev (con una aceleración en latencia de 3.53x) y aceleración de alta calidad a una tasa de compresión de 5.00x en HunyuanVideo (con una aceleración en latencia de 4.65x)! Esperamos que </em>TaylorSeer* pueda mover el paradigma de los métodos de caché de características de reutilización a predicción. Para más detalles, por favor consulte nuestro artículo de investigación más reciente.
<ul><li><code>2025/02/19</code> 🚀🚀 La solución ToCa para <strong>FLUX</strong> ha sido oficialmente lanzada tras ajustes, logrando ahora hasta <strong>3.14× aceleración sin pérdidas</strong> (en FLOPs)!</li>
<li><code>2025/01/22</code> 💥💥 ¡ToCa tiene el honor de ser aceptado en ICLR 2025!</li>
<li><code>2024/12/29</code> 🚀🚀 Publicamos nuestro trabajo <a href="https://arxiv.org/abs/2412.18911" target="_blank" rel="noopener noreferrer">DuCa</a> sobre la aceleración de transformadores de difusión GRATIS, que logra una aceleración casi sin pérdidas de <strong>2.50×</strong> en <a href="https://github.com/hpcaitech/Open-Sora" target="_blank" rel="noopener noreferrer">OpenSora</a>! 🎉 <strong>DuCa también supera la limitación de ToCa al soportar completamente FlashAttention, permitiendo una mayor compatibilidad y mejoras de eficiencia.</strong></li>
<li><code>2024/12/24</code> 🤗🤗 Publicamos un repositorio de código abierto "<a href="https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression" target="_blank" rel="noopener noreferrer">Awesome-Token-Reduction-for-Model-Compression</a>", que recopila recientes trabajos sobresalientes sobre reducción de tokens! ¡No dudes en contribuir con tus sugerencias!</li>
<li><code>2024/12/10</code> 💥💥 El trabajo reciente de nuestro equipo, <strong>SiTo</strong> (https://github.com/EvelynZhang-epiclab/SiTo), ha sido aceptado en <strong>AAAI 2025</strong>. Acelera modelos de difusión mediante <strong>Poda Adaptativa de Tokens</strong>.</li>
<li><code>2024/07/15</code> 🤗🤗 Publicamos un repositorio de código abierto "<a href="https://github.com/xuyang-liu16/Awesome-Generation-Acceleration" target="_blank" rel="noopener noreferrer">Awesome-Generation-Acceleration</a>", que recopila recientes trabajos sobresalientes sobre aceleración de generación! ¡No dudes en contribuir con tus sugerencias!</li></p><p></ul><details>
  <summary><strong>Resumen</strong></summary></p><p>  Los Transformadores de Difusión (DiT) han revolucionado la síntesis de imágenes y videos de alta fidelidad, pero sus demandas computacionales siguen siendo prohibitivas para aplicaciones en tiempo real. Para resolver este problema, se ha propuesto el caché de características para acelerar modelos de difusión almacenando las características en pasos de tiempo anteriores y reutilizándolas en los siguientes. Sin embargo, en pasos de tiempo con intervalos significativos, la similitud de características en modelos de difusión disminuye sustancialmente, lo que conduce a un aumento pronunciado en los errores introducidos por el caché de características, dañando significativamente la calidad de la generación. Para solucionar este problema, proponemos TaylorSeer, que primero demuestra que las características de los modelos de difusión en pasos de tiempo futuros pueden predecirse basándose en sus valores en pasos de tiempo anteriores. Basado en el hecho de que las características cambian lenta y continuamente a través de los pasos de tiempo, TaylorSeer emplea un método diferencial para aproximar las derivadas de orden superior de las características y predecir las características en pasos de tiempo futuros con la expansión en series de Taylor. Experimentos extensos demuestran su efectividad significativa tanto en síntesis de imágenes como de video, especialmente en altas tasas de aceleración. Por ejemplo, logra una aceleración casi sin pérdidas de 4.99 $\times$ en FLUX y 5.00 $\times$ en HunyuanVideo sin entrenamiento adicional. En DiT, logra un FID $3.41$ menor en comparación con el estado del arte previo con una aceleración de $4.53$ $\times$.</p><p></details></p><h2>🧩 Contribuciones de la Comunidad</h2></p><p>¡Gracias a todos los colaboradores de código abierto por su fuerte apoyo! ¡Nos encantaría saber de ti!</p><ul><li>ComfyUI-TaylorSeer-philipy1219 (Inferencia FP8 en FLUX, más modelos de video próximamente): <a href="https://github.com/philipy1219/ComfyUI-TaylorSeer" target="_blank" rel="noopener noreferrer">ComfyUI-TaylorSeer-philipy1219</a> por <a href="https://github.com/philipy1219" target="_blank" rel="noopener noreferrer">philipy1219</a>.</li></p><p></ul><h2>🛠 Instalación</h2></p><p>``<code> cmd
git clone https://github.com/Shenyi-Z/TaylorSeer.git
<pre><code class="language-">
<h2>TaylorSeer-FLUX</h2></p><p>TaylorSeer logró una compresión computacional sin pérdidas de 4.99 $\times$ y una aceleración de latencia de 3.53 $\times$ en FLUX.1-dev, medida por <a href="https://github.com/THUDM/ImageReward" target="_blank" rel="noopener noreferrer">ImageReward</a> para calidad integral. Para ejecutar TaylorSeer-FLUX, consulte <a href="https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md" target="_blank" rel="noopener noreferrer">TaylorSeer-FLUX</a>.</p><p>Además, hemos proporcionado ejemplos de scripts de inferencia para la <strong>versión diffusers</strong>, así como scripts de inferencia paralela multi-GPU <strong>xDiT</strong>. También puede realizar pruebas basadas en ellos, ubicados en <a href="./TaylorSeers-Diffusers " target="_blank" rel="noopener noreferrer">TaylorSeers-Diffusers</a> y <a href="./TaylorSeers-xDiT" target="_blank" rel="noopener noreferrer">TaylorSeers-xDiT</a> respectivamente.</p><h2>TaylorSeer-HunyuanVideo</h2></p><p>TaylorSeer logró una compresión computacional de 5.00 $\times$ y una notable aceleración de latencia de 4.65 $\times$ en HunyuanVideo, medida integralmente por la métrica <a href="https://github.com/Vchitect/VBench" target="_blank" rel="noopener noreferrer">VBench</a>. En comparación con métodos anteriores, demostró mejoras significativas tanto en eficiencia de aceleración como en calidad. Para ejecutar TaylorSeer-HunyuanVideo, consulte <a href="https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md" target="_blank" rel="noopener noreferrer">TaylorSeer-HunyuanVideo</a>.</p><p>Además, nuestros scripts también soportan aceleración paralela multi-GPU implementada por HunyuanVideo usando xDiT. En este caso, el efecto de aceleración aportado por la caché y el efecto de aceleración del paralelismo multi-GPU son independientes entre sí y se multiplican, logrando efectos de aceleración extremadamente altos.</p><h2>TayorSeer-DiT</h2></p><p>TaylorSeer logró una compresión computacional sin pérdidas de 2.77 $\times$ en el modelo base DiT, evaluado integralmente por métricas como FID. Su rendimiento en varios ratios de aceleración superó significativamente a métodos anteriores. Por ejemplo, en un escenario extremo con una relación de compresión de 4.53 $\times$, el FID de TaylorSeer solo aumentó 0.33 respecto a la línea base sin acelerar de 2.32, alcanzando 2.65, mientras que ToCa y DuCa exhibieron puntuaciones FID superiores a 6.0 bajo las mismas condiciones. Para ejecutar TaylorSeer-DiT, consulte <a href="https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md" target="_blank" rel="noopener noreferrer">TaylorSeer-DiT</a>.</p><h2>TaylorSeer-Wan2.1</h2></p><p>Implementamos el método de aceleración TaylorSeer en Wan2.1, con soporte para inferencia paralela multi-GPU. Los comandos de instalación e inferencia para TaylorSeer-Wan2.1 son totalmente compatibles con los de Wan2.1. Para ejecutar TaylorSeer-Wan2.1, consulte <a href="https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md" target="_blank" rel="noopener noreferrer">TaylorSeer-Wan2.1</a>.</p><h2>TaylorSeer-HiDream</h2></p><p>El modelo de generación de imágenes recientemente abierto <strong>HiDream</strong>, a pesar de su impresionante calidad de salida, enfrenta demandas crecientes de aceleración debido a su mayor tiempo de inferencia. Aplicamos <strong>TaylorSeer</strong> para acelerar la inferencia de HiDream, logrando una <strong>reducción del 72% en el tiempo de ejecución</strong>. Para más detalles, consulte <a href="https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md" target="_blank" rel="noopener noreferrer">TaylorSeer-HiDream</a>.</p><h2>👍 Agradecimientos</h2></p><ul><li>Gracias a <a href="https://github.com/facebookresearch/DiT" target="_blank" rel="noopener noreferrer">DiT</a> por su gran trabajo y base de código sobre la cual construimos TaylorSeer-DiT.</li>
<li>Gracias a <a href="https://github.com/black-forest-labs/flux" target="_blank" rel="noopener noreferrer">FLUX</a> por su gran trabajo y base de código sobre la cual construimos TaylorSeer-FLUX.</li>
<li>Gracias a <a href="https://github.com/HiDream-ai/HiDream-I1" target="_blank" rel="noopener noreferrer">HiDream</a> por su gran trabajo y base de código sobre la cual construimos TaylorSeer-HiDream.</li>
<li>Gracias a <a href="https://github.com/Tencent/HunyuanVideo" target="_blank" rel="noopener noreferrer">HunyuanVideo</a> por su gran trabajo y base de código sobre la cual construimos TaylorSeer-HunyuanVideo.</li>
<li>Gracias a <a href="https://github.com/Wan-Video/Wan2.1" target="_blank" rel="noopener noreferrer">Wan2.1</a> por su gran trabajo y base de código sobre la cual construimos TaylorSeer-Wan2.1.</li>
<li>Gracias a <a href="https://github.com/THUDM/ImageReward" target="_blank" rel="noopener noreferrer">ImageReward</a> por la evaluación de calidad Texto-a-Imagen.</li>
<li>Gracias a <a href="https://github.com/Vchitect/VBench" target="_blank" rel="noopener noreferrer">VBench</a> por la evaluación de calidad Texto-a-Video.</li></p><p>
</ul><h2>📌 Citación</h2></p><p></code></pre>bibtex
@article{TaylorSeer2025,
  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},
  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},
  journal={arXiv preprint arXiv:2503.06923},
  year={2025}
}
</code>`<code></p><h2>:e-mail: Contacto</h2></p><p>Si tiene alguna pregunta, por favor envíe un correo electrónico a <a href="https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com" target="_blank" rel="noopener noreferrer"></code>shenyizou@outlook.com`</a>.</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-29

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>