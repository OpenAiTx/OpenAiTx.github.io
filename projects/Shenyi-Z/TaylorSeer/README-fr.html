<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TaylorSeer - [ICCV2025] De la r&#233;utilisation &#224; la pr&#233;vision : Acc&#233;l&#233;rer les mod&#232;les de diffusion avec TaylorSeers</title>
    <meta name="description" content="[ICCV2025] De la r&#233;utilisation &#224; la pr&#233;vision : Acc&#233;l&#233;rer les mod&#232;les de diffusion avec TaylorSeers">
    <meta name="keywords" content="TaylorSeer, French, documentation, GitHub, open source">
    <meta name="author" content="OpenAiTx">
    <meta name="robots" content="index, follow">
    
    <!-- Structured Data -->
    <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "SoftwareApplication",
  "name": "TaylorSeer",
  "description": "[ICCV2025] De la réutilisation à la prévision : Accélérer les modèles de diffusion avec TaylorSeers",
  "author": {
    "@type": "Person",
    "name": "Shenyi-Z"
  },
  "applicationCategory": "DeveloperApplication",
  "operatingSystem": "Any",
  "offers": {
    "@type": "Offer",
    "price": "0",
    "priceCurrency": "USD"
  },
  "aggregateRating": {
    "@type": "AggregateRating",
    "ratingValue": "5",
    "ratingCount": 241
  },
  "url": "https://OpenAiTx.github.io/projects/Shenyi-Z/TaylorSeer/README-fr.html",
  "sameAs": "https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/README.md",
  "datePublished": "2025-09-16",
  "dateModified": "2025-09-16"
}
    </script>
    
    <!-- GitHub-style CSS -->
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #ffffff;
            max-width: 980px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .container {
            background: #ffffff;
            border: 1px solid #e1e4e8;
            border-radius: 6px;
            padding: 24px;
            margin-bottom: 20px;
        }
        
        .header {
            border-bottom: 1px solid #e1e4e8;
            padding-bottom: 16px;
            margin-bottom: 24px;
        }
        
        .project-title {
            font-size: 2em;
            font-weight: 600;
            margin-bottom: 8px;
        }
        
        .project-title a {
            color: #24292e;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 8px;
            transition: color 0.2s ease;
        }
        
        .project-title a:hover {
            color: #0366d6;
            text-decoration: none;
        }
        
        .project-title .github-icon {
            width: 1em;
            height: 1em;
            fill: currentColor;
            opacity: 0.7;
            transition: opacity 0.2s ease;
        }
        
        .project-title a:hover .github-icon {
            opacity: 1;
        }
        
        .project-meta {
            color: #586069;
            font-size: 14px;
            margin-bottom: 16px;
        }
        
        .stars {
            display: inline-block;
            margin-right: 16px;
        }
        
        .language {
            display: inline-block;
            background-color: #f1f8ff;
            color: #0366d6;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 12px;
            font-weight: 500;
        }
        
        .content {
            font-size: 16px;
            line-height: 1.6;
        }
        
        h1, h2, h3, h4, h5, h6 {
            margin-top: 24px;
            margin-bottom: 16px;
            font-weight: 600;
            line-height: 1.25;
            color: #24292e;
        }
        
        h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h3 { font-size: 1.25em; }
        
        p {
            margin-bottom: 16px;
        }
        
        code {
            background-color: #f6f8fa;
            border-radius: 3px;
            font-size: 85%;
            margin: 0;
            padding: 0.2em 0.4em;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
        }
        
        pre {
            background-color: #f6f8fa;
            border-radius: 6px;
            font-size: 85%;
            line-height: 1.45;
            overflow: auto;
            padding: 16px;
            margin-bottom: 16px;
        }
        
        pre code {
            background-color: transparent;
            border: 0;
            display: inline;
            line-height: inherit;
            margin: 0;
            overflow: visible;
            padding: 0;
            word-wrap: normal;
        }
        
        a {
            color: #0366d6;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        ul, ol {
            margin-bottom: 16px;
            padding-left: 2em;
        }
        
        li {
            margin-bottom: 0.25em;
        }
        
        blockquote {
            border-left: 4px solid #dfe2e5;
            color: #6a737d;
            margin: 0 0 16px 0;
            padding: 0 1em;
        }
        
        .footer {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #e1e4e8;
            color: #586069;
            font-size: 14px;
            text-align: center;
        }
        
        .footer a {
            color: #0366d6;
        }
        
        .original-link {
            margin-top: 16px;
            padding: 12px;
            background-color: #f6f8fa;
            border-radius: 6px;
            border: 1px solid #e1e4e8;
        }
        
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .container {
                padding: 16px;
            }
            
            .project-title {
                font-size: 1.5em;
            }
        }
    </style>
    
    <!-- Prism.js for syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- Bing Count -->
    <script type="text/javascript">
        (function(c,l,a,r,i,t,y){
            c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
            t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
            y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
        })(window, document, "clarity", "script", "sh95yd6uwt");
    </script>        

    <!-- Statcounter -->
    <script type="text/javascript">
        var sc_project = 13142514;
        var sc_invisible = 1;
        var sc_security = "d03a31d8"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img
                    class="statcounter" src="https://c.statcounter.com/13142514/0/d03a31d8/1/" alt="Web Analytics"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>    
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="project-title">
                <a href="https://github.com/Shenyi-Z/TaylorSeer" target="_blank" rel="noopener noreferrer">
                    <svg class="github-icon" viewBox="0 0 16 16" aria-hidden="true">
                        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                    </svg>
                    TaylorSeer
                </a>
            </h1>
            <div class="project-meta">
                <span class="stars">⭐ 241 stars</span>
                <span class="language">French</span>
                <span>by Shenyi-Z</span>
            </div>
        </div>
        
        <div class="content">
            <p><div align=center>
  
<h1>[ICCV 2025] <em>TaylorSeer</em> : De la réutilisation à la prévision : Accélérer les modèles de diffusion avec <em>TaylorSeers</em></h1></p><p><p>
<a href='https://arxiv.org/abs/2503.06923'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>
<a href='https://taylorseer.github.io/TaylorSeer/'><img src='https://img.shields.io/badge/Project-Page-blue'></a>
</p></p><p></div></p><h2>🔥 Actualités</h2></p><ul><li><code>2025/06/26</code> 💥💥 TaylorSeer a l'honneur d'être accepté par ICCV 2025 !</li></p><p><li><code>2025/05/03</code> 🚀🚀 TaylorSeer pour HiDream est publié.</li></p><p><li><code>2025/03/30</code> 🚀🚀 TaylorSeer pour Wan2.1 est publié.</li></p><p><li><code>2025/03/30</code> 🚀🚀 Les scripts d'inférence Diffusers pour TaylorSeers et les scripts xDiT applicables à l'inférence parallèle multi-GPU ont été officiellement publiés.</li></p><p></ul><em> <code>2025/03/10</code> 🚀🚀 Notre dernier travail "De la réutilisation à la prévision : Accélérer les modèles de diffusion avec TaylorSeers" est publié ! Les codes sont disponibles sur <a href="https://github.com/Shenyi-Z/TaylorSeer" target="_blank" rel="noopener noreferrer">TaylorSeer</a> ! TaylorSeer supporte une compression sans perte à un taux de 4,99x sur FLUX.1-dev (avec une accélération de latence de 3,53x) et une accélération de haute qualité à un taux de compression de 5,00x sur HunyuanVideo (avec une accélération de latence de 4,65x) ! Nous espérons que </em>TaylorSeer* pourra faire évoluer le paradigme des méthodes de mise en cache des caractéristiques de la réutilisation à la prévision. Pour plus de détails, veuillez vous référer à notre dernier article de recherche.
<ul><li><code>2025/02/19</code> 🚀🚀 La solution ToCa pour <strong>FLUX</strong> a été officiellement publiée après ajustements, atteignant désormais jusqu'à <strong>3,14× d'accélération sans perte</strong> (en FLOPs) !</li>
<li><code>2025/01/22</code> 💥💥 ToCa a l'honneur d'être accepté par ICLR 2025 !</li>
<li><code>2024/12/29</code> 🚀🚀 Nous publions gratuitement notre travail <a href="https://arxiv.org/abs/2412.18911" target="_blank" rel="noopener noreferrer">DuCa</a> sur l'accélération des transformateurs de diffusion, qui atteint une accélération quasi sans perte de <strong>2,50×</strong> sur <a href="https://github.com/hpcaitech/Open-Sora" target="_blank" rel="noopener noreferrer">OpenSora</a> ! 🎉 <strong>DuCa surmonte également la limitation de ToCa en supportant pleinement FlashAttention, permettant une compatibilité et des améliorations d'efficacité plus larges.</strong></li>
<li><code>2024/12/24</code> 🤗🤗 Nous publions un dépôt open-source "<a href="https://github.com/xuyang-liu16/Awesome-Token-Reduction-for-Model-Compression" target="_blank" rel="noopener noreferrer">Awesome-Token-Reduction-for-Model-Compression</a>", qui rassemble les récents excellents articles sur la réduction de tokens ! N'hésitez pas à contribuer avec vos suggestions !</li>
<li><code>2024/12/10</code> 💥💥 Le travail récent de notre équipe, <strong>SiTo</strong> (https://github.com/EvelynZhang-epiclab/SiTo), a été accepté à <strong>AAAI 2025</strong>. Il accélère les modèles de diffusion grâce à la <strong>pruning adaptative des tokens</strong>.</li>
<li><code>2024/07/15</code> 🤗🤗 Nous publions un dépôt open-source "<a href="https://github.com/xuyang-liu16/Awesome-Generation-Acceleration" target="_blank" rel="noopener noreferrer">Awesome-Generation-Acceleration</a>", qui rassemble les récents excellents articles sur l'accélération de génération ! N'hésitez pas à contribuer avec vos suggestions !</li></p><p></ul><details>
  <summary><strong>Résumé</strong></summary></p><p>  Les Diffusion Transformers (DiT) ont révolutionné la synthèse d'images et de vidéos à haute fidélité, mais leurs exigences computationnelles restent prohibitives pour les applications en temps réel. Pour résoudre ce problème, la mise en cache des caractéristiques a été proposée pour accélérer les modèles de diffusion en mettant en cache les caractéristiques des pas de temps précédents puis en les réutilisant aux pas de temps suivants. Cependant, aux pas de temps avec des intervalles importants, la similarité des caractéristiques dans les modèles de diffusion diminue considérablement, entraînant une augmentation marquée des erreurs introduites par la mise en cache des caractéristiques, ce qui nuit fortement à la qualité de génération. Pour résoudre ce problème, nous proposons TaylorSeer, qui montre d'abord que les caractéristiques des modèles de diffusion aux pas de temps futurs peuvent être prédites à partir de leurs valeurs aux pas de temps précédents. Basé sur le fait que les caractéristiques changent lentement et continuellement au fil des pas de temps, TaylorSeer emploie une méthode différentielle pour approximer les dérivées d'ordre supérieur des caractéristiques et prédire les caractéristiques aux pas de temps futurs avec une expansion en série de Taylor. Des expériences approfondies démontrent son efficacité significative tant en synthèse d'images que de vidéos, particulièrement pour des taux d'accélération élevés. Par exemple, il atteint une accélération quasi sans perte de 4,99 $\times$ sur FLUX et 5,00 $\times$ sur HunyuanVideo sans entraînement supplémentaire. Sur DiT, il obtient un FID inférieur de $3,41$ comparé au précédent état de l'art à une accélération de $4,53$ $\times$.</p><p></details></p><h2>🧩 Contributions de la communauté</h2></p><p>Merci à tous les contributeurs open-source pour leur fort soutien ! Nous serions ravis d’avoir de vos nouvelles !</p><ul><li>ComfyUI-TaylorSeer-philipy1219 (inférence FP8 sur FLUX, plus de modèles vidéo à venir) : <a href="https://github.com/philipy1219/ComfyUI-TaylorSeer" target="_blank" rel="noopener noreferrer">ComfyUI-TaylorSeer-philipy1219</a> par <a href="https://github.com/philipy1219" target="_blank" rel="noopener noreferrer">philipy1219</a>.</li></p><p></ul><h2>🛠 Installation</h2></p><p>``<code> cmd
git clone https://github.com/Shenyi-Z/TaylorSeer.git
<pre><code class="language-">
<h2>TaylorSeer-FLUX</h2></p><p>TaylorSeer a réalisé une compression computationnelle sans perte de 4,99 $\times$ et une accélération de latence de 3,53 $\times$ sur FLUX.1-dev, mesurées par <a href="https://github.com/THUDM/ImageReward" target="_blank" rel="noopener noreferrer">ImageReward</a> pour une qualité globale. Pour exécuter TaylorSeer-FLUX, voir <a href="https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-FLUX.md" target="_blank" rel="noopener noreferrer">TaylorSeer-FLUX</a>.</p><p>De plus, nous avons fourni des exemples de scripts d'inférence pour la <strong>version diffusers</strong>, ainsi que des scripts d'inférence <strong>xDiT</strong> en parallèle multi-GPU. Vous pouvez également réaliser des tests basés sur ceux-ci, situés respectivement à <a href="./TaylorSeers-Diffusers " target="_blank" rel="noopener noreferrer">TaylorSeers-Diffusers</a> et <a href="./TaylorSeers-xDiT" target="_blank" rel="noopener noreferrer">TaylorSeers-xDiT</a>.</p><h2>TaylorSeer-HunyuanVideo</h2></p><p>TaylorSeer a atteint une compression computationnelle de 5,00 $\times$ et une remarquable accélération de latence de 4,65 $\times$ sur HunyuanVideo, mesurées de manière exhaustive par la métrique <a href="https://github.com/Vchitect/VBench" target="_blank" rel="noopener noreferrer">VBench</a>. Par rapport aux méthodes précédentes, il a démontré des améliorations significatives tant en efficacité d'accélération qu'en qualité. Pour exécuter TaylorSeer-HunyuanVideo, voir <a href="https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HunyuanVideo.md" target="_blank" rel="noopener noreferrer">TaylorSeer-HunyuanVideo</a>.</p><p>De plus, nos scripts prennent également en charge l'accélération parallèle multi-GPU mise en œuvre par HunyuanVideo utilisant xDiT. Dans ce cas, l'effet d'accélération apporté par le cache et celui du parallélisme multi-GPU sont indépendants l'un de l'autre et se multiplient, atteignant des effets d'accélération extrêmement élevés.</p><h2>TayorSeer-DiT</h2></p><p>TaylorSeer a réalisé une compression computationnelle sans perte de 2,77 $\times$ sur le modèle de base DiT, évaluée de manière exhaustive par des métriques telles que le FID. Ses performances à divers ratios d'accélération ont largement surpassé les méthodes précédentes. Par exemple, dans un scénario extrême avec un ratio de compression de 4,53 $\times$, le FID de TaylorSeer n'a augmenté que de 0,33 par rapport à la référence non accélérée de 2,32, atteignant 2,65, tandis que ToCa et DuCa affichaient des scores FID supérieurs à 6,0 dans les mêmes conditions. Pour exécuter TaylorSeer-DiT, voir <a href="https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-DiT.md" target="_blank" rel="noopener noreferrer">TaylorSeer-DiT</a>.</p><h2>TaylorSeer-Wan2.1</h2></p><p>Nous avons implémenté la méthode d'accélération TaylorSeer sur Wan2.1, avec prise en charge de l'inférence parallèle multi-GPU. Les commandes d'installation et d'inférence pour TaylorSeer-Wan2.1 sont entièrement compatibles avec celles de Wan2.1. Pour exécuter TaylorSeer-Wan2.1, voir <a href="https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-Wan2.1.md" target="_blank" rel="noopener noreferrer">TaylorSeer-Wan2.1</a>.</p><h2>TaylorSeer-HiDream</h2></p><p>Le modèle de génération d'images récemment open source <strong>HiDream</strong>, malgré sa qualité de sortie impressionnante, fait face à des demandes croissantes d'accélération en raison de son temps d'inférence plus long. Nous avons appliqué <strong>TaylorSeer</strong> pour accélérer l'inférence de HiDream, réalisant une <strong>réduction de 72 % du temps d'exécution</strong>. Pour plus de détails, voir <a href="https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/TaylorSeer-HiDream.md" target="_blank" rel="noopener noreferrer">TaylorSeer-HiDream</a>.</p><h2>👍 Remerciements</h2></p><ul><li>Merci à <a href="https://github.com/facebookresearch/DiT" target="_blank" rel="noopener noreferrer">DiT</a> pour leur excellent travail et leur base de code sur laquelle nous avons construit TaylorSeer-DiT.</li>
<li>Merci à <a href="https://github.com/black-forest-labs/flux" target="_blank" rel="noopener noreferrer">FLUX</a> pour leur excellent travail et leur base de code sur laquelle nous avons construit TaylorSeer-FLUX.</li>
<li>Merci à <a href="https://github.com/HiDream-ai/HiDream-I1" target="_blank" rel="noopener noreferrer">HiDream</a> pour leur excellent travail et leur base de code sur laquelle nous avons construit TaylorSeer-HiDream.</li>
<li>Merci à <a href="https://github.com/Tencent/HunyuanVideo" target="_blank" rel="noopener noreferrer">HunyuanVideo</a> pour leur excellent travail et leur base de code sur laquelle nous avons construit TaylorSeer-HunyuanVideo.</li>
<li>Merci à <a href="https://github.com/Wan-Video/Wan2.1" target="_blank" rel="noopener noreferrer">Wan2.1</a> pour leur excellent travail et leur base de code sur laquelle nous avons construit TaylorSeer-Wan2.1.</li>
<li>Merci à <a href="https://github.com/THUDM/ImageReward" target="_blank" rel="noopener noreferrer">ImageReward</a> pour l'évaluation de la qualité texte-image.</li>
<li>Merci à <a href="https://github.com/Vchitect/VBench" target="_blank" rel="noopener noreferrer">VBench</a> pour l'évaluation de la qualité texte-vidéo.</li></p><p>
</ul><h2>📌 Citation</h2></p><p></code></pre>bibtex
@article{TaylorSeer2025,
  title={From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers},
  author={Liu, Jiacheng and Zou, Chang and Lyu, Yuanhuiyi and Chen, Junjie and Zhang, Linfeng},
  journal={arXiv preprint arXiv:2503.06923},
  year={2025}
}
</code>`<code></p><h2>:e-mail: Contact</h2></p><p>Si vous avez des questions, veuillez envoyer un courriel à <a href="https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/mailto:shenyizou@outlook.com" target="_blank" rel="noopener noreferrer"></code>shenyizou@outlook.com`</a>.</p><p>

---

Tranlated By <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">Open Ai Tx</a> | Last indexed: 2025-07-29

---</p>
        </div>
        
        <div class="original-link">
            <strong>Original README:</strong> <a href="https://raw.githubusercontent.com/Shenyi-Z/TaylorSeer/main/README.md" target="_blank" rel="noopener noreferrer">View on GitHub</a>
        </div>
    </div>
    
    <div class="footer">
        <p>Translated by <a href="https://github.com/OpenAiTx/OpenAiTx" target="_blank" rel="noopener noreferrer">OpenAiTx</a> | 
        Last updated: 2025-09-16 
    </div>
    
</body>
</html>